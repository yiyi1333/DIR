Seed:  0
Epoch: 1, Loss: 1.9566, Train: 0.1429, Val: 0.1360, Test: 0.1620
Epoch: 2, Loss: 1.9450, Train: 0.1857, Val: 0.1460, Test: 0.1690
Epoch: 3, Loss: 1.9369, Train: 0.2214, Val: 0.1620, Test: 0.1780
Epoch: 4, Loss: 1.9310, Train: 0.2643, Val: 0.1660, Test: 0.1860
Epoch: 5, Loss: 1.9277, Train: 0.3143, Val: 0.1860, Test: 0.1980
Epoch: 6, Loss: 1.9148, Train: 0.3357, Val: 0.1880, Test: 0.2140
Epoch: 7, Loss: 1.9119, Train: 0.3714, Val: 0.2080, Test: 0.2230
Epoch: 8, Loss: 1.9142, Train: 0.3929, Val: 0.2180, Test: 0.2380
Epoch: 9, Loss: 1.9144, Train: 0.4071, Val: 0.2300, Test: 0.2500
Epoch: 10, Loss: 1.9001, Train: 0.4214, Val: 0.2440, Test: 0.2580
Epoch: 11, Loss: 1.8928, Train: 0.4571, Val: 0.2560, Test: 0.2710
Epoch: 12, Loss: 1.8886, Train: 0.4786, Val: 0.2700, Test: 0.2740
Epoch: 13, Loss: 1.8788, Train: 0.5000, Val: 0.2800, Test: 0.2880
Epoch: 14, Loss: 1.8645, Train: 0.5143, Val: 0.2940, Test: 0.3100
Epoch: 15, Loss: 1.8741, Train: 0.5357, Val: 0.3120, Test: 0.3240
Epoch: 16, Loss: 1.8661, Train: 0.5714, Val: 0.3260, Test: 0.3400
Epoch: 17, Loss: 1.8597, Train: 0.6000, Val: 0.3440, Test: 0.3510
Epoch: 18, Loss: 1.8434, Train: 0.6143, Val: 0.3560, Test: 0.3660
Epoch: 19, Loss: 1.8446, Train: 0.6143, Val: 0.3740, Test: 0.3720
Epoch: 20, Loss: 1.8323, Train: 0.6571, Val: 0.3900, Test: 0.3840
Epoch: 21, Loss: 1.8068, Train: 0.6714, Val: 0.4120, Test: 0.4020
Epoch: 22, Loss: 1.7971, Train: 0.7000, Val: 0.4220, Test: 0.4130
Epoch: 23, Loss: 1.8170, Train: 0.7000, Val: 0.4340, Test: 0.4240
Epoch: 24, Loss: 1.7792, Train: 0.7143, Val: 0.4500, Test: 0.4380
Epoch: 25, Loss: 1.7682, Train: 0.7143, Val: 0.4640, Test: 0.4520
Epoch: 26, Loss: 1.7562, Train: 0.7214, Val: 0.4680, Test: 0.4620
Epoch: 27, Loss: 1.7546, Train: 0.7214, Val: 0.4840, Test: 0.4710
Epoch: 28, Loss: 1.7588, Train: 0.7571, Val: 0.4920, Test: 0.4830
Epoch: 29, Loss: 1.7472, Train: 0.7786, Val: 0.5060, Test: 0.4900
Epoch: 30, Loss: 1.7480, Train: 0.7857, Val: 0.5140, Test: 0.5030
Epoch: 31, Loss: 1.7390, Train: 0.7929, Val: 0.5220, Test: 0.5190
Epoch: 32, Loss: 1.7293, Train: 0.8071, Val: 0.5220, Test: 0.5280
Epoch: 33, Loss: 1.7064, Train: 0.8143, Val: 0.5280, Test: 0.5380
Epoch: 34, Loss: 1.7129, Train: 0.8357, Val: 0.5380, Test: 0.5430
Epoch: 35, Loss: 1.6842, Train: 0.8357, Val: 0.5540, Test: 0.5500
Epoch: 36, Loss: 1.6690, Train: 0.8429, Val: 0.5680, Test: 0.5550
Epoch: 37, Loss: 1.6329, Train: 0.8571, Val: 0.5740, Test: 0.5630
Epoch: 38, Loss: 1.6475, Train: 0.8571, Val: 0.5820, Test: 0.5660
Epoch: 39, Loss: 1.6390, Train: 0.8643, Val: 0.5840, Test: 0.5740
Epoch: 40, Loss: 1.6324, Train: 0.8714, Val: 0.5880, Test: 0.5810
Epoch: 41, Loss: 1.6454, Train: 0.8714, Val: 0.5920, Test: 0.5850
Epoch: 42, Loss: 1.6738, Train: 0.8714, Val: 0.6020, Test: 0.5910
Epoch: 43, Loss: 1.6077, Train: 0.8714, Val: 0.6120, Test: 0.5980
Epoch: 44, Loss: 1.6199, Train: 0.8714, Val: 0.6180, Test: 0.6060
Epoch: 45, Loss: 1.5764, Train: 0.8714, Val: 0.6240, Test: 0.6130
Epoch: 46, Loss: 1.5508, Train: 0.8786, Val: 0.6280, Test: 0.6190
Epoch: 47, Loss: 1.5511, Train: 0.8786, Val: 0.6300, Test: 0.6230
Epoch: 48, Loss: 1.5688, Train: 0.8786, Val: 0.6400, Test: 0.6250
Epoch: 49, Loss: 1.5539, Train: 0.8786, Val: 0.6380, Test: 0.6310
Epoch: 50, Loss: 1.5742, Train: 0.8786, Val: 0.6420, Test: 0.6390
MAD:  0.5752
Best Test Accuracy: 0.6390, Val Accuracy: 0.6420, Train Accuracy: 0.8786
Training completed.
Seed:  1
Epoch: 1, Loss: 1.9587, Train: 0.1214, Val: 0.1940, Test: 0.2020
Epoch: 2, Loss: 1.9417, Train: 0.1929, Val: 0.1960, Test: 0.2180
Epoch: 3, Loss: 1.9364, Train: 0.2571, Val: 0.2020, Test: 0.2310
Epoch: 4, Loss: 1.9210, Train: 0.3071, Val: 0.2260, Test: 0.2510
Epoch: 5, Loss: 1.9106, Train: 0.3786, Val: 0.2480, Test: 0.2680
Epoch: 6, Loss: 1.9057, Train: 0.4286, Val: 0.2640, Test: 0.2830
Epoch: 7, Loss: 1.9073, Train: 0.4714, Val: 0.2900, Test: 0.3000
Epoch: 8, Loss: 1.8848, Train: 0.5214, Val: 0.3180, Test: 0.3150
Epoch: 9, Loss: 1.8837, Train: 0.5643, Val: 0.3360, Test: 0.3400
Epoch: 10, Loss: 1.8772, Train: 0.5786, Val: 0.3640, Test: 0.3610
Epoch: 11, Loss: 1.8628, Train: 0.5786, Val: 0.3760, Test: 0.3820
Epoch: 12, Loss: 1.8699, Train: 0.6143, Val: 0.3940, Test: 0.3940
Epoch: 13, Loss: 1.8500, Train: 0.6214, Val: 0.4140, Test: 0.4080
Epoch: 14, Loss: 1.8304, Train: 0.6500, Val: 0.4320, Test: 0.4280
Epoch: 15, Loss: 1.8252, Train: 0.6571, Val: 0.4380, Test: 0.4390
Epoch: 16, Loss: 1.8254, Train: 0.6714, Val: 0.4540, Test: 0.4560
Epoch: 17, Loss: 1.7981, Train: 0.6857, Val: 0.4660, Test: 0.4600
Epoch: 18, Loss: 1.8025, Train: 0.6929, Val: 0.4700, Test: 0.4700
Epoch: 19, Loss: 1.7910, Train: 0.6929, Val: 0.4800, Test: 0.4830
Epoch: 20, Loss: 1.7818, Train: 0.7000, Val: 0.4960, Test: 0.4980
Epoch: 21, Loss: 1.7899, Train: 0.7143, Val: 0.4980, Test: 0.5090
Epoch: 22, Loss: 1.7762, Train: 0.7143, Val: 0.5140, Test: 0.5200
Epoch: 23, Loss: 1.7642, Train: 0.7286, Val: 0.5200, Test: 0.5260
Epoch: 24, Loss: 1.7503, Train: 0.7357, Val: 0.5320, Test: 0.5380
Epoch: 25, Loss: 1.7307, Train: 0.7500, Val: 0.5500, Test: 0.5480
Epoch: 26, Loss: 1.7522, Train: 0.7714, Val: 0.5680, Test: 0.5570
Epoch: 27, Loss: 1.7337, Train: 0.7786, Val: 0.5780, Test: 0.5720
Epoch: 28, Loss: 1.7160, Train: 0.7857, Val: 0.5860, Test: 0.5820
Epoch: 29, Loss: 1.6692, Train: 0.8214, Val: 0.5920, Test: 0.5970
Epoch: 30, Loss: 1.7053, Train: 0.8571, Val: 0.6040, Test: 0.6060
Epoch: 31, Loss: 1.6784, Train: 0.8571, Val: 0.6060, Test: 0.6220
Epoch: 32, Loss: 1.6865, Train: 0.8571, Val: 0.6080, Test: 0.6270
Epoch: 33, Loss: 1.6703, Train: 0.8786, Val: 0.6160, Test: 0.6320
Epoch: 34, Loss: 1.6786, Train: 0.8786, Val: 0.6180, Test: 0.6380
Epoch: 35, Loss: 1.6162, Train: 0.8857, Val: 0.6220, Test: 0.6450
Epoch: 36, Loss: 1.6211, Train: 0.9071, Val: 0.6240, Test: 0.6520
Epoch: 37, Loss: 1.5789, Train: 0.9286, Val: 0.6320, Test: 0.6560
Epoch: 38, Loss: 1.6349, Train: 0.9357, Val: 0.6380, Test: 0.6620
Epoch: 39, Loss: 1.5554, Train: 0.9500, Val: 0.6400, Test: 0.6690
Epoch: 40, Loss: 1.5775, Train: 0.9571, Val: 0.6460, Test: 0.6740
Epoch: 41, Loss: 1.5886, Train: 0.9571, Val: 0.6500, Test: 0.6770
Epoch: 42, Loss: 1.5553, Train: 0.9643, Val: 0.6520, Test: 0.6800
Epoch: 43, Loss: 1.5077, Train: 0.9714, Val: 0.6480, Test: 0.6810
Epoch: 44, Loss: 1.5379, Train: 0.9714, Val: 0.6480, Test: 0.6830
Epoch: 45, Loss: 1.5406, Train: 0.9714, Val: 0.6500, Test: 0.6860
Epoch: 46, Loss: 1.4968, Train: 0.9714, Val: 0.6500, Test: 0.6890
Epoch: 47, Loss: 1.5023, Train: 0.9786, Val: 0.6480, Test: 0.6920
Epoch: 48, Loss: 1.5371, Train: 0.9786, Val: 0.6500, Test: 0.6950
Epoch: 49, Loss: 1.4352, Train: 0.9786, Val: 0.6520, Test: 0.6940
Epoch: 50, Loss: 1.4718, Train: 0.9786, Val: 0.6540, Test: 0.6940
MAD:  0.5574
Best Test Accuracy: 0.6950, Val Accuracy: 0.6500, Train Accuracy: 0.9786
Training completed.
Seed:  2
Epoch: 1, Loss: 1.9523, Train: 0.1571, Val: 0.1800, Test: 0.1910
Epoch: 2, Loss: 1.9422, Train: 0.2000, Val: 0.1980, Test: 0.2150
Epoch: 3, Loss: 1.9396, Train: 0.2500, Val: 0.2120, Test: 0.2330
Epoch: 4, Loss: 1.9307, Train: 0.2786, Val: 0.2180, Test: 0.2530
Epoch: 5, Loss: 1.9159, Train: 0.3143, Val: 0.2380, Test: 0.2730
Epoch: 6, Loss: 1.9167, Train: 0.4071, Val: 0.2580, Test: 0.2980
Epoch: 7, Loss: 1.9015, Train: 0.4500, Val: 0.2880, Test: 0.3220
Epoch: 8, Loss: 1.8888, Train: 0.4643, Val: 0.3000, Test: 0.3400
Epoch: 9, Loss: 1.8845, Train: 0.4929, Val: 0.3080, Test: 0.3550
Epoch: 10, Loss: 1.8880, Train: 0.5429, Val: 0.3200, Test: 0.3720
Epoch: 11, Loss: 1.8657, Train: 0.5714, Val: 0.3340, Test: 0.3810
Epoch: 12, Loss: 1.8601, Train: 0.5857, Val: 0.3580, Test: 0.3930
Epoch: 13, Loss: 1.8567, Train: 0.5857, Val: 0.3780, Test: 0.4100
Epoch: 14, Loss: 1.8449, Train: 0.5929, Val: 0.3880, Test: 0.4180
Epoch: 15, Loss: 1.8500, Train: 0.6000, Val: 0.3960, Test: 0.4220
Epoch: 16, Loss: 1.8344, Train: 0.6143, Val: 0.4100, Test: 0.4290
Epoch: 17, Loss: 1.8083, Train: 0.6214, Val: 0.4220, Test: 0.4370
Epoch: 18, Loss: 1.8251, Train: 0.6357, Val: 0.4380, Test: 0.4460
Epoch: 19, Loss: 1.8074, Train: 0.6643, Val: 0.4420, Test: 0.4560
Epoch: 20, Loss: 1.8025, Train: 0.6714, Val: 0.4500, Test: 0.4590
Epoch: 21, Loss: 1.8022, Train: 0.6786, Val: 0.4640, Test: 0.4630
Epoch: 22, Loss: 1.7844, Train: 0.6857, Val: 0.4760, Test: 0.4710
Epoch: 23, Loss: 1.7811, Train: 0.7071, Val: 0.4880, Test: 0.4800
Epoch: 24, Loss: 1.7650, Train: 0.7286, Val: 0.4980, Test: 0.4930
Epoch: 25, Loss: 1.7334, Train: 0.7286, Val: 0.5040, Test: 0.4960
Epoch: 26, Loss: 1.7359, Train: 0.7429, Val: 0.5080, Test: 0.5090
Epoch: 27, Loss: 1.7313, Train: 0.7643, Val: 0.5160, Test: 0.5150
Epoch: 28, Loss: 1.7157, Train: 0.7714, Val: 0.5160, Test: 0.5230
Epoch: 29, Loss: 1.6947, Train: 0.7714, Val: 0.5260, Test: 0.5230
Epoch: 30, Loss: 1.7297, Train: 0.7786, Val: 0.5260, Test: 0.5320
Epoch: 31, Loss: 1.7113, Train: 0.7857, Val: 0.5280, Test: 0.5400
Epoch: 32, Loss: 1.6645, Train: 0.7857, Val: 0.5300, Test: 0.5450
Epoch: 33, Loss: 1.6775, Train: 0.8000, Val: 0.5380, Test: 0.5570
Epoch: 34, Loss: 1.6908, Train: 0.8071, Val: 0.5380, Test: 0.5670
Epoch: 35, Loss: 1.6344, Train: 0.8071, Val: 0.5440, Test: 0.5700
Epoch: 36, Loss: 1.6858, Train: 0.8071, Val: 0.5400, Test: 0.5730
Epoch: 37, Loss: 1.6428, Train: 0.8071, Val: 0.5460, Test: 0.5770
Epoch: 38, Loss: 1.6264, Train: 0.8143, Val: 0.5500, Test: 0.5790
Epoch: 39, Loss: 1.6378, Train: 0.8214, Val: 0.5500, Test: 0.5810
Epoch: 40, Loss: 1.6657, Train: 0.8214, Val: 0.5540, Test: 0.5840
Epoch: 41, Loss: 1.6288, Train: 0.8214, Val: 0.5600, Test: 0.5860
Epoch: 42, Loss: 1.5553, Train: 0.8286, Val: 0.5640, Test: 0.5880
Epoch: 43, Loss: 1.5615, Train: 0.8286, Val: 0.5660, Test: 0.5920
Epoch: 44, Loss: 1.5750, Train: 0.8357, Val: 0.5660, Test: 0.5980
Epoch: 45, Loss: 1.5692, Train: 0.8357, Val: 0.5760, Test: 0.6000
Epoch: 46, Loss: 1.5553, Train: 0.8357, Val: 0.5780, Test: 0.6040
Epoch: 47, Loss: 1.5342, Train: 0.8429, Val: 0.5840, Test: 0.6080
Epoch: 48, Loss: 1.5556, Train: 0.8500, Val: 0.5860, Test: 0.6150
Epoch: 49, Loss: 1.5130, Train: 0.8571, Val: 0.5880, Test: 0.6170
Epoch: 50, Loss: 1.4988, Train: 0.8643, Val: 0.5940, Test: 0.6210
MAD:  0.5525
Best Test Accuracy: 0.6210, Val Accuracy: 0.5940, Train Accuracy: 0.8643
Training completed.
Seed:  3
Epoch: 1, Loss: 1.9441, Train: 0.1571, Val: 0.1460, Test: 0.1600
Epoch: 2, Loss: 1.9374, Train: 0.2071, Val: 0.1620, Test: 0.1860
Epoch: 3, Loss: 1.9359, Train: 0.2429, Val: 0.1780, Test: 0.1970
Epoch: 4, Loss: 1.9283, Train: 0.3357, Val: 0.1880, Test: 0.2160
Epoch: 5, Loss: 1.9135, Train: 0.3786, Val: 0.2140, Test: 0.2370
Epoch: 6, Loss: 1.9040, Train: 0.4286, Val: 0.2400, Test: 0.2470
Epoch: 7, Loss: 1.9015, Train: 0.4429, Val: 0.2580, Test: 0.2630
Epoch: 8, Loss: 1.8910, Train: 0.4929, Val: 0.2780, Test: 0.2760
Epoch: 9, Loss: 1.8769, Train: 0.5214, Val: 0.2920, Test: 0.2930
Epoch: 10, Loss: 1.8774, Train: 0.5357, Val: 0.3080, Test: 0.3080
Epoch: 11, Loss: 1.8729, Train: 0.5500, Val: 0.3120, Test: 0.3150
Epoch: 12, Loss: 1.8494, Train: 0.5714, Val: 0.3240, Test: 0.3290
Epoch: 13, Loss: 1.8489, Train: 0.5929, Val: 0.3400, Test: 0.3440
Epoch: 14, Loss: 1.8517, Train: 0.6286, Val: 0.3500, Test: 0.3550
Epoch: 15, Loss: 1.8404, Train: 0.6429, Val: 0.3660, Test: 0.3700
Epoch: 16, Loss: 1.8269, Train: 0.6500, Val: 0.3740, Test: 0.3810
Epoch: 17, Loss: 1.8081, Train: 0.6643, Val: 0.3800, Test: 0.4010
Epoch: 18, Loss: 1.8013, Train: 0.6714, Val: 0.4000, Test: 0.4200
Epoch: 19, Loss: 1.7990, Train: 0.6786, Val: 0.4240, Test: 0.4330
Epoch: 20, Loss: 1.7853, Train: 0.7000, Val: 0.4360, Test: 0.4470
Epoch: 21, Loss: 1.7965, Train: 0.7000, Val: 0.4500, Test: 0.4580
Epoch: 22, Loss: 1.7658, Train: 0.7071, Val: 0.4580, Test: 0.4690
Epoch: 23, Loss: 1.7749, Train: 0.7214, Val: 0.4680, Test: 0.4840
Epoch: 24, Loss: 1.7677, Train: 0.7286, Val: 0.4740, Test: 0.4980
Epoch: 25, Loss: 1.7410, Train: 0.7429, Val: 0.4820, Test: 0.5120
Epoch: 26, Loss: 1.7423, Train: 0.7571, Val: 0.4900, Test: 0.5220
Epoch: 27, Loss: 1.7005, Train: 0.7643, Val: 0.5040, Test: 0.5370
Epoch: 28, Loss: 1.7165, Train: 0.7786, Val: 0.5140, Test: 0.5480
Epoch: 29, Loss: 1.6922, Train: 0.7857, Val: 0.5180, Test: 0.5590
Epoch: 30, Loss: 1.6868, Train: 0.7929, Val: 0.5160, Test: 0.5740
Epoch: 31, Loss: 1.6623, Train: 0.8000, Val: 0.5240, Test: 0.5850
Epoch: 32, Loss: 1.6877, Train: 0.8000, Val: 0.5300, Test: 0.5900
Epoch: 33, Loss: 1.6488, Train: 0.8143, Val: 0.5380, Test: 0.5900
Epoch: 34, Loss: 1.6352, Train: 0.8214, Val: 0.5500, Test: 0.5950
Epoch: 35, Loss: 1.6768, Train: 0.8286, Val: 0.5580, Test: 0.6000
Epoch: 36, Loss: 1.6092, Train: 0.8286, Val: 0.5620, Test: 0.6030
Epoch: 37, Loss: 1.6037, Train: 0.8500, Val: 0.5660, Test: 0.6050
Epoch: 38, Loss: 1.6038, Train: 0.8571, Val: 0.5680, Test: 0.6070
Epoch: 39, Loss: 1.5953, Train: 0.8643, Val: 0.5740, Test: 0.6090
Epoch: 40, Loss: 1.5796, Train: 0.8786, Val: 0.5760, Test: 0.6140
Epoch: 41, Loss: 1.5933, Train: 0.8857, Val: 0.5860, Test: 0.6240
Epoch: 42, Loss: 1.5267, Train: 0.9071, Val: 0.5900, Test: 0.6280
Epoch: 43, Loss: 1.5575, Train: 0.9143, Val: 0.5960, Test: 0.6340
Epoch: 44, Loss: 1.5286, Train: 0.9214, Val: 0.5980, Test: 0.6410
Epoch: 45, Loss: 1.4918, Train: 0.9286, Val: 0.6020, Test: 0.6490
Epoch: 46, Loss: 1.5213, Train: 0.9286, Val: 0.6000, Test: 0.6510
Epoch: 47, Loss: 1.5266, Train: 0.9286, Val: 0.6020, Test: 0.6540
Epoch: 48, Loss: 1.5034, Train: 0.9357, Val: 0.6140, Test: 0.6600
Epoch: 49, Loss: 1.4662, Train: 0.9357, Val: 0.6180, Test: 0.6580
Epoch: 50, Loss: 1.4510, Train: 0.9429, Val: 0.6220, Test: 0.6620
MAD:  0.5542
Best Test Accuracy: 0.6620, Val Accuracy: 0.6220, Train Accuracy: 0.9429
Training completed.
Seed:  4
Epoch: 1, Loss: 1.9460, Train: 0.2000, Val: 0.1220, Test: 0.1150
Epoch: 2, Loss: 1.9414, Train: 0.2214, Val: 0.1300, Test: 0.1240
Epoch: 3, Loss: 1.9351, Train: 0.2500, Val: 0.1340, Test: 0.1350
Epoch: 4, Loss: 1.9299, Train: 0.2714, Val: 0.1480, Test: 0.1400
Epoch: 5, Loss: 1.9273, Train: 0.2929, Val: 0.1680, Test: 0.1440
Epoch: 6, Loss: 1.9229, Train: 0.3000, Val: 0.1800, Test: 0.1510
Epoch: 7, Loss: 1.9172, Train: 0.3214, Val: 0.1940, Test: 0.1640
Epoch: 8, Loss: 1.9094, Train: 0.3500, Val: 0.1980, Test: 0.1810
Epoch: 9, Loss: 1.8996, Train: 0.3571, Val: 0.2160, Test: 0.1890
Epoch: 10, Loss: 1.9025, Train: 0.3786, Val: 0.2220, Test: 0.1970
Epoch: 11, Loss: 1.8940, Train: 0.3786, Val: 0.2280, Test: 0.2050
Epoch: 12, Loss: 1.8886, Train: 0.3929, Val: 0.2440, Test: 0.2170
Epoch: 13, Loss: 1.8782, Train: 0.4357, Val: 0.2520, Test: 0.2370
Epoch: 14, Loss: 1.8748, Train: 0.4429, Val: 0.2560, Test: 0.2510
Epoch: 15, Loss: 1.8749, Train: 0.4571, Val: 0.2680, Test: 0.2610
Epoch: 16, Loss: 1.8552, Train: 0.4714, Val: 0.2880, Test: 0.2760
Epoch: 17, Loss: 1.8636, Train: 0.4929, Val: 0.2960, Test: 0.2870
Epoch: 18, Loss: 1.8477, Train: 0.5214, Val: 0.3020, Test: 0.2950
Epoch: 19, Loss: 1.8432, Train: 0.5286, Val: 0.3040, Test: 0.3000
Epoch: 20, Loss: 1.8286, Train: 0.5500, Val: 0.3140, Test: 0.3010
Epoch: 21, Loss: 1.8173, Train: 0.5571, Val: 0.3180, Test: 0.3040
Epoch: 22, Loss: 1.8345, Train: 0.5786, Val: 0.3260, Test: 0.3110
Epoch: 23, Loss: 1.8051, Train: 0.5929, Val: 0.3340, Test: 0.3210
Epoch: 24, Loss: 1.8008, Train: 0.6000, Val: 0.3520, Test: 0.3240
Epoch: 25, Loss: 1.7989, Train: 0.6000, Val: 0.3640, Test: 0.3260
Epoch: 26, Loss: 1.7849, Train: 0.5929, Val: 0.3660, Test: 0.3290
Epoch: 27, Loss: 1.7704, Train: 0.5929, Val: 0.3700, Test: 0.3350
Epoch: 28, Loss: 1.7927, Train: 0.6000, Val: 0.3760, Test: 0.3390
Epoch: 29, Loss: 1.7791, Train: 0.6143, Val: 0.3880, Test: 0.3450
Epoch: 30, Loss: 1.7658, Train: 0.6286, Val: 0.3940, Test: 0.3540
Epoch: 31, Loss: 1.7680, Train: 0.6357, Val: 0.4060, Test: 0.3650
Epoch: 32, Loss: 1.7301, Train: 0.6500, Val: 0.4140, Test: 0.3720
Epoch: 33, Loss: 1.7144, Train: 0.6571, Val: 0.4140, Test: 0.3800
Epoch: 34, Loss: 1.7114, Train: 0.6714, Val: 0.4200, Test: 0.3880
Epoch: 35, Loss: 1.7145, Train: 0.6857, Val: 0.4220, Test: 0.3910
Epoch: 36, Loss: 1.7181, Train: 0.7000, Val: 0.4200, Test: 0.3990
Epoch: 37, Loss: 1.6922, Train: 0.7214, Val: 0.4260, Test: 0.4000
Epoch: 38, Loss: 1.6910, Train: 0.7357, Val: 0.4360, Test: 0.4020
Epoch: 39, Loss: 1.6566, Train: 0.7357, Val: 0.4420, Test: 0.4120
Epoch: 40, Loss: 1.6893, Train: 0.7500, Val: 0.4480, Test: 0.4170
Epoch: 41, Loss: 1.6582, Train: 0.7500, Val: 0.4600, Test: 0.4240
Epoch: 42, Loss: 1.6397, Train: 0.7571, Val: 0.4640, Test: 0.4320
Epoch: 43, Loss: 1.6153, Train: 0.7786, Val: 0.4680, Test: 0.4390
Epoch: 44, Loss: 1.6365, Train: 0.7786, Val: 0.4760, Test: 0.4430
Epoch: 45, Loss: 1.6090, Train: 0.8000, Val: 0.4780, Test: 0.4540
Epoch: 46, Loss: 1.5922, Train: 0.8071, Val: 0.4840, Test: 0.4560
Epoch: 47, Loss: 1.6053, Train: 0.8071, Val: 0.4840, Test: 0.4620
Epoch: 48, Loss: 1.5868, Train: 0.8143, Val: 0.4900, Test: 0.4680
Epoch: 49, Loss: 1.5837, Train: 0.8214, Val: 0.5040, Test: 0.4730
Epoch: 50, Loss: 1.5636, Train: 0.8286, Val: 0.5120, Test: 0.4800
MAD:  0.6165
Best Test Accuracy: 0.4800, Val Accuracy: 0.5120, Train Accuracy: 0.8286
Training completed.
Seed:  5
Epoch: 1, Loss: 1.9444, Train: 0.2000, Val: 0.1820, Test: 0.1880
Epoch: 2, Loss: 1.9478, Train: 0.2286, Val: 0.2060, Test: 0.2170
Epoch: 3, Loss: 1.9270, Train: 0.3000, Val: 0.2240, Test: 0.2360
Epoch: 4, Loss: 1.9255, Train: 0.3357, Val: 0.2380, Test: 0.2590
Epoch: 5, Loss: 1.9172, Train: 0.3571, Val: 0.2540, Test: 0.2740
Epoch: 6, Loss: 1.9107, Train: 0.4143, Val: 0.2680, Test: 0.2870
Epoch: 7, Loss: 1.8991, Train: 0.4500, Val: 0.2840, Test: 0.3010
Epoch: 8, Loss: 1.8889, Train: 0.5143, Val: 0.3100, Test: 0.3200
Epoch: 9, Loss: 1.8780, Train: 0.5429, Val: 0.3280, Test: 0.3450
Epoch: 10, Loss: 1.8733, Train: 0.5500, Val: 0.3500, Test: 0.3630
Epoch: 11, Loss: 1.8667, Train: 0.5857, Val: 0.3660, Test: 0.3770
Epoch: 12, Loss: 1.8604, Train: 0.6000, Val: 0.3780, Test: 0.3920
Epoch: 13, Loss: 1.8467, Train: 0.6286, Val: 0.3960, Test: 0.4100
Epoch: 14, Loss: 1.8312, Train: 0.6500, Val: 0.4140, Test: 0.4240
Epoch: 15, Loss: 1.8361, Train: 0.6643, Val: 0.4320, Test: 0.4340
Epoch: 16, Loss: 1.8207, Train: 0.7000, Val: 0.4460, Test: 0.4520
Epoch: 17, Loss: 1.8035, Train: 0.7000, Val: 0.4560, Test: 0.4730
Epoch: 18, Loss: 1.7885, Train: 0.7214, Val: 0.4740, Test: 0.4890
Epoch: 19, Loss: 1.8021, Train: 0.7643, Val: 0.4840, Test: 0.4990
Epoch: 20, Loss: 1.8000, Train: 0.7714, Val: 0.4920, Test: 0.5090
Epoch: 21, Loss: 1.7942, Train: 0.7857, Val: 0.4980, Test: 0.5190
Epoch: 22, Loss: 1.7627, Train: 0.7857, Val: 0.5060, Test: 0.5310
Epoch: 23, Loss: 1.7526, Train: 0.8143, Val: 0.5200, Test: 0.5480
Epoch: 24, Loss: 1.7382, Train: 0.8357, Val: 0.5360, Test: 0.5590
Epoch: 25, Loss: 1.7200, Train: 0.8643, Val: 0.5420, Test: 0.5750
Epoch: 26, Loss: 1.7324, Train: 0.8714, Val: 0.5460, Test: 0.5810
Epoch: 27, Loss: 1.7110, Train: 0.8786, Val: 0.5460, Test: 0.5850
Epoch: 28, Loss: 1.6758, Train: 0.9000, Val: 0.5600, Test: 0.6010
Epoch: 29, Loss: 1.6809, Train: 0.9000, Val: 0.5640, Test: 0.6100
Epoch: 30, Loss: 1.6743, Train: 0.9071, Val: 0.5740, Test: 0.6210
Epoch: 31, Loss: 1.6733, Train: 0.9143, Val: 0.5860, Test: 0.6270
Epoch: 32, Loss: 1.6527, Train: 0.9286, Val: 0.5960, Test: 0.6340
Epoch: 33, Loss: 1.6053, Train: 0.9357, Val: 0.6040, Test: 0.6390
Epoch: 34, Loss: 1.6265, Train: 0.9357, Val: 0.6060, Test: 0.6440
Epoch: 35, Loss: 1.6211, Train: 0.9429, Val: 0.6140, Test: 0.6520
Epoch: 36, Loss: 1.6022, Train: 0.9500, Val: 0.6220, Test: 0.6520
Epoch: 37, Loss: 1.5949, Train: 0.9500, Val: 0.6220, Test: 0.6590
Epoch: 38, Loss: 1.6144, Train: 0.9500, Val: 0.6260, Test: 0.6640
Epoch: 39, Loss: 1.5911, Train: 0.9500, Val: 0.6280, Test: 0.6660
Epoch: 40, Loss: 1.5872, Train: 0.9500, Val: 0.6340, Test: 0.6710
Epoch: 41, Loss: 1.5568, Train: 0.9500, Val: 0.6360, Test: 0.6730
Epoch: 42, Loss: 1.5514, Train: 0.9500, Val: 0.6420, Test: 0.6710
Epoch: 43, Loss: 1.5436, Train: 0.9500, Val: 0.6460, Test: 0.6700
Epoch: 44, Loss: 1.5300, Train: 0.9643, Val: 0.6520, Test: 0.6780
Epoch: 45, Loss: 1.4924, Train: 0.9643, Val: 0.6540, Test: 0.6830
Epoch: 46, Loss: 1.4975, Train: 0.9643, Val: 0.6560, Test: 0.6840
Epoch: 47, Loss: 1.5129, Train: 0.9643, Val: 0.6580, Test: 0.6850
Epoch: 48, Loss: 1.5483, Train: 0.9643, Val: 0.6620, Test: 0.6870
Epoch: 49, Loss: 1.4860, Train: 0.9643, Val: 0.6640, Test: 0.6910
Epoch: 50, Loss: 1.4699, Train: 0.9643, Val: 0.6680, Test: 0.6930
MAD:  0.5723
Best Test Accuracy: 0.6930, Val Accuracy: 0.6680, Train Accuracy: 0.9643
Training completed.
Seed:  6
Epoch: 1, Loss: 1.9355, Train: 0.2571, Val: 0.1700, Test: 0.1830
Epoch: 2, Loss: 1.9277, Train: 0.3143, Val: 0.1860, Test: 0.2130
Epoch: 3, Loss: 1.9165, Train: 0.3571, Val: 0.1880, Test: 0.2330
Epoch: 4, Loss: 1.9088, Train: 0.3929, Val: 0.2040, Test: 0.2460
Epoch: 5, Loss: 1.8968, Train: 0.4500, Val: 0.2080, Test: 0.2660
Epoch: 6, Loss: 1.8858, Train: 0.5071, Val: 0.2400, Test: 0.2810
Epoch: 7, Loss: 1.8897, Train: 0.5571, Val: 0.2500, Test: 0.2950
Epoch: 8, Loss: 1.8636, Train: 0.5714, Val: 0.2760, Test: 0.3110
Epoch: 9, Loss: 1.8664, Train: 0.5857, Val: 0.2840, Test: 0.3240
Epoch: 10, Loss: 1.8561, Train: 0.6000, Val: 0.2960, Test: 0.3380
Epoch: 11, Loss: 1.8528, Train: 0.6143, Val: 0.3180, Test: 0.3510
Epoch: 12, Loss: 1.8354, Train: 0.6214, Val: 0.3340, Test: 0.3620
Epoch: 13, Loss: 1.8359, Train: 0.6429, Val: 0.3420, Test: 0.3690
Epoch: 14, Loss: 1.8249, Train: 0.6429, Val: 0.3540, Test: 0.3810
Epoch: 15, Loss: 1.7974, Train: 0.6500, Val: 0.3680, Test: 0.3940
Epoch: 16, Loss: 1.8170, Train: 0.6571, Val: 0.3800, Test: 0.4040
Epoch: 17, Loss: 1.7995, Train: 0.6714, Val: 0.3960, Test: 0.4170
Epoch: 18, Loss: 1.7944, Train: 0.6786, Val: 0.4060, Test: 0.4280
Epoch: 19, Loss: 1.7742, Train: 0.6857, Val: 0.4220, Test: 0.4420
Epoch: 20, Loss: 1.7711, Train: 0.7000, Val: 0.4440, Test: 0.4480
Epoch: 21, Loss: 1.7676, Train: 0.7000, Val: 0.4480, Test: 0.4540
Epoch: 22, Loss: 1.7700, Train: 0.7000, Val: 0.4580, Test: 0.4600
Epoch: 23, Loss: 1.7372, Train: 0.7071, Val: 0.4620, Test: 0.4730
Epoch: 24, Loss: 1.7486, Train: 0.7143, Val: 0.4700, Test: 0.4790
Epoch: 25, Loss: 1.7515, Train: 0.7429, Val: 0.4760, Test: 0.4880
Epoch: 26, Loss: 1.7153, Train: 0.7429, Val: 0.4780, Test: 0.5000
Epoch: 27, Loss: 1.7136, Train: 0.7429, Val: 0.4860, Test: 0.5060
Epoch: 28, Loss: 1.7006, Train: 0.7429, Val: 0.5040, Test: 0.5140
Epoch: 29, Loss: 1.7243, Train: 0.7500, Val: 0.5140, Test: 0.5220
Epoch: 30, Loss: 1.6476, Train: 0.7714, Val: 0.5260, Test: 0.5290
Epoch: 31, Loss: 1.6554, Train: 0.7857, Val: 0.5300, Test: 0.5370
Epoch: 32, Loss: 1.6474, Train: 0.8000, Val: 0.5340, Test: 0.5450
Epoch: 33, Loss: 1.6387, Train: 0.8357, Val: 0.5500, Test: 0.5520
Epoch: 34, Loss: 1.6249, Train: 0.8429, Val: 0.5620, Test: 0.5600
Epoch: 35, Loss: 1.6563, Train: 0.8500, Val: 0.5700, Test: 0.5720
Epoch: 36, Loss: 1.6264, Train: 0.8643, Val: 0.5820, Test: 0.5770
Epoch: 37, Loss: 1.6250, Train: 0.8786, Val: 0.5860, Test: 0.5820
Epoch: 38, Loss: 1.5937, Train: 0.8857, Val: 0.5880, Test: 0.5880
Epoch: 39, Loss: 1.5753, Train: 0.9000, Val: 0.5860, Test: 0.5910
Epoch: 40, Loss: 1.5588, Train: 0.9000, Val: 0.5920, Test: 0.5940
Epoch: 41, Loss: 1.6048, Train: 0.9000, Val: 0.6000, Test: 0.6010
Epoch: 42, Loss: 1.5455, Train: 0.9000, Val: 0.6040, Test: 0.6110
Epoch: 43, Loss: 1.5572, Train: 0.9071, Val: 0.6100, Test: 0.6190
Epoch: 44, Loss: 1.5215, Train: 0.9143, Val: 0.6140, Test: 0.6220
Epoch: 45, Loss: 1.4949, Train: 0.9214, Val: 0.6180, Test: 0.6280
Epoch: 46, Loss: 1.5186, Train: 0.9214, Val: 0.6180, Test: 0.6330
Epoch: 47, Loss: 1.5276, Train: 0.9286, Val: 0.6160, Test: 0.6390
Epoch: 48, Loss: 1.4858, Train: 0.9286, Val: 0.6180, Test: 0.6440
Epoch: 49, Loss: 1.4690, Train: 0.9357, Val: 0.6340, Test: 0.6500
Epoch: 50, Loss: 1.4516, Train: 0.9357, Val: 0.6340, Test: 0.6540
MAD:  0.5671
Best Test Accuracy: 0.6540, Val Accuracy: 0.6340, Train Accuracy: 0.9357
Training completed.
Seed:  7
Epoch: 1, Loss: 1.9405, Train: 0.2357, Val: 0.1820, Test: 0.1630
Epoch: 2, Loss: 1.9423, Train: 0.2571, Val: 0.2080, Test: 0.1780
Epoch: 3, Loss: 1.9226, Train: 0.3571, Val: 0.2160, Test: 0.2020
Epoch: 4, Loss: 1.9200, Train: 0.3929, Val: 0.2400, Test: 0.2210
Epoch: 5, Loss: 1.9062, Train: 0.4071, Val: 0.2660, Test: 0.2420
Epoch: 6, Loss: 1.9040, Train: 0.4357, Val: 0.2940, Test: 0.2730
Epoch: 7, Loss: 1.8897, Train: 0.4857, Val: 0.3100, Test: 0.2960
Epoch: 8, Loss: 1.8865, Train: 0.5214, Val: 0.3400, Test: 0.3170
Epoch: 9, Loss: 1.8698, Train: 0.5357, Val: 0.3540, Test: 0.3500
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
Epoch: 10, Loss: 1.8675, Train: 0.5929, Val: 0.3760, Test: 0.3710
Epoch: 11, Loss: 1.8503, Train: 0.6429, Val: 0.3940, Test: 0.3920
Epoch: 12, Loss: 1.8593, Train: 0.6429, Val: 0.4080, Test: 0.4130
Epoch: 13, Loss: 1.8227, Train: 0.6643, Val: 0.4220, Test: 0.4290
Epoch: 14, Loss: 1.8294, Train: 0.6786, Val: 0.4300, Test: 0.4450
Epoch: 15, Loss: 1.8282, Train: 0.7286, Val: 0.4460, Test: 0.4570
Epoch: 16, Loss: 1.8160, Train: 0.7357, Val: 0.4500, Test: 0.4780
Epoch: 17, Loss: 1.7968, Train: 0.7500, Val: 0.4580, Test: 0.4990
Epoch: 18, Loss: 1.7719, Train: 0.7929, Val: 0.4700, Test: 0.5140
Epoch: 19, Loss: 1.7773, Train: 0.8143, Val: 0.4840, Test: 0.5310
Epoch: 20, Loss: 1.7775, Train: 0.8357, Val: 0.4940, Test: 0.5440
Epoch: 21, Loss: 1.7786, Train: 0.8357, Val: 0.5080, Test: 0.5530
Epoch: 22, Loss: 1.7310, Train: 0.8429, Val: 0.5160, Test: 0.5660
Epoch: 23, Loss: 1.7351, Train: 0.8429, Val: 0.5220, Test: 0.5820
Epoch: 24, Loss: 1.7259, Train: 0.8571, Val: 0.5440, Test: 0.5950
Epoch: 25, Loss: 1.7076, Train: 0.8643, Val: 0.5520, Test: 0.6130
Epoch: 26, Loss: 1.6865, Train: 0.8643, Val: 0.5660, Test: 0.6190
Epoch: 27, Loss: 1.6943, Train: 0.8714, Val: 0.5800, Test: 0.6310
Epoch: 28, Loss: 1.6854, Train: 0.8786, Val: 0.5880, Test: 0.6330
Epoch: 29, Loss: 1.6798, Train: 0.8786, Val: 0.6020, Test: 0.6430
Epoch: 30, Loss: 1.6502, Train: 0.8857, Val: 0.6120, Test: 0.6520
Epoch: 31, Loss: 1.6487, Train: 0.8929, Val: 0.6220, Test: 0.6560
Epoch: 32, Loss: 1.6574, Train: 0.9143, Val: 0.6220, Test: 0.6620
Epoch: 33, Loss: 1.6294, Train: 0.9214, Val: 0.6220, Test: 0.6700
Epoch: 34, Loss: 1.6222, Train: 0.9214, Val: 0.6280, Test: 0.6780
Epoch: 35, Loss: 1.6084, Train: 0.9214, Val: 0.6300, Test: 0.6820
Epoch: 36, Loss: 1.6048, Train: 0.9214, Val: 0.6360, Test: 0.6840
Epoch: 37, Loss: 1.5827, Train: 0.9214, Val: 0.6320, Test: 0.6850
Epoch: 38, Loss: 1.5551, Train: 0.9286, Val: 0.6360, Test: 0.6850
Epoch: 39, Loss: 1.5642, Train: 0.9286, Val: 0.6440, Test: 0.6820
Epoch: 40, Loss: 1.5431, Train: 0.9357, Val: 0.6500, Test: 0.6830
Epoch: 41, Loss: 1.5724, Train: 0.9357, Val: 0.6520, Test: 0.6860
Epoch: 42, Loss: 1.5455, Train: 0.9357, Val: 0.6560, Test: 0.6920
Epoch: 43, Loss: 1.4849, Train: 0.9357, Val: 0.6620, Test: 0.6930
Epoch: 44, Loss: 1.4983, Train: 0.9429, Val: 0.6640, Test: 0.6990
Epoch: 45, Loss: 1.4619, Train: 0.9429, Val: 0.6700, Test: 0.7020
Epoch: 46, Loss: 1.4449, Train: 0.9429, Val: 0.6720, Test: 0.7050
Epoch: 47, Loss: 1.4497, Train: 0.9429, Val: 0.6740, Test: 0.7130
Epoch: 48, Loss: 1.4832, Train: 0.9500, Val: 0.6800, Test: 0.7150
Epoch: 49, Loss: 1.3895, Train: 0.9500, Val: 0.6800, Test: 0.7150
Epoch: 50, Loss: 1.4703, Train: 0.9571, Val: 0.6780, Test: 0.7180
MAD:  0.5518
Best Test Accuracy: 0.7180, Val Accuracy: 0.6780, Train Accuracy: 0.9571
Training completed.
Seed:  8
Epoch: 1, Loss: 1.9423, Train: 0.2357, Val: 0.1520, Test: 0.1320
Epoch: 2, Loss: 1.9375, Train: 0.2571, Val: 0.1660, Test: 0.1480
Epoch: 3, Loss: 1.9190, Train: 0.2929, Val: 0.1740, Test: 0.1610
Epoch: 4, Loss: 1.9204, Train: 0.3214, Val: 0.1920, Test: 0.1750
Epoch: 5, Loss: 1.9088, Train: 0.3643, Val: 0.2020, Test: 0.1940
Epoch: 6, Loss: 1.8990, Train: 0.3857, Val: 0.2000, Test: 0.2100
Epoch: 7, Loss: 1.8960, Train: 0.4214, Val: 0.2120, Test: 0.2210
Epoch: 8, Loss: 1.9005, Train: 0.4571, Val: 0.2340, Test: 0.2350
Epoch: 9, Loss: 1.8724, Train: 0.4929, Val: 0.2520, Test: 0.2500
Epoch: 10, Loss: 1.8616, Train: 0.5286, Val: 0.2660, Test: 0.2680
Epoch: 11, Loss: 1.8527, Train: 0.5357, Val: 0.2780, Test: 0.2770
Epoch: 12, Loss: 1.8504, Train: 0.5857, Val: 0.2920, Test: 0.2910
Epoch: 13, Loss: 1.8592, Train: 0.5929, Val: 0.3120, Test: 0.2980
Epoch: 14, Loss: 1.8468, Train: 0.5929, Val: 0.3180, Test: 0.3110
Epoch: 15, Loss: 1.8311, Train: 0.6214, Val: 0.3320, Test: 0.3250
Epoch: 16, Loss: 1.8148, Train: 0.6500, Val: 0.3460, Test: 0.3350
Epoch: 17, Loss: 1.8175, Train: 0.6786, Val: 0.3560, Test: 0.3480
Epoch: 18, Loss: 1.8011, Train: 0.6929, Val: 0.3720, Test: 0.3520
Epoch: 19, Loss: 1.7958, Train: 0.7000, Val: 0.3820, Test: 0.3590
Epoch: 20, Loss: 1.7694, Train: 0.7143, Val: 0.3900, Test: 0.3680
Epoch: 21, Loss: 1.7874, Train: 0.7214, Val: 0.3960, Test: 0.3800
Epoch: 22, Loss: 1.7625, Train: 0.7214, Val: 0.4040, Test: 0.3960
Epoch: 23, Loss: 1.7508, Train: 0.7286, Val: 0.4140, Test: 0.4020
Epoch: 24, Loss: 1.7669, Train: 0.7357, Val: 0.4200, Test: 0.4100
Epoch: 25, Loss: 1.7215, Train: 0.7429, Val: 0.4240, Test: 0.4210
Epoch: 26, Loss: 1.7149, Train: 0.7429, Val: 0.4380, Test: 0.4290
Epoch: 27, Loss: 1.7095, Train: 0.7429, Val: 0.4380, Test: 0.4360
Epoch: 28, Loss: 1.6864, Train: 0.7500, Val: 0.4400, Test: 0.4470
Epoch: 29, Loss: 1.6704, Train: 0.7714, Val: 0.4460, Test: 0.4490
Epoch: 30, Loss: 1.6894, Train: 0.8000, Val: 0.4500, Test: 0.4570
Epoch: 31, Loss: 1.6746, Train: 0.8214, Val: 0.4540, Test: 0.4590
Epoch: 32, Loss: 1.7076, Train: 0.8429, Val: 0.4600, Test: 0.4640
Epoch: 33, Loss: 1.6408, Train: 0.8500, Val: 0.4700, Test: 0.4700
Epoch: 34, Loss: 1.6156, Train: 0.8500, Val: 0.4840, Test: 0.4770
Epoch: 35, Loss: 1.6137, Train: 0.8571, Val: 0.4940, Test: 0.4850
Epoch: 36, Loss: 1.6087, Train: 0.8643, Val: 0.5000, Test: 0.4890
Epoch: 37, Loss: 1.6131, Train: 0.8643, Val: 0.5060, Test: 0.4950
Epoch: 38, Loss: 1.6165, Train: 0.8714, Val: 0.5060, Test: 0.5030
Epoch: 39, Loss: 1.6046, Train: 0.8714, Val: 0.5120, Test: 0.5050
Epoch: 40, Loss: 1.5491, Train: 0.8714, Val: 0.5160, Test: 0.5080
Epoch: 41, Loss: 1.5473, Train: 0.8714, Val: 0.5220, Test: 0.5120
Epoch: 42, Loss: 1.5719, Train: 0.8786, Val: 0.5220, Test: 0.5140
Epoch: 43, Loss: 1.5682, Train: 0.8786, Val: 0.5220, Test: 0.5140
Epoch: 44, Loss: 1.5389, Train: 0.8857, Val: 0.5260, Test: 0.5190
Epoch: 45, Loss: 1.5300, Train: 0.8857, Val: 0.5320, Test: 0.5200
Epoch: 46, Loss: 1.5522, Train: 0.8857, Val: 0.5340, Test: 0.5260
Epoch: 47, Loss: 1.5032, Train: 0.8857, Val: 0.5420, Test: 0.5290
Epoch: 48, Loss: 1.4889, Train: 0.8857, Val: 0.5440, Test: 0.5300
Epoch: 49, Loss: 1.4990, Train: 0.8929, Val: 0.5480, Test: 0.5320
Epoch: 50, Loss: 1.4902, Train: 0.8929, Val: 0.5520, Test: 0.5340
MAD:  0.587
Best Test Accuracy: 0.5340, Val Accuracy: 0.5520, Train Accuracy: 0.8929
Training completed.
Seed:  9
Epoch: 1, Loss: 1.9555, Train: 0.1429, Val: 0.1620, Test: 0.1610
Epoch: 2, Loss: 1.9463, Train: 0.1786, Val: 0.1800, Test: 0.1770
Epoch: 3, Loss: 1.9385, Train: 0.2071, Val: 0.2040, Test: 0.2010
Epoch: 4, Loss: 1.9305, Train: 0.2571, Val: 0.2220, Test: 0.2210
Epoch: 5, Loss: 1.9246, Train: 0.3071, Val: 0.2540, Test: 0.2420
Epoch: 6, Loss: 1.9193, Train: 0.3857, Val: 0.2780, Test: 0.2580
Epoch: 7, Loss: 1.9183, Train: 0.4429, Val: 0.2880, Test: 0.2810
Epoch: 8, Loss: 1.9054, Train: 0.4929, Val: 0.3180, Test: 0.3040
Epoch: 9, Loss: 1.8979, Train: 0.5357, Val: 0.3440, Test: 0.3170
Epoch: 10, Loss: 1.8859, Train: 0.5500, Val: 0.3580, Test: 0.3380
Epoch: 11, Loss: 1.8845, Train: 0.5571, Val: 0.3680, Test: 0.3600
Epoch: 12, Loss: 1.8858, Train: 0.5714, Val: 0.3860, Test: 0.3790
Epoch: 13, Loss: 1.8759, Train: 0.6000, Val: 0.4020, Test: 0.3990
Epoch: 14, Loss: 1.8540, Train: 0.6143, Val: 0.4260, Test: 0.4100
Epoch: 15, Loss: 1.8716, Train: 0.6286, Val: 0.4340, Test: 0.4240
Epoch: 16, Loss: 1.8597, Train: 0.6643, Val: 0.4340, Test: 0.4400
Epoch: 17, Loss: 1.8406, Train: 0.6714, Val: 0.4480, Test: 0.4480
Epoch: 18, Loss: 1.8204, Train: 0.6786, Val: 0.4540, Test: 0.4550
Epoch: 19, Loss: 1.8071, Train: 0.7000, Val: 0.4660, Test: 0.4680
Epoch: 20, Loss: 1.8053, Train: 0.7143, Val: 0.4740, Test: 0.4810
Epoch: 21, Loss: 1.8016, Train: 0.7286, Val: 0.4820, Test: 0.4870
Epoch: 22, Loss: 1.7726, Train: 0.7286, Val: 0.4860, Test: 0.4920
Epoch: 23, Loss: 1.7863, Train: 0.7286, Val: 0.4940, Test: 0.5010
Epoch: 24, Loss: 1.7715, Train: 0.7429, Val: 0.5080, Test: 0.5110
Epoch: 25, Loss: 1.7691, Train: 0.7643, Val: 0.5280, Test: 0.5220
Epoch: 26, Loss: 1.7732, Train: 0.7714, Val: 0.5320, Test: 0.5280
Epoch: 27, Loss: 1.7268, Train: 0.7786, Val: 0.5420, Test: 0.5350
Epoch: 28, Loss: 1.7371, Train: 0.7786, Val: 0.5460, Test: 0.5410
Epoch: 29, Loss: 1.7181, Train: 0.7857, Val: 0.5520, Test: 0.5490
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
Epoch: 30, Loss: 1.7153, Train: 0.8143, Val: 0.5600, Test: 0.5590
Epoch: 31, Loss: 1.6881, Train: 0.8143, Val: 0.5620, Test: 0.5660
Epoch: 32, Loss: 1.6950, Train: 0.8143, Val: 0.5720, Test: 0.5680
Epoch: 33, Loss: 1.6706, Train: 0.8214, Val: 0.5780, Test: 0.5750
Epoch: 34, Loss: 1.6627, Train: 0.8214, Val: 0.5820, Test: 0.5800
Epoch: 35, Loss: 1.6483, Train: 0.8214, Val: 0.5900, Test: 0.5900
Epoch: 36, Loss: 1.6688, Train: 0.8214, Val: 0.5940, Test: 0.5950
Epoch: 37, Loss: 1.6284, Train: 0.8214, Val: 0.5960, Test: 0.6010
Epoch: 38, Loss: 1.6484, Train: 0.8214, Val: 0.5980, Test: 0.6050
Epoch: 39, Loss: 1.6297, Train: 0.8357, Val: 0.6020, Test: 0.6100
Epoch: 40, Loss: 1.5917, Train: 0.8500, Val: 0.6020, Test: 0.6120
Epoch: 41, Loss: 1.5978, Train: 0.8500, Val: 0.6080, Test: 0.6160
Epoch: 42, Loss: 1.5992, Train: 0.8500, Val: 0.6120, Test: 0.6190
Epoch: 43, Loss: 1.5474, Train: 0.8500, Val: 0.6120, Test: 0.6180
Epoch: 44, Loss: 1.5987, Train: 0.8500, Val: 0.6160, Test: 0.6190
Epoch: 45, Loss: 1.5540, Train: 0.8500, Val: 0.6160, Test: 0.6200
Epoch: 46, Loss: 1.5059, Train: 0.8500, Val: 0.6160, Test: 0.6230
Epoch: 47, Loss: 1.5498, Train: 0.8500, Val: 0.6180, Test: 0.6240
Epoch: 48, Loss: 1.4988, Train: 0.8500, Val: 0.6200, Test: 0.6250
Epoch: 49, Loss: 1.5261, Train: 0.8500, Val: 0.6200, Test: 0.6260
Epoch: 50, Loss: 1.4991, Train: 0.8571, Val: 0.6220, Test: 0.6270
MAD:  0.5705
Best Test Accuracy: 0.6270, Val Accuracy: 0.6220, Train Accuracy: 0.8571
Training completed.
Average Test Accuracy:  0.6323 ± 0.0702652830350807
Average MAD:  0.57045 ± 0.018804534027728536
