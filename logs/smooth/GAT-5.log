Seed:  0
Epoch: 1, Loss: 1.9447, Train: 0.2000, Val: 0.1540, Test: 0.1570
Epoch: 2, Loss: 1.9421, Train: 0.2429, Val: 0.2020, Test: 0.1890
Epoch: 3, Loss: 1.9373, Train: 0.3643, Val: 0.2620, Test: 0.2600
Epoch: 4, Loss: 1.9327, Train: 0.4000, Val: 0.2900, Test: 0.3000
Epoch: 5, Loss: 1.9316, Train: 0.4857, Val: 0.3000, Test: 0.3290
Epoch: 6, Loss: 1.9269, Train: 0.5143, Val: 0.3640, Test: 0.3620
Epoch: 7, Loss: 1.9243, Train: 0.5143, Val: 0.3860, Test: 0.3850
Epoch: 8, Loss: 1.9157, Train: 0.5429, Val: 0.4120, Test: 0.4060
Epoch: 9, Loss: 1.9052, Train: 0.5571, Val: 0.4260, Test: 0.4160
Epoch: 10, Loss: 1.9003, Train: 0.5714, Val: 0.4320, Test: 0.4180
Epoch: 11, Loss: 1.8719, Train: 0.5643, Val: 0.4240, Test: 0.4120
Epoch: 12, Loss: 1.8747, Train: 0.5643, Val: 0.4220, Test: 0.4120
Epoch: 13, Loss: 1.8545, Train: 0.5857, Val: 0.4380, Test: 0.4160
Epoch: 14, Loss: 1.8677, Train: 0.6071, Val: 0.4520, Test: 0.4300
Epoch: 15, Loss: 1.8328, Train: 0.6143, Val: 0.4640, Test: 0.4590
Epoch: 16, Loss: 1.8086, Train: 0.6214, Val: 0.4780, Test: 0.4680
Epoch: 17, Loss: 1.7793, Train: 0.6429, Val: 0.4820, Test: 0.4700
Epoch: 18, Loss: 1.7412, Train: 0.6429, Val: 0.4900, Test: 0.4750
Epoch: 19, Loss: 1.7461, Train: 0.6500, Val: 0.4900, Test: 0.4760
Epoch: 20, Loss: 1.6855, Train: 0.6500, Val: 0.4960, Test: 0.4790
Epoch: 21, Loss: 1.6970, Train: 0.6500, Val: 0.5060, Test: 0.4820
Epoch: 22, Loss: 1.6131, Train: 0.6500, Val: 0.5040, Test: 0.4850
Epoch: 23, Loss: 1.6602, Train: 0.6571, Val: 0.5080, Test: 0.4840
Epoch: 24, Loss: 1.5393, Train: 0.6643, Val: 0.5120, Test: 0.4930
Epoch: 25, Loss: 1.5149, Train: 0.6714, Val: 0.5200, Test: 0.4980
Epoch: 26, Loss: 1.4069, Train: 0.6786, Val: 0.5260, Test: 0.5060
Epoch: 27, Loss: 1.4287, Train: 0.6786, Val: 0.5300, Test: 0.5060
Epoch: 28, Loss: 1.3688, Train: 0.6786, Val: 0.5320, Test: 0.5090
Epoch: 29, Loss: 1.4231, Train: 0.6857, Val: 0.5320, Test: 0.5050
Epoch: 30, Loss: 1.2621, Train: 0.6857, Val: 0.5280, Test: 0.4990
Epoch: 31, Loss: 1.2786, Train: 0.6857, Val: 0.5300, Test: 0.5010
Epoch: 32, Loss: 1.2071, Train: 0.6786, Val: 0.5300, Test: 0.5110
Epoch: 33, Loss: 1.2853, Train: 0.6857, Val: 0.5240, Test: 0.5060
Epoch: 34, Loss: 1.1642, Train: 0.6857, Val: 0.5280, Test: 0.5020
Epoch: 35, Loss: 1.3562, Train: 0.6857, Val: 0.5260, Test: 0.5010
Epoch: 36, Loss: 1.2069, Train: 0.6929, Val: 0.5340, Test: 0.5070
Epoch: 37, Loss: 1.1634, Train: 0.6786, Val: 0.5300, Test: 0.5020
Epoch: 38, Loss: 1.2520, Train: 0.6786, Val: 0.5300, Test: 0.5010
Epoch: 39, Loss: 1.2141, Train: 0.6857, Val: 0.5280, Test: 0.5030
Epoch: 40, Loss: 1.0890, Train: 0.6929, Val: 0.5300, Test: 0.5040
Epoch: 41, Loss: 1.0905, Train: 0.6857, Val: 0.5280, Test: 0.5020
Epoch: 42, Loss: 1.1466, Train: 0.6857, Val: 0.5280, Test: 0.5020
Epoch: 43, Loss: 1.1776, Train: 0.6857, Val: 0.5300, Test: 0.4990
Epoch: 44, Loss: 1.1308, Train: 0.6929, Val: 0.5360, Test: 0.5020
Epoch: 45, Loss: 0.9957, Train: 0.6929, Val: 0.5360, Test: 0.5050
Epoch: 46, Loss: 1.1039, Train: 0.6929, Val: 0.5340, Test: 0.5060
Epoch: 47, Loss: 1.0538, Train: 0.6929, Val: 0.5320, Test: 0.5070
Epoch: 48, Loss: 1.0537, Train: 0.6929, Val: 0.5320, Test: 0.5020
Epoch: 49, Loss: 1.0549, Train: 0.6929, Val: 0.5360, Test: 0.5070
Epoch: 50, Loss: 1.0654, Train: 0.6929, Val: 0.5340, Test: 0.5040
MAD:  0.5575
Best Test Accuracy: 0.5110, Val Accuracy: 0.5300, Train Accuracy: 0.6786
Training completed.
Seed:  1
Epoch: 1, Loss: 1.9447, Train: 0.1571, Val: 0.2360, Test: 0.2210
Epoch: 2, Loss: 1.9454, Train: 0.2286, Val: 0.2340, Test: 0.2340
Epoch: 3, Loss: 1.9408, Train: 0.3286, Val: 0.2640, Test: 0.2940
Epoch: 4, Loss: 1.9350, Train: 0.4071, Val: 0.2780, Test: 0.3130
Epoch: 5, Loss: 1.9337, Train: 0.4714, Val: 0.3180, Test: 0.3850
Epoch: 6, Loss: 1.9286, Train: 0.4929, Val: 0.3740, Test: 0.4180
Epoch: 7, Loss: 1.9244, Train: 0.5143, Val: 0.3900, Test: 0.4400
Epoch: 8, Loss: 1.9221, Train: 0.5357, Val: 0.4160, Test: 0.4550
Epoch: 9, Loss: 1.9176, Train: 0.5571, Val: 0.3940, Test: 0.4540
Epoch: 10, Loss: 1.9004, Train: 0.5429, Val: 0.3900, Test: 0.4480
Epoch: 11, Loss: 1.8805, Train: 0.5571, Val: 0.3820, Test: 0.4360
Epoch: 12, Loss: 1.8860, Train: 0.5571, Val: 0.3720, Test: 0.4160
Epoch: 13, Loss: 1.8712, Train: 0.5500, Val: 0.3700, Test: 0.4060
Epoch: 14, Loss: 1.8458, Train: 0.5500, Val: 0.3720, Test: 0.4120
Epoch: 15, Loss: 1.8443, Train: 0.5429, Val: 0.3740, Test: 0.4220
Epoch: 16, Loss: 1.8237, Train: 0.5357, Val: 0.3880, Test: 0.4340
Epoch: 17, Loss: 1.8207, Train: 0.5643, Val: 0.4080, Test: 0.4500
Epoch: 18, Loss: 1.8097, Train: 0.5786, Val: 0.4300, Test: 0.4750
Epoch: 19, Loss: 1.7666, Train: 0.5786, Val: 0.4480, Test: 0.4790
Epoch: 20, Loss: 1.7503, Train: 0.5786, Val: 0.4540, Test: 0.4800
Epoch: 21, Loss: 1.6627, Train: 0.5786, Val: 0.4520, Test: 0.4750
Epoch: 22, Loss: 1.7025, Train: 0.5786, Val: 0.4600, Test: 0.4950
Epoch: 23, Loss: 1.5983, Train: 0.5857, Val: 0.4720, Test: 0.5070
Epoch: 24, Loss: 1.5864, Train: 0.6071, Val: 0.4840, Test: 0.5180
Epoch: 25, Loss: 1.6074, Train: 0.6214, Val: 0.5080, Test: 0.5330
Epoch: 26, Loss: 1.5377, Train: 0.6286, Val: 0.5180, Test: 0.5410
Epoch: 27, Loss: 1.4653, Train: 0.6286, Val: 0.5100, Test: 0.5400
Epoch: 28, Loss: 1.4584, Train: 0.6429, Val: 0.5200, Test: 0.5440
Epoch: 29, Loss: 1.4946, Train: 0.6714, Val: 0.5700, Test: 0.5800
Epoch: 30, Loss: 1.4451, Train: 0.6857, Val: 0.5880, Test: 0.5950
Epoch: 31, Loss: 1.3791, Train: 0.6857, Val: 0.5960, Test: 0.6010
Epoch: 32, Loss: 1.3461, Train: 0.6929, Val: 0.6080, Test: 0.6120
Epoch: 33, Loss: 1.3160, Train: 0.7214, Val: 0.6260, Test: 0.6340
Epoch: 34, Loss: 1.3342, Train: 0.7571, Val: 0.6480, Test: 0.6520
Epoch: 35, Loss: 1.2790, Train: 0.7643, Val: 0.6540, Test: 0.6660
Epoch: 36, Loss: 1.2237, Train: 0.7714, Val: 0.6540, Test: 0.6750
Epoch: 37, Loss: 1.1716, Train: 0.7786, Val: 0.6420, Test: 0.6750
Epoch: 38, Loss: 1.1432, Train: 0.8071, Val: 0.6480, Test: 0.6750
Epoch: 39, Loss: 1.1667, Train: 0.8071, Val: 0.6560, Test: 0.6870
Epoch: 40, Loss: 1.1402, Train: 0.8071, Val: 0.6680, Test: 0.6940
Epoch: 41, Loss: 1.1115, Train: 0.8143, Val: 0.6760, Test: 0.6870
Epoch: 42, Loss: 1.0475, Train: 0.7929, Val: 0.6840, Test: 0.6980
Epoch: 43, Loss: 1.0760, Train: 0.7929, Val: 0.7000, Test: 0.7080
Epoch: 44, Loss: 1.0219, Train: 0.8143, Val: 0.6860, Test: 0.7090
Epoch: 45, Loss: 1.1176, Train: 0.8286, Val: 0.6880, Test: 0.7060
Epoch: 46, Loss: 1.0074, Train: 0.8357, Val: 0.6940, Test: 0.7000
Epoch: 47, Loss: 0.9799, Train: 0.8500, Val: 0.6900, Test: 0.7040
Epoch: 48, Loss: 1.0245, Train: 0.8429, Val: 0.6920, Test: 0.7040
Epoch: 49, Loss: 1.0378, Train: 0.8429, Val: 0.6980, Test: 0.7060
Epoch: 50, Loss: 0.9532, Train: 0.8500, Val: 0.6960, Test: 0.7190
MAD:  0.7159
Best Test Accuracy: 0.7190, Val Accuracy: 0.6960, Train Accuracy: 0.8500
Training completed.
Seed:  2
Epoch: 1, Loss: 1.9483, Train: 0.2714, Val: 0.2500, Test: 0.2310
Epoch: 2, Loss: 1.9438, Train: 0.2500, Val: 0.2040, Test: 0.2090
Epoch: 3, Loss: 1.9409, Train: 0.3286, Val: 0.2600, Test: 0.2630
Epoch: 4, Loss: 1.9379, Train: 0.4071, Val: 0.3140, Test: 0.3250
Epoch: 5, Loss: 1.9350, Train: 0.4643, Val: 0.3860, Test: 0.3790
Epoch: 6, Loss: 1.9356, Train: 0.5143, Val: 0.4280, Test: 0.4040
Epoch: 7, Loss: 1.9223, Train: 0.5286, Val: 0.4320, Test: 0.4140
Epoch: 8, Loss: 1.9191, Train: 0.5357, Val: 0.4500, Test: 0.4290
Epoch: 9, Loss: 1.9102, Train: 0.5357, Val: 0.4620, Test: 0.4360
Epoch: 10, Loss: 1.8999, Train: 0.5643, Val: 0.4760, Test: 0.4560
Epoch: 11, Loss: 1.9010, Train: 0.6071, Val: 0.5020, Test: 0.4810
Epoch: 12, Loss: 1.8780, Train: 0.6286, Val: 0.5280, Test: 0.5010
Epoch: 13, Loss: 1.8747, Train: 0.6214, Val: 0.5340, Test: 0.5050
Epoch: 14, Loss: 1.8608, Train: 0.6214, Val: 0.5260, Test: 0.5040
Epoch: 15, Loss: 1.8273, Train: 0.6643, Val: 0.5180, Test: 0.5010
Epoch: 16, Loss: 1.8116, Train: 0.6500, Val: 0.5200, Test: 0.4950
Epoch: 17, Loss: 1.7913, Train: 0.6500, Val: 0.5300, Test: 0.4950
Epoch: 18, Loss: 1.7917, Train: 0.6500, Val: 0.5300, Test: 0.4930
Epoch: 19, Loss: 1.7027, Train: 0.6500, Val: 0.5320, Test: 0.4970
Epoch: 20, Loss: 1.6487, Train: 0.6643, Val: 0.5300, Test: 0.5020
Epoch: 21, Loss: 1.6639, Train: 0.6643, Val: 0.5260, Test: 0.5040
Epoch: 22, Loss: 1.6251, Train: 0.6571, Val: 0.5260, Test: 0.5080
Epoch: 23, Loss: 1.5931, Train: 0.6714, Val: 0.5260, Test: 0.5150
Epoch: 24, Loss: 1.6066, Train: 0.7000, Val: 0.5400, Test: 0.5260
Epoch: 25, Loss: 1.5769, Train: 0.7214, Val: 0.5520, Test: 0.5360
Epoch: 26, Loss: 1.4360, Train: 0.7429, Val: 0.5560, Test: 0.5510
Epoch: 27, Loss: 1.3957, Train: 0.7643, Val: 0.5780, Test: 0.5720
Epoch: 28, Loss: 1.3409, Train: 0.7786, Val: 0.5980, Test: 0.5900
Epoch: 29, Loss: 1.3235, Train: 0.7857, Val: 0.6340, Test: 0.6090
Epoch: 30, Loss: 1.1995, Train: 0.8071, Val: 0.6460, Test: 0.6350
Epoch: 31, Loss: 1.3577, Train: 0.8214, Val: 0.6820, Test: 0.6580
Epoch: 32, Loss: 1.2479, Train: 0.8714, Val: 0.7000, Test: 0.6830
Epoch: 33, Loss: 1.1970, Train: 0.8857, Val: 0.7180, Test: 0.7110
Epoch: 34, Loss: 1.1578, Train: 0.9071, Val: 0.7420, Test: 0.7340
Epoch: 35, Loss: 1.0289, Train: 0.9071, Val: 0.7580, Test: 0.7460
Epoch: 36, Loss: 0.9220, Train: 0.9214, Val: 0.7700, Test: 0.7500
Epoch: 37, Loss: 1.0180, Train: 0.9357, Val: 0.7640, Test: 0.7440
Epoch: 38, Loss: 1.1193, Train: 0.9429, Val: 0.7720, Test: 0.7450
Epoch: 39, Loss: 1.0611, Train: 0.9500, Val: 0.7700, Test: 0.7450
Epoch: 40, Loss: 1.1215, Train: 0.9714, Val: 0.7620, Test: 0.7470
Epoch: 41, Loss: 1.0294, Train: 0.9643, Val: 0.7660, Test: 0.7540
Epoch: 42, Loss: 1.0018, Train: 0.9571, Val: 0.7900, Test: 0.7700
Epoch: 43, Loss: 0.9721, Train: 0.9571, Val: 0.7880, Test: 0.7720
Epoch: 44, Loss: 0.9903, Train: 0.9571, Val: 0.7920, Test: 0.7760
Epoch: 45, Loss: 0.8748, Train: 0.9571, Val: 0.7920, Test: 0.7790
Epoch: 46, Loss: 0.8864, Train: 0.9714, Val: 0.7900, Test: 0.7780
Epoch: 47, Loss: 0.8002, Train: 0.9714, Val: 0.7920, Test: 0.7870
Epoch: 48, Loss: 0.8514, Train: 0.9714, Val: 0.7900, Test: 0.7830
Epoch: 49, Loss: 0.7424, Train: 0.9714, Val: 0.7820, Test: 0.7820
Epoch: 50, Loss: 0.7496, Train: 0.9786, Val: 0.7680, Test: 0.7800
MAD:  0.7197
Best Test Accuracy: 0.7870, Val Accuracy: 0.7920, Train Accuracy: 0.9714
Training completed.
Seed:  3
Epoch: 1, Loss: 1.9451, Train: 0.1429, Val: 0.3160, Test: 0.3160
Epoch: 2, Loss: 1.9454, Train: 0.1500, Val: 0.3180, Test: 0.3200
Epoch: 3, Loss: 1.9412, Train: 0.1643, Val: 0.3280, Test: 0.3280
Epoch: 4, Loss: 1.9412, Train: 0.2714, Val: 0.3820, Test: 0.3730
Epoch: 5, Loss: 1.9382, Train: 0.3071, Val: 0.3980, Test: 0.3970
Epoch: 6, Loss: 1.9343, Train: 0.3286, Val: 0.4240, Test: 0.4220
Epoch: 7, Loss: 1.9333, Train: 0.3500, Val: 0.4220, Test: 0.4240
Epoch: 8, Loss: 1.9313, Train: 0.3500, Val: 0.4300, Test: 0.4310
Epoch: 9, Loss: 1.9279, Train: 0.3571, Val: 0.4380, Test: 0.4410
Epoch: 10, Loss: 1.9267, Train: 0.4143, Val: 0.4720, Test: 0.4620
Epoch: 11, Loss: 1.9166, Train: 0.4571, Val: 0.4880, Test: 0.4820
Epoch: 12, Loss: 1.9041, Train: 0.4929, Val: 0.5160, Test: 0.5180
Epoch: 13, Loss: 1.9015, Train: 0.5000, Val: 0.5360, Test: 0.5420
Epoch: 14, Loss: 1.8898, Train: 0.5357, Val: 0.5360, Test: 0.5500
Epoch: 15, Loss: 1.8931, Train: 0.5429, Val: 0.5500, Test: 0.5520
Epoch: 16, Loss: 1.8714, Train: 0.5500, Val: 0.5580, Test: 0.5570
Epoch: 17, Loss: 1.8585, Train: 0.5500, Val: 0.5600, Test: 0.5600
Epoch: 18, Loss: 1.8527, Train: 0.5643, Val: 0.5660, Test: 0.5670
Epoch: 19, Loss: 1.8463, Train: 0.5929, Val: 0.5880, Test: 0.5680
Epoch: 20, Loss: 1.7986, Train: 0.6000, Val: 0.5900, Test: 0.5820
Epoch: 21, Loss: 1.7730, Train: 0.6071, Val: 0.5980, Test: 0.5880
Epoch: 22, Loss: 1.7236, Train: 0.6071, Val: 0.5940, Test: 0.5810
Epoch: 23, Loss: 1.7122, Train: 0.6071, Val: 0.5820, Test: 0.5740
Epoch: 24, Loss: 1.6742, Train: 0.6000, Val: 0.5840, Test: 0.5770
Epoch: 25, Loss: 1.6552, Train: 0.6500, Val: 0.6060, Test: 0.6060
Epoch: 26, Loss: 1.6422, Train: 0.6786, Val: 0.6320, Test: 0.6330
Epoch: 27, Loss: 1.5905, Train: 0.7143, Val: 0.6420, Test: 0.6470
Epoch: 28, Loss: 1.6216, Train: 0.7286, Val: 0.6380, Test: 0.6580
Epoch: 29, Loss: 1.4913, Train: 0.7429, Val: 0.6320, Test: 0.6490
Epoch: 30, Loss: 1.4933, Train: 0.7643, Val: 0.6300, Test: 0.6500
Epoch: 31, Loss: 1.3632, Train: 0.7643, Val: 0.6140, Test: 0.6440
Epoch: 32, Loss: 1.3896, Train: 0.7643, Val: 0.6080, Test: 0.6380
Epoch: 33, Loss: 1.2338, Train: 0.7643, Val: 0.6120, Test: 0.6430
Epoch: 34, Loss: 1.1918, Train: 0.7643, Val: 0.6060, Test: 0.6330
Epoch: 35, Loss: 1.2840, Train: 0.7643, Val: 0.5880, Test: 0.6130
Epoch: 36, Loss: 1.3761, Train: 0.7643, Val: 0.5800, Test: 0.6110
Epoch: 37, Loss: 1.1553, Train: 0.7714, Val: 0.6020, Test: 0.6300
Epoch: 38, Loss: 1.1141, Train: 0.7929, Val: 0.6160, Test: 0.6460
Epoch: 39, Loss: 1.1179, Train: 0.7857, Val: 0.6380, Test: 0.6600
Epoch: 40, Loss: 1.1705, Train: 0.7929, Val: 0.6500, Test: 0.6730
Epoch: 41, Loss: 1.0099, Train: 0.8071, Val: 0.6700, Test: 0.6870
Epoch: 42, Loss: 1.1420, Train: 0.8071, Val: 0.6680, Test: 0.6810
Epoch: 43, Loss: 1.1579, Train: 0.8143, Val: 0.6540, Test: 0.6730
Epoch: 44, Loss: 1.0997, Train: 0.8071, Val: 0.6520, Test: 0.6680
Epoch: 45, Loss: 1.0786, Train: 0.8214, Val: 0.6460, Test: 0.6650
Epoch: 46, Loss: 1.0077, Train: 0.8214, Val: 0.6540, Test: 0.6720
Epoch: 47, Loss: 1.0059, Train: 0.8500, Val: 0.6600, Test: 0.6810
Epoch: 48, Loss: 1.1113, Train: 0.8500, Val: 0.6560, Test: 0.6840
Epoch: 49, Loss: 1.0370, Train: 0.8500, Val: 0.6460, Test: 0.6750
Epoch: 50, Loss: 1.0106, Train: 0.8429, Val: 0.6340, Test: 0.6690
MAD:  0.5183
Best Test Accuracy: 0.6870, Val Accuracy: 0.6700, Train Accuracy: 0.8071
Training completed.
Seed:  4
Epoch: 1, Loss: 1.9455, Train: 0.1500, Val: 0.0620, Test: 0.0740
Epoch: 2, Loss: 1.9452, Train: 0.1500, Val: 0.0660, Test: 0.0780
Epoch: 3, Loss: 1.9423, Train: 0.2286, Val: 0.1320, Test: 0.1440
Epoch: 4, Loss: 1.9416, Train: 0.2857, Val: 0.2040, Test: 0.1970
Epoch: 5, Loss: 1.9393, Train: 0.2857, Val: 0.2060, Test: 0.1990
Epoch: 6, Loss: 1.9384, Train: 0.2857, Val: 0.2100, Test: 0.2020
Epoch: 7, Loss: 1.9357, Train: 0.2857, Val: 0.2100, Test: 0.2030
Epoch: 8, Loss: 1.9307, Train: 0.2857, Val: 0.2100, Test: 0.2030
Epoch: 9, Loss: 1.9283, Train: 0.2857, Val: 0.2100, Test: 0.2030
Epoch: 10, Loss: 1.9269, Train: 0.2857, Val: 0.2100, Test: 0.2050
Epoch: 11, Loss: 1.9216, Train: 0.2857, Val: 0.2120, Test: 0.2060
Epoch: 12, Loss: 1.9096, Train: 0.2857, Val: 0.2120, Test: 0.2050
Epoch: 13, Loss: 1.9132, Train: 0.2857, Val: 0.2100, Test: 0.2050
Epoch: 14, Loss: 1.8926, Train: 0.2857, Val: 0.2100, Test: 0.2060
Epoch: 15, Loss: 1.8819, Train: 0.2857, Val: 0.2100, Test: 0.2060
Epoch: 16, Loss: 1.8801, Train: 0.2857, Val: 0.2100, Test: 0.2060
Epoch: 17, Loss: 1.8714, Train: 0.2857, Val: 0.2120, Test: 0.2060
Epoch: 18, Loss: 1.8514, Train: 0.2857, Val: 0.2120, Test: 0.2060
Epoch: 19, Loss: 1.8221, Train: 0.2857, Val: 0.2120, Test: 0.2060
Epoch: 20, Loss: 1.8364, Train: 0.2857, Val: 0.2120, Test: 0.2060
Epoch: 21, Loss: 1.7738, Train: 0.2857, Val: 0.2120, Test: 0.2060
Epoch: 22, Loss: 1.8030, Train: 0.2857, Val: 0.2120, Test: 0.2060
Epoch: 23, Loss: 1.7979, Train: 0.3000, Val: 0.2240, Test: 0.2190
Epoch: 24, Loss: 1.7359, Train: 0.3214, Val: 0.2380, Test: 0.2360
Epoch: 25, Loss: 1.7280, Train: 0.3286, Val: 0.2600, Test: 0.2590
Epoch: 26, Loss: 1.6986, Train: 0.3500, Val: 0.2820, Test: 0.2800
Epoch: 27, Loss: 1.6786, Train: 0.3643, Val: 0.3160, Test: 0.3040
Epoch: 28, Loss: 1.6404, Train: 0.3714, Val: 0.3400, Test: 0.3260
Epoch: 29, Loss: 1.5750, Train: 0.3857, Val: 0.3680, Test: 0.3430
Epoch: 30, Loss: 1.5640, Train: 0.3857, Val: 0.4140, Test: 0.3730
Epoch: 31, Loss: 1.5872, Train: 0.3857, Val: 0.4300, Test: 0.3940
Epoch: 32, Loss: 1.6185, Train: 0.3929, Val: 0.4480, Test: 0.4150
Epoch: 33, Loss: 1.5240, Train: 0.3857, Val: 0.4540, Test: 0.4340
Epoch: 34, Loss: 1.5673, Train: 0.4071, Val: 0.4580, Test: 0.4540
Epoch: 35, Loss: 1.5965, Train: 0.4071, Val: 0.4740, Test: 0.4750
Epoch: 36, Loss: 1.5951, Train: 0.4143, Val: 0.4900, Test: 0.4830
Epoch: 37, Loss: 1.5991, Train: 0.4214, Val: 0.5000, Test: 0.4890
Epoch: 38, Loss: 1.5677, Train: 0.4214, Val: 0.5080, Test: 0.4900
Epoch: 39, Loss: 1.5691, Train: 0.4286, Val: 0.5060, Test: 0.4900
Epoch: 40, Loss: 1.5197, Train: 0.4286, Val: 0.5000, Test: 0.4880
Epoch: 41, Loss: 1.5103, Train: 0.4286, Val: 0.4920, Test: 0.4850
Epoch: 42, Loss: 1.4762, Train: 0.4286, Val: 0.4820, Test: 0.4840
Epoch: 43, Loss: 1.5126, Train: 0.4286, Val: 0.4800, Test: 0.4790
Epoch: 44, Loss: 1.4825, Train: 0.4357, Val: 0.4660, Test: 0.4770
Epoch: 45, Loss: 1.5855, Train: 0.4357, Val: 0.4620, Test: 0.4700
Epoch: 46, Loss: 1.5206, Train: 0.4357, Val: 0.4680, Test: 0.4740
Epoch: 47, Loss: 1.5103, Train: 0.4357, Val: 0.4760, Test: 0.4750
Epoch: 48, Loss: 1.4294, Train: 0.4429, Val: 0.4800, Test: 0.4840
Epoch: 49, Loss: 1.4609, Train: 0.4571, Val: 0.4900, Test: 0.4920
Epoch: 50, Loss: 1.4821, Train: 0.4571, Val: 0.4960, Test: 0.5050
MAD:  0.6993
Best Test Accuracy: 0.5050, Val Accuracy: 0.4960, Train Accuracy: 0.4571
Training completed.
Seed:  5
Epoch: 1, Loss: 1.9451, Train: 0.1500, Val: 0.1220, Test: 0.1350
Epoch: 2, Loss: 1.9434, Train: 0.1571, Val: 0.1220, Test: 0.1330
Epoch: 3, Loss: 1.9394, Train: 0.1857, Val: 0.1220, Test: 0.1380
Epoch: 4, Loss: 1.9409, Train: 0.2071, Val: 0.1220, Test: 0.1420
Epoch: 5, Loss: 1.9387, Train: 0.2214, Val: 0.1220, Test: 0.1500
Epoch: 6, Loss: 1.9313, Train: 0.2357, Val: 0.1240, Test: 0.1600
Epoch: 7, Loss: 1.9316, Train: 0.2500, Val: 0.1280, Test: 0.1640
Epoch: 8, Loss: 1.9336, Train: 0.2500, Val: 0.1420, Test: 0.1770
Epoch: 9, Loss: 1.9236, Train: 0.2571, Val: 0.1480, Test: 0.1870
Epoch: 10, Loss: 1.9194, Train: 0.2571, Val: 0.1580, Test: 0.1910
Epoch: 11, Loss: 1.9164, Train: 0.2714, Val: 0.1680, Test: 0.1950
Epoch: 12, Loss: 1.9199, Train: 0.2857, Val: 0.1880, Test: 0.2040
Epoch: 13, Loss: 1.8850, Train: 0.3000, Val: 0.2040, Test: 0.2200
Epoch: 14, Loss: 1.8785, Train: 0.3071, Val: 0.2180, Test: 0.2240
Epoch: 15, Loss: 1.8776, Train: 0.3286, Val: 0.2260, Test: 0.2370
Epoch: 16, Loss: 1.8643, Train: 0.3357, Val: 0.2360, Test: 0.2440
Epoch: 17, Loss: 1.8506, Train: 0.3429, Val: 0.2340, Test: 0.2430
Epoch: 18, Loss: 1.8307, Train: 0.3571, Val: 0.2460, Test: 0.2580
Epoch: 19, Loss: 1.8056, Train: 0.3714, Val: 0.2500, Test: 0.2720
Epoch: 20, Loss: 1.8105, Train: 0.4071, Val: 0.2640, Test: 0.2910
Epoch: 21, Loss: 1.8003, Train: 0.4214, Val: 0.2880, Test: 0.3160
Epoch: 22, Loss: 1.7657, Train: 0.4643, Val: 0.3240, Test: 0.3540
Epoch: 23, Loss: 1.7538, Train: 0.4857, Val: 0.3700, Test: 0.4010
Epoch: 24, Loss: 1.6767, Train: 0.5000, Val: 0.4260, Test: 0.4530
Epoch: 25, Loss: 1.6841, Train: 0.5143, Val: 0.4580, Test: 0.4940
Epoch: 26, Loss: 1.6627, Train: 0.5857, Val: 0.5080, Test: 0.5410
Epoch: 27, Loss: 1.5841, Train: 0.6286, Val: 0.5420, Test: 0.5750
Epoch: 28, Loss: 1.5332, Train: 0.6429, Val: 0.5480, Test: 0.5880
Epoch: 29, Loss: 1.5306, Train: 0.6643, Val: 0.5540, Test: 0.5990
Epoch: 30, Loss: 1.5396, Train: 0.6643, Val: 0.5620, Test: 0.6100
Epoch: 31, Loss: 1.4291, Train: 0.6714, Val: 0.5640, Test: 0.6150
Epoch: 32, Loss: 1.4326, Train: 0.6714, Val: 0.5600, Test: 0.6140
Epoch: 33, Loss: 1.3467, Train: 0.6857, Val: 0.5560, Test: 0.6170
Epoch: 34, Loss: 1.3495, Train: 0.6786, Val: 0.5500, Test: 0.6100
Epoch: 35, Loss: 1.2989, Train: 0.6786, Val: 0.5540, Test: 0.6160
Epoch: 36, Loss: 1.4745, Train: 0.6643, Val: 0.5520, Test: 0.6140
Epoch: 37, Loss: 1.3185, Train: 0.6714, Val: 0.5580, Test: 0.6210
Epoch: 38, Loss: 1.2909, Train: 0.6643, Val: 0.5580, Test: 0.6190
Epoch: 39, Loss: 1.1733, Train: 0.6643, Val: 0.5560, Test: 0.6140
Epoch: 40, Loss: 1.2500, Train: 0.6786, Val: 0.5560, Test: 0.6140
Epoch: 41, Loss: 1.1677, Train: 0.6929, Val: 0.5600, Test: 0.6190
Epoch: 42, Loss: 1.0921, Train: 0.7000, Val: 0.5640, Test: 0.6170
Epoch: 43, Loss: 1.1026, Train: 0.7000, Val: 0.5560, Test: 0.6140
Epoch: 44, Loss: 0.9955, Train: 0.7000, Val: 0.5540, Test: 0.6090
Epoch: 45, Loss: 1.2309, Train: 0.7000, Val: 0.5520, Test: 0.6100
Epoch: 46, Loss: 1.1218, Train: 0.7071, Val: 0.5480, Test: 0.6090
Epoch: 47, Loss: 1.0910, Train: 0.7071, Val: 0.5540, Test: 0.6110
Epoch: 48, Loss: 1.0956, Train: 0.7000, Val: 0.5580, Test: 0.6090
Epoch: 49, Loss: 1.0722, Train: 0.7000, Val: 0.5560, Test: 0.6060
Epoch: 50, Loss: 1.0578, Train: 0.7071, Val: 0.5480, Test: 0.5990
MAD:  0.5095
Best Test Accuracy: 0.6210, Val Accuracy: 0.5580, Train Accuracy: 0.6714
Training completed.
Seed:  6
Epoch: 1, Loss: 1.9461, Train: 0.2071, Val: 0.1200, Test: 0.1080
Epoch: 2, Loss: 1.9438, Train: 0.3143, Val: 0.2160, Test: 0.2370
Epoch: 3, Loss: 1.9437, Train: 0.2786, Val: 0.2100, Test: 0.2240
Epoch: 4, Loss: 1.9404, Train: 0.2786, Val: 0.2140, Test: 0.2280
Epoch: 5, Loss: 1.9341, Train: 0.3000, Val: 0.2160, Test: 0.2410
Epoch: 6, Loss: 1.9295, Train: 0.3786, Val: 0.2640, Test: 0.2910
Epoch: 7, Loss: 1.9294, Train: 0.4571, Val: 0.3580, Test: 0.3600
Epoch: 8, Loss: 1.9261, Train: 0.5000, Val: 0.3860, Test: 0.3900
Epoch: 9, Loss: 1.9206, Train: 0.5143, Val: 0.4120, Test: 0.4050
Epoch: 10, Loss: 1.9063, Train: 0.5071, Val: 0.4100, Test: 0.4100
Epoch: 11, Loss: 1.9123, Train: 0.5214, Val: 0.4140, Test: 0.4110
Epoch: 12, Loss: 1.8890, Train: 0.5286, Val: 0.4120, Test: 0.4080
Epoch: 13, Loss: 1.8844, Train: 0.5286, Val: 0.4100, Test: 0.4040
Epoch: 14, Loss: 1.8591, Train: 0.5214, Val: 0.4060, Test: 0.4020
Epoch: 15, Loss: 1.8525, Train: 0.5214, Val: 0.4120, Test: 0.4120
Epoch: 16, Loss: 1.8510, Train: 0.5286, Val: 0.4180, Test: 0.4160
Epoch: 17, Loss: 1.8058, Train: 0.5286, Val: 0.4200, Test: 0.4170
Epoch: 18, Loss: 1.8110, Train: 0.5357, Val: 0.4180, Test: 0.4210
Epoch: 19, Loss: 1.8048, Train: 0.5357, Val: 0.4280, Test: 0.4280
Epoch: 20, Loss: 1.7355, Train: 0.5429, Val: 0.4340, Test: 0.4290
Epoch: 21, Loss: 1.7111, Train: 0.5500, Val: 0.4320, Test: 0.4270
Epoch: 22, Loss: 1.6947, Train: 0.5500, Val: 0.4420, Test: 0.4290
Epoch: 23, Loss: 1.6809, Train: 0.5500, Val: 0.4400, Test: 0.4310
Epoch: 24, Loss: 1.6139, Train: 0.5500, Val: 0.4340, Test: 0.4280
Epoch: 25, Loss: 1.5219, Train: 0.5500, Val: 0.4340, Test: 0.4320
Epoch: 26, Loss: 1.5616, Train: 0.5500, Val: 0.4460, Test: 0.4370
Epoch: 27, Loss: 1.5628, Train: 0.5571, Val: 0.4500, Test: 0.4400
Epoch: 28, Loss: 1.5338, Train: 0.5571, Val: 0.4520, Test: 0.4360
Epoch: 29, Loss: 1.4717, Train: 0.5571, Val: 0.4540, Test: 0.4360
Epoch: 30, Loss: 1.5214, Train: 0.5571, Val: 0.4520, Test: 0.4350
Epoch: 31, Loss: 1.4374, Train: 0.5500, Val: 0.4560, Test: 0.4350
Epoch: 32, Loss: 1.3475, Train: 0.5571, Val: 0.4540, Test: 0.4360
Epoch: 33, Loss: 1.4059, Train: 0.5571, Val: 0.4580, Test: 0.4360
Epoch: 34, Loss: 1.3957, Train: 0.5571, Val: 0.4540, Test: 0.4340
Epoch: 35, Loss: 1.4134, Train: 0.5571, Val: 0.4520, Test: 0.4390
Epoch: 36, Loss: 1.3452, Train: 0.5571, Val: 0.4520, Test: 0.4380
Epoch: 37, Loss: 1.2727, Train: 0.5643, Val: 0.4480, Test: 0.4380
Epoch: 38, Loss: 1.4049, Train: 0.5643, Val: 0.4500, Test: 0.4400
Epoch: 39, Loss: 1.2862, Train: 0.5714, Val: 0.4460, Test: 0.4370
Epoch: 40, Loss: 1.2973, Train: 0.5714, Val: 0.4500, Test: 0.4430
Epoch: 41, Loss: 1.2762, Train: 0.6000, Val: 0.4940, Test: 0.4730
Epoch: 42, Loss: 1.2864, Train: 0.6286, Val: 0.5440, Test: 0.5140
Epoch: 43, Loss: 1.2849, Train: 0.6429, Val: 0.5980, Test: 0.5610
Epoch: 44, Loss: 1.2432, Train: 0.6643, Val: 0.6200, Test: 0.5990
Epoch: 45, Loss: 1.1156, Train: 0.6714, Val: 0.6320, Test: 0.6230
Epoch: 46, Loss: 1.0914, Train: 0.6786, Val: 0.6460, Test: 0.6330
Epoch: 47, Loss: 1.2876, Train: 0.6857, Val: 0.6640, Test: 0.6440
Epoch: 48, Loss: 1.2918, Train: 0.6857, Val: 0.6660, Test: 0.6510
Epoch: 49, Loss: 1.2604, Train: 0.6929, Val: 0.6580, Test: 0.6500
Epoch: 50, Loss: 1.1561, Train: 0.6929, Val: 0.6540, Test: 0.6570
MAD:  0.6896
Best Test Accuracy: 0.6570, Val Accuracy: 0.6540, Train Accuracy: 0.6929
Training completed.
Seed:  7
Epoch: 1, Loss: 1.9440, Train: 0.1500, Val: 0.0580, Test: 0.0670
Epoch: 2, Loss: 1.9455, Train: 0.3000, Val: 0.2140, Test: 0.2090
Epoch: 3, Loss: 1.9366, Train: 0.3071, Val: 0.2220, Test: 0.2210
Epoch: 4, Loss: 1.9360, Train: 0.2929, Val: 0.2040, Test: 0.2040
Epoch: 5, Loss: 1.9290, Train: 0.2929, Val: 0.2020, Test: 0.1990
Epoch: 6, Loss: 1.9258, Train: 0.2929, Val: 0.2020, Test: 0.2010
Epoch: 7, Loss: 1.9168, Train: 0.2929, Val: 0.2020, Test: 0.2010
Epoch: 8, Loss: 1.9213, Train: 0.2929, Val: 0.2040, Test: 0.2010
Epoch: 9, Loss: 1.8946, Train: 0.2857, Val: 0.2120, Test: 0.2020
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
Epoch: 10, Loss: 1.9063, Train: 0.3000, Val: 0.2180, Test: 0.2110
Epoch: 11, Loss: 1.8684, Train: 0.3357, Val: 0.2220, Test: 0.2230
Epoch: 12, Loss: 1.8553, Train: 0.3357, Val: 0.2280, Test: 0.2260
Epoch: 13, Loss: 1.8635, Train: 0.3429, Val: 0.2280, Test: 0.2300
Epoch: 14, Loss: 1.8206, Train: 0.3429, Val: 0.2200, Test: 0.2330
Epoch: 15, Loss: 1.8031, Train: 0.3429, Val: 0.2220, Test: 0.2280
Epoch: 16, Loss: 1.7899, Train: 0.3357, Val: 0.2240, Test: 0.2300
Epoch: 17, Loss: 1.7965, Train: 0.3786, Val: 0.2420, Test: 0.2530
Epoch: 18, Loss: 1.7702, Train: 0.3929, Val: 0.2740, Test: 0.2750
Epoch: 19, Loss: 1.7403, Train: 0.4143, Val: 0.2960, Test: 0.2930
Epoch: 20, Loss: 1.6990, Train: 0.4214, Val: 0.3060, Test: 0.3000
Epoch: 21, Loss: 1.6979, Train: 0.4214, Val: 0.3120, Test: 0.3080
Epoch: 22, Loss: 1.6983, Train: 0.4214, Val: 0.3240, Test: 0.3140
Epoch: 23, Loss: 1.6786, Train: 0.4214, Val: 0.3320, Test: 0.3200
Epoch: 24, Loss: 1.5816, Train: 0.4214, Val: 0.3340, Test: 0.3240
Epoch: 25, Loss: 1.5616, Train: 0.4214, Val: 0.3380, Test: 0.3250
Epoch: 26, Loss: 1.6339, Train: 0.4286, Val: 0.3460, Test: 0.3280
Epoch: 27, Loss: 1.5985, Train: 0.4286, Val: 0.3520, Test: 0.3370
Epoch: 28, Loss: 1.6403, Train: 0.4286, Val: 0.3560, Test: 0.3390
Epoch: 29, Loss: 1.4832, Train: 0.4286, Val: 0.3600, Test: 0.3420
Epoch: 30, Loss: 1.5623, Train: 0.4286, Val: 0.3600, Test: 0.3410
Epoch: 31, Loss: 1.6265, Train: 0.4286, Val: 0.3600, Test: 0.3420
Epoch: 32, Loss: 1.5011, Train: 0.4357, Val: 0.3600, Test: 0.3430
Epoch: 33, Loss: 1.4852, Train: 0.5000, Val: 0.3860, Test: 0.3840
Epoch: 34, Loss: 1.5784, Train: 0.5500, Val: 0.4000, Test: 0.4000
Epoch: 35, Loss: 1.5233, Train: 0.5143, Val: 0.3680, Test: 0.3620
Epoch: 36, Loss: 1.5858, Train: 0.4857, Val: 0.3480, Test: 0.3360
Epoch: 37, Loss: 1.5587, Train: 0.4786, Val: 0.3380, Test: 0.3280
Epoch: 38, Loss: 1.4826, Train: 0.4786, Val: 0.3500, Test: 0.3370
Epoch: 39, Loss: 1.5651, Train: 0.5286, Val: 0.3760, Test: 0.3850
Epoch: 40, Loss: 1.4448, Train: 0.5571, Val: 0.4100, Test: 0.4050
Epoch: 41, Loss: 1.4967, Train: 0.5571, Val: 0.4240, Test: 0.4180
Epoch: 42, Loss: 1.5137, Train: 0.5571, Val: 0.4180, Test: 0.4130
Epoch: 43, Loss: 1.5193, Train: 0.4571, Val: 0.3740, Test: 0.3620
Epoch: 44, Loss: 1.4366, Train: 0.4429, Val: 0.3640, Test: 0.3510
Epoch: 45, Loss: 1.4454, Train: 0.4429, Val: 0.3680, Test: 0.3550
Epoch: 46, Loss: 1.4051, Train: 0.5071, Val: 0.4060, Test: 0.3900
Epoch: 47, Loss: 1.4352, Train: 0.5571, Val: 0.4340, Test: 0.4220
Epoch: 48, Loss: 1.4283, Train: 0.5571, Val: 0.4360, Test: 0.4230
Epoch: 49, Loss: 1.3202, Train: 0.5571, Val: 0.4380, Test: 0.4280
Epoch: 50, Loss: 1.3558, Train: 0.5571, Val: 0.4400, Test: 0.4330
MAD:  0.6753
Best Test Accuracy: 0.4330, Val Accuracy: 0.4400, Train Accuracy: 0.5571
Training completed.
Seed:  8
Epoch: 1, Loss: 1.9465, Train: 0.1429, Val: 0.1220, Test: 0.1300
Epoch: 2, Loss: 1.9459, Train: 0.1714, Val: 0.1300, Test: 0.1390
Epoch: 3, Loss: 1.9451, Train: 0.3500, Val: 0.2560, Test: 0.2680
Epoch: 4, Loss: 1.9431, Train: 0.3786, Val: 0.2980, Test: 0.2970
Epoch: 5, Loss: 1.9438, Train: 0.3571, Val: 0.2980, Test: 0.2890
Epoch: 6, Loss: 1.9407, Train: 0.3786, Val: 0.3020, Test: 0.2870
Epoch: 7, Loss: 1.9390, Train: 0.4286, Val: 0.3300, Test: 0.3100
Epoch: 8, Loss: 1.9366, Train: 0.4429, Val: 0.3920, Test: 0.3490
Epoch: 9, Loss: 1.9374, Train: 0.4929, Val: 0.4960, Test: 0.4640
Epoch: 10, Loss: 1.9313, Train: 0.5571, Val: 0.5360, Test: 0.5300
Epoch: 11, Loss: 1.9308, Train: 0.5857, Val: 0.5380, Test: 0.5310
Epoch: 12, Loss: 1.9248, Train: 0.5857, Val: 0.5180, Test: 0.5090
Epoch: 13, Loss: 1.9226, Train: 0.5786, Val: 0.4720, Test: 0.4740
Epoch: 14, Loss: 1.9054, Train: 0.5571, Val: 0.4280, Test: 0.4290
Epoch: 15, Loss: 1.9058, Train: 0.5500, Val: 0.4280, Test: 0.4120
Epoch: 16, Loss: 1.8883, Train: 0.5429, Val: 0.4280, Test: 0.4240
Epoch: 17, Loss: 1.8916, Train: 0.5643, Val: 0.4420, Test: 0.4430
Epoch: 18, Loss: 1.8817, Train: 0.5643, Val: 0.4620, Test: 0.4620
Epoch: 19, Loss: 1.8759, Train: 0.5714, Val: 0.4700, Test: 0.4700
Epoch: 20, Loss: 1.8362, Train: 0.5714, Val: 0.4760, Test: 0.4780
Epoch: 21, Loss: 1.8446, Train: 0.5786, Val: 0.4860, Test: 0.4860
Epoch: 22, Loss: 1.8136, Train: 0.5929, Val: 0.4960, Test: 0.5030
Epoch: 23, Loss: 1.8263, Train: 0.5929, Val: 0.5000, Test: 0.5100
Epoch: 24, Loss: 1.7717, Train: 0.5857, Val: 0.5000, Test: 0.5150
Epoch: 25, Loss: 1.7650, Train: 0.5929, Val: 0.5060, Test: 0.5190
Epoch: 26, Loss: 1.7212, Train: 0.6000, Val: 0.5060, Test: 0.5140
Epoch: 27, Loss: 1.6740, Train: 0.5929, Val: 0.4980, Test: 0.5160
Epoch: 28, Loss: 1.6187, Train: 0.5857, Val: 0.4920, Test: 0.5140
Epoch: 29, Loss: 1.5733, Train: 0.5929, Val: 0.5000, Test: 0.5090
Epoch: 30, Loss: 1.5507, Train: 0.6357, Val: 0.5120, Test: 0.5220
Epoch: 31, Loss: 1.5116, Train: 0.6500, Val: 0.5300, Test: 0.5310
Epoch: 32, Loss: 1.4676, Train: 0.6500, Val: 0.5420, Test: 0.5430
Epoch: 33, Loss: 1.4320, Train: 0.6643, Val: 0.5780, Test: 0.5870
Epoch: 34, Loss: 1.4061, Train: 0.6571, Val: 0.6120, Test: 0.6030
Epoch: 35, Loss: 1.4010, Train: 0.6500, Val: 0.6200, Test: 0.6100
Epoch: 36, Loss: 1.3278, Train: 0.6643, Val: 0.6200, Test: 0.6120
Epoch: 37, Loss: 1.3953, Train: 0.6714, Val: 0.6320, Test: 0.6150
Epoch: 38, Loss: 1.3496, Train: 0.6714, Val: 0.6440, Test: 0.6220
Epoch: 39, Loss: 1.3304, Train: 0.6857, Val: 0.6400, Test: 0.6380
Epoch: 40, Loss: 1.2654, Train: 0.6929, Val: 0.6400, Test: 0.6340
Epoch: 41, Loss: 1.2323, Train: 0.6929, Val: 0.6400, Test: 0.6340
Epoch: 42, Loss: 1.1865, Train: 0.6786, Val: 0.6400, Test: 0.6310
Epoch: 43, Loss: 1.1589, Train: 0.6786, Val: 0.6480, Test: 0.6300
Epoch: 44, Loss: 1.3366, Train: 0.6786, Val: 0.6500, Test: 0.6380
Epoch: 45, Loss: 1.1980, Train: 0.6857, Val: 0.6580, Test: 0.6430
Epoch: 46, Loss: 1.0425, Train: 0.6929, Val: 0.6660, Test: 0.6530
Epoch: 47, Loss: 1.1099, Train: 0.7000, Val: 0.6600, Test: 0.6590
Epoch: 48, Loss: 1.0930, Train: 0.7357, Val: 0.6640, Test: 0.6780
Epoch: 49, Loss: 1.1050, Train: 0.7786, Val: 0.6860, Test: 0.6950
Epoch: 50, Loss: 1.1161, Train: 0.8071, Val: 0.6940, Test: 0.7010
MAD:  0.7157
Best Test Accuracy: 0.7010, Val Accuracy: 0.6940, Train Accuracy: 0.8071
Training completed.
Seed:  9
Epoch: 1, Loss: 1.9460, Train: 0.2571, Val: 0.1620, Test: 0.1650
Epoch: 2, Loss: 1.9433, Train: 0.1429, Val: 0.1240, Test: 0.1100
Epoch: 3, Loss: 1.9425, Train: 0.1857, Val: 0.1340, Test: 0.1300
Epoch: 4, Loss: 1.9401, Train: 0.3143, Val: 0.2060, Test: 0.2000
Epoch: 5, Loss: 1.9377, Train: 0.3857, Val: 0.2600, Test: 0.2660
Epoch: 6, Loss: 1.9338, Train: 0.4571, Val: 0.3620, Test: 0.3570
Epoch: 7, Loss: 1.9285, Train: 0.5000, Val: 0.3880, Test: 0.3680
Epoch: 8, Loss: 1.9194, Train: 0.5143, Val: 0.3920, Test: 0.3760
Epoch: 9, Loss: 1.9195, Train: 0.5071, Val: 0.4040, Test: 0.3830
Epoch: 10, Loss: 1.9192, Train: 0.5429, Val: 0.4200, Test: 0.3960
Epoch: 11, Loss: 1.9016, Train: 0.5571, Val: 0.4320, Test: 0.4110
Epoch: 12, Loss: 1.8892, Train: 0.5643, Val: 0.4400, Test: 0.4230
Epoch: 13, Loss: 1.8687, Train: 0.5714, Val: 0.4540, Test: 0.4300
Epoch: 14, Loss: 1.8588, Train: 0.5714, Val: 0.4580, Test: 0.4320
Epoch: 15, Loss: 1.8540, Train: 0.5714, Val: 0.4600, Test: 0.4330
Epoch: 16, Loss: 1.8407, Train: 0.5714, Val: 0.4600, Test: 0.4340
Epoch: 17, Loss: 1.8315, Train: 0.5714, Val: 0.4660, Test: 0.4370
Epoch: 18, Loss: 1.7984, Train: 0.5714, Val: 0.4700, Test: 0.4440
Epoch: 19, Loss: 1.7807, Train: 0.5714, Val: 0.4700, Test: 0.4460
Epoch: 20, Loss: 1.7040, Train: 0.5714, Val: 0.4700, Test: 0.4450
Epoch: 21, Loss: 1.7205, Train: 0.5714, Val: 0.4700, Test: 0.4460
Epoch: 22, Loss: 1.6461, Train: 0.5714, Val: 0.4700, Test: 0.4480
Epoch: 23, Loss: 1.6486, Train: 0.5714, Val: 0.4700, Test: 0.4510
Epoch: 24, Loss: 1.5335, Train: 0.5714, Val: 0.4680, Test: 0.4510
Epoch: 25, Loss: 1.4892, Train: 0.5714, Val: 0.4680, Test: 0.4540
Epoch: 26, Loss: 1.5107, Train: 0.5714, Val: 0.4680, Test: 0.4550
Epoch: 27, Loss: 1.5401, Train: 0.5714, Val: 0.4700, Test: 0.4500
Epoch: 28, Loss: 1.5491, Train: 0.5643, Val: 0.4800, Test: 0.4550
Epoch: 29, Loss: 1.4519, Train: 0.5643, Val: 0.4820, Test: 0.4560
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
/home/yiyi/code/code/DIR-GNN/train/cora.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f'./pkl/{save_name}.pkl'))
Epoch: 30, Loss: 1.4471, Train: 0.5571, Val: 0.4740, Test: 0.4520
Epoch: 31, Loss: 1.3768, Train: 0.5786, Val: 0.4980, Test: 0.4640
Epoch: 32, Loss: 1.4430, Train: 0.6214, Val: 0.5200, Test: 0.5040
Epoch: 33, Loss: 1.3299, Train: 0.6571, Val: 0.5240, Test: 0.5090
Epoch: 34, Loss: 1.2805, Train: 0.6714, Val: 0.5240, Test: 0.5090
Epoch: 35, Loss: 1.2048, Train: 0.6786, Val: 0.5300, Test: 0.5190
Epoch: 36, Loss: 1.3516, Train: 0.6786, Val: 0.5420, Test: 0.5300
Epoch: 37, Loss: 1.2560, Train: 0.6643, Val: 0.5380, Test: 0.5370
Epoch: 38, Loss: 1.1801, Train: 0.6714, Val: 0.5380, Test: 0.5390
Epoch: 39, Loss: 1.1852, Train: 0.6786, Val: 0.5440, Test: 0.5390
Epoch: 40, Loss: 1.0500, Train: 0.6786, Val: 0.5400, Test: 0.5370
Epoch: 41, Loss: 1.2015, Train: 0.6857, Val: 0.5380, Test: 0.5360
Epoch: 42, Loss: 1.2449, Train: 0.6857, Val: 0.5380, Test: 0.5350
Epoch: 43, Loss: 1.2957, Train: 0.6857, Val: 0.5400, Test: 0.5340
Epoch: 44, Loss: 1.1428, Train: 0.6786, Val: 0.5400, Test: 0.5340
Epoch: 45, Loss: 1.1306, Train: 0.6786, Val: 0.5400, Test: 0.5320
Epoch: 46, Loss: 1.1023, Train: 0.6786, Val: 0.5440, Test: 0.5340
Epoch: 47, Loss: 1.1042, Train: 0.6929, Val: 0.5420, Test: 0.5360
Epoch: 48, Loss: 1.1954, Train: 0.6929, Val: 0.5480, Test: 0.5390
Epoch: 49, Loss: 1.0496, Train: 0.7071, Val: 0.5440, Test: 0.5380
Epoch: 50, Loss: 1.1148, Train: 0.7071, Val: 0.5420, Test: 0.5320
MAD:  0.5933
Best Test Accuracy: 0.5390, Val Accuracy: 0.5380, Train Accuracy: 0.6714
Training completed.
Average Test Accuracy:  0.6159999999999999 ± 0.10797499710581149
Average MAD:  0.63941 ± 0.08117322772934436
