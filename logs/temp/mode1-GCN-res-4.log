Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8487, Train: 0.0786, Val: 0.0140, Test: 0.0220
Epoch: 2, Loss: 4.7870, Train: 0.2500, Val: 0.0980, Test: 0.1060
Epoch: 3, Loss: 4.6723, Train: 0.4500, Val: 0.1900, Test: 0.1890
Epoch: 4, Loss: 4.6171, Train: 0.5429, Val: 0.2460, Test: 0.2440
Epoch: 5, Loss: 4.6636, Train: 0.5929, Val: 0.2740, Test: 0.2850
Epoch: 6, Loss: 4.3025, Train: 0.6429, Val: 0.3000, Test: 0.3110
Epoch: 7, Loss: 4.3822, Train: 0.6714, Val: 0.3500, Test: 0.3440
Epoch: 8, Loss: 4.4117, Train: 0.6929, Val: 0.3840, Test: 0.3950
Epoch: 9, Loss: 4.3385, Train: 0.7714, Val: 0.4200, Test: 0.4240
Epoch: 10, Loss: 4.4656, Train: 0.8571, Val: 0.4580, Test: 0.4650
Epoch: 11, Loss: 3.9525, Train: 0.9000, Val: 0.4900, Test: 0.5090
Epoch: 12, Loss: 4.2327, Train: 0.9143, Val: 0.5260, Test: 0.5450
Epoch: 13, Loss: 4.1078, Train: 0.9429, Val: 0.5640, Test: 0.5910
Epoch: 14, Loss: 3.9721, Train: 0.9571, Val: 0.5780, Test: 0.6260
Epoch: 15, Loss: 3.8635, Train: 0.9643, Val: 0.6080, Test: 0.6510
Epoch: 16, Loss: 3.7812, Train: 0.9714, Val: 0.6220, Test: 0.6660
Epoch: 17, Loss: 3.7285, Train: 0.9857, Val: 0.6380, Test: 0.6760
Epoch: 18, Loss: 3.7954, Train: 0.9857, Val: 0.6560, Test: 0.6950
Epoch: 19, Loss: 3.5350, Train: 0.9857, Val: 0.6720, Test: 0.7130
Epoch: 20, Loss: 3.7053, Train: 0.9857, Val: 0.6840, Test: 0.7270
Epoch: 21, Loss: 3.7397, Train: 0.9857, Val: 0.7100, Test: 0.7370
Epoch: 22, Loss: 3.5587, Train: 0.9929, Val: 0.7180, Test: 0.7500
Epoch: 23, Loss: 3.8957, Train: 0.9929, Val: 0.7320, Test: 0.7600
Epoch: 24, Loss: 3.7105, Train: 0.9929, Val: 0.7340, Test: 0.7630
Epoch: 25, Loss: 3.7396, Train: 0.9929, Val: 0.7400, Test: 0.7630
Epoch: 26, Loss: 3.5688, Train: 1.0000, Val: 0.7400, Test: 0.7650
Epoch: 27, Loss: 3.5530, Train: 0.9929, Val: 0.7440, Test: 0.7650
Epoch: 28, Loss: 3.6151, Train: 1.0000, Val: 0.7460, Test: 0.7640
Epoch: 29, Loss: 3.4479, Train: 1.0000, Val: 0.7480, Test: 0.7620
Epoch: 30, Loss: 3.5142, Train: 1.0000, Val: 0.7440, Test: 0.7630
Epoch: 31, Loss: 4.1080, Train: 1.0000, Val: 0.7440, Test: 0.7680
Epoch: 32, Loss: 3.4970, Train: 1.0000, Val: 0.7420, Test: 0.7700
Epoch: 33, Loss: 3.7569, Train: 1.0000, Val: 0.7400, Test: 0.7690
Epoch: 34, Loss: 3.1679, Train: 1.0000, Val: 0.7400, Test: 0.7710
Epoch: 35, Loss: 3.7311, Train: 1.0000, Val: 0.7420, Test: 0.7720
Epoch: 36, Loss: 3.4432, Train: 1.0000, Val: 0.7400, Test: 0.7720
Epoch: 37, Loss: 3.6436, Train: 1.0000, Val: 0.7400, Test: 0.7760
Epoch: 38, Loss: 3.2762, Train: 1.0000, Val: 0.7420, Test: 0.7770
Epoch: 39, Loss: 3.6598, Train: 1.0000, Val: 0.7440, Test: 0.7830
Epoch: 40, Loss: 3.3813, Train: 1.0000, Val: 0.7500, Test: 0.7810
Epoch: 41, Loss: 3.3535, Train: 1.0000, Val: 0.7480, Test: 0.7800
Epoch: 42, Loss: 3.7638, Train: 1.0000, Val: 0.7460, Test: 0.7790
Epoch: 43, Loss: 3.2065, Train: 1.0000, Val: 0.7480, Test: 0.7820
Epoch: 44, Loss: 3.4433, Train: 1.0000, Val: 0.7520, Test: 0.7810
Epoch: 45, Loss: 3.6655, Train: 1.0000, Val: 0.7560, Test: 0.7810
Epoch: 46, Loss: 3.4226, Train: 1.0000, Val: 0.7560, Test: 0.7830
Epoch: 47, Loss: 3.4884, Train: 1.0000, Val: 0.7560, Test: 0.7820
Epoch: 48, Loss: 2.9532, Train: 1.0000, Val: 0.7580, Test: 0.7820
Epoch: 49, Loss: 3.3068, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 50, Loss: 3.5546, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 51, Loss: 3.1946, Train: 1.0000, Val: 0.7600, Test: 0.7880
Epoch: 52, Loss: 3.6617, Train: 1.0000, Val: 0.7580, Test: 0.7890
Epoch: 53, Loss: 3.0659, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 54, Loss: 3.2740, Train: 1.0000, Val: 0.7580, Test: 0.7870
Epoch: 55, Loss: 3.6231, Train: 1.0000, Val: 0.7580, Test: 0.7890
Epoch: 56, Loss: 3.4782, Train: 1.0000, Val: 0.7580, Test: 0.7890
Epoch: 57, Loss: 3.5247, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 58, Loss: 3.6954, Train: 1.0000, Val: 0.7580, Test: 0.7870
Epoch: 59, Loss: 3.2561, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 60, Loss: 3.5440, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 61, Loss: 3.1657, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 62, Loss: 3.5453, Train: 1.0000, Val: 0.7660, Test: 0.7810
Epoch: 63, Loss: 3.1487, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 64, Loss: 3.2915, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 65, Loss: 3.1389, Train: 1.0000, Val: 0.7540, Test: 0.7800
Epoch: 66, Loss: 3.1121, Train: 1.0000, Val: 0.7520, Test: 0.7780
Epoch: 67, Loss: 3.3045, Train: 1.0000, Val: 0.7520, Test: 0.7790
Epoch: 68, Loss: 3.4874, Train: 1.0000, Val: 0.7520, Test: 0.7800
Epoch: 69, Loss: 3.0811, Train: 1.0000, Val: 0.7540, Test: 0.7770
Epoch: 70, Loss: 3.2017, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 71, Loss: 3.5327, Train: 1.0000, Val: 0.7540, Test: 0.7760
Epoch: 72, Loss: 3.2173, Train: 1.0000, Val: 0.7500, Test: 0.7770
Epoch: 73, Loss: 3.1993, Train: 1.0000, Val: 0.7500, Test: 0.7760
Epoch: 74, Loss: 3.5385, Train: 1.0000, Val: 0.7500, Test: 0.7790
Epoch: 75, Loss: 3.2888, Train: 1.0000, Val: 0.7500, Test: 0.7780
Epoch: 76, Loss: 3.0820, Train: 1.0000, Val: 0.7480, Test: 0.7770
Epoch: 77, Loss: 3.0439, Train: 1.0000, Val: 0.7480, Test: 0.7750
Epoch: 78, Loss: 3.2682, Train: 1.0000, Val: 0.7500, Test: 0.7750
Epoch: 79, Loss: 3.2031, Train: 1.0000, Val: 0.7560, Test: 0.7740
Epoch: 80, Loss: 3.3624, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 81, Loss: 3.0788, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 82, Loss: 3.2061, Train: 1.0000, Val: 0.7600, Test: 0.7810
Epoch: 83, Loss: 3.2067, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 84, Loss: 3.4240, Train: 1.0000, Val: 0.7640, Test: 0.7800
Epoch: 85, Loss: 3.2722, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 86, Loss: 3.0107, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 87, Loss: 3.2721, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 88, Loss: 3.0904, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 89, Loss: 3.4476, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 90, Loss: 3.1917, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 91, Loss: 3.2212, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 92, Loss: 3.1290, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 93, Loss: 3.4642, Train: 1.0000, Val: 0.7600, Test: 0.7750
Epoch: 94, Loss: 2.9006, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 95, Loss: 2.9098, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 96, Loss: 3.2933, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 97, Loss: 3.0736, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 98, Loss: 2.9364, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 99, Loss: 2.8809, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 100, Loss: 3.2585, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 101, Loss: 3.0002, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 102, Loss: 2.8338, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 103, Loss: 3.0907, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 104, Loss: 2.8338, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 105, Loss: 3.1331, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 106, Loss: 3.4702, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 107, Loss: 2.9089, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 108, Loss: 3.0430, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 109, Loss: 3.3462, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 110, Loss: 3.1447, Train: 1.0000, Val: 0.7540, Test: 0.7780
Epoch: 111, Loss: 2.9638, Train: 1.0000, Val: 0.7520, Test: 0.7780
Epoch: 112, Loss: 3.0916, Train: 1.0000, Val: 0.7500, Test: 0.7750
Epoch: 113, Loss: 3.3416, Train: 1.0000, Val: 0.7500, Test: 0.7760
Epoch: 114, Loss: 3.2018, Train: 1.0000, Val: 0.7500, Test: 0.7760
Epoch: 115, Loss: 2.8368, Train: 1.0000, Val: 0.7480, Test: 0.7780
Epoch: 116, Loss: 3.4108, Train: 1.0000, Val: 0.7500, Test: 0.7790
Epoch: 117, Loss: 3.3512, Train: 1.0000, Val: 0.7480, Test: 0.7790
Epoch: 118, Loss: 3.0894, Train: 1.0000, Val: 0.7520, Test: 0.7810
Epoch: 119, Loss: 3.2580, Train: 1.0000, Val: 0.7520, Test: 0.7790
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 3.1628, Train: 1.0000, Val: 0.7500, Test: 0.7790
Epoch: 121, Loss: 3.2368, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 122, Loss: 3.4593, Train: 1.0000, Val: 0.7540, Test: 0.7770
Epoch: 123, Loss: 3.0730, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 124, Loss: 3.3082, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 125, Loss: 2.9974, Train: 1.0000, Val: 0.7540, Test: 0.7790
Epoch: 126, Loss: 3.1500, Train: 1.0000, Val: 0.7540, Test: 0.7790
Epoch: 127, Loss: 3.5396, Train: 1.0000, Val: 0.7560, Test: 0.7810
Epoch: 128, Loss: 2.9235, Train: 1.0000, Val: 0.7560, Test: 0.7820
Epoch: 129, Loss: 2.8494, Train: 1.0000, Val: 0.7560, Test: 0.7820
Epoch: 130, Loss: 2.7142, Train: 1.0000, Val: 0.7560, Test: 0.7800
Epoch: 131, Loss: 2.9912, Train: 1.0000, Val: 0.7560, Test: 0.7830
Epoch: 132, Loss: 3.1447, Train: 1.0000, Val: 0.7560, Test: 0.7830
Epoch: 133, Loss: 3.0964, Train: 1.0000, Val: 0.7540, Test: 0.7790
Epoch: 134, Loss: 3.2062, Train: 1.0000, Val: 0.7540, Test: 0.7790
Epoch: 135, Loss: 3.0542, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 136, Loss: 3.0297, Train: 1.0000, Val: 0.7480, Test: 0.7760
Epoch: 137, Loss: 3.2002, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 138, Loss: 3.3431, Train: 1.0000, Val: 0.7520, Test: 0.7750
Epoch: 139, Loss: 3.0606, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 140, Loss: 3.2269, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 141, Loss: 2.9265, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 142, Loss: 3.3590, Train: 1.0000, Val: 0.7540, Test: 0.7760
Epoch: 143, Loss: 2.9658, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 144, Loss: 2.9998, Train: 1.0000, Val: 0.7540, Test: 0.7740
Epoch: 145, Loss: 3.0814, Train: 1.0000, Val: 0.7480, Test: 0.7730
Epoch: 146, Loss: 3.5215, Train: 1.0000, Val: 0.7500, Test: 0.7750
Epoch: 147, Loss: 3.3461, Train: 1.0000, Val: 0.7500, Test: 0.7750
Epoch: 148, Loss: 3.4531, Train: 1.0000, Val: 0.7500, Test: 0.7740
Epoch: 149, Loss: 3.0138, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 150, Loss: 2.9309, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 151, Loss: 3.1194, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 152, Loss: 2.7323, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 153, Loss: 2.9710, Train: 1.0000, Val: 0.7480, Test: 0.7750
Epoch: 154, Loss: 2.9242, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 155, Loss: 3.0163, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 156, Loss: 2.9174, Train: 1.0000, Val: 0.7480, Test: 0.7720
Epoch: 157, Loss: 3.1569, Train: 1.0000, Val: 0.7480, Test: 0.7720
Epoch: 158, Loss: 3.0214, Train: 1.0000, Val: 0.7500, Test: 0.7730
Epoch: 159, Loss: 3.2468, Train: 1.0000, Val: 0.7540, Test: 0.7740
Epoch: 160, Loss: 3.3160, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 161, Loss: 3.1860, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 162, Loss: 3.2997, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 163, Loss: 3.2462, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 164, Loss: 3.1294, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 165, Loss: 2.7824, Train: 1.0000, Val: 0.7540, Test: 0.7770
Epoch: 166, Loss: 3.1512, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 167, Loss: 3.2685, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 168, Loss: 2.7027, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 169, Loss: 3.0250, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 170, Loss: 3.1133, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 171, Loss: 3.2360, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 172, Loss: 3.1471, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 173, Loss: 2.6465, Train: 1.0000, Val: 0.7560, Test: 0.7800
Epoch: 174, Loss: 3.0023, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 175, Loss: 3.2127, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 176, Loss: 2.8336, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 177, Loss: 2.9580, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 178, Loss: 2.9479, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 179, Loss: 3.3166, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 180, Loss: 3.0208, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 181, Loss: 3.1594, Train: 1.0000, Val: 0.7620, Test: 0.7770
Epoch: 182, Loss: 3.1331, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 183, Loss: 3.0201, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 184, Loss: 2.9947, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 185, Loss: 3.1115, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 186, Loss: 2.9545, Train: 1.0000, Val: 0.7520, Test: 0.7780
Epoch: 187, Loss: 2.6448, Train: 1.0000, Val: 0.7500, Test: 0.7800
Epoch: 188, Loss: 2.9896, Train: 1.0000, Val: 0.7520, Test: 0.7780
Epoch: 189, Loss: 2.7642, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 190, Loss: 3.0862, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 191, Loss: 3.0608, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 192, Loss: 3.1635, Train: 1.0000, Val: 0.7540, Test: 0.7770
Epoch: 193, Loss: 3.0180, Train: 1.0000, Val: 0.7500, Test: 0.7760
Epoch: 194, Loss: 3.1346, Train: 1.0000, Val: 0.7520, Test: 0.7800
Epoch: 195, Loss: 2.8536, Train: 1.0000, Val: 0.7520, Test: 0.7800
Epoch: 196, Loss: 2.9581, Train: 1.0000, Val: 0.7520, Test: 0.7780
Epoch: 197, Loss: 2.5172, Train: 1.0000, Val: 0.7520, Test: 0.7790
Epoch: 198, Loss: 2.9151, Train: 1.0000, Val: 0.7520, Test: 0.7800
Epoch: 199, Loss: 3.0833, Train: 1.0000, Val: 0.7560, Test: 0.7810
Epoch: 200, Loss: 3.0880, Train: 1.0000, Val: 0.7560, Test: 0.7790
MAD:  0.4566
Best Test Accuracy: 0.7890, Val Accuracy: 0.7580, Train Accuracy: 1.0000
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8774, Train: 0.0857, Val: 0.0480, Test: 0.0330
Epoch: 2, Loss: 4.8131, Train: 0.2643, Val: 0.1220, Test: 0.1140
Epoch: 3, Loss: 4.7749, Train: 0.3286, Val: 0.1760, Test: 0.1770
Epoch: 4, Loss: 4.6916, Train: 0.4143, Val: 0.2160, Test: 0.2240
Epoch: 5, Loss: 4.6047, Train: 0.4929, Val: 0.2500, Test: 0.2680
Epoch: 6, Loss: 4.6148, Train: 0.5500, Val: 0.3000, Test: 0.3160
Epoch: 7, Loss: 4.5729, Train: 0.6357, Val: 0.3880, Test: 0.3770
Epoch: 8, Loss: 4.4128, Train: 0.7214, Val: 0.4360, Test: 0.4210
Epoch: 9, Loss: 4.4106, Train: 0.8357, Val: 0.4780, Test: 0.4780
Epoch: 10, Loss: 4.3686, Train: 0.9214, Val: 0.5180, Test: 0.5290
Epoch: 11, Loss: 4.2117, Train: 0.9286, Val: 0.5580, Test: 0.5740
Epoch: 12, Loss: 4.1301, Train: 0.9429, Val: 0.5980, Test: 0.6120
Epoch: 13, Loss: 4.1920, Train: 0.9571, Val: 0.6360, Test: 0.6470
Epoch: 14, Loss: 3.7809, Train: 0.9571, Val: 0.6440, Test: 0.6840
Epoch: 15, Loss: 4.1369, Train: 0.9643, Val: 0.6780, Test: 0.7130
Epoch: 16, Loss: 3.9229, Train: 0.9857, Val: 0.7120, Test: 0.7280
Epoch: 17, Loss: 3.7217, Train: 0.9857, Val: 0.7140, Test: 0.7400
Epoch: 18, Loss: 4.0282, Train: 0.9929, Val: 0.7060, Test: 0.7450
Epoch: 19, Loss: 3.7533, Train: 0.9857, Val: 0.7080, Test: 0.7510
Epoch: 20, Loss: 3.6947, Train: 0.9857, Val: 0.7120, Test: 0.7520
Epoch: 21, Loss: 3.8896, Train: 0.9857, Val: 0.7120, Test: 0.7550
Epoch: 22, Loss: 3.5443, Train: 0.9857, Val: 0.7140, Test: 0.7520
Epoch: 23, Loss: 3.7821, Train: 0.9857, Val: 0.7160, Test: 0.7450
Epoch: 24, Loss: 3.8722, Train: 0.9857, Val: 0.7100, Test: 0.7430
Epoch: 25, Loss: 3.4891, Train: 0.9929, Val: 0.7140, Test: 0.7400
Epoch: 26, Loss: 3.4549, Train: 0.9929, Val: 0.7200, Test: 0.7400
Epoch: 27, Loss: 3.4555, Train: 0.9929, Val: 0.7300, Test: 0.7400
Epoch: 28, Loss: 3.6589, Train: 0.9929, Val: 0.7380, Test: 0.7440
Epoch: 29, Loss: 3.4761, Train: 0.9929, Val: 0.7420, Test: 0.7410
Epoch: 30, Loss: 3.3507, Train: 0.9929, Val: 0.7460, Test: 0.7460
Epoch: 31, Loss: 3.5839, Train: 0.9929, Val: 0.7380, Test: 0.7480
Epoch: 32, Loss: 3.6450, Train: 0.9929, Val: 0.7380, Test: 0.7500
Epoch: 33, Loss: 3.4305, Train: 0.9929, Val: 0.7440, Test: 0.7500
Epoch: 34, Loss: 3.6230, Train: 0.9929, Val: 0.7460, Test: 0.7520
Epoch: 35, Loss: 3.1641, Train: 0.9929, Val: 0.7500, Test: 0.7540
Epoch: 36, Loss: 3.4330, Train: 0.9929, Val: 0.7500, Test: 0.7630
Epoch: 37, Loss: 3.7998, Train: 0.9929, Val: 0.7500, Test: 0.7690
Epoch: 38, Loss: 3.5259, Train: 0.9929, Val: 0.7520, Test: 0.7680
Epoch: 39, Loss: 3.3937, Train: 0.9929, Val: 0.7620, Test: 0.7700
Epoch: 40, Loss: 3.5813, Train: 0.9929, Val: 0.7620, Test: 0.7700
Epoch: 41, Loss: 3.6356, Train: 0.9929, Val: 0.7660, Test: 0.7710
Epoch: 42, Loss: 3.0169, Train: 0.9929, Val: 0.7680, Test: 0.7730
Epoch: 43, Loss: 3.2746, Train: 0.9929, Val: 0.7660, Test: 0.7740
Epoch: 44, Loss: 3.6454, Train: 0.9929, Val: 0.7640, Test: 0.7750
Epoch: 45, Loss: 2.9813, Train: 0.9929, Val: 0.7660, Test: 0.7750
Epoch: 46, Loss: 3.6924, Train: 0.9929, Val: 0.7620, Test: 0.7740
Epoch: 47, Loss: 3.2512, Train: 0.9929, Val: 0.7600, Test: 0.7740
Epoch: 48, Loss: 3.5349, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 49, Loss: 3.2520, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 50, Loss: 2.8878, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 51, Loss: 3.2394, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 52, Loss: 3.4606, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 53, Loss: 3.2310, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 54, Loss: 3.0771, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 55, Loss: 3.4525, Train: 1.0000, Val: 0.7660, Test: 0.7730
Epoch: 56, Loss: 3.1285, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 57, Loss: 3.2047, Train: 1.0000, Val: 0.7660, Test: 0.7730
Epoch: 58, Loss: 3.6571, Train: 1.0000, Val: 0.7660, Test: 0.7710
Epoch: 59, Loss: 3.1802, Train: 1.0000, Val: 0.7620, Test: 0.7690
Epoch: 60, Loss: 3.1157, Train: 1.0000, Val: 0.7620, Test: 0.7660
Epoch: 61, Loss: 3.5284, Train: 1.0000, Val: 0.7580, Test: 0.7670
Epoch: 62, Loss: 3.0564, Train: 1.0000, Val: 0.7560, Test: 0.7700
Epoch: 63, Loss: 3.1467, Train: 1.0000, Val: 0.7600, Test: 0.7720
Epoch: 64, Loss: 3.2301, Train: 1.0000, Val: 0.7600, Test: 0.7730
Epoch: 65, Loss: 3.4989, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 66, Loss: 3.2469, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 67, Loss: 3.4968, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 68, Loss: 3.6301, Train: 1.0000, Val: 0.7620, Test: 0.7780
Epoch: 69, Loss: 3.4511, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 70, Loss: 3.3728, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 71, Loss: 3.1660, Train: 1.0000, Val: 0.7560, Test: 0.7820
Epoch: 72, Loss: 3.3519, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 73, Loss: 3.0655, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 74, Loss: 2.8835, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 75, Loss: 3.1429, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 76, Loss: 3.5266, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 77, Loss: 3.5361, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 78, Loss: 3.3222, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 79, Loss: 3.0630, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 80, Loss: 2.9455, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 81, Loss: 3.5026, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 82, Loss: 2.7757, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 83, Loss: 3.2198, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 84, Loss: 3.0398, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 85, Loss: 3.1727, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 86, Loss: 3.1295, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 87, Loss: 3.5097, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 88, Loss: 3.0195, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 89, Loss: 3.2072, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 90, Loss: 2.9378, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 91, Loss: 2.9906, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 92, Loss: 3.0290, Train: 1.0000, Val: 0.7600, Test: 0.7810
Epoch: 93, Loss: 3.0292, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 94, Loss: 3.4578, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 95, Loss: 3.4839, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 96, Loss: 3.1810, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 97, Loss: 3.3204, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 98, Loss: 3.3919, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 99, Loss: 3.1077, Train: 1.0000, Val: 0.7640, Test: 0.7800
Epoch: 100, Loss: 3.6032, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 101, Loss: 2.7848, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 102, Loss: 3.2352, Train: 1.0000, Val: 0.7620, Test: 0.7770
Epoch: 103, Loss: 3.0693, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 104, Loss: 3.0452, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 105, Loss: 3.2450, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 106, Loss: 2.8139, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 107, Loss: 3.2556, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 108, Loss: 2.8512, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 109, Loss: 3.0955, Train: 1.0000, Val: 0.7640, Test: 0.7800
Epoch: 110, Loss: 3.1585, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 111, Loss: 3.0223, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 112, Loss: 3.2733, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 113, Loss: 3.0830, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 114, Loss: 2.9750, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 115, Loss: 3.3764, Train: 1.0000, Val: 0.7580, Test: 0.7830
Epoch: 116, Loss: 2.9623, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 117, Loss: 3.4316, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 118, Loss: 2.8942, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 119, Loss: 3.1129, Train: 1.0000, Val: 0.7600, Test: 0.7810
Epoch: 120, Loss: 2.7835, Train: 1.0000, Val: 0.7580, Test: 0.7820
Epoch: 121, Loss: 3.1987, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 122, Loss: 3.1939, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 123, Loss: 3.0608, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 124, Loss: 3.0293, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 125, Loss: 3.2210, Train: 1.0000, Val: 0.7620, Test: 0.7740
Epoch: 126, Loss: 3.1505, Train: 1.0000, Val: 0.7580, Test: 0.7720
Epoch: 127, Loss: 3.2541, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 128, Loss: 3.1347, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 129, Loss: 3.0813, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 130, Loss: 3.1808, Train: 1.0000, Val: 0.7540, Test: 0.7690
Epoch: 131, Loss: 3.0173, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 132, Loss: 3.2031, Train: 1.0000, Val: 0.7560, Test: 0.7680
Epoch: 133, Loss: 2.6720, Train: 1.0000, Val: 0.7560, Test: 0.7680
Epoch: 134, Loss: 3.2187, Train: 1.0000, Val: 0.7580, Test: 0.7700
Epoch: 135, Loss: 3.0480, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 136, Loss: 3.2431, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 137, Loss: 2.9697, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 138, Loss: 2.6994, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 139, Loss: 3.1375, Train: 1.0000, Val: 0.7600, Test: 0.7810
Epoch: 140, Loss: 3.0037, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 141, Loss: 3.2180, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 142, Loss: 3.1534, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 143, Loss: 3.1353, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 144, Loss: 3.1345, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 145, Loss: 2.9517, Train: 1.0000, Val: 0.7620, Test: 0.7770
Epoch: 146, Loss: 3.1747, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 147, Loss: 3.0094, Train: 1.0000, Val: 0.7620, Test: 0.7770
Epoch: 148, Loss: 3.3417, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 149, Loss: 3.1175, Train: 1.0000, Val: 0.7560, Test: 0.7750
Epoch: 150, Loss: 3.1051, Train: 1.0000, Val: 0.7560, Test: 0.7740
Epoch: 151, Loss: 3.2314, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 152, Loss: 3.2610, Train: 1.0000, Val: 0.7560, Test: 0.7750
Epoch: 153, Loss: 3.2496, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 154, Loss: 3.0973, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 155, Loss: 3.2321, Train: 1.0000, Val: 0.7540, Test: 0.7760
Epoch: 156, Loss: 2.7895, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 157, Loss: 2.6843, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 158, Loss: 3.0968, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 159, Loss: 3.1197, Train: 1.0000, Val: 0.7600, Test: 0.7780
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 160, Loss: 3.3103, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 161, Loss: 2.8954, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 162, Loss: 3.4608, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 163, Loss: 2.9780, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 164, Loss: 2.9374, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 165, Loss: 3.2380, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 166, Loss: 3.0849, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 167, Loss: 2.9477, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 168, Loss: 3.0671, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 169, Loss: 3.1077, Train: 1.0000, Val: 0.7540, Test: 0.7780
Epoch: 170, Loss: 3.1081, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 171, Loss: 3.0653, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 172, Loss: 3.0504, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 173, Loss: 3.1783, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 174, Loss: 3.2312, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 175, Loss: 3.0941, Train: 1.0000, Val: 0.7600, Test: 0.7750
Epoch: 176, Loss: 3.2986, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 177, Loss: 3.1220, Train: 1.0000, Val: 0.7680, Test: 0.7790
Epoch: 178, Loss: 3.2623, Train: 1.0000, Val: 0.7700, Test: 0.7810
Epoch: 179, Loss: 3.1069, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 180, Loss: 2.8520, Train: 1.0000, Val: 0.7740, Test: 0.7820
Epoch: 181, Loss: 2.8450, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 182, Loss: 3.0096, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 183, Loss: 3.0455, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 184, Loss: 2.9589, Train: 1.0000, Val: 0.7660, Test: 0.7820
Epoch: 185, Loss: 3.5803, Train: 1.0000, Val: 0.7660, Test: 0.7820
Epoch: 186, Loss: 2.8866, Train: 1.0000, Val: 0.7660, Test: 0.7810
Epoch: 187, Loss: 2.9582, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 188, Loss: 3.0937, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 189, Loss: 2.7264, Train: 1.0000, Val: 0.7680, Test: 0.7800
Epoch: 190, Loss: 3.2134, Train: 1.0000, Val: 0.7700, Test: 0.7790
Epoch: 191, Loss: 3.0861, Train: 1.0000, Val: 0.7740, Test: 0.7770
Epoch: 192, Loss: 3.2059, Train: 1.0000, Val: 0.7680, Test: 0.7770
Epoch: 193, Loss: 3.1261, Train: 1.0000, Val: 0.7700, Test: 0.7760
Epoch: 194, Loss: 3.0824, Train: 1.0000, Val: 0.7700, Test: 0.7760
Epoch: 195, Loss: 2.9889, Train: 1.0000, Val: 0.7680, Test: 0.7760
Epoch: 196, Loss: 2.8115, Train: 1.0000, Val: 0.7680, Test: 0.7760
Epoch: 197, Loss: 3.0273, Train: 1.0000, Val: 0.7660, Test: 0.7780
Epoch: 198, Loss: 3.0513, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 199, Loss: 3.1505, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 200, Loss: 3.0249, Train: 1.0000, Val: 0.7600, Test: 0.7810
MAD:  0.4923
Best Test Accuracy: 0.7870, Val Accuracy: 0.7680, Train Accuracy: 1.0000
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8741, Train: 0.0357, Val: 0.0400, Test: 0.0450
Epoch: 2, Loss: 4.8484, Train: 0.1571, Val: 0.1080, Test: 0.1060
Epoch: 3, Loss: 4.7748, Train: 0.3857, Val: 0.1860, Test: 0.1850
Epoch: 4, Loss: 4.6726, Train: 0.5143, Val: 0.2660, Test: 0.2570
Epoch: 5, Loss: 4.5251, Train: 0.5929, Val: 0.3040, Test: 0.2970
Epoch: 6, Loss: 4.5084, Train: 0.6357, Val: 0.3200, Test: 0.3380
Epoch: 7, Loss: 4.6254, Train: 0.6857, Val: 0.3280, Test: 0.3590
Epoch: 8, Loss: 4.3753, Train: 0.7071, Val: 0.3560, Test: 0.3850
Epoch: 9, Loss: 4.2998, Train: 0.7143, Val: 0.3700, Test: 0.3980
Epoch: 10, Loss: 4.1321, Train: 0.7286, Val: 0.3800, Test: 0.4110
Epoch: 11, Loss: 4.3793, Train: 0.7571, Val: 0.3860, Test: 0.4130
Epoch: 12, Loss: 4.0863, Train: 0.7857, Val: 0.4060, Test: 0.4170
Epoch: 13, Loss: 4.0937, Train: 0.8214, Val: 0.4060, Test: 0.4350
Epoch: 14, Loss: 4.4229, Train: 0.8357, Val: 0.4240, Test: 0.4560
Epoch: 15, Loss: 3.9734, Train: 0.8929, Val: 0.4560, Test: 0.4790
Epoch: 16, Loss: 3.8040, Train: 0.9500, Val: 0.4820, Test: 0.5150
Epoch: 17, Loss: 3.6548, Train: 0.9571, Val: 0.5280, Test: 0.5520
Epoch: 18, Loss: 3.9762, Train: 0.9786, Val: 0.5780, Test: 0.6060
Epoch: 19, Loss: 3.8301, Train: 0.9786, Val: 0.6260, Test: 0.6490
Epoch: 20, Loss: 3.8142, Train: 0.9929, Val: 0.6520, Test: 0.6830
Epoch: 21, Loss: 3.5929, Train: 0.9929, Val: 0.6800, Test: 0.7110
Epoch: 22, Loss: 3.7747, Train: 0.9929, Val: 0.6860, Test: 0.7270
Epoch: 23, Loss: 3.8891, Train: 0.9929, Val: 0.7040, Test: 0.7350
Epoch: 24, Loss: 3.7020, Train: 0.9929, Val: 0.7200, Test: 0.7440
Epoch: 25, Loss: 3.6225, Train: 0.9929, Val: 0.7160, Test: 0.7440
Epoch: 26, Loss: 3.6732, Train: 0.9929, Val: 0.7120, Test: 0.7470
Epoch: 27, Loss: 3.5251, Train: 0.9929, Val: 0.7080, Test: 0.7400
Epoch: 28, Loss: 3.7274, Train: 0.9929, Val: 0.7120, Test: 0.7340
Epoch: 29, Loss: 3.6202, Train: 0.9929, Val: 0.7020, Test: 0.7320
Epoch: 30, Loss: 3.5658, Train: 0.9929, Val: 0.7020, Test: 0.7350
Epoch: 31, Loss: 3.7156, Train: 0.9929, Val: 0.7000, Test: 0.7350
Epoch: 32, Loss: 3.4561, Train: 0.9929, Val: 0.7000, Test: 0.7330
Epoch: 33, Loss: 3.6097, Train: 0.9929, Val: 0.6980, Test: 0.7340
Epoch: 34, Loss: 3.4510, Train: 0.9929, Val: 0.7020, Test: 0.7350
Epoch: 35, Loss: 3.6405, Train: 0.9929, Val: 0.7060, Test: 0.7370
Epoch: 36, Loss: 3.4915, Train: 0.9929, Val: 0.7100, Test: 0.7370
Epoch: 37, Loss: 3.6315, Train: 0.9929, Val: 0.7120, Test: 0.7350
Epoch: 38, Loss: 3.5311, Train: 0.9929, Val: 0.7160, Test: 0.7340
Epoch: 39, Loss: 3.6842, Train: 1.0000, Val: 0.7140, Test: 0.7330
Epoch: 40, Loss: 3.3672, Train: 1.0000, Val: 0.7160, Test: 0.7340
Epoch: 41, Loss: 3.4506, Train: 1.0000, Val: 0.7240, Test: 0.7390
Epoch: 42, Loss: 3.3725, Train: 1.0000, Val: 0.7280, Test: 0.7410
Epoch: 43, Loss: 3.6359, Train: 1.0000, Val: 0.7300, Test: 0.7450
Epoch: 44, Loss: 3.7000, Train: 1.0000, Val: 0.7380, Test: 0.7480
Epoch: 45, Loss: 3.4493, Train: 1.0000, Val: 0.7420, Test: 0.7490
Epoch: 46, Loss: 3.5433, Train: 1.0000, Val: 0.7460, Test: 0.7480
Epoch: 47, Loss: 3.4375, Train: 1.0000, Val: 0.7440, Test: 0.7500
Epoch: 48, Loss: 3.5700, Train: 1.0000, Val: 0.7460, Test: 0.7540
Epoch: 49, Loss: 3.3216, Train: 1.0000, Val: 0.7500, Test: 0.7590
Epoch: 50, Loss: 3.3381, Train: 1.0000, Val: 0.7480, Test: 0.7560
Epoch: 51, Loss: 3.4864, Train: 1.0000, Val: 0.7480, Test: 0.7560
Epoch: 52, Loss: 3.3450, Train: 1.0000, Val: 0.7520, Test: 0.7570
Epoch: 53, Loss: 3.3117, Train: 1.0000, Val: 0.7520, Test: 0.7590
Epoch: 54, Loss: 3.4687, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 55, Loss: 2.9962, Train: 1.0000, Val: 0.7480, Test: 0.7620
Epoch: 56, Loss: 3.5100, Train: 1.0000, Val: 0.7460, Test: 0.7630
Epoch: 57, Loss: 3.5703, Train: 1.0000, Val: 0.7480, Test: 0.7630
Epoch: 58, Loss: 3.0952, Train: 1.0000, Val: 0.7460, Test: 0.7620
Epoch: 59, Loss: 3.4478, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 60, Loss: 3.3971, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 61, Loss: 3.0744, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 62, Loss: 3.2680, Train: 1.0000, Val: 0.7480, Test: 0.7620
Epoch: 63, Loss: 3.1536, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 64, Loss: 2.9829, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 65, Loss: 3.6676, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 66, Loss: 3.1811, Train: 1.0000, Val: 0.7480, Test: 0.7650
Epoch: 67, Loss: 3.3357, Train: 1.0000, Val: 0.7460, Test: 0.7620
Epoch: 68, Loss: 3.1195, Train: 1.0000, Val: 0.7440, Test: 0.7610
Epoch: 69, Loss: 3.3806, Train: 1.0000, Val: 0.7480, Test: 0.7590
Epoch: 70, Loss: 3.4713, Train: 1.0000, Val: 0.7480, Test: 0.7570
Epoch: 71, Loss: 3.4165, Train: 1.0000, Val: 0.7420, Test: 0.7580
Epoch: 72, Loss: 3.4490, Train: 1.0000, Val: 0.7500, Test: 0.7590
Epoch: 73, Loss: 3.0911, Train: 1.0000, Val: 0.7520, Test: 0.7600
Epoch: 74, Loss: 3.1695, Train: 1.0000, Val: 0.7520, Test: 0.7600
Epoch: 75, Loss: 3.1719, Train: 1.0000, Val: 0.7500, Test: 0.7590
Epoch: 76, Loss: 3.2788, Train: 1.0000, Val: 0.7500, Test: 0.7630
Epoch: 77, Loss: 2.7934, Train: 1.0000, Val: 0.7520, Test: 0.7680
Epoch: 78, Loss: 3.0931, Train: 1.0000, Val: 0.7540, Test: 0.7690
Epoch: 79, Loss: 3.2324, Train: 1.0000, Val: 0.7600, Test: 0.7700
Epoch: 80, Loss: 3.2524, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 81, Loss: 3.6363, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 82, Loss: 3.3530, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 83, Loss: 3.0917, Train: 1.0000, Val: 0.7600, Test: 0.7720
Epoch: 84, Loss: 3.2092, Train: 1.0000, Val: 0.7600, Test: 0.7730
Epoch: 85, Loss: 3.3222, Train: 1.0000, Val: 0.7660, Test: 0.7750
Epoch: 86, Loss: 3.1289, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 87, Loss: 3.3692, Train: 1.0000, Val: 0.7700, Test: 0.7770
Epoch: 88, Loss: 3.2933, Train: 1.0000, Val: 0.7740, Test: 0.7770
Epoch: 89, Loss: 3.2040, Train: 1.0000, Val: 0.7720, Test: 0.7770
Epoch: 90, Loss: 3.1617, Train: 1.0000, Val: 0.7740, Test: 0.7790
Epoch: 91, Loss: 3.0233, Train: 1.0000, Val: 0.7720, Test: 0.7800
Epoch: 92, Loss: 3.2712, Train: 1.0000, Val: 0.7700, Test: 0.7790
Epoch: 93, Loss: 3.4217, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 94, Loss: 2.9660, Train: 1.0000, Val: 0.7640, Test: 0.7800
Epoch: 95, Loss: 3.1617, Train: 1.0000, Val: 0.7640, Test: 0.7800
Epoch: 96, Loss: 3.1146, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 97, Loss: 3.5218, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 98, Loss: 3.4560, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 99, Loss: 3.0259, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 100, Loss: 3.1369, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 101, Loss: 3.6026, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 102, Loss: 3.1679, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 103, Loss: 3.2815, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 104, Loss: 3.3566, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 105, Loss: 3.1530, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 106, Loss: 2.7752, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 107, Loss: 3.2911, Train: 1.0000, Val: 0.7600, Test: 0.7750
Epoch: 108, Loss: 3.0500, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 109, Loss: 3.2625, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 110, Loss: 3.4758, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 111, Loss: 2.9676, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 112, Loss: 3.2629, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 113, Loss: 3.0176, Train: 1.0000, Val: 0.7560, Test: 0.7700
Epoch: 114, Loss: 3.1547, Train: 1.0000, Val: 0.7540, Test: 0.7670
Epoch: 115, Loss: 2.9550, Train: 1.0000, Val: 0.7560, Test: 0.7670
Epoch: 116, Loss: 3.1911, Train: 1.0000, Val: 0.7580, Test: 0.7690
Epoch: 117, Loss: 3.1963, Train: 1.0000, Val: 0.7520, Test: 0.7670
Epoch: 118, Loss: 2.8404, Train: 1.0000, Val: 0.7540, Test: 0.7690
Epoch: 119, Loss: 3.3853, Train: 1.0000, Val: 0.7520, Test: 0.7690
Epoch: 120, Loss: 3.2654, Train: 1.0000, Val: 0.7520, Test: 0.7690
Epoch: 121, Loss: 3.2897, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 122, Loss: 3.0382, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 123, Loss: 3.3540, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 124, Loss: 3.1342, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 125, Loss: 3.3175, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 126, Loss: 2.8193, Train: 1.0000, Val: 0.7500, Test: 0.7750
Epoch: 127, Loss: 3.4675, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 128, Loss: 3.0389, Train: 1.0000, Val: 0.7540, Test: 0.7770
Epoch: 129, Loss: 3.1567, Train: 1.0000, Val: 0.7560, Test: 0.7750
Epoch: 130, Loss: 3.1646, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 131, Loss: 3.0397, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 132, Loss: 2.8955, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 133, Loss: 3.0752, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 134, Loss: 3.1472, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 135, Loss: 3.0943, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 136, Loss: 3.2093, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 137, Loss: 3.3144, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 138, Loss: 2.8093, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 139, Loss: 2.7569, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 140, Loss: 3.1032, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 141, Loss: 3.1013, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 142, Loss: 3.3013, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 143, Loss: 3.3801, Train: 1.0000, Val: 0.7660, Test: 0.7810
Epoch: 144, Loss: 2.9321, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 145, Loss: 3.0896, Train: 1.0000, Val: 0.7660, Test: 0.7780
Epoch: 146, Loss: 3.1567, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 147, Loss: 3.0353, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 148, Loss: 2.6510, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 149, Loss: 2.7480, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 150, Loss: 2.8343, Train: 1.0000, Val: 0.7620, Test: 0.7780
Epoch: 151, Loss: 3.3936, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 152, Loss: 3.2367, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 153, Loss: 3.2299, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 154, Loss: 3.3226, Train: 1.0000, Val: 0.7580, Test: 0.7820
Epoch: 155, Loss: 3.2651, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 156, Loss: 3.1586, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 157, Loss: 3.2950, Train: 1.0000, Val: 0.7580, Test: 0.7720
Epoch: 158, Loss: 3.2698, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 159, Loss: 3.0822, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 160, Loss: 2.8572, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 161, Loss: 2.7241, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 162, Loss: 2.7877, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 163, Loss: 2.9769, Train: 1.0000, Val: 0.7560, Test: 0.7710
Epoch: 164, Loss: 3.0884, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 165, Loss: 3.1655, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 166, Loss: 3.0937, Train: 1.0000, Val: 0.7480, Test: 0.7740
Epoch: 167, Loss: 3.0757, Train: 1.0000, Val: 0.7500, Test: 0.7740
Epoch: 168, Loss: 2.9800, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 169, Loss: 2.9603, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 170, Loss: 3.0427, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 171, Loss: 2.8752, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 172, Loss: 3.2309, Train: 1.0000, Val: 0.7540, Test: 0.7740
Epoch: 173, Loss: 2.9177, Train: 1.0000, Val: 0.7560, Test: 0.7750
Epoch: 174, Loss: 2.9609, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 175, Loss: 2.8701, Train: 1.0000, Val: 0.7600, Test: 0.7750
Epoch: 176, Loss: 3.1546, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 177, Loss: 3.0489, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 178, Loss: 3.1934, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 179, Loss: 3.1170, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 180, Loss: 3.3136, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 181, Loss: 2.9240, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 182, Loss: 3.2942, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 183, Loss: 2.8755, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 184, Loss: 3.0620, Train: 1.0000, Val: 0.7680, Test: 0.7740
Epoch: 185, Loss: 2.8383, Train: 1.0000, Val: 0.7660, Test: 0.7740
Epoch: 186, Loss: 2.9713, Train: 1.0000, Val: 0.7660, Test: 0.7730
Epoch: 187, Loss: 3.0220, Train: 1.0000, Val: 0.7680, Test: 0.7760
Epoch: 188, Loss: 3.1064, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 189, Loss: 3.1006, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 190, Loss: 3.4095, Train: 1.0000, Val: 0.7660, Test: 0.7740
Epoch: 191, Loss: 2.9470, Train: 1.0000, Val: 0.7680, Test: 0.7720
Epoch: 192, Loss: 3.1752, Train: 1.0000, Val: 0.7660, Test: 0.7670
Epoch: 193, Loss: 2.8168, Train: 1.0000, Val: 0.7620, Test: 0.7680
Epoch: 194, Loss: 3.1684, Train: 1.0000, Val: 0.7600, Test: 0.7650
Epoch: 195, Loss: 2.7263, Train: 1.0000, Val: 0.7600, Test: 0.7660
Epoch: 196, Loss: 3.0061, Train: 1.0000, Val: 0.7620, Test: 0.7660
Epoch: 197, Loss: 3.2274, Train: 1.0000, Val: 0.7600, Test: 0.7620
Epoch: 198, Loss: 3.0901, Train: 1.0000, Val: 0.7600, Test: 0.7600
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 199, Loss: 3.0200, Train: 1.0000, Val: 0.7580, Test: 0.7580
Epoch: 200, Loss: 2.9451, Train: 1.0000, Val: 0.7540, Test: 0.7550
MAD:  0.4124
Best Test Accuracy: 0.7900, Val Accuracy: 0.7660, Train Accuracy: 1.0000
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8647, Train: 0.0786, Val: 0.0320, Test: 0.0400
Epoch: 2, Loss: 4.8505, Train: 0.2857, Val: 0.1000, Test: 0.1020
Epoch: 3, Loss: 4.7691, Train: 0.3929, Val: 0.1880, Test: 0.1640
Epoch: 4, Loss: 4.6479, Train: 0.4643, Val: 0.2340, Test: 0.2120
Epoch: 5, Loss: 4.6345, Train: 0.5286, Val: 0.2540, Test: 0.2500
Epoch: 6, Loss: 4.4802, Train: 0.5643, Val: 0.2760, Test: 0.2730
Epoch: 7, Loss: 4.4661, Train: 0.5929, Val: 0.2800, Test: 0.2890
Epoch: 8, Loss: 4.2380, Train: 0.6429, Val: 0.2980, Test: 0.3120
Epoch: 9, Loss: 4.3055, Train: 0.7286, Val: 0.3200, Test: 0.3290
Epoch: 10, Loss: 4.4355, Train: 0.7643, Val: 0.3760, Test: 0.3750
Epoch: 11, Loss: 4.1594, Train: 0.8500, Val: 0.4340, Test: 0.4300
Epoch: 12, Loss: 4.2232, Train: 0.8929, Val: 0.5000, Test: 0.4890
Epoch: 13, Loss: 4.0380, Train: 0.9357, Val: 0.5580, Test: 0.5360
Epoch: 14, Loss: 4.2719, Train: 0.9500, Val: 0.5940, Test: 0.5820
Epoch: 15, Loss: 3.6644, Train: 0.9571, Val: 0.6180, Test: 0.6320
Epoch: 16, Loss: 3.9707, Train: 0.9714, Val: 0.6620, Test: 0.6550
Epoch: 17, Loss: 4.1013, Train: 0.9786, Val: 0.6860, Test: 0.6820
Epoch: 18, Loss: 3.7486, Train: 0.9786, Val: 0.6940, Test: 0.6960
Epoch: 19, Loss: 3.7273, Train: 0.9786, Val: 0.6940, Test: 0.7050
Epoch: 20, Loss: 3.6530, Train: 0.9786, Val: 0.7000, Test: 0.7120
Epoch: 21, Loss: 3.9451, Train: 0.9786, Val: 0.7060, Test: 0.7150
Epoch: 22, Loss: 3.9633, Train: 0.9786, Val: 0.7060, Test: 0.7160
Epoch: 23, Loss: 3.7127, Train: 0.9786, Val: 0.7080, Test: 0.7180
Epoch: 24, Loss: 4.1733, Train: 0.9786, Val: 0.7040, Test: 0.7210
Epoch: 25, Loss: 3.9817, Train: 0.9786, Val: 0.7060, Test: 0.7310
Epoch: 26, Loss: 3.1677, Train: 0.9857, Val: 0.7100, Test: 0.7410
Epoch: 27, Loss: 3.6392, Train: 0.9857, Val: 0.7140, Test: 0.7400
Epoch: 28, Loss: 3.6682, Train: 0.9929, Val: 0.7100, Test: 0.7460
Epoch: 29, Loss: 3.1336, Train: 0.9929, Val: 0.7140, Test: 0.7470
Epoch: 30, Loss: 3.7043, Train: 0.9929, Val: 0.7160, Test: 0.7500
Epoch: 31, Loss: 3.5196, Train: 0.9929, Val: 0.7180, Test: 0.7510
Epoch: 32, Loss: 3.7642, Train: 0.9929, Val: 0.7360, Test: 0.7570
Epoch: 33, Loss: 3.6303, Train: 0.9929, Val: 0.7420, Test: 0.7580
Epoch: 34, Loss: 3.5474, Train: 0.9929, Val: 0.7440, Test: 0.7630
Epoch: 35, Loss: 3.5126, Train: 0.9929, Val: 0.7560, Test: 0.7710
Epoch: 36, Loss: 3.4717, Train: 1.0000, Val: 0.7560, Test: 0.7710
Epoch: 37, Loss: 3.3948, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 38, Loss: 3.5842, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 39, Loss: 3.6387, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 40, Loss: 3.6186, Train: 1.0000, Val: 0.7540, Test: 0.7760
Epoch: 41, Loss: 3.3127, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 42, Loss: 3.3252, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 43, Loss: 3.3444, Train: 1.0000, Val: 0.7540, Test: 0.7770
Epoch: 44, Loss: 3.1939, Train: 1.0000, Val: 0.7560, Test: 0.7750
Epoch: 45, Loss: 3.5224, Train: 1.0000, Val: 0.7520, Test: 0.7750
Epoch: 46, Loss: 3.4786, Train: 1.0000, Val: 0.7540, Test: 0.7770
Epoch: 47, Loss: 3.3788, Train: 1.0000, Val: 0.7540, Test: 0.7810
Epoch: 48, Loss: 3.3656, Train: 1.0000, Val: 0.7520, Test: 0.7790
Epoch: 49, Loss: 3.4071, Train: 1.0000, Val: 0.7540, Test: 0.7760
Epoch: 50, Loss: 3.2774, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 51, Loss: 3.4252, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 52, Loss: 3.3130, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 53, Loss: 3.3700, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 54, Loss: 3.3776, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 55, Loss: 3.3854, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 56, Loss: 3.3739, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 57, Loss: 3.0838, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 58, Loss: 3.1254, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 59, Loss: 3.5086, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 60, Loss: 3.3581, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 61, Loss: 3.2722, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 62, Loss: 3.2789, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 63, Loss: 3.4468, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 64, Loss: 3.1817, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 65, Loss: 2.9984, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 66, Loss: 3.3062, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 67, Loss: 3.3908, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 68, Loss: 3.4672, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 69, Loss: 3.5112, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 70, Loss: 2.9811, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 71, Loss: 3.2982, Train: 1.0000, Val: 0.7680, Test: 0.7820
Epoch: 72, Loss: 3.4138, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 73, Loss: 3.0814, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 74, Loss: 3.5974, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 75, Loss: 3.1772, Train: 1.0000, Val: 0.7640, Test: 0.7750
Epoch: 76, Loss: 3.1901, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 77, Loss: 3.3127, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 78, Loss: 3.2555, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 79, Loss: 3.2968, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 80, Loss: 2.7370, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 81, Loss: 2.8920, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 82, Loss: 3.3536, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 83, Loss: 3.3324, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 84, Loss: 3.2207, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 85, Loss: 3.3653, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 86, Loss: 3.3824, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 87, Loss: 3.0208, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 88, Loss: 3.0879, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 89, Loss: 3.2212, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 90, Loss: 3.1467, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 91, Loss: 3.3260, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 92, Loss: 3.0717, Train: 1.0000, Val: 0.7620, Test: 0.7700
Epoch: 93, Loss: 3.2432, Train: 1.0000, Val: 0.7620, Test: 0.7700
Epoch: 94, Loss: 3.3107, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 95, Loss: 3.2696, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 96, Loss: 3.6721, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 97, Loss: 3.1613, Train: 1.0000, Val: 0.7640, Test: 0.7750
Epoch: 98, Loss: 3.0536, Train: 1.0000, Val: 0.7640, Test: 0.7730
Epoch: 99, Loss: 3.1989, Train: 1.0000, Val: 0.7640, Test: 0.7750
Epoch: 100, Loss: 2.9521, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 101, Loss: 3.1869, Train: 1.0000, Val: 0.7620, Test: 0.7740
Epoch: 102, Loss: 3.3420, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 103, Loss: 3.0501, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 104, Loss: 3.2230, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 105, Loss: 3.0698, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 106, Loss: 3.1463, Train: 1.0000, Val: 0.7560, Test: 0.7800
Epoch: 107, Loss: 2.9247, Train: 1.0000, Val: 0.7540, Test: 0.7810
Epoch: 108, Loss: 3.0896, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 109, Loss: 3.4251, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 110, Loss: 3.0884, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 111, Loss: 3.0121, Train: 1.0000, Val: 0.7520, Test: 0.7670
Epoch: 112, Loss: 3.2291, Train: 1.0000, Val: 0.7540, Test: 0.7660
Epoch: 113, Loss: 3.0535, Train: 1.0000, Val: 0.7560, Test: 0.7660
Epoch: 114, Loss: 3.0077, Train: 1.0000, Val: 0.7580, Test: 0.7700
Epoch: 115, Loss: 3.0898, Train: 1.0000, Val: 0.7580, Test: 0.7700
Epoch: 116, Loss: 2.7556, Train: 1.0000, Val: 0.7580, Test: 0.7730
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 117, Loss: 3.1838, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 118, Loss: 3.2218, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 119, Loss: 3.2782, Train: 1.0000, Val: 0.7540, Test: 0.7740
Epoch: 120, Loss: 3.4147, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 121, Loss: 3.0586, Train: 1.0000, Val: 0.7580, Test: 0.7700
Epoch: 122, Loss: 2.8551, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 123, Loss: 3.0638, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 124, Loss: 3.0594, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 125, Loss: 2.8046, Train: 1.0000, Val: 0.7560, Test: 0.7740
Epoch: 126, Loss: 3.3791, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 127, Loss: 2.9067, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 128, Loss: 3.2095, Train: 1.0000, Val: 0.7480, Test: 0.7660
Epoch: 129, Loss: 3.2448, Train: 1.0000, Val: 0.7540, Test: 0.7640
Epoch: 130, Loss: 3.0844, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 131, Loss: 2.9062, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 132, Loss: 3.3301, Train: 1.0000, Val: 0.7540, Test: 0.7610
Epoch: 133, Loss: 2.6060, Train: 1.0000, Val: 0.7480, Test: 0.7570
Epoch: 134, Loss: 2.9120, Train: 1.0000, Val: 0.7500, Test: 0.7600
Epoch: 135, Loss: 3.2937, Train: 1.0000, Val: 0.7460, Test: 0.7620
Epoch: 136, Loss: 3.1030, Train: 1.0000, Val: 0.7460, Test: 0.7610
Epoch: 137, Loss: 2.8244, Train: 1.0000, Val: 0.7460, Test: 0.7590
Epoch: 138, Loss: 3.4100, Train: 1.0000, Val: 0.7460, Test: 0.7590
Epoch: 139, Loss: 3.1979, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 140, Loss: 3.1917, Train: 1.0000, Val: 0.7480, Test: 0.7630
Epoch: 141, Loss: 3.1103, Train: 1.0000, Val: 0.7500, Test: 0.7630
Epoch: 142, Loss: 2.9499, Train: 1.0000, Val: 0.7520, Test: 0.7620
Epoch: 143, Loss: 3.4506, Train: 1.0000, Val: 0.7540, Test: 0.7660
Epoch: 144, Loss: 3.2894, Train: 1.0000, Val: 0.7580, Test: 0.7640
Epoch: 145, Loss: 2.8743, Train: 1.0000, Val: 0.7600, Test: 0.7610
Epoch: 146, Loss: 3.0815, Train: 1.0000, Val: 0.7580, Test: 0.7650
Epoch: 147, Loss: 3.4619, Train: 1.0000, Val: 0.7560, Test: 0.7630
Epoch: 148, Loss: 3.1093, Train: 1.0000, Val: 0.7540, Test: 0.7650
Epoch: 149, Loss: 2.9765, Train: 1.0000, Val: 0.7540, Test: 0.7680
Epoch: 150, Loss: 2.8784, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 151, Loss: 3.3059, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 152, Loss: 2.9712, Train: 1.0000, Val: 0.7560, Test: 0.7700
Epoch: 153, Loss: 3.0719, Train: 1.0000, Val: 0.7560, Test: 0.7700
Epoch: 154, Loss: 3.0527, Train: 1.0000, Val: 0.7580, Test: 0.7690
Epoch: 155, Loss: 2.9579, Train: 1.0000, Val: 0.7560, Test: 0.7690
Epoch: 156, Loss: 3.0170, Train: 1.0000, Val: 0.7540, Test: 0.7680
Epoch: 157, Loss: 3.0325, Train: 1.0000, Val: 0.7560, Test: 0.7670
Epoch: 158, Loss: 2.9311, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 159, Loss: 3.6013, Train: 1.0000, Val: 0.7520, Test: 0.7650
Epoch: 160, Loss: 3.1421, Train: 1.0000, Val: 0.7540, Test: 0.7650
Epoch: 161, Loss: 2.6877, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 162, Loss: 3.4091, Train: 1.0000, Val: 0.7560, Test: 0.7660
Epoch: 163, Loss: 3.1366, Train: 1.0000, Val: 0.7560, Test: 0.7660
Epoch: 164, Loss: 3.0572, Train: 1.0000, Val: 0.7540, Test: 0.7650
Epoch: 165, Loss: 3.4217, Train: 1.0000, Val: 0.7520, Test: 0.7660
Epoch: 166, Loss: 3.0737, Train: 1.0000, Val: 0.7460, Test: 0.7670
Epoch: 167, Loss: 2.8997, Train: 1.0000, Val: 0.7480, Test: 0.7680
Epoch: 168, Loss: 3.1502, Train: 1.0000, Val: 0.7560, Test: 0.7690
Epoch: 169, Loss: 2.9112, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 170, Loss: 2.7515, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 171, Loss: 3.0925, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 172, Loss: 2.6592, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 173, Loss: 2.9265, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 174, Loss: 3.1179, Train: 1.0000, Val: 0.7460, Test: 0.7670
Epoch: 175, Loss: 3.2802, Train: 1.0000, Val: 0.7460, Test: 0.7670
Epoch: 176, Loss: 3.2582, Train: 1.0000, Val: 0.7460, Test: 0.7660
Epoch: 177, Loss: 3.0036, Train: 1.0000, Val: 0.7480, Test: 0.7660
Epoch: 178, Loss: 3.3177, Train: 1.0000, Val: 0.7480, Test: 0.7640
Epoch: 179, Loss: 2.9718, Train: 1.0000, Val: 0.7500, Test: 0.7640
Epoch: 180, Loss: 3.1684, Train: 1.0000, Val: 0.7500, Test: 0.7640
Epoch: 181, Loss: 3.3217, Train: 1.0000, Val: 0.7500, Test: 0.7650
Epoch: 182, Loss: 3.1789, Train: 1.0000, Val: 0.7520, Test: 0.7640
Epoch: 183, Loss: 3.1748, Train: 1.0000, Val: 0.7500, Test: 0.7650
Epoch: 184, Loss: 2.7520, Train: 1.0000, Val: 0.7500, Test: 0.7670
Epoch: 185, Loss: 3.5834, Train: 1.0000, Val: 0.7500, Test: 0.7670
Epoch: 186, Loss: 3.1622, Train: 1.0000, Val: 0.7520, Test: 0.7660
Epoch: 187, Loss: 2.8940, Train: 1.0000, Val: 0.7520, Test: 0.7640
Epoch: 188, Loss: 3.2741, Train: 1.0000, Val: 0.7540, Test: 0.7650
Epoch: 189, Loss: 2.9041, Train: 1.0000, Val: 0.7560, Test: 0.7640
Epoch: 190, Loss: 3.2707, Train: 1.0000, Val: 0.7560, Test: 0.7630
Epoch: 191, Loss: 3.2629, Train: 1.0000, Val: 0.7580, Test: 0.7630
Epoch: 192, Loss: 3.1223, Train: 1.0000, Val: 0.7540, Test: 0.7620
Epoch: 193, Loss: 2.7485, Train: 1.0000, Val: 0.7520, Test: 0.7630
Epoch: 194, Loss: 3.3275, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 195, Loss: 3.0185, Train: 1.0000, Val: 0.7520, Test: 0.7640
Epoch: 196, Loss: 2.9237, Train: 1.0000, Val: 0.7480, Test: 0.7630
Epoch: 197, Loss: 3.2014, Train: 1.0000, Val: 0.7460, Test: 0.7630
Epoch: 198, Loss: 3.0503, Train: 1.0000, Val: 0.7460, Test: 0.7640
Epoch: 199, Loss: 2.9890, Train: 1.0000, Val: 0.7460, Test: 0.7630
Epoch: 200, Loss: 2.6997, Train: 1.0000, Val: 0.7460, Test: 0.7640
MAD:  0.49
Best Test Accuracy: 0.7870, Val Accuracy: 0.7680, Train Accuracy: 1.0000
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8690, Train: 0.0929, Val: 0.0260, Test: 0.0410
Epoch: 2, Loss: 4.8236, Train: 0.2571, Val: 0.0940, Test: 0.1050
Epoch: 3, Loss: 4.7388, Train: 0.3714, Val: 0.1600, Test: 0.1660
Epoch: 4, Loss: 4.6621, Train: 0.4714, Val: 0.2220, Test: 0.2130
Epoch: 5, Loss: 4.5803, Train: 0.5500, Val: 0.2660, Test: 0.2620
Epoch: 6, Loss: 4.4286, Train: 0.6143, Val: 0.3220, Test: 0.3010
Epoch: 7, Loss: 4.2608, Train: 0.6643, Val: 0.3540, Test: 0.3520
Epoch: 8, Loss: 4.2604, Train: 0.7143, Val: 0.4080, Test: 0.4080
Epoch: 9, Loss: 4.0873, Train: 0.8143, Val: 0.4600, Test: 0.4640
Epoch: 10, Loss: 4.2397, Train: 0.8357, Val: 0.5080, Test: 0.5140
Epoch: 11, Loss: 4.2550, Train: 0.8857, Val: 0.5460, Test: 0.5500
Epoch: 12, Loss: 3.9789, Train: 0.9143, Val: 0.5660, Test: 0.5820
Epoch: 13, Loss: 3.9483, Train: 0.9500, Val: 0.5840, Test: 0.6160
Epoch: 14, Loss: 3.8385, Train: 0.9571, Val: 0.6020, Test: 0.6360
Epoch: 15, Loss: 3.8992, Train: 0.9786, Val: 0.6520, Test: 0.6630
Epoch: 16, Loss: 4.1590, Train: 0.9786, Val: 0.6720, Test: 0.6800
Epoch: 17, Loss: 3.8896, Train: 0.9786, Val: 0.6960, Test: 0.7120
Epoch: 18, Loss: 3.8851, Train: 0.9786, Val: 0.7000, Test: 0.7160
Epoch: 19, Loss: 3.8168, Train: 0.9857, Val: 0.7000, Test: 0.7190
Epoch: 20, Loss: 3.9372, Train: 0.9857, Val: 0.7020, Test: 0.7170
Epoch: 21, Loss: 3.9787, Train: 0.9857, Val: 0.7040, Test: 0.7140
Epoch: 22, Loss: 3.8426, Train: 0.9857, Val: 0.7100, Test: 0.7150
Epoch: 23, Loss: 3.6970, Train: 0.9857, Val: 0.7140, Test: 0.7210
Epoch: 24, Loss: 3.6254, Train: 0.9857, Val: 0.7180, Test: 0.7220
Epoch: 25, Loss: 3.6812, Train: 0.9929, Val: 0.7160, Test: 0.7240
Epoch: 26, Loss: 3.5247, Train: 0.9929, Val: 0.7260, Test: 0.7330
Epoch: 27, Loss: 3.7612, Train: 0.9929, Val: 0.7360, Test: 0.7440
Epoch: 28, Loss: 3.5824, Train: 0.9929, Val: 0.7420, Test: 0.7500
Epoch: 29, Loss: 3.2615, Train: 0.9929, Val: 0.7520, Test: 0.7580
Epoch: 30, Loss: 3.5355, Train: 0.9929, Val: 0.7600, Test: 0.7660
Epoch: 31, Loss: 3.6289, Train: 0.9929, Val: 0.7620, Test: 0.7710
Epoch: 32, Loss: 3.8016, Train: 0.9929, Val: 0.7640, Test: 0.7730
Epoch: 33, Loss: 3.5014, Train: 0.9929, Val: 0.7620, Test: 0.7800
Epoch: 34, Loss: 3.6245, Train: 0.9929, Val: 0.7680, Test: 0.7840
Epoch: 35, Loss: 3.3989, Train: 0.9929, Val: 0.7680, Test: 0.7830
Epoch: 36, Loss: 3.6114, Train: 0.9929, Val: 0.7660, Test: 0.7880
Epoch: 37, Loss: 3.5321, Train: 0.9929, Val: 0.7740, Test: 0.7910
Epoch: 38, Loss: 3.5352, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 39, Loss: 3.2686, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 40, Loss: 3.2366, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 41, Loss: 3.5705, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 42, Loss: 3.4912, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 43, Loss: 3.7006, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 44, Loss: 3.6055, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 45, Loss: 3.3973, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 46, Loss: 3.4513, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 47, Loss: 3.4869, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 48, Loss: 3.3012, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 49, Loss: 3.4549, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 50, Loss: 3.1697, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 51, Loss: 3.5240, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 52, Loss: 3.3157, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 53, Loss: 3.3714, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 54, Loss: 3.3002, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 55, Loss: 3.0718, Train: 1.0000, Val: 0.7640, Test: 0.7800
Epoch: 56, Loss: 3.1912, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 57, Loss: 3.2575, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 58, Loss: 3.5607, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 59, Loss: 3.0051, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 60, Loss: 3.2586, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 61, Loss: 3.3111, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 62, Loss: 2.9399, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 63, Loss: 3.1781, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 64, Loss: 3.3166, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 65, Loss: 3.1067, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 66, Loss: 3.6253, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 67, Loss: 3.3035, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 68, Loss: 3.2068, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 69, Loss: 3.1214, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 70, Loss: 3.1340, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 71, Loss: 3.3386, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 72, Loss: 3.3927, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 73, Loss: 3.3928, Train: 1.0000, Val: 0.7600, Test: 0.7750
Epoch: 74, Loss: 3.2557, Train: 1.0000, Val: 0.7540, Test: 0.7750
Epoch: 75, Loss: 3.2298, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 76, Loss: 2.7325, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 77, Loss: 3.5703, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 78, Loss: 3.1202, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 79, Loss: 3.4457, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 80, Loss: 3.1627, Train: 1.0000, Val: 0.7480, Test: 0.7680
Epoch: 81, Loss: 3.2628, Train: 1.0000, Val: 0.7500, Test: 0.7660
Epoch: 82, Loss: 3.1136, Train: 1.0000, Val: 0.7500, Test: 0.7650
Epoch: 83, Loss: 3.3024, Train: 1.0000, Val: 0.7500, Test: 0.7640
Epoch: 84, Loss: 3.2035, Train: 1.0000, Val: 0.7520, Test: 0.7650
Epoch: 85, Loss: 3.4924, Train: 1.0000, Val: 0.7560, Test: 0.7660
Epoch: 86, Loss: 2.9486, Train: 1.0000, Val: 0.7560, Test: 0.7640
Epoch: 87, Loss: 3.0896, Train: 1.0000, Val: 0.7560, Test: 0.7640
Epoch: 88, Loss: 3.1200, Train: 1.0000, Val: 0.7580, Test: 0.7650
Epoch: 89, Loss: 3.1261, Train: 1.0000, Val: 0.7580, Test: 0.7630
Epoch: 90, Loss: 3.2099, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 91, Loss: 3.1079, Train: 1.0000, Val: 0.7560, Test: 0.7690
Epoch: 92, Loss: 3.3645, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 93, Loss: 2.7983, Train: 1.0000, Val: 0.7600, Test: 0.7730
Epoch: 94, Loss: 3.1614, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 95, Loss: 3.2697, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 96, Loss: 3.1268, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 97, Loss: 3.2040, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 98, Loss: 3.5298, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 99, Loss: 3.3444, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 100, Loss: 2.9057, Train: 1.0000, Val: 0.7640, Test: 0.7730
Epoch: 101, Loss: 3.0754, Train: 1.0000, Val: 0.7580, Test: 0.7720
Epoch: 102, Loss: 3.1872, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 103, Loss: 3.2460, Train: 1.0000, Val: 0.7500, Test: 0.7740
Epoch: 104, Loss: 3.2962, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 105, Loss: 3.0597, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 106, Loss: 3.0210, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 107, Loss: 2.9144, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 108, Loss: 3.3373, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 109, Loss: 3.3098, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 110, Loss: 2.9543, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 111, Loss: 3.1113, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 112, Loss: 3.2725, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 113, Loss: 3.2466, Train: 1.0000, Val: 0.7540, Test: 0.7690
Epoch: 114, Loss: 3.1731, Train: 1.0000, Val: 0.7500, Test: 0.7720
Epoch: 115, Loss: 3.0359, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 116, Loss: 3.2443, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 117, Loss: 2.9966, Train: 1.0000, Val: 0.7620, Test: 0.7690
Epoch: 118, Loss: 3.3080, Train: 1.0000, Val: 0.7620, Test: 0.7680
Epoch: 119, Loss: 3.4729, Train: 1.0000, Val: 0.7620, Test: 0.7690
Epoch: 120, Loss: 3.1612, Train: 1.0000, Val: 0.7600, Test: 0.7670
Epoch: 121, Loss: 3.1739, Train: 1.0000, Val: 0.7640, Test: 0.7670
Epoch: 122, Loss: 2.8753, Train: 1.0000, Val: 0.7640, Test: 0.7680
Epoch: 123, Loss: 3.0163, Train: 1.0000, Val: 0.7660, Test: 0.7690
Epoch: 124, Loss: 3.1656, Train: 1.0000, Val: 0.7640, Test: 0.7690
Epoch: 125, Loss: 3.2485, Train: 1.0000, Val: 0.7620, Test: 0.7690
Epoch: 126, Loss: 3.0673, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 127, Loss: 3.0459, Train: 1.0000, Val: 0.7560, Test: 0.7700
Epoch: 128, Loss: 3.1097, Train: 1.0000, Val: 0.7560, Test: 0.7690
Epoch: 129, Loss: 3.1633, Train: 1.0000, Val: 0.7560, Test: 0.7680
Epoch: 130, Loss: 2.9990, Train: 1.0000, Val: 0.7560, Test: 0.7670
Epoch: 131, Loss: 2.9162, Train: 1.0000, Val: 0.7580, Test: 0.7660
Epoch: 132, Loss: 3.0920, Train: 1.0000, Val: 0.7580, Test: 0.7660
Epoch: 133, Loss: 3.3397, Train: 1.0000, Val: 0.7580, Test: 0.7670
Epoch: 134, Loss: 3.1950, Train: 1.0000, Val: 0.7600, Test: 0.7660
Epoch: 135, Loss: 3.0569, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 136, Loss: 3.1073, Train: 1.0000, Val: 0.7540, Test: 0.7680
Epoch: 137, Loss: 3.0310, Train: 1.0000, Val: 0.7540, Test: 0.7670
Epoch: 138, Loss: 2.9522, Train: 1.0000, Val: 0.7560, Test: 0.7670
Epoch: 139, Loss: 3.0336, Train: 1.0000, Val: 0.7580, Test: 0.7660
Epoch: 140, Loss: 2.9217, Train: 1.0000, Val: 0.7600, Test: 0.7660
Epoch: 141, Loss: 3.2400, Train: 1.0000, Val: 0.7660, Test: 0.7680
Epoch: 142, Loss: 2.8295, Train: 1.0000, Val: 0.7640, Test: 0.7690
Epoch: 143, Loss: 3.0625, Train: 1.0000, Val: 0.7640, Test: 0.7700
Epoch: 144, Loss: 3.1248, Train: 1.0000, Val: 0.7600, Test: 0.7700
Epoch: 145, Loss: 2.8728, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 146, Loss: 3.2809, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 147, Loss: 2.8620, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 148, Loss: 3.2262, Train: 1.0000, Val: 0.7580, Test: 0.7690
Epoch: 149, Loss: 3.1377, Train: 1.0000, Val: 0.7560, Test: 0.7700
Epoch: 150, Loss: 3.0039, Train: 1.0000, Val: 0.7560, Test: 0.7690
Epoch: 151, Loss: 3.2136, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 152, Loss: 3.3468, Train: 1.0000, Val: 0.7600, Test: 0.7730
Epoch: 153, Loss: 3.0425, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 154, Loss: 2.9806, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 155, Loss: 3.0435, Train: 1.0000, Val: 0.7640, Test: 0.7730
Epoch: 156, Loss: 3.0523, Train: 1.0000, Val: 0.7640, Test: 0.7720
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 157, Loss: 3.1454, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 158, Loss: 3.0869, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 159, Loss: 3.0568, Train: 1.0000, Val: 0.7660, Test: 0.7720
Epoch: 160, Loss: 3.3307, Train: 1.0000, Val: 0.7580, Test: 0.7690
Epoch: 161, Loss: 3.0506, Train: 1.0000, Val: 0.7600, Test: 0.7680
Epoch: 162, Loss: 3.1134, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 163, Loss: 2.6744, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 164, Loss: 3.0973, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 165, Loss: 3.0540, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 166, Loss: 3.0525, Train: 1.0000, Val: 0.7600, Test: 0.7720
Epoch: 167, Loss: 3.0730, Train: 1.0000, Val: 0.7600, Test: 0.7720
Epoch: 168, Loss: 3.1224, Train: 1.0000, Val: 0.7580, Test: 0.7720
Epoch: 169, Loss: 3.2113, Train: 1.0000, Val: 0.7580, Test: 0.7700
Epoch: 170, Loss: 3.0103, Train: 1.0000, Val: 0.7600, Test: 0.7700
Epoch: 171, Loss: 3.0077, Train: 1.0000, Val: 0.7620, Test: 0.7700
Epoch: 172, Loss: 2.8332, Train: 1.0000, Val: 0.7660, Test: 0.7700
Epoch: 173, Loss: 2.8839, Train: 1.0000, Val: 0.7660, Test: 0.7710
Epoch: 174, Loss: 3.3380, Train: 1.0000, Val: 0.7660, Test: 0.7720
Epoch: 175, Loss: 3.0629, Train: 1.0000, Val: 0.7660, Test: 0.7710
Epoch: 176, Loss: 2.9641, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 177, Loss: 3.4621, Train: 1.0000, Val: 0.7640, Test: 0.7700
Epoch: 178, Loss: 2.8911, Train: 1.0000, Val: 0.7640, Test: 0.7690
Epoch: 179, Loss: 3.0117, Train: 1.0000, Val: 0.7640, Test: 0.7690
Epoch: 180, Loss: 2.7129, Train: 1.0000, Val: 0.7640, Test: 0.7670
Epoch: 181, Loss: 2.8945, Train: 1.0000, Val: 0.7600, Test: 0.7670
Epoch: 182, Loss: 3.4459, Train: 1.0000, Val: 0.7580, Test: 0.7650
Epoch: 183, Loss: 3.1987, Train: 1.0000, Val: 0.7580, Test: 0.7650
Epoch: 184, Loss: 2.9960, Train: 1.0000, Val: 0.7580, Test: 0.7660
Epoch: 185, Loss: 3.3231, Train: 1.0000, Val: 0.7580, Test: 0.7660
Epoch: 186, Loss: 2.9067, Train: 1.0000, Val: 0.7640, Test: 0.7650
Epoch: 187, Loss: 3.0501, Train: 1.0000, Val: 0.7580, Test: 0.7660
Epoch: 188, Loss: 3.2256, Train: 1.0000, Val: 0.7580, Test: 0.7670
Epoch: 189, Loss: 3.0171, Train: 1.0000, Val: 0.7640, Test: 0.7650
Epoch: 190, Loss: 3.1635, Train: 1.0000, Val: 0.7640, Test: 0.7690
Epoch: 191, Loss: 2.9366, Train: 1.0000, Val: 0.7640, Test: 0.7700
Epoch: 192, Loss: 3.1057, Train: 1.0000, Val: 0.7680, Test: 0.7700
Epoch: 193, Loss: 2.6777, Train: 1.0000, Val: 0.7680, Test: 0.7690
Epoch: 194, Loss: 3.0372, Train: 1.0000, Val: 0.7660, Test: 0.7700
Epoch: 195, Loss: 3.1191, Train: 1.0000, Val: 0.7640, Test: 0.7700
Epoch: 196, Loss: 3.0315, Train: 1.0000, Val: 0.7620, Test: 0.7690
Epoch: 197, Loss: 2.8907, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 198, Loss: 3.0965, Train: 1.0000, Val: 0.7580, Test: 0.7680
Epoch: 199, Loss: 3.3092, Train: 1.0000, Val: 0.7540, Test: 0.7640
Epoch: 200, Loss: 3.0422, Train: 1.0000, Val: 0.7560, Test: 0.7620
MAD:  0.4428
Best Test Accuracy: 0.7930, Val Accuracy: 0.7780, Train Accuracy: 1.0000
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8919, Train: 0.0786, Val: 0.0320, Test: 0.0270
Epoch: 2, Loss: 4.8311, Train: 0.1857, Val: 0.0960, Test: 0.0850
Epoch: 3, Loss: 4.8216, Train: 0.3214, Val: 0.1640, Test: 0.1540
Epoch: 4, Loss: 4.6409, Train: 0.3929, Val: 0.2000, Test: 0.1900
Epoch: 5, Loss: 4.5808, Train: 0.4643, Val: 0.2100, Test: 0.2190
Epoch: 6, Loss: 4.3950, Train: 0.5000, Val: 0.2180, Test: 0.2320
Epoch: 7, Loss: 4.4455, Train: 0.5429, Val: 0.2400, Test: 0.2470
Epoch: 8, Loss: 4.4991, Train: 0.5714, Val: 0.2800, Test: 0.2820
Epoch: 9, Loss: 4.3520, Train: 0.6357, Val: 0.3240, Test: 0.3260
Epoch: 10, Loss: 4.3510, Train: 0.7214, Val: 0.3780, Test: 0.3830
Epoch: 11, Loss: 4.3597, Train: 0.7929, Val: 0.4520, Test: 0.4410
Epoch: 12, Loss: 4.1379, Train: 0.8429, Val: 0.5280, Test: 0.5030
Epoch: 13, Loss: 3.9366, Train: 0.8857, Val: 0.5920, Test: 0.5560
Epoch: 14, Loss: 4.0639, Train: 0.9286, Val: 0.6480, Test: 0.6200
Epoch: 15, Loss: 3.9916, Train: 0.9429, Val: 0.6780, Test: 0.6730
Epoch: 16, Loss: 3.9415, Train: 0.9571, Val: 0.7100, Test: 0.7060
Epoch: 17, Loss: 3.9088, Train: 0.9643, Val: 0.7320, Test: 0.7280
Epoch: 18, Loss: 3.8200, Train: 0.9571, Val: 0.7320, Test: 0.7360
Epoch: 19, Loss: 3.8019, Train: 0.9786, Val: 0.7280, Test: 0.7380
Epoch: 20, Loss: 3.7428, Train: 0.9857, Val: 0.7260, Test: 0.7330
Epoch: 21, Loss: 3.7921, Train: 0.9857, Val: 0.7260, Test: 0.7320
Epoch: 22, Loss: 3.8096, Train: 0.9857, Val: 0.7240, Test: 0.7310
Epoch: 23, Loss: 3.8921, Train: 0.9857, Val: 0.7200, Test: 0.7330
Epoch: 24, Loss: 3.8842, Train: 0.9857, Val: 0.7240, Test: 0.7300
Epoch: 25, Loss: 3.7871, Train: 0.9857, Val: 0.7360, Test: 0.7340
Epoch: 26, Loss: 3.7535, Train: 0.9857, Val: 0.7400, Test: 0.7410
Epoch: 27, Loss: 3.7668, Train: 0.9857, Val: 0.7460, Test: 0.7440
Epoch: 28, Loss: 3.8084, Train: 0.9857, Val: 0.7420, Test: 0.7440
Epoch: 29, Loss: 3.5121, Train: 0.9857, Val: 0.7480, Test: 0.7480
Epoch: 30, Loss: 3.8083, Train: 0.9929, Val: 0.7520, Test: 0.7560
Epoch: 31, Loss: 3.5485, Train: 0.9929, Val: 0.7620, Test: 0.7650
Epoch: 32, Loss: 3.7218, Train: 0.9929, Val: 0.7640, Test: 0.7710
Epoch: 33, Loss: 3.5398, Train: 0.9929, Val: 0.7660, Test: 0.7750
Epoch: 34, Loss: 3.7447, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 35, Loss: 3.4541, Train: 1.0000, Val: 0.7680, Test: 0.7800
Epoch: 36, Loss: 3.6311, Train: 1.0000, Val: 0.7660, Test: 0.7800
Epoch: 37, Loss: 3.8184, Train: 1.0000, Val: 0.7660, Test: 0.7810
Epoch: 38, Loss: 3.5474, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 39, Loss: 3.5099, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 40, Loss: 3.2356, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 41, Loss: 3.2572, Train: 1.0000, Val: 0.7740, Test: 0.7820
Epoch: 42, Loss: 3.6477, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 43, Loss: 3.3808, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 44, Loss: 3.1298, Train: 1.0000, Val: 0.7720, Test: 0.7790
Epoch: 45, Loss: 3.3864, Train: 1.0000, Val: 0.7720, Test: 0.7750
Epoch: 46, Loss: 3.5378, Train: 1.0000, Val: 0.7700, Test: 0.7740
Epoch: 47, Loss: 3.3301, Train: 1.0000, Val: 0.7680, Test: 0.7700
Epoch: 48, Loss: 3.3584, Train: 1.0000, Val: 0.7600, Test: 0.7700
Epoch: 49, Loss: 4.0552, Train: 1.0000, Val: 0.7540, Test: 0.7680
Epoch: 50, Loss: 3.2760, Train: 1.0000, Val: 0.7520, Test: 0.7680
Epoch: 51, Loss: 3.4845, Train: 1.0000, Val: 0.7500, Test: 0.7690
Epoch: 52, Loss: 3.2683, Train: 1.0000, Val: 0.7480, Test: 0.7680
Epoch: 53, Loss: 3.5761, Train: 1.0000, Val: 0.7460, Test: 0.7730
Epoch: 54, Loss: 3.6294, Train: 1.0000, Val: 0.7480, Test: 0.7790
Epoch: 55, Loss: 3.2408, Train: 1.0000, Val: 0.7520, Test: 0.7810
Epoch: 56, Loss: 3.1972, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 57, Loss: 2.7554, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 58, Loss: 3.5292, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 59, Loss: 3.1465, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 60, Loss: 3.4357, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 61, Loss: 3.2429, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 62, Loss: 3.4604, Train: 1.0000, Val: 0.7600, Test: 0.7860
Epoch: 63, Loss: 3.1102, Train: 1.0000, Val: 0.7600, Test: 0.7870
Epoch: 64, Loss: 3.4138, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 65, Loss: 3.3506, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 66, Loss: 3.3568, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 67, Loss: 3.4295, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 68, Loss: 3.3130, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 69, Loss: 3.2680, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 70, Loss: 3.3731, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 71, Loss: 3.1608, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 72, Loss: 3.0822, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 73, Loss: 3.2322, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 74, Loss: 3.3958, Train: 1.0000, Val: 0.7720, Test: 0.7870
Epoch: 75, Loss: 3.1985, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 76, Loss: 2.9459, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 77, Loss: 2.9254, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 78, Loss: 3.2960, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 79, Loss: 3.2057, Train: 1.0000, Val: 0.7720, Test: 0.7830
Epoch: 80, Loss: 3.3203, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 81, Loss: 3.6991, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 82, Loss: 3.5282, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 83, Loss: 3.2222, Train: 1.0000, Val: 0.7680, Test: 0.7830
Epoch: 84, Loss: 3.3660, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 85, Loss: 3.1636, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 86, Loss: 3.0771, Train: 1.0000, Val: 0.7540, Test: 0.7830
Epoch: 87, Loss: 3.2079, Train: 1.0000, Val: 0.7540, Test: 0.7840
Epoch: 88, Loss: 2.7874, Train: 1.0000, Val: 0.7540, Test: 0.7830
Epoch: 89, Loss: 2.9915, Train: 1.0000, Val: 0.7520, Test: 0.7830
Epoch: 90, Loss: 3.2265, Train: 1.0000, Val: 0.7520, Test: 0.7850
Epoch: 91, Loss: 3.1136, Train: 1.0000, Val: 0.7540, Test: 0.7830
Epoch: 92, Loss: 3.1532, Train: 1.0000, Val: 0.7580, Test: 0.7830
Epoch: 93, Loss: 3.1923, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 94, Loss: 3.3666, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 95, Loss: 3.2675, Train: 1.0000, Val: 0.7580, Test: 0.7860
Epoch: 96, Loss: 3.0983, Train: 1.0000, Val: 0.7560, Test: 0.7840
Epoch: 97, Loss: 3.3542, Train: 1.0000, Val: 0.7540, Test: 0.7830
Epoch: 98, Loss: 3.0156, Train: 1.0000, Val: 0.7520, Test: 0.7840
Epoch: 99, Loss: 3.2524, Train: 1.0000, Val: 0.7560, Test: 0.7860
Epoch: 100, Loss: 3.1792, Train: 1.0000, Val: 0.7560, Test: 0.7850
Epoch: 101, Loss: 3.3608, Train: 1.0000, Val: 0.7560, Test: 0.7850
Epoch: 102, Loss: 3.0821, Train: 1.0000, Val: 0.7500, Test: 0.7860
Epoch: 103, Loss: 3.2046, Train: 1.0000, Val: 0.7500, Test: 0.7860
Epoch: 104, Loss: 3.1230, Train: 1.0000, Val: 0.7500, Test: 0.7840
Epoch: 105, Loss: 3.2274, Train: 1.0000, Val: 0.7520, Test: 0.7850
Epoch: 106, Loss: 3.2238, Train: 1.0000, Val: 0.7500, Test: 0.7840
Epoch: 107, Loss: 3.1441, Train: 1.0000, Val: 0.7500, Test: 0.7860
Epoch: 108, Loss: 3.2968, Train: 1.0000, Val: 0.7500, Test: 0.7840
Epoch: 109, Loss: 3.3917, Train: 1.0000, Val: 0.7540, Test: 0.7820
Epoch: 110, Loss: 3.0344, Train: 1.0000, Val: 0.7520, Test: 0.7810
Epoch: 111, Loss: 3.2542, Train: 1.0000, Val: 0.7520, Test: 0.7810
Epoch: 112, Loss: 3.1435, Train: 1.0000, Val: 0.7540, Test: 0.7810
Epoch: 113, Loss: 2.8316, Train: 1.0000, Val: 0.7540, Test: 0.7790
Epoch: 114, Loss: 3.2929, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 115, Loss: 3.1962, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 116, Loss: 2.7900, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 117, Loss: 2.6885, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 118, Loss: 3.1125, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 119, Loss: 3.1469, Train: 1.0000, Val: 0.7560, Test: 0.7810
Epoch: 120, Loss: 2.9659, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 121, Loss: 3.2557, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 122, Loss: 3.4371, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 123, Loss: 3.0177, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 124, Loss: 3.2478, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 125, Loss: 2.7480, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 126, Loss: 2.9729, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 127, Loss: 3.0625, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 128, Loss: 2.9989, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 129, Loss: 3.4033, Train: 1.0000, Val: 0.7560, Test: 0.7750
Epoch: 130, Loss: 3.1269, Train: 1.0000, Val: 0.7540, Test: 0.7750
Epoch: 131, Loss: 3.0989, Train: 1.0000, Val: 0.7600, Test: 0.7750
Epoch: 132, Loss: 3.0745, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 133, Loss: 3.2369, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 134, Loss: 3.0650, Train: 1.0000, Val: 0.7480, Test: 0.7810
Epoch: 135, Loss: 3.0701, Train: 1.0000, Val: 0.7520, Test: 0.7810
Epoch: 136, Loss: 3.0566, Train: 1.0000, Val: 0.7560, Test: 0.7820
Epoch: 137, Loss: 2.9743, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 138, Loss: 2.9979, Train: 1.0000, Val: 0.7540, Test: 0.7850
Epoch: 139, Loss: 3.4277, Train: 1.0000, Val: 0.7500, Test: 0.7850
Epoch: 140, Loss: 3.2769, Train: 1.0000, Val: 0.7480, Test: 0.7870
Epoch: 141, Loss: 3.2327, Train: 1.0000, Val: 0.7480, Test: 0.7850
Epoch: 142, Loss: 3.2579, Train: 1.0000, Val: 0.7460, Test: 0.7840
Epoch: 143, Loss: 2.8221, Train: 1.0000, Val: 0.7480, Test: 0.7850
Epoch: 144, Loss: 3.0049, Train: 1.0000, Val: 0.7460, Test: 0.7830
Epoch: 145, Loss: 3.3672, Train: 1.0000, Val: 0.7460, Test: 0.7800
Epoch: 146, Loss: 3.1167, Train: 1.0000, Val: 0.7500, Test: 0.7790
Epoch: 147, Loss: 3.0599, Train: 1.0000, Val: 0.7540, Test: 0.7790
Epoch: 148, Loss: 3.0336, Train: 1.0000, Val: 0.7540, Test: 0.7770
Epoch: 149, Loss: 2.9578, Train: 1.0000, Val: 0.7520, Test: 0.7750
Epoch: 150, Loss: 2.8763, Train: 1.0000, Val: 0.7520, Test: 0.7750
Epoch: 151, Loss: 3.1171, Train: 1.0000, Val: 0.7500, Test: 0.7770
Epoch: 152, Loss: 2.6187, Train: 1.0000, Val: 0.7540, Test: 0.7780
Epoch: 153, Loss: 3.0179, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 154, Loss: 2.9992, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 155, Loss: 3.1623, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 156, Loss: 2.7285, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 157, Loss: 2.7248, Train: 1.0000, Val: 0.7540, Test: 0.7750
Epoch: 158, Loss: 3.2653, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 159, Loss: 3.0561, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 160, Loss: 2.9502, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 161, Loss: 2.8529, Train: 1.0000, Val: 0.7620, Test: 0.7780
Epoch: 162, Loss: 3.0102, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 163, Loss: 3.3580, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 164, Loss: 3.1786, Train: 1.0000, Val: 0.7500, Test: 0.7720
Epoch: 165, Loss: 3.2428, Train: 1.0000, Val: 0.7500, Test: 0.7720
Epoch: 166, Loss: 2.9968, Train: 1.0000, Val: 0.7480, Test: 0.7720
Epoch: 167, Loss: 3.1084, Train: 1.0000, Val: 0.7460, Test: 0.7710
Epoch: 168, Loss: 3.0275, Train: 1.0000, Val: 0.7480, Test: 0.7710
Epoch: 169, Loss: 3.0743, Train: 1.0000, Val: 0.7480, Test: 0.7710
Epoch: 170, Loss: 2.7767, Train: 1.0000, Val: 0.7500, Test: 0.7740
Epoch: 171, Loss: 3.1738, Train: 1.0000, Val: 0.7500, Test: 0.7740
Epoch: 172, Loss: 3.1660, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 173, Loss: 2.8762, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 174, Loss: 2.8502, Train: 1.0000, Val: 0.7500, Test: 0.7750
Epoch: 175, Loss: 3.1493, Train: 1.0000, Val: 0.7500, Test: 0.7730
Epoch: 176, Loss: 2.5713, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 177, Loss: 3.0143, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 178, Loss: 3.3410, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 179, Loss: 3.2698, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 180, Loss: 2.8927, Train: 1.0000, Val: 0.7520, Test: 0.7740
Epoch: 181, Loss: 2.9669, Train: 1.0000, Val: 0.7520, Test: 0.7750
Epoch: 182, Loss: 2.7964, Train: 1.0000, Val: 0.7540, Test: 0.7750
Epoch: 183, Loss: 2.8751, Train: 1.0000, Val: 0.7520, Test: 0.7790
Epoch: 184, Loss: 2.9381, Train: 1.0000, Val: 0.7500, Test: 0.7770
Epoch: 185, Loss: 2.9419, Train: 1.0000, Val: 0.7480, Test: 0.7780
Epoch: 186, Loss: 3.0622, Train: 1.0000, Val: 0.7500, Test: 0.7790
Epoch: 187, Loss: 2.8407, Train: 1.0000, Val: 0.7500, Test: 0.7750
Epoch: 188, Loss: 3.3801, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 189, Loss: 2.5572, Train: 1.0000, Val: 0.7500, Test: 0.7790
Epoch: 190, Loss: 2.9137, Train: 1.0000, Val: 0.7520, Test: 0.7780
Epoch: 191, Loss: 3.1531, Train: 1.0000, Val: 0.7520, Test: 0.7770
Epoch: 192, Loss: 2.9286, Train: 1.0000, Val: 0.7500, Test: 0.7780
Epoch: 193, Loss: 2.9227, Train: 1.0000, Val: 0.7500, Test: 0.7780
Epoch: 194, Loss: 3.0373, Train: 1.0000, Val: 0.7500, Test: 0.7770
Epoch: 195, Loss: 2.9090, Train: 1.0000, Val: 0.7560, Test: 0.7770
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 196, Loss: 3.0327, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 197, Loss: 2.7391, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 198, Loss: 3.1136, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 199, Loss: 2.7387, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 200, Loss: 3.2641, Train: 1.0000, Val: 0.7600, Test: 0.7790
MAD:  0.4876
Best Test Accuracy: 0.7890, Val Accuracy: 0.7620, Train Accuracy: 1.0000
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8129, Train: 0.1857, Val: 0.0920, Test: 0.1050
Epoch: 2, Loss: 4.7388, Train: 0.3571, Val: 0.1980, Test: 0.2050
Epoch: 3, Loss: 4.7048, Train: 0.5143, Val: 0.3020, Test: 0.2960
Epoch: 4, Loss: 4.5898, Train: 0.5714, Val: 0.3880, Test: 0.3700
Epoch: 5, Loss: 4.5542, Train: 0.6357, Val: 0.4240, Test: 0.4250
Epoch: 6, Loss: 4.3868, Train: 0.6786, Val: 0.4480, Test: 0.4610
Epoch: 7, Loss: 4.3586, Train: 0.7571, Val: 0.4920, Test: 0.5040
Epoch: 8, Loss: 4.3377, Train: 0.8000, Val: 0.5400, Test: 0.5390
Epoch: 9, Loss: 4.2719, Train: 0.8214, Val: 0.5820, Test: 0.5630
Epoch: 10, Loss: 4.1765, Train: 0.8286, Val: 0.6060, Test: 0.5970
Epoch: 11, Loss: 4.2778, Train: 0.8571, Val: 0.6160, Test: 0.6230
Epoch: 12, Loss: 4.1056, Train: 0.8714, Val: 0.6340, Test: 0.6440
Epoch: 13, Loss: 3.9799, Train: 0.8857, Val: 0.6600, Test: 0.6710
Epoch: 14, Loss: 3.7229, Train: 0.9214, Val: 0.6820, Test: 0.6920
Epoch: 15, Loss: 4.1843, Train: 0.9500, Val: 0.6940, Test: 0.6990
Epoch: 16, Loss: 4.1264, Train: 0.9643, Val: 0.7080, Test: 0.7150
Epoch: 17, Loss: 3.9006, Train: 0.9786, Val: 0.7200, Test: 0.7240
Epoch: 18, Loss: 3.7914, Train: 0.9857, Val: 0.7160, Test: 0.7300
Epoch: 19, Loss: 3.6359, Train: 0.9929, Val: 0.7340, Test: 0.7270
Epoch: 20, Loss: 3.6148, Train: 1.0000, Val: 0.7400, Test: 0.7250
Epoch: 21, Loss: 3.8577, Train: 1.0000, Val: 0.7440, Test: 0.7370
Epoch: 22, Loss: 3.4383, Train: 1.0000, Val: 0.7520, Test: 0.7450
Epoch: 23, Loss: 3.8188, Train: 1.0000, Val: 0.7560, Test: 0.7580
Epoch: 24, Loss: 3.6304, Train: 1.0000, Val: 0.7580, Test: 0.7620
Epoch: 25, Loss: 3.7096, Train: 1.0000, Val: 0.7620, Test: 0.7610
Epoch: 26, Loss: 3.7938, Train: 1.0000, Val: 0.7600, Test: 0.7640
Epoch: 27, Loss: 3.7162, Train: 1.0000, Val: 0.7620, Test: 0.7650
Epoch: 28, Loss: 3.9512, Train: 1.0000, Val: 0.7640, Test: 0.7670
Epoch: 29, Loss: 3.9439, Train: 1.0000, Val: 0.7640, Test: 0.7690
Epoch: 30, Loss: 3.6216, Train: 1.0000, Val: 0.7680, Test: 0.7750
Epoch: 31, Loss: 3.4679, Train: 1.0000, Val: 0.7720, Test: 0.7740
Epoch: 32, Loss: 3.7387, Train: 1.0000, Val: 0.7740, Test: 0.7740
Epoch: 33, Loss: 3.4874, Train: 1.0000, Val: 0.7740, Test: 0.7750
Epoch: 34, Loss: 3.4318, Train: 1.0000, Val: 0.7700, Test: 0.7780
Epoch: 35, Loss: 3.5216, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 36, Loss: 3.5011, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 37, Loss: 3.4838, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 38, Loss: 3.3853, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 39, Loss: 3.3322, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 40, Loss: 3.3362, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 41, Loss: 3.3388, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 42, Loss: 3.3386, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 43, Loss: 3.4183, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 44, Loss: 3.4054, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 45, Loss: 3.2760, Train: 1.0000, Val: 0.7660, Test: 0.7800
Epoch: 46, Loss: 3.3962, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 47, Loss: 3.6479, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 48, Loss: 3.5294, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 49, Loss: 3.7291, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 50, Loss: 3.2726, Train: 1.0000, Val: 0.7700, Test: 0.7810
Epoch: 51, Loss: 3.6621, Train: 1.0000, Val: 0.7720, Test: 0.7820
Epoch: 52, Loss: 3.3426, Train: 1.0000, Val: 0.7760, Test: 0.7810
Epoch: 53, Loss: 3.1299, Train: 1.0000, Val: 0.7780, Test: 0.7800
Epoch: 54, Loss: 3.2940, Train: 1.0000, Val: 0.7780, Test: 0.7840
Epoch: 55, Loss: 3.3202, Train: 1.0000, Val: 0.7780, Test: 0.7810
Epoch: 56, Loss: 3.3844, Train: 1.0000, Val: 0.7760, Test: 0.7800
Epoch: 57, Loss: 3.2570, Train: 1.0000, Val: 0.7780, Test: 0.7800
Epoch: 58, Loss: 3.4810, Train: 1.0000, Val: 0.7760, Test: 0.7750
Epoch: 59, Loss: 3.1825, Train: 1.0000, Val: 0.7780, Test: 0.7760
Epoch: 60, Loss: 2.8901, Train: 1.0000, Val: 0.7760, Test: 0.7780
Epoch: 61, Loss: 3.4147, Train: 1.0000, Val: 0.7720, Test: 0.7780
Epoch: 62, Loss: 3.1137, Train: 1.0000, Val: 0.7700, Test: 0.7810
Epoch: 63, Loss: 3.2319, Train: 1.0000, Val: 0.7700, Test: 0.7810
Epoch: 64, Loss: 3.2245, Train: 1.0000, Val: 0.7720, Test: 0.7800
Epoch: 65, Loss: 3.1680, Train: 1.0000, Val: 0.7720, Test: 0.7790
Epoch: 66, Loss: 3.0557, Train: 1.0000, Val: 0.7740, Test: 0.7810
Epoch: 67, Loss: 3.1741, Train: 1.0000, Val: 0.7720, Test: 0.7810
Epoch: 68, Loss: 3.4272, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 69, Loss: 3.1574, Train: 1.0000, Val: 0.7720, Test: 0.7800
Epoch: 70, Loss: 3.4523, Train: 1.0000, Val: 0.7700, Test: 0.7780
Epoch: 71, Loss: 3.2968, Train: 1.0000, Val: 0.7700, Test: 0.7810
Epoch: 72, Loss: 3.0275, Train: 1.0000, Val: 0.7740, Test: 0.7810
Epoch: 73, Loss: 3.1941, Train: 1.0000, Val: 0.7720, Test: 0.7800
Epoch: 74, Loss: 3.0132, Train: 1.0000, Val: 0.7740, Test: 0.7800
Epoch: 75, Loss: 3.1454, Train: 1.0000, Val: 0.7720, Test: 0.7790
Epoch: 76, Loss: 3.1387, Train: 1.0000, Val: 0.7720, Test: 0.7800
Epoch: 77, Loss: 3.4343, Train: 1.0000, Val: 0.7700, Test: 0.7800
Epoch: 78, Loss: 3.2562, Train: 1.0000, Val: 0.7720, Test: 0.7810
Epoch: 79, Loss: 3.1953, Train: 1.0000, Val: 0.7740, Test: 0.7810
Epoch: 80, Loss: 3.3917, Train: 1.0000, Val: 0.7740, Test: 0.7800
Epoch: 81, Loss: 3.0678, Train: 1.0000, Val: 0.7740, Test: 0.7800
Epoch: 82, Loss: 3.1075, Train: 1.0000, Val: 0.7740, Test: 0.7790
Epoch: 83, Loss: 3.2229, Train: 1.0000, Val: 0.7700, Test: 0.7780
Epoch: 84, Loss: 3.1846, Train: 1.0000, Val: 0.7700, Test: 0.7770
Epoch: 85, Loss: 2.9273, Train: 1.0000, Val: 0.7700, Test: 0.7780
Epoch: 86, Loss: 3.2050, Train: 1.0000, Val: 0.7740, Test: 0.7780
Epoch: 87, Loss: 3.3423, Train: 1.0000, Val: 0.7720, Test: 0.7780
Epoch: 88, Loss: 3.2833, Train: 1.0000, Val: 0.7720, Test: 0.7750
Epoch: 89, Loss: 3.2348, Train: 1.0000, Val: 0.7700, Test: 0.7760
Epoch: 90, Loss: 3.4827, Train: 1.0000, Val: 0.7680, Test: 0.7750
Epoch: 91, Loss: 3.4112, Train: 1.0000, Val: 0.7680, Test: 0.7740
Epoch: 92, Loss: 2.9950, Train: 1.0000, Val: 0.7700, Test: 0.7730
Epoch: 93, Loss: 3.2667, Train: 1.0000, Val: 0.7700, Test: 0.7720
Epoch: 94, Loss: 3.2875, Train: 1.0000, Val: 0.7720, Test: 0.7720
Epoch: 95, Loss: 3.1506, Train: 1.0000, Val: 0.7720, Test: 0.7720
Epoch: 96, Loss: 3.1785, Train: 1.0000, Val: 0.7720, Test: 0.7750
Epoch: 97, Loss: 3.0167, Train: 1.0000, Val: 0.7720, Test: 0.7750
Epoch: 98, Loss: 3.3344, Train: 1.0000, Val: 0.7720, Test: 0.7740
Epoch: 99, Loss: 3.0416, Train: 1.0000, Val: 0.7720, Test: 0.7750
Epoch: 100, Loss: 3.1687, Train: 1.0000, Val: 0.7700, Test: 0.7730
Epoch: 101, Loss: 3.1242, Train: 1.0000, Val: 0.7660, Test: 0.7710
Epoch: 102, Loss: 2.6992, Train: 1.0000, Val: 0.7680, Test: 0.7680
Epoch: 103, Loss: 3.2379, Train: 1.0000, Val: 0.7680, Test: 0.7680
Epoch: 104, Loss: 3.0253, Train: 1.0000, Val: 0.7660, Test: 0.7670
Epoch: 105, Loss: 3.2884, Train: 1.0000, Val: 0.7660, Test: 0.7680
Epoch: 106, Loss: 3.1839, Train: 1.0000, Val: 0.7640, Test: 0.7680
Epoch: 107, Loss: 3.2476, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 108, Loss: 3.1125, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 109, Loss: 3.5328, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 110, Loss: 3.3859, Train: 1.0000, Val: 0.7700, Test: 0.7720
Epoch: 111, Loss: 2.6321, Train: 1.0000, Val: 0.7720, Test: 0.7720
Epoch: 112, Loss: 3.2409, Train: 1.0000, Val: 0.7720, Test: 0.7720
Epoch: 113, Loss: 3.2136, Train: 1.0000, Val: 0.7720, Test: 0.7720
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 114, Loss: 2.9569, Train: 1.0000, Val: 0.7680, Test: 0.7720
Epoch: 115, Loss: 3.3835, Train: 1.0000, Val: 0.7680, Test: 0.7730
Epoch: 116, Loss: 3.3573, Train: 1.0000, Val: 0.7680, Test: 0.7730
Epoch: 117, Loss: 3.1634, Train: 1.0000, Val: 0.7720, Test: 0.7730
Epoch: 118, Loss: 3.1803, Train: 1.0000, Val: 0.7700, Test: 0.7730
Epoch: 119, Loss: 3.1670, Train: 1.0000, Val: 0.7700, Test: 0.7730
Epoch: 120, Loss: 3.2510, Train: 1.0000, Val: 0.7740, Test: 0.7730
Epoch: 121, Loss: 2.7550, Train: 1.0000, Val: 0.7740, Test: 0.7740
Epoch: 122, Loss: 3.0376, Train: 1.0000, Val: 0.7760, Test: 0.7740
Epoch: 123, Loss: 3.0316, Train: 1.0000, Val: 0.7700, Test: 0.7740
Epoch: 124, Loss: 2.7643, Train: 1.0000, Val: 0.7700, Test: 0.7740
Epoch: 125, Loss: 3.0327, Train: 1.0000, Val: 0.7700, Test: 0.7730
Epoch: 126, Loss: 2.7679, Train: 1.0000, Val: 0.7700, Test: 0.7720
Epoch: 127, Loss: 3.1041, Train: 1.0000, Val: 0.7680, Test: 0.7720
Epoch: 128, Loss: 3.2083, Train: 1.0000, Val: 0.7660, Test: 0.7710
Epoch: 129, Loss: 3.1289, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 130, Loss: 2.9063, Train: 1.0000, Val: 0.7620, Test: 0.7700
Epoch: 131, Loss: 3.3248, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 132, Loss: 3.0279, Train: 1.0000, Val: 0.7660, Test: 0.7720
Epoch: 133, Loss: 3.1299, Train: 1.0000, Val: 0.7660, Test: 0.7710
Epoch: 134, Loss: 2.9557, Train: 1.0000, Val: 0.7620, Test: 0.7690
Epoch: 135, Loss: 3.4331, Train: 1.0000, Val: 0.7620, Test: 0.7680
Epoch: 136, Loss: 3.0924, Train: 1.0000, Val: 0.7680, Test: 0.7700
Epoch: 137, Loss: 3.1920, Train: 1.0000, Val: 0.7700, Test: 0.7710
Epoch: 138, Loss: 3.4551, Train: 1.0000, Val: 0.7680, Test: 0.7690
Epoch: 139, Loss: 3.1502, Train: 1.0000, Val: 0.7640, Test: 0.7700
Epoch: 140, Loss: 2.6721, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 141, Loss: 3.0405, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 142, Loss: 3.1877, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 143, Loss: 3.1134, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 144, Loss: 3.0115, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 145, Loss: 3.3061, Train: 1.0000, Val: 0.7560, Test: 0.7670
Epoch: 146, Loss: 3.0355, Train: 1.0000, Val: 0.7540, Test: 0.7690
Epoch: 147, Loss: 2.8973, Train: 1.0000, Val: 0.7500, Test: 0.7690
Epoch: 148, Loss: 3.1958, Train: 1.0000, Val: 0.7480, Test: 0.7690
Epoch: 149, Loss: 3.1721, Train: 1.0000, Val: 0.7500, Test: 0.7680
Epoch: 150, Loss: 2.8422, Train: 1.0000, Val: 0.7520, Test: 0.7680
Epoch: 151, Loss: 3.0263, Train: 1.0000, Val: 0.7520, Test: 0.7700
Epoch: 152, Loss: 3.0837, Train: 1.0000, Val: 0.7520, Test: 0.7700
Epoch: 153, Loss: 2.8431, Train: 1.0000, Val: 0.7520, Test: 0.7700
Epoch: 154, Loss: 2.9767, Train: 1.0000, Val: 0.7520, Test: 0.7700
Epoch: 155, Loss: 2.8483, Train: 1.0000, Val: 0.7500, Test: 0.7690
Epoch: 156, Loss: 3.0260, Train: 1.0000, Val: 0.7540, Test: 0.7690
Epoch: 157, Loss: 3.1873, Train: 1.0000, Val: 0.7520, Test: 0.7690
Epoch: 158, Loss: 2.9297, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 159, Loss: 2.9318, Train: 1.0000, Val: 0.7500, Test: 0.7710
Epoch: 160, Loss: 3.1076, Train: 1.0000, Val: 0.7500, Test: 0.7720
Epoch: 161, Loss: 3.1010, Train: 1.0000, Val: 0.7500, Test: 0.7710
Epoch: 162, Loss: 3.1637, Train: 1.0000, Val: 0.7500, Test: 0.7710
Epoch: 163, Loss: 3.2169, Train: 1.0000, Val: 0.7480, Test: 0.7720
Epoch: 164, Loss: 2.6282, Train: 1.0000, Val: 0.7500, Test: 0.7720
Epoch: 165, Loss: 3.0053, Train: 1.0000, Val: 0.7500, Test: 0.7710
Epoch: 166, Loss: 2.9320, Train: 1.0000, Val: 0.7500, Test: 0.7710
Epoch: 167, Loss: 3.1599, Train: 1.0000, Val: 0.7500, Test: 0.7700
Epoch: 168, Loss: 3.1694, Train: 1.0000, Val: 0.7500, Test: 0.7710
Epoch: 169, Loss: 3.1132, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 170, Loss: 3.1217, Train: 1.0000, Val: 0.7540, Test: 0.7690
Epoch: 171, Loss: 3.2794, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 172, Loss: 2.9508, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 173, Loss: 2.9439, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 174, Loss: 2.9919, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 175, Loss: 3.1500, Train: 1.0000, Val: 0.7560, Test: 0.7710
Epoch: 176, Loss: 3.0411, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 177, Loss: 3.0017, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 178, Loss: 2.7200, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 179, Loss: 3.0714, Train: 1.0000, Val: 0.7620, Test: 0.7720
Epoch: 180, Loss: 3.2136, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 181, Loss: 3.3058, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 182, Loss: 3.2327, Train: 1.0000, Val: 0.7660, Test: 0.7720
Epoch: 183, Loss: 3.1177, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 184, Loss: 3.1175, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 185, Loss: 2.7753, Train: 1.0000, Val: 0.7600, Test: 0.7700
Epoch: 186, Loss: 3.1300, Train: 1.0000, Val: 0.7600, Test: 0.7700
Epoch: 187, Loss: 2.8072, Train: 1.0000, Val: 0.7620, Test: 0.7720
Epoch: 188, Loss: 3.0286, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 189, Loss: 3.2093, Train: 1.0000, Val: 0.7580, Test: 0.7690
Epoch: 190, Loss: 2.9468, Train: 1.0000, Val: 0.7580, Test: 0.7700
Epoch: 191, Loss: 2.9866, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 192, Loss: 2.8344, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 193, Loss: 3.2804, Train: 1.0000, Val: 0.7560, Test: 0.7710
Epoch: 194, Loss: 2.8989, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 195, Loss: 2.9254, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 196, Loss: 3.0425, Train: 1.0000, Val: 0.7720, Test: 0.7730
Epoch: 197, Loss: 2.8646, Train: 1.0000, Val: 0.7720, Test: 0.7740
Epoch: 198, Loss: 2.9696, Train: 1.0000, Val: 0.7660, Test: 0.7760
Epoch: 199, Loss: 3.3078, Train: 1.0000, Val: 0.7660, Test: 0.7750
Epoch: 200, Loss: 3.1345, Train: 1.0000, Val: 0.7620, Test: 0.7740
MAD:  0.433
Best Test Accuracy: 0.7920, Val Accuracy: 0.7720, Train Accuracy: 1.0000
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8657, Train: 0.0929, Val: 0.0160, Test: 0.0360
Epoch: 2, Loss: 4.8340, Train: 0.1929, Val: 0.0800, Test: 0.1090
Epoch: 3, Loss: 4.7944, Train: 0.3000, Val: 0.1500, Test: 0.1930
Epoch: 4, Loss: 4.7528, Train: 0.3929, Val: 0.2180, Test: 0.2480
Epoch: 5, Loss: 4.6323, Train: 0.4643, Val: 0.2640, Test: 0.2830
Epoch: 6, Loss: 4.5847, Train: 0.5429, Val: 0.2780, Test: 0.3160
Epoch: 7, Loss: 4.4943, Train: 0.5786, Val: 0.2940, Test: 0.3430
Epoch: 8, Loss: 4.3828, Train: 0.6286, Val: 0.3100, Test: 0.3680
Epoch: 9, Loss: 4.2892, Train: 0.6571, Val: 0.3240, Test: 0.3940
Epoch: 10, Loss: 4.4675, Train: 0.7071, Val: 0.3520, Test: 0.4120
Epoch: 11, Loss: 4.2050, Train: 0.7714, Val: 0.3820, Test: 0.4580
Epoch: 12, Loss: 4.2943, Train: 0.8071, Val: 0.4160, Test: 0.4970
Epoch: 13, Loss: 4.2041, Train: 0.8429, Val: 0.4740, Test: 0.5380
Epoch: 14, Loss: 4.0817, Train: 0.8929, Val: 0.5440, Test: 0.5890
Epoch: 15, Loss: 3.9599, Train: 0.9286, Val: 0.6040, Test: 0.6450
Epoch: 16, Loss: 3.9409, Train: 0.9571, Val: 0.6340, Test: 0.6830
Epoch: 17, Loss: 4.1651, Train: 0.9857, Val: 0.6720, Test: 0.7130
Epoch: 18, Loss: 3.9729, Train: 0.9929, Val: 0.6960, Test: 0.7370
Epoch: 19, Loss: 3.9710, Train: 0.9929, Val: 0.7080, Test: 0.7580
Epoch: 20, Loss: 3.9720, Train: 1.0000, Val: 0.7180, Test: 0.7720
Epoch: 21, Loss: 3.5752, Train: 1.0000, Val: 0.7260, Test: 0.7760
Epoch: 22, Loss: 3.7568, Train: 1.0000, Val: 0.7280, Test: 0.7770
Epoch: 23, Loss: 3.4659, Train: 1.0000, Val: 0.7380, Test: 0.7890
Epoch: 24, Loss: 3.8421, Train: 1.0000, Val: 0.7440, Test: 0.7910
Epoch: 25, Loss: 4.0679, Train: 1.0000, Val: 0.7480, Test: 0.7930
Epoch: 26, Loss: 3.5077, Train: 1.0000, Val: 0.7580, Test: 0.7910
Epoch: 27, Loss: 3.7135, Train: 1.0000, Val: 0.7580, Test: 0.7900
Epoch: 28, Loss: 3.8098, Train: 1.0000, Val: 0.7580, Test: 0.7880
Epoch: 29, Loss: 3.9299, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 30, Loss: 3.4308, Train: 1.0000, Val: 0.7500, Test: 0.7800
Epoch: 31, Loss: 3.4721, Train: 1.0000, Val: 0.7400, Test: 0.7740
Epoch: 32, Loss: 3.4182, Train: 1.0000, Val: 0.7300, Test: 0.7730
Epoch: 33, Loss: 3.4667, Train: 0.9929, Val: 0.7280, Test: 0.7710
Epoch: 34, Loss: 3.3103, Train: 0.9929, Val: 0.7340, Test: 0.7770
Epoch: 35, Loss: 3.4935, Train: 0.9929, Val: 0.7360, Test: 0.7760
Epoch: 36, Loss: 3.3233, Train: 1.0000, Val: 0.7440, Test: 0.7840
Epoch: 37, Loss: 3.2771, Train: 1.0000, Val: 0.7640, Test: 0.7900
Epoch: 38, Loss: 3.4526, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 39, Loss: 3.4972, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 40, Loss: 3.3946, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 41, Loss: 3.4666, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 42, Loss: 3.6283, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 43, Loss: 3.3135, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 44, Loss: 3.4076, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 45, Loss: 3.2836, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 46, Loss: 3.3567, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 47, Loss: 3.5681, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 48, Loss: 3.5449, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 49, Loss: 3.1691, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 50, Loss: 3.5357, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 51, Loss: 3.4143, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 52, Loss: 3.3609, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 53, Loss: 3.1620, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 54, Loss: 3.3228, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 55, Loss: 3.4148, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 56, Loss: 3.3455, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 57, Loss: 3.1558, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 58, Loss: 3.2752, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 59, Loss: 3.2378, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 60, Loss: 3.0693, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 61, Loss: 3.4138, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 62, Loss: 3.5390, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 63, Loss: 3.4076, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 64, Loss: 3.4222, Train: 1.0000, Val: 0.7720, Test: 0.7870
Epoch: 65, Loss: 3.2927, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 66, Loss: 3.2476, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 67, Loss: 3.2581, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 68, Loss: 3.3480, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 69, Loss: 3.2030, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 70, Loss: 3.0806, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 71, Loss: 3.5814, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 72, Loss: 3.3690, Train: 1.0000, Val: 0.7720, Test: 0.7870
Epoch: 73, Loss: 3.1103, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 74, Loss: 3.3180, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 75, Loss: 3.0072, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 76, Loss: 3.2813, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 77, Loss: 3.2616, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 78, Loss: 3.3361, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 79, Loss: 2.9976, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 80, Loss: 3.2990, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 81, Loss: 3.3662, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 82, Loss: 3.5249, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 83, Loss: 3.4916, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 84, Loss: 3.2019, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 85, Loss: 3.4320, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 86, Loss: 2.9860, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 87, Loss: 3.2204, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 88, Loss: 3.3375, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 89, Loss: 3.0141, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 90, Loss: 3.1124, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 91, Loss: 3.3330, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 92, Loss: 3.1288, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 93, Loss: 3.3907, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 94, Loss: 2.8210, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 95, Loss: 3.3503, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 96, Loss: 3.3147, Train: 1.0000, Val: 0.7720, Test: 0.7860
Epoch: 97, Loss: 3.3235, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 98, Loss: 3.3293, Train: 1.0000, Val: 0.7720, Test: 0.7860
Epoch: 99, Loss: 3.3884, Train: 1.0000, Val: 0.7740, Test: 0.7860
Epoch: 100, Loss: 3.0874, Train: 1.0000, Val: 0.7740, Test: 0.7850
Epoch: 101, Loss: 3.2187, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 102, Loss: 2.8339, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 103, Loss: 3.0743, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 104, Loss: 3.3982, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 105, Loss: 3.2737, Train: 1.0000, Val: 0.7700, Test: 0.7780
Epoch: 106, Loss: 3.3447, Train: 1.0000, Val: 0.7700, Test: 0.7790
Epoch: 107, Loss: 3.1834, Train: 1.0000, Val: 0.7700, Test: 0.7780
Epoch: 108, Loss: 3.1494, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 109, Loss: 3.5719, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 110, Loss: 3.3507, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 111, Loss: 3.3096, Train: 1.0000, Val: 0.7640, Test: 0.7750
Epoch: 112, Loss: 2.9383, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 113, Loss: 3.0010, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 114, Loss: 3.1497, Train: 1.0000, Val: 0.7640, Test: 0.7730
Epoch: 115, Loss: 3.2881, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 116, Loss: 2.8950, Train: 1.0000, Val: 0.7700, Test: 0.7800
Epoch: 117, Loss: 3.2409, Train: 1.0000, Val: 0.7680, Test: 0.7790
Epoch: 118, Loss: 3.4295, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 119, Loss: 3.1103, Train: 1.0000, Val: 0.7720, Test: 0.7830
Epoch: 120, Loss: 2.9564, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 121, Loss: 3.1500, Train: 1.0000, Val: 0.7740, Test: 0.7820
Epoch: 122, Loss: 3.0941, Train: 1.0000, Val: 0.7740, Test: 0.7820
Epoch: 123, Loss: 3.0852, Train: 1.0000, Val: 0.7740, Test: 0.7780
Epoch: 124, Loss: 2.9332, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 125, Loss: 2.9052, Train: 1.0000, Val: 0.7660, Test: 0.7760
Epoch: 126, Loss: 3.0431, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 127, Loss: 3.1871, Train: 1.0000, Val: 0.7680, Test: 0.7780
Epoch: 128, Loss: 3.3693, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 129, Loss: 3.5656, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 130, Loss: 2.9184, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 131, Loss: 2.9327, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 132, Loss: 3.0684, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 133, Loss: 3.0915, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 134, Loss: 3.5619, Train: 1.0000, Val: 0.7660, Test: 0.7800
Epoch: 135, Loss: 3.0466, Train: 1.0000, Val: 0.7660, Test: 0.7810
Epoch: 136, Loss: 3.0818, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 137, Loss: 2.8078, Train: 1.0000, Val: 0.7700, Test: 0.7810
Epoch: 138, Loss: 3.2063, Train: 1.0000, Val: 0.7720, Test: 0.7820
Epoch: 139, Loss: 2.9171, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 140, Loss: 3.2261, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 141, Loss: 3.1002, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 142, Loss: 3.0675, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 143, Loss: 2.9886, Train: 1.0000, Val: 0.7660, Test: 0.7820
Epoch: 144, Loss: 2.9907, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 145, Loss: 2.7889, Train: 1.0000, Val: 0.7660, Test: 0.7810
Epoch: 146, Loss: 3.0945, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 147, Loss: 2.9043, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 148, Loss: 2.9370, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 149, Loss: 3.2278, Train: 1.0000, Val: 0.7620, Test: 0.7740
Epoch: 150, Loss: 3.0530, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 151, Loss: 3.0747, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 152, Loss: 3.1497, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 153, Loss: 2.8463, Train: 1.0000, Val: 0.7580, Test: 0.7710
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 2.7554, Train: 1.0000, Val: 0.7580, Test: 0.7690
Epoch: 155, Loss: 3.2401, Train: 1.0000, Val: 0.7580, Test: 0.7680
Epoch: 156, Loss: 3.0743, Train: 1.0000, Val: 0.7580, Test: 0.7680
Epoch: 157, Loss: 2.5074, Train: 1.0000, Val: 0.7600, Test: 0.7700
Epoch: 158, Loss: 2.8837, Train: 1.0000, Val: 0.7580, Test: 0.7720
Epoch: 159, Loss: 3.1180, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 160, Loss: 3.4659, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 161, Loss: 3.1827, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 162, Loss: 2.8827, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 163, Loss: 3.1228, Train: 1.0000, Val: 0.7660, Test: 0.7810
Epoch: 164, Loss: 2.7115, Train: 1.0000, Val: 0.7700, Test: 0.7830
Epoch: 165, Loss: 3.0848, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 166, Loss: 2.9865, Train: 1.0000, Val: 0.7680, Test: 0.7830
Epoch: 167, Loss: 3.1475, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 168, Loss: 2.9283, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 169, Loss: 3.2703, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 170, Loss: 2.6597, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 171, Loss: 3.0611, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 172, Loss: 3.0236, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 173, Loss: 2.6914, Train: 1.0000, Val: 0.7580, Test: 0.7870
Epoch: 174, Loss: 3.2483, Train: 1.0000, Val: 0.7580, Test: 0.7850
Epoch: 175, Loss: 3.0838, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 176, Loss: 3.2083, Train: 1.0000, Val: 0.7560, Test: 0.7740
Epoch: 177, Loss: 3.1669, Train: 1.0000, Val: 0.7560, Test: 0.7660
Epoch: 178, Loss: 2.6558, Train: 1.0000, Val: 0.7560, Test: 0.7670
Epoch: 179, Loss: 3.1429, Train: 1.0000, Val: 0.7560, Test: 0.7670
Epoch: 180, Loss: 2.8200, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 181, Loss: 3.1132, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 182, Loss: 3.3337, Train: 1.0000, Val: 0.7560, Test: 0.7640
Epoch: 183, Loss: 3.1112, Train: 1.0000, Val: 0.7580, Test: 0.7680
Epoch: 184, Loss: 3.1138, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 185, Loss: 3.2440, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 186, Loss: 2.9969, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 187, Loss: 3.3117, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 188, Loss: 3.3449, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 189, Loss: 3.1431, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 190, Loss: 3.1174, Train: 1.0000, Val: 0.7600, Test: 0.7900
Epoch: 191, Loss: 2.9893, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 192, Loss: 3.0555, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 193, Loss: 2.5603, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 194, Loss: 2.7555, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 195, Loss: 3.0405, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 196, Loss: 2.6770, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 197, Loss: 2.9179, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 198, Loss: 3.1550, Train: 1.0000, Val: 0.7620, Test: 0.7770
Epoch: 199, Loss: 3.0777, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 200, Loss: 2.9032, Train: 1.0000, Val: 0.7580, Test: 0.7750
MAD:  0.4642
Best Test Accuracy: 0.8000, Val Accuracy: 0.7740, Train Accuracy: 1.0000
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8431, Train: 0.1214, Val: 0.0540, Test: 0.0670
Epoch: 2, Loss: 4.7677, Train: 0.3429, Val: 0.1940, Test: 0.2100
Epoch: 3, Loss: 4.6955, Train: 0.5071, Val: 0.2820, Test: 0.3400
Epoch: 4, Loss: 4.6469, Train: 0.5786, Val: 0.3500, Test: 0.3970
Epoch: 5, Loss: 4.5964, Train: 0.6071, Val: 0.3720, Test: 0.4340
Epoch: 6, Loss: 4.5224, Train: 0.6286, Val: 0.3900, Test: 0.4330
Epoch: 7, Loss: 4.4729, Train: 0.6357, Val: 0.4100, Test: 0.4170
Epoch: 8, Loss: 4.2413, Train: 0.6500, Val: 0.4160, Test: 0.4270
Epoch: 9, Loss: 4.1300, Train: 0.6571, Val: 0.4260, Test: 0.4380
Epoch: 10, Loss: 4.1886, Train: 0.6786, Val: 0.4480, Test: 0.4520
Epoch: 11, Loss: 4.2035, Train: 0.7000, Val: 0.4720, Test: 0.4830
Epoch: 12, Loss: 4.2210, Train: 0.7643, Val: 0.5020, Test: 0.5130
Epoch: 13, Loss: 3.9934, Train: 0.7786, Val: 0.5320, Test: 0.5400
Epoch: 14, Loss: 4.4241, Train: 0.8643, Val: 0.5760, Test: 0.5860
Epoch: 15, Loss: 4.1301, Train: 0.8857, Val: 0.6120, Test: 0.6380
Epoch: 16, Loss: 4.2981, Train: 0.9143, Val: 0.6460, Test: 0.6740
Epoch: 17, Loss: 4.1925, Train: 0.9571, Val: 0.6940, Test: 0.7050
Epoch: 18, Loss: 3.9045, Train: 0.9643, Val: 0.7320, Test: 0.7260
Epoch: 19, Loss: 4.0602, Train: 0.9714, Val: 0.7380, Test: 0.7440
Epoch: 20, Loss: 3.8498, Train: 0.9929, Val: 0.7520, Test: 0.7570
Epoch: 21, Loss: 3.8523, Train: 0.9929, Val: 0.7600, Test: 0.7540
Epoch: 22, Loss: 4.0383, Train: 0.9929, Val: 0.7580, Test: 0.7570
Epoch: 23, Loss: 3.7470, Train: 1.0000, Val: 0.7540, Test: 0.7540
Epoch: 24, Loss: 3.6293, Train: 1.0000, Val: 0.7640, Test: 0.7550
Epoch: 25, Loss: 3.8111, Train: 1.0000, Val: 0.7640, Test: 0.7560
Epoch: 26, Loss: 3.7692, Train: 1.0000, Val: 0.7580, Test: 0.7550
Epoch: 27, Loss: 3.9904, Train: 1.0000, Val: 0.7580, Test: 0.7590
Epoch: 28, Loss: 3.6453, Train: 1.0000, Val: 0.7580, Test: 0.7600
Epoch: 29, Loss: 3.5199, Train: 1.0000, Val: 0.7540, Test: 0.7610
Epoch: 30, Loss: 3.6255, Train: 1.0000, Val: 0.7560, Test: 0.7650
Epoch: 31, Loss: 3.3498, Train: 1.0000, Val: 0.7600, Test: 0.7630
Epoch: 32, Loss: 3.4902, Train: 1.0000, Val: 0.7620, Test: 0.7650
Epoch: 33, Loss: 3.4313, Train: 1.0000, Val: 0.7600, Test: 0.7690
Epoch: 34, Loss: 3.4325, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 35, Loss: 3.6233, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 36, Loss: 3.7313, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 37, Loss: 3.7351, Train: 1.0000, Val: 0.7560, Test: 0.7750
Epoch: 38, Loss: 3.7537, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 39, Loss: 3.4678, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 40, Loss: 3.4898, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 41, Loss: 3.6071, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 42, Loss: 3.4396, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 43, Loss: 3.5851, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 44, Loss: 3.4456, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 45, Loss: 3.3379, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 46, Loss: 3.5348, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 47, Loss: 3.3282, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 48, Loss: 3.6649, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 49, Loss: 3.5315, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 50, Loss: 3.3471, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 51, Loss: 3.5319, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 52, Loss: 3.0104, Train: 1.0000, Val: 0.7820, Test: 0.7910
Epoch: 53, Loss: 3.6970, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 54, Loss: 3.5510, Train: 1.0000, Val: 0.7820, Test: 0.7880
Epoch: 55, Loss: 3.2654, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 56, Loss: 3.2675, Train: 1.0000, Val: 0.7780, Test: 0.7850
Epoch: 57, Loss: 3.1735, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 58, Loss: 3.2472, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 59, Loss: 3.5374, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 60, Loss: 3.4357, Train: 1.0000, Val: 0.7740, Test: 0.7810
Epoch: 61, Loss: 3.1213, Train: 1.0000, Val: 0.7720, Test: 0.7830
Epoch: 62, Loss: 3.3680, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 63, Loss: 3.2013, Train: 1.0000, Val: 0.7720, Test: 0.7840
Epoch: 64, Loss: 3.6006, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 65, Loss: 3.1300, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 66, Loss: 3.3063, Train: 1.0000, Val: 0.7700, Test: 0.7830
Epoch: 67, Loss: 3.4543, Train: 1.0000, Val: 0.7660, Test: 0.7820
Epoch: 68, Loss: 3.2332, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 69, Loss: 3.4178, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 70, Loss: 3.2272, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 71, Loss: 3.2375, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 72, Loss: 3.3859, Train: 1.0000, Val: 0.7640, Test: 0.7800
Epoch: 73, Loss: 3.0963, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 74, Loss: 3.2141, Train: 1.0000, Val: 0.7600, Test: 0.7750
Epoch: 75, Loss: 3.2321, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 76, Loss: 3.1217, Train: 1.0000, Val: 0.7560, Test: 0.7740
Epoch: 77, Loss: 3.5107, Train: 1.0000, Val: 0.7600, Test: 0.7720
Epoch: 78, Loss: 3.2616, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 79, Loss: 3.1718, Train: 1.0000, Val: 0.7640, Test: 0.7690
Epoch: 80, Loss: 3.4188, Train: 1.0000, Val: 0.7660, Test: 0.7690
Epoch: 81, Loss: 3.5260, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 82, Loss: 3.1750, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 83, Loss: 3.1776, Train: 1.0000, Val: 0.7620, Test: 0.7770
Epoch: 84, Loss: 3.2361, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 85, Loss: 3.2126, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 86, Loss: 2.8985, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 87, Loss: 3.1933, Train: 1.0000, Val: 0.7540, Test: 0.7760
Epoch: 88, Loss: 3.2052, Train: 1.0000, Val: 0.7500, Test: 0.7720
Epoch: 89, Loss: 3.2837, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 90, Loss: 3.1316, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 91, Loss: 3.2952, Train: 1.0000, Val: 0.7520, Test: 0.7730
Epoch: 92, Loss: 2.9869, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 93, Loss: 3.3512, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 94, Loss: 3.1647, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 95, Loss: 3.3162, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 96, Loss: 3.1431, Train: 1.0000, Val: 0.7600, Test: 0.7760
Epoch: 97, Loss: 3.0454, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 98, Loss: 3.4606, Train: 1.0000, Val: 0.7620, Test: 0.7730
Epoch: 99, Loss: 3.1393, Train: 1.0000, Val: 0.7620, Test: 0.7720
Epoch: 100, Loss: 3.0207, Train: 1.0000, Val: 0.7600, Test: 0.7730
Epoch: 101, Loss: 3.1955, Train: 1.0000, Val: 0.7600, Test: 0.7730
Epoch: 102, Loss: 3.0589, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 103, Loss: 3.3846, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 104, Loss: 3.2905, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 105, Loss: 3.0386, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 106, Loss: 3.2211, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 107, Loss: 3.1195, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 108, Loss: 2.9876, Train: 1.0000, Val: 0.7600, Test: 0.7750
Epoch: 109, Loss: 2.7411, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 110, Loss: 3.4777, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 111, Loss: 2.9090, Train: 1.0000, Val: 0.7620, Test: 0.7770
Epoch: 112, Loss: 3.1877, Train: 1.0000, Val: 0.7620, Test: 0.7780
Epoch: 113, Loss: 3.4965, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 114, Loss: 3.1560, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 115, Loss: 2.9763, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 116, Loss: 3.1282, Train: 1.0000, Val: 0.7620, Test: 0.7780
Epoch: 117, Loss: 3.0408, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 118, Loss: 2.9029, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 119, Loss: 2.7564, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 120, Loss: 3.1823, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 121, Loss: 2.8087, Train: 1.0000, Val: 0.7560, Test: 0.7770
Epoch: 122, Loss: 3.0623, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 123, Loss: 3.1677, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 124, Loss: 2.9267, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 125, Loss: 2.7021, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 126, Loss: 2.9601, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 127, Loss: 2.7736, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 128, Loss: 3.3036, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 129, Loss: 2.8264, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 130, Loss: 3.2260, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 131, Loss: 3.1154, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 132, Loss: 2.9888, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 133, Loss: 2.9502, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 134, Loss: 3.0861, Train: 1.0000, Val: 0.7660, Test: 0.7750
Epoch: 135, Loss: 3.0849, Train: 1.0000, Val: 0.7660, Test: 0.7760
Epoch: 136, Loss: 2.5556, Train: 1.0000, Val: 0.7680, Test: 0.7740
Epoch: 137, Loss: 3.2271, Train: 1.0000, Val: 0.7680, Test: 0.7730
Epoch: 138, Loss: 2.9487, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 139, Loss: 3.2272, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 140, Loss: 2.9985, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 141, Loss: 3.1072, Train: 1.0000, Val: 0.7660, Test: 0.7750
Epoch: 142, Loss: 3.3837, Train: 1.0000, Val: 0.7660, Test: 0.7730
Epoch: 143, Loss: 3.2302, Train: 1.0000, Val: 0.7660, Test: 0.7700
Epoch: 144, Loss: 2.8961, Train: 1.0000, Val: 0.7660, Test: 0.7700
Epoch: 145, Loss: 3.0690, Train: 1.0000, Val: 0.7640, Test: 0.7700
Epoch: 146, Loss: 3.0755, Train: 1.0000, Val: 0.7640, Test: 0.7710
Epoch: 147, Loss: 3.5201, Train: 1.0000, Val: 0.7640, Test: 0.7730
Epoch: 148, Loss: 3.1863, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 149, Loss: 3.1398, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 150, Loss: 2.9204, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 151, Loss: 3.3436, Train: 1.0000, Val: 0.7660, Test: 0.7710
Epoch: 152, Loss: 3.2252, Train: 1.0000, Val: 0.7680, Test: 0.7750
Epoch: 153, Loss: 2.8842, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 154, Loss: 3.1106, Train: 1.0000, Val: 0.7660, Test: 0.7780
Epoch: 155, Loss: 3.0955, Train: 1.0000, Val: 0.7660, Test: 0.7750
Epoch: 156, Loss: 3.1964, Train: 1.0000, Val: 0.7660, Test: 0.7760
Epoch: 157, Loss: 3.0979, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 158, Loss: 2.9522, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 159, Loss: 2.8774, Train: 1.0000, Val: 0.7640, Test: 0.7720
Epoch: 160, Loss: 3.1963, Train: 1.0000, Val: 0.7660, Test: 0.7720
Epoch: 161, Loss: 2.9952, Train: 1.0000, Val: 0.7660, Test: 0.7700
Epoch: 162, Loss: 3.2603, Train: 1.0000, Val: 0.7680, Test: 0.7700
Epoch: 163, Loss: 3.2086, Train: 1.0000, Val: 0.7700, Test: 0.7680
Epoch: 164, Loss: 3.1584, Train: 1.0000, Val: 0.7680, Test: 0.7700
Epoch: 165, Loss: 3.0230, Train: 1.0000, Val: 0.7680, Test: 0.7710
Epoch: 166, Loss: 2.8839, Train: 1.0000, Val: 0.7660, Test: 0.7700
Epoch: 167, Loss: 2.9726, Train: 1.0000, Val: 0.7620, Test: 0.7700
Epoch: 168, Loss: 3.2904, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 169, Loss: 2.7765, Train: 1.0000, Val: 0.7600, Test: 0.7710
Epoch: 170, Loss: 3.1981, Train: 1.0000, Val: 0.7620, Test: 0.7720
Epoch: 171, Loss: 2.9602, Train: 1.0000, Val: 0.7600, Test: 0.7730
Epoch: 172, Loss: 3.1510, Train: 1.0000, Val: 0.7600, Test: 0.7720
Epoch: 173, Loss: 3.0372, Train: 1.0000, Val: 0.7580, Test: 0.7720
Epoch: 174, Loss: 2.6309, Train: 1.0000, Val: 0.7560, Test: 0.7710
Epoch: 175, Loss: 3.0834, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 176, Loss: 2.9525, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 177, Loss: 3.0292, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 178, Loss: 2.8459, Train: 1.0000, Val: 0.7600, Test: 0.7740
Epoch: 179, Loss: 2.9467, Train: 1.0000, Val: 0.7620, Test: 0.7770
Epoch: 180, Loss: 2.9261, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 181, Loss: 3.1887, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 182, Loss: 3.0221, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 183, Loss: 2.7508, Train: 1.0000, Val: 0.7660, Test: 0.7770
Epoch: 184, Loss: 2.8066, Train: 1.0000, Val: 0.7660, Test: 0.7780
Epoch: 185, Loss: 3.0152, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 186, Loss: 2.9229, Train: 1.0000, Val: 0.7640, Test: 0.7740
Epoch: 187, Loss: 3.2820, Train: 1.0000, Val: 0.7660, Test: 0.7730
Epoch: 188, Loss: 2.9994, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 189, Loss: 2.9220, Train: 1.0000, Val: 0.7620, Test: 0.7710
Epoch: 190, Loss: 2.7851, Train: 1.0000, Val: 0.7680, Test: 0.7720
Epoch: 191, Loss: 3.2720, Train: 1.0000, Val: 0.7660, Test: 0.7710
Epoch: 192, Loss: 3.1388, Train: 1.0000, Val: 0.7660, Test: 0.7720
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 2.8777, Train: 1.0000, Val: 0.7660, Test: 0.7740
Epoch: 194, Loss: 3.0244, Train: 1.0000, Val: 0.7680, Test: 0.7740
Epoch: 195, Loss: 3.0351, Train: 1.0000, Val: 0.7660, Test: 0.7740
Epoch: 196, Loss: 3.0897, Train: 1.0000, Val: 0.7680, Test: 0.7780
Epoch: 197, Loss: 3.2028, Train: 1.0000, Val: 0.7640, Test: 0.7750
Epoch: 198, Loss: 2.9527, Train: 1.0000, Val: 0.7640, Test: 0.7770
Epoch: 199, Loss: 2.8611, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 200, Loss: 2.7286, Train: 1.0000, Val: 0.7580, Test: 0.7750
MAD:  0.4507
Best Test Accuracy: 0.7960, Val Accuracy: 0.7800, Train Accuracy: 1.0000
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8470, Train: 0.0857, Val: 0.0420, Test: 0.0530
Epoch: 2, Loss: 4.7874, Train: 0.2571, Val: 0.1060, Test: 0.1400
Epoch: 3, Loss: 4.7269, Train: 0.4214, Val: 0.2060, Test: 0.2250
Epoch: 4, Loss: 4.6576, Train: 0.5357, Val: 0.2840, Test: 0.2920
Epoch: 5, Loss: 4.5775, Train: 0.5929, Val: 0.3440, Test: 0.3280
Epoch: 6, Loss: 4.4977, Train: 0.6786, Val: 0.3840, Test: 0.3580
Epoch: 7, Loss: 4.4971, Train: 0.7286, Val: 0.4140, Test: 0.3860
Epoch: 8, Loss: 4.2604, Train: 0.7571, Val: 0.4340, Test: 0.4340
Epoch: 9, Loss: 4.2571, Train: 0.7786, Val: 0.4780, Test: 0.4560
Epoch: 10, Loss: 4.1307, Train: 0.8000, Val: 0.5000, Test: 0.4720
Epoch: 11, Loss: 4.0566, Train: 0.8143, Val: 0.4860, Test: 0.4760
Epoch: 12, Loss: 4.1353, Train: 0.8357, Val: 0.4960, Test: 0.4870
Epoch: 13, Loss: 4.1453, Train: 0.8857, Val: 0.5160, Test: 0.5260
Epoch: 14, Loss: 3.8750, Train: 0.9000, Val: 0.5580, Test: 0.5570
Epoch: 15, Loss: 3.9334, Train: 0.9286, Val: 0.5980, Test: 0.6120
Epoch: 16, Loss: 4.0609, Train: 0.9643, Val: 0.6380, Test: 0.6780
Epoch: 17, Loss: 4.1106, Train: 0.9929, Val: 0.6720, Test: 0.7180
Epoch: 18, Loss: 4.0339, Train: 0.9929, Val: 0.6820, Test: 0.7460
Epoch: 19, Loss: 3.8754, Train: 0.9929, Val: 0.6980, Test: 0.7550
Epoch: 20, Loss: 3.7368, Train: 0.9929, Val: 0.7020, Test: 0.7630
Epoch: 21, Loss: 3.9888, Train: 0.9929, Val: 0.6980, Test: 0.7670
Epoch: 22, Loss: 3.6268, Train: 0.9929, Val: 0.7040, Test: 0.7670
Epoch: 23, Loss: 3.4983, Train: 1.0000, Val: 0.7020, Test: 0.7610
Epoch: 24, Loss: 3.7620, Train: 1.0000, Val: 0.7060, Test: 0.7610
Epoch: 25, Loss: 3.8141, Train: 1.0000, Val: 0.7080, Test: 0.7560
Epoch: 26, Loss: 3.6477, Train: 1.0000, Val: 0.7160, Test: 0.7530
Epoch: 27, Loss: 3.8043, Train: 1.0000, Val: 0.7180, Test: 0.7520
Epoch: 28, Loss: 3.3833, Train: 1.0000, Val: 0.7220, Test: 0.7530
Epoch: 29, Loss: 3.8815, Train: 1.0000, Val: 0.7300, Test: 0.7540
Epoch: 30, Loss: 3.6589, Train: 1.0000, Val: 0.7320, Test: 0.7620
Epoch: 31, Loss: 3.5686, Train: 1.0000, Val: 0.7360, Test: 0.7630
Epoch: 32, Loss: 3.7476, Train: 1.0000, Val: 0.7360, Test: 0.7630
Epoch: 33, Loss: 3.4661, Train: 1.0000, Val: 0.7420, Test: 0.7640
Epoch: 34, Loss: 3.6520, Train: 1.0000, Val: 0.7440, Test: 0.7690
Epoch: 35, Loss: 3.6544, Train: 1.0000, Val: 0.7440, Test: 0.7670
Epoch: 36, Loss: 3.4241, Train: 1.0000, Val: 0.7440, Test: 0.7640
Epoch: 37, Loss: 3.4660, Train: 1.0000, Val: 0.7440, Test: 0.7660
Epoch: 38, Loss: 3.5900, Train: 1.0000, Val: 0.7460, Test: 0.7660
Epoch: 39, Loss: 3.5843, Train: 1.0000, Val: 0.7440, Test: 0.7660
Epoch: 40, Loss: 3.0919, Train: 1.0000, Val: 0.7460, Test: 0.7690
Epoch: 41, Loss: 3.7573, Train: 1.0000, Val: 0.7440, Test: 0.7680
Epoch: 42, Loss: 3.7137, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 43, Loss: 3.7543, Train: 1.0000, Val: 0.7480, Test: 0.7720
Epoch: 44, Loss: 3.3955, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 45, Loss: 3.3419, Train: 1.0000, Val: 0.7460, Test: 0.7720
Epoch: 46, Loss: 3.4276, Train: 1.0000, Val: 0.7420, Test: 0.7790
Epoch: 47, Loss: 3.5494, Train: 1.0000, Val: 0.7400, Test: 0.7790
Epoch: 48, Loss: 3.2931, Train: 1.0000, Val: 0.7460, Test: 0.7790
Epoch: 49, Loss: 2.9310, Train: 1.0000, Val: 0.7460, Test: 0.7810
Epoch: 50, Loss: 3.3827, Train: 1.0000, Val: 0.7460, Test: 0.7800
Epoch: 51, Loss: 3.3626, Train: 1.0000, Val: 0.7440, Test: 0.7800
Epoch: 52, Loss: 3.2935, Train: 1.0000, Val: 0.7440, Test: 0.7800
Epoch: 53, Loss: 3.3604, Train: 1.0000, Val: 0.7440, Test: 0.7790
Epoch: 54, Loss: 3.4822, Train: 1.0000, Val: 0.7460, Test: 0.7800
Epoch: 55, Loss: 3.6661, Train: 1.0000, Val: 0.7460, Test: 0.7790
Epoch: 56, Loss: 3.2628, Train: 1.0000, Val: 0.7460, Test: 0.7790
Epoch: 57, Loss: 3.5556, Train: 1.0000, Val: 0.7480, Test: 0.7780
Epoch: 58, Loss: 3.3476, Train: 1.0000, Val: 0.7500, Test: 0.7780
Epoch: 59, Loss: 3.3133, Train: 1.0000, Val: 0.7440, Test: 0.7750
Epoch: 60, Loss: 3.2165, Train: 1.0000, Val: 0.7440, Test: 0.7740
Epoch: 61, Loss: 2.9503, Train: 1.0000, Val: 0.7440, Test: 0.7720
Epoch: 62, Loss: 3.4595, Train: 1.0000, Val: 0.7440, Test: 0.7720
Epoch: 63, Loss: 3.3489, Train: 1.0000, Val: 0.7440, Test: 0.7730
Epoch: 64, Loss: 2.7839, Train: 1.0000, Val: 0.7460, Test: 0.7730
Epoch: 65, Loss: 3.2630, Train: 1.0000, Val: 0.7460, Test: 0.7720
Epoch: 66, Loss: 3.0848, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 67, Loss: 2.9196, Train: 1.0000, Val: 0.7480, Test: 0.7690
Epoch: 68, Loss: 3.4905, Train: 1.0000, Val: 0.7500, Test: 0.7690
Epoch: 69, Loss: 3.3745, Train: 1.0000, Val: 0.7480, Test: 0.7680
Epoch: 70, Loss: 3.1839, Train: 1.0000, Val: 0.7480, Test: 0.7690
Epoch: 71, Loss: 3.2104, Train: 1.0000, Val: 0.7460, Test: 0.7690
Epoch: 72, Loss: 3.2551, Train: 1.0000, Val: 0.7460, Test: 0.7690
Epoch: 73, Loss: 3.1692, Train: 1.0000, Val: 0.7460, Test: 0.7690
Epoch: 74, Loss: 3.2715, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 75, Loss: 3.1295, Train: 1.0000, Val: 0.7460, Test: 0.7710
Epoch: 76, Loss: 3.1233, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 77, Loss: 3.5717, Train: 1.0000, Val: 0.7460, Test: 0.7680
Epoch: 78, Loss: 3.2789, Train: 1.0000, Val: 0.7460, Test: 0.7680
Epoch: 79, Loss: 3.2822, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 80, Loss: 3.5039, Train: 1.0000, Val: 0.7480, Test: 0.7690
Epoch: 81, Loss: 3.2774, Train: 1.0000, Val: 0.7460, Test: 0.7700
Epoch: 82, Loss: 3.1888, Train: 1.0000, Val: 0.7460, Test: 0.7700
Epoch: 83, Loss: 3.2125, Train: 1.0000, Val: 0.7460, Test: 0.7710
Epoch: 84, Loss: 3.3498, Train: 1.0000, Val: 0.7440, Test: 0.7690
Epoch: 85, Loss: 3.0935, Train: 1.0000, Val: 0.7440, Test: 0.7670
Epoch: 86, Loss: 3.5529, Train: 1.0000, Val: 0.7420, Test: 0.7680
Epoch: 87, Loss: 3.4300, Train: 1.0000, Val: 0.7440, Test: 0.7700
Epoch: 88, Loss: 2.9659, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 89, Loss: 3.3084, Train: 1.0000, Val: 0.7500, Test: 0.7710
Epoch: 90, Loss: 3.0901, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 91, Loss: 3.1497, Train: 1.0000, Val: 0.7580, Test: 0.7730
Epoch: 92, Loss: 3.1537, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 93, Loss: 3.0605, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 94, Loss: 3.1567, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 95, Loss: 3.0559, Train: 1.0000, Val: 0.7560, Test: 0.7700
Epoch: 96, Loss: 3.2955, Train: 1.0000, Val: 0.7560, Test: 0.7690
Epoch: 97, Loss: 3.3627, Train: 1.0000, Val: 0.7580, Test: 0.7700
Epoch: 98, Loss: 3.3625, Train: 1.0000, Val: 0.7600, Test: 0.7700
Epoch: 99, Loss: 3.0796, Train: 1.0000, Val: 0.7580, Test: 0.7700
Epoch: 100, Loss: 3.0293, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 101, Loss: 3.0400, Train: 1.0000, Val: 0.7580, Test: 0.7720
Epoch: 102, Loss: 3.3806, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 103, Loss: 3.1425, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 104, Loss: 3.2622, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 105, Loss: 3.2456, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 106, Loss: 2.8373, Train: 1.0000, Val: 0.7560, Test: 0.7710
Epoch: 107, Loss: 3.6120, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 108, Loss: 3.2422, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 109, Loss: 3.3297, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 110, Loss: 3.0589, Train: 1.0000, Val: 0.7540, Test: 0.7740
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 111, Loss: 3.0665, Train: 1.0000, Val: 0.7500, Test: 0.7730
Epoch: 112, Loss: 3.3984, Train: 1.0000, Val: 0.7500, Test: 0.7690
Epoch: 113, Loss: 3.0533, Train: 1.0000, Val: 0.7500, Test: 0.7680
Epoch: 114, Loss: 3.0721, Train: 1.0000, Val: 0.7460, Test: 0.7680
Epoch: 115, Loss: 3.0129, Train: 1.0000, Val: 0.7500, Test: 0.7680
Epoch: 116, Loss: 3.0574, Train: 1.0000, Val: 0.7480, Test: 0.7680
Epoch: 117, Loss: 3.1428, Train: 1.0000, Val: 0.7500, Test: 0.7670
Epoch: 118, Loss: 3.0288, Train: 1.0000, Val: 0.7500, Test: 0.7660
Epoch: 119, Loss: 3.1823, Train: 1.0000, Val: 0.7500, Test: 0.7690
Epoch: 120, Loss: 3.0863, Train: 1.0000, Val: 0.7480, Test: 0.7630
Epoch: 121, Loss: 3.1250, Train: 1.0000, Val: 0.7460, Test: 0.7630
Epoch: 122, Loss: 3.1122, Train: 1.0000, Val: 0.7440, Test: 0.7620
Epoch: 123, Loss: 2.7372, Train: 1.0000, Val: 0.7440, Test: 0.7610
Epoch: 124, Loss: 3.0511, Train: 1.0000, Val: 0.7460, Test: 0.7610
Epoch: 125, Loss: 3.0450, Train: 1.0000, Val: 0.7460, Test: 0.7610
Epoch: 126, Loss: 3.3306, Train: 1.0000, Val: 0.7440, Test: 0.7610
Epoch: 127, Loss: 3.2129, Train: 1.0000, Val: 0.7460, Test: 0.7620
Epoch: 128, Loss: 3.1586, Train: 1.0000, Val: 0.7440, Test: 0.7660
Epoch: 129, Loss: 3.1251, Train: 1.0000, Val: 0.7460, Test: 0.7670
Epoch: 130, Loss: 2.9869, Train: 1.0000, Val: 0.7460, Test: 0.7700
Epoch: 131, Loss: 3.2623, Train: 1.0000, Val: 0.7460, Test: 0.7710
Epoch: 132, Loss: 3.1759, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 133, Loss: 2.9804, Train: 1.0000, Val: 0.7480, Test: 0.7700
Epoch: 134, Loss: 2.8276, Train: 1.0000, Val: 0.7500, Test: 0.7720
Epoch: 135, Loss: 2.8635, Train: 1.0000, Val: 0.7500, Test: 0.7720
Epoch: 136, Loss: 3.2954, Train: 1.0000, Val: 0.7520, Test: 0.7720
Epoch: 137, Loss: 3.0395, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 138, Loss: 3.1890, Train: 1.0000, Val: 0.7560, Test: 0.7730
Epoch: 139, Loss: 3.0511, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 140, Loss: 3.0883, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 141, Loss: 3.0993, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 142, Loss: 2.8767, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 143, Loss: 3.0136, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 144, Loss: 2.9989, Train: 1.0000, Val: 0.7560, Test: 0.7670
Epoch: 145, Loss: 3.1293, Train: 1.0000, Val: 0.7520, Test: 0.7660
Epoch: 146, Loss: 2.8247, Train: 1.0000, Val: 0.7540, Test: 0.7660
Epoch: 147, Loss: 2.9653, Train: 1.0000, Val: 0.7500, Test: 0.7690
Epoch: 148, Loss: 2.7318, Train: 1.0000, Val: 0.7500, Test: 0.7660
Epoch: 149, Loss: 3.3197, Train: 1.0000, Val: 0.7440, Test: 0.7670
Epoch: 150, Loss: 3.2076, Train: 1.0000, Val: 0.7400, Test: 0.7670
Epoch: 151, Loss: 2.8310, Train: 1.0000, Val: 0.7360, Test: 0.7640
Epoch: 152, Loss: 3.1943, Train: 1.0000, Val: 0.7360, Test: 0.7630
Epoch: 153, Loss: 3.0526, Train: 1.0000, Val: 0.7380, Test: 0.7590
Epoch: 154, Loss: 3.4655, Train: 1.0000, Val: 0.7420, Test: 0.7580
Epoch: 155, Loss: 3.1217, Train: 1.0000, Val: 0.7380, Test: 0.7560
Epoch: 156, Loss: 3.0221, Train: 1.0000, Val: 0.7400, Test: 0.7550
Epoch: 157, Loss: 3.0532, Train: 1.0000, Val: 0.7440, Test: 0.7560
Epoch: 158, Loss: 3.0409, Train: 1.0000, Val: 0.7460, Test: 0.7540
Epoch: 159, Loss: 2.8860, Train: 1.0000, Val: 0.7500, Test: 0.7530
Epoch: 160, Loss: 2.8857, Train: 1.0000, Val: 0.7420, Test: 0.7530
Epoch: 161, Loss: 2.8651, Train: 1.0000, Val: 0.7420, Test: 0.7570
Epoch: 162, Loss: 3.1673, Train: 1.0000, Val: 0.7440, Test: 0.7580
Epoch: 163, Loss: 2.9558, Train: 1.0000, Val: 0.7420, Test: 0.7570
Epoch: 164, Loss: 3.0139, Train: 1.0000, Val: 0.7420, Test: 0.7570
Epoch: 165, Loss: 2.8677, Train: 1.0000, Val: 0.7420, Test: 0.7580
Epoch: 166, Loss: 3.1030, Train: 1.0000, Val: 0.7420, Test: 0.7600
Epoch: 167, Loss: 3.1034, Train: 1.0000, Val: 0.7460, Test: 0.7620
Epoch: 168, Loss: 3.2160, Train: 1.0000, Val: 0.7420, Test: 0.7640
Epoch: 169, Loss: 3.2977, Train: 1.0000, Val: 0.7480, Test: 0.7650
Epoch: 170, Loss: 3.1497, Train: 1.0000, Val: 0.7500, Test: 0.7680
Epoch: 171, Loss: 2.7656, Train: 1.0000, Val: 0.7540, Test: 0.7690
Epoch: 172, Loss: 2.9402, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 173, Loss: 2.7907, Train: 1.0000, Val: 0.7520, Test: 0.7660
Epoch: 174, Loss: 3.2468, Train: 1.0000, Val: 0.7520, Test: 0.7640
Epoch: 175, Loss: 3.2013, Train: 1.0000, Val: 0.7500, Test: 0.7640
Epoch: 176, Loss: 3.1556, Train: 1.0000, Val: 0.7480, Test: 0.7630
Epoch: 177, Loss: 3.3368, Train: 1.0000, Val: 0.7460, Test: 0.7630
Epoch: 178, Loss: 2.9483, Train: 1.0000, Val: 0.7480, Test: 0.7620
Epoch: 179, Loss: 2.9430, Train: 1.0000, Val: 0.7480, Test: 0.7620
Epoch: 180, Loss: 3.2046, Train: 1.0000, Val: 0.7500, Test: 0.7620
Epoch: 181, Loss: 3.2432, Train: 1.0000, Val: 0.7460, Test: 0.7640
Epoch: 182, Loss: 3.0903, Train: 1.0000, Val: 0.7480, Test: 0.7630
Epoch: 183, Loss: 2.8918, Train: 1.0000, Val: 0.7480, Test: 0.7620
Epoch: 184, Loss: 3.2802, Train: 1.0000, Val: 0.7460, Test: 0.7620
Epoch: 185, Loss: 3.2098, Train: 1.0000, Val: 0.7480, Test: 0.7620
Epoch: 186, Loss: 3.3805, Train: 1.0000, Val: 0.7460, Test: 0.7650
Epoch: 187, Loss: 2.9714, Train: 1.0000, Val: 0.7380, Test: 0.7640
Epoch: 188, Loss: 3.2555, Train: 1.0000, Val: 0.7380, Test: 0.7630
Epoch: 189, Loss: 3.3468, Train: 1.0000, Val: 0.7420, Test: 0.7640
Epoch: 190, Loss: 3.3417, Train: 1.0000, Val: 0.7440, Test: 0.7630
Epoch: 191, Loss: 2.9123, Train: 1.0000, Val: 0.7460, Test: 0.7640
Epoch: 192, Loss: 3.1074, Train: 1.0000, Val: 0.7460, Test: 0.7620
Epoch: 193, Loss: 2.8565, Train: 1.0000, Val: 0.7480, Test: 0.7630
Epoch: 194, Loss: 2.7774, Train: 1.0000, Val: 0.7480, Test: 0.7630
Epoch: 195, Loss: 2.7312, Train: 1.0000, Val: 0.7460, Test: 0.7630
Epoch: 196, Loss: 2.7708, Train: 1.0000, Val: 0.7440, Test: 0.7650
Epoch: 197, Loss: 2.9738, Train: 1.0000, Val: 0.7420, Test: 0.7640
Epoch: 198, Loss: 3.0438, Train: 1.0000, Val: 0.7460, Test: 0.7640
Epoch: 199, Loss: 3.3301, Train: 1.0000, Val: 0.7420, Test: 0.7650
Epoch: 200, Loss: 3.0481, Train: 1.0000, Val: 0.7480, Test: 0.7640
MAD:  0.4462
Best Test Accuracy: 0.7810, Val Accuracy: 0.7460, Train Accuracy: 1.0000
Training completed.
Average Test Accuracy:  0.7914444444444445 ± 0.004085505846855611
Average MAD:  0.4626 ± 0.021016342847095606
