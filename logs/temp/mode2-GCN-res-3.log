Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8659, Train: 0.0500, Val: 0.0220, Test: 0.0140
Epoch: 2, Loss: 4.8394, Train: 0.2000, Val: 0.0960, Test: 0.1020
Epoch: 3, Loss: 4.8102, Train: 0.3214, Val: 0.1420, Test: 0.1760
Epoch: 4, Loss: 4.7691, Train: 0.4143, Val: 0.2200, Test: 0.2640
Epoch: 5, Loss: 4.7252, Train: 0.5143, Val: 0.2880, Test: 0.3390
Epoch: 6, Loss: 4.6807, Train: 0.5714, Val: 0.3200, Test: 0.3610
Epoch: 7, Loss: 4.6205, Train: 0.6071, Val: 0.3540, Test: 0.3850
Epoch: 8, Loss: 4.5655, Train: 0.6286, Val: 0.3440, Test: 0.3880
Epoch: 9, Loss: 4.4887, Train: 0.6429, Val: 0.3540, Test: 0.3960
Epoch: 10, Loss: 4.4349, Train: 0.6429, Val: 0.3560, Test: 0.3960
Epoch: 11, Loss: 4.3403, Train: 0.6429, Val: 0.3600, Test: 0.4020
Epoch: 12, Loss: 4.4193, Train: 0.6643, Val: 0.3720, Test: 0.4320
Epoch: 13, Loss: 4.1772, Train: 0.6786, Val: 0.3880, Test: 0.4540
Epoch: 14, Loss: 4.0855, Train: 0.7071, Val: 0.4060, Test: 0.4690
Epoch: 15, Loss: 4.0877, Train: 0.7143, Val: 0.4420, Test: 0.4930
Epoch: 16, Loss: 4.1027, Train: 0.7143, Val: 0.4680, Test: 0.5170
Epoch: 17, Loss: 4.0335, Train: 0.7357, Val: 0.5000, Test: 0.5370
Epoch: 18, Loss: 3.8118, Train: 0.7571, Val: 0.5420, Test: 0.5660
Epoch: 19, Loss: 3.5482, Train: 0.7643, Val: 0.5700, Test: 0.5840
Epoch: 20, Loss: 3.6542, Train: 0.7786, Val: 0.5780, Test: 0.5970
Epoch: 21, Loss: 3.4697, Train: 0.7857, Val: 0.5880, Test: 0.6080
Epoch: 22, Loss: 3.7050, Train: 0.8143, Val: 0.5980, Test: 0.6270
Epoch: 23, Loss: 3.3831, Train: 0.8286, Val: 0.6080, Test: 0.6390
Epoch: 24, Loss: 3.5477, Train: 0.8357, Val: 0.6220, Test: 0.6530
Epoch: 25, Loss: 3.5183, Train: 0.8286, Val: 0.6300, Test: 0.6630
Epoch: 26, Loss: 3.5700, Train: 0.8357, Val: 0.6340, Test: 0.6630
Epoch: 27, Loss: 3.1700, Train: 0.8357, Val: 0.6300, Test: 0.6640
Epoch: 28, Loss: 3.3478, Train: 0.9000, Val: 0.6480, Test: 0.6770
Epoch: 29, Loss: 3.2572, Train: 0.9429, Val: 0.6660, Test: 0.7000
Epoch: 30, Loss: 2.8287, Train: 0.9500, Val: 0.7160, Test: 0.7460
Epoch: 31, Loss: 3.1058, Train: 0.9643, Val: 0.7460, Test: 0.7700
Epoch: 32, Loss: 3.1519, Train: 0.9857, Val: 0.7620, Test: 0.7730
Epoch: 33, Loss: 3.3409, Train: 0.9857, Val: 0.7660, Test: 0.7760
Epoch: 34, Loss: 3.2710, Train: 0.9857, Val: 0.7680, Test: 0.7750
Epoch: 35, Loss: 2.9192, Train: 0.9857, Val: 0.7660, Test: 0.7800
Epoch: 36, Loss: 3.0718, Train: 0.9857, Val: 0.7740, Test: 0.7850
Epoch: 37, Loss: 3.1572, Train: 0.9857, Val: 0.7860, Test: 0.7910
Epoch: 38, Loss: 2.8672, Train: 0.9857, Val: 0.7920, Test: 0.7950
Epoch: 39, Loss: 2.9040, Train: 0.9857, Val: 0.7960, Test: 0.8050
Epoch: 40, Loss: 2.7793, Train: 0.9929, Val: 0.7980, Test: 0.8100
Epoch: 41, Loss: 2.8244, Train: 0.9929, Val: 0.7980, Test: 0.8180
Epoch: 42, Loss: 2.7541, Train: 0.9929, Val: 0.8020, Test: 0.8190
Epoch: 43, Loss: 2.9099, Train: 0.9929, Val: 0.8020, Test: 0.8160
Epoch: 44, Loss: 2.7037, Train: 0.9929, Val: 0.7980, Test: 0.8140
Epoch: 45, Loss: 2.5762, Train: 0.9929, Val: 0.8020, Test: 0.8130
Epoch: 46, Loss: 2.7809, Train: 0.9929, Val: 0.8000, Test: 0.8070
Epoch: 47, Loss: 2.5508, Train: 0.9929, Val: 0.7960, Test: 0.8040
Epoch: 48, Loss: 2.6667, Train: 0.9929, Val: 0.7940, Test: 0.8030
Epoch: 49, Loss: 2.8803, Train: 0.9929, Val: 0.7880, Test: 0.8010
Epoch: 50, Loss: 2.3641, Train: 0.9929, Val: 0.7880, Test: 0.8020
Epoch: 51, Loss: 2.6243, Train: 0.9929, Val: 0.7860, Test: 0.8010
Epoch: 52, Loss: 2.9708, Train: 0.9929, Val: 0.7860, Test: 0.7980
Epoch: 53, Loss: 2.6413, Train: 0.9929, Val: 0.7800, Test: 0.7930
Epoch: 54, Loss: 2.5781, Train: 0.9929, Val: 0.7720, Test: 0.7880
Epoch: 55, Loss: 2.5640, Train: 0.9929, Val: 0.7780, Test: 0.7910
Epoch: 56, Loss: 3.0931, Train: 0.9929, Val: 0.7720, Test: 0.7920
Epoch: 57, Loss: 2.7387, Train: 0.9929, Val: 0.7700, Test: 0.7930
Epoch: 58, Loss: 2.4702, Train: 0.9929, Val: 0.7720, Test: 0.7950
Epoch: 59, Loss: 2.6066, Train: 0.9929, Val: 0.7680, Test: 0.7940
Epoch: 60, Loss: 2.9899, Train: 0.9929, Val: 0.7740, Test: 0.7970
Epoch: 61, Loss: 2.6072, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 62, Loss: 2.7174, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 63, Loss: 2.5422, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 64, Loss: 2.2682, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 65, Loss: 2.6320, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 66, Loss: 2.4980, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 67, Loss: 2.6212, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 68, Loss: 2.7232, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 69, Loss: 2.7093, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 70, Loss: 2.2462, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 71, Loss: 2.3901, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 72, Loss: 2.5805, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 73, Loss: 2.5753, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 74, Loss: 2.6486, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 75, Loss: 2.3363, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 76, Loss: 2.7930, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 77, Loss: 2.7938, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 78, Loss: 2.7056, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 79, Loss: 2.6846, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 80, Loss: 2.5386, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 81, Loss: 2.3067, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 82, Loss: 2.6347, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 83, Loss: 2.6690, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 84, Loss: 2.1405, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 85, Loss: 2.3764, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 86, Loss: 2.6589, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 87, Loss: 2.3315, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 88, Loss: 2.4517, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 89, Loss: 2.7038, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 90, Loss: 2.5034, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 91, Loss: 2.5472, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 92, Loss: 2.2767, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 93, Loss: 2.2036, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 94, Loss: 2.5243, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 95, Loss: 2.4099, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 96, Loss: 2.3371, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 97, Loss: 2.5559, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 98, Loss: 2.7468, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 99, Loss: 2.2840, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 100, Loss: 2.5071, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 101, Loss: 2.5769, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 102, Loss: 2.3246, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 103, Loss: 2.4353, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 104, Loss: 2.3541, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 105, Loss: 2.1919, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 106, Loss: 2.6170, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 107, Loss: 2.6740, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 108, Loss: 2.3586, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 109, Loss: 2.5385, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 110, Loss: 2.0991, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 111, Loss: 2.6357, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 112, Loss: 2.5021, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 113, Loss: 2.4871, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 114, Loss: 2.5226, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 115, Loss: 2.6400, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 116, Loss: 2.3923, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 117, Loss: 2.5959, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 118, Loss: 2.6635, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 119, Loss: 2.1834, Train: 1.0000, Val: 0.7840, Test: 0.8060
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 2.5901, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 121, Loss: 2.3109, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 122, Loss: 2.4294, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 123, Loss: 2.3482, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 124, Loss: 2.5454, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 125, Loss: 2.1794, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 126, Loss: 2.2281, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 127, Loss: 2.4627, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 128, Loss: 2.5569, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 129, Loss: 2.3433, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 130, Loss: 2.3197, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 131, Loss: 2.3899, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 132, Loss: 2.2380, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 133, Loss: 2.5203, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 134, Loss: 2.1569, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 135, Loss: 2.3524, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 136, Loss: 2.2178, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 137, Loss: 2.4898, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 138, Loss: 2.5942, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 139, Loss: 2.4948, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 140, Loss: 2.3808, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 141, Loss: 2.6584, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 142, Loss: 2.4220, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 143, Loss: 2.6225, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 144, Loss: 2.2161, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 145, Loss: 2.4078, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 146, Loss: 2.7261, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 147, Loss: 2.6289, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 148, Loss: 2.3191, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 149, Loss: 2.2102, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 150, Loss: 2.4529, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 151, Loss: 2.6280, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 152, Loss: 2.6273, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 153, Loss: 2.3470, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 154, Loss: 2.8305, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 155, Loss: 2.3128, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 156, Loss: 2.5135, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 157, Loss: 2.4083, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 158, Loss: 2.2064, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 159, Loss: 2.4183, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 160, Loss: 2.4789, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 161, Loss: 2.4476, Train: 1.0000, Val: 0.7860, Test: 0.7930
Epoch: 162, Loss: 2.8307, Train: 1.0000, Val: 0.7860, Test: 0.7940
Epoch: 163, Loss: 2.2798, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 164, Loss: 2.4426, Train: 1.0000, Val: 0.7900, Test: 0.7980
Epoch: 165, Loss: 2.5804, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 166, Loss: 2.3809, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 167, Loss: 2.2528, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 168, Loss: 2.5886, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 169, Loss: 2.3861, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 170, Loss: 2.3115, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 171, Loss: 2.2355, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 172, Loss: 2.1023, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 173, Loss: 2.4801, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 174, Loss: 2.0639, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 175, Loss: 2.5853, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 176, Loss: 2.3115, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 177, Loss: 2.0710, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 178, Loss: 2.4395, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 179, Loss: 2.4181, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 180, Loss: 2.1604, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 181, Loss: 2.3448, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 182, Loss: 2.2064, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 183, Loss: 2.3027, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 184, Loss: 2.6539, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 185, Loss: 2.4830, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 186, Loss: 2.6469, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 187, Loss: 2.4245, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 188, Loss: 2.4467, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 189, Loss: 2.8328, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 190, Loss: 2.2696, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 191, Loss: 2.5162, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 192, Loss: 2.2673, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 193, Loss: 2.4726, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 194, Loss: 2.5759, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 195, Loss: 2.3430, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 196, Loss: 2.5506, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 197, Loss: 2.6515, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 198, Loss: 2.2705, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 199, Loss: 2.2340, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 200, Loss: 2.2973, Train: 1.0000, Val: 0.7860, Test: 0.7980
MAD:  0.195
Best Test Accuracy: 0.8190, Val Accuracy: 0.8020, Train Accuracy: 0.9929
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8410, Train: 0.0929, Val: 0.0980, Test: 0.0930
Epoch: 2, Loss: 4.8173, Train: 0.3000, Val: 0.1700, Test: 0.1840
Epoch: 3, Loss: 4.7692, Train: 0.4071, Val: 0.2060, Test: 0.2250
Epoch: 4, Loss: 4.7410, Train: 0.4357, Val: 0.2240, Test: 0.2520
Epoch: 5, Loss: 4.7091, Train: 0.5000, Val: 0.2460, Test: 0.2770
Epoch: 6, Loss: 4.6265, Train: 0.4929, Val: 0.2660, Test: 0.2980
Epoch: 7, Loss: 4.5899, Train: 0.5071, Val: 0.2760, Test: 0.3140
Epoch: 8, Loss: 4.5687, Train: 0.5429, Val: 0.2900, Test: 0.3260
Epoch: 9, Loss: 4.5479, Train: 0.5500, Val: 0.3000, Test: 0.3430
Epoch: 10, Loss: 4.3822, Train: 0.5643, Val: 0.3080, Test: 0.3450
Epoch: 11, Loss: 4.3939, Train: 0.5643, Val: 0.3060, Test: 0.3430
Epoch: 12, Loss: 4.2413, Train: 0.5643, Val: 0.3080, Test: 0.3460
Epoch: 13, Loss: 4.1536, Train: 0.5714, Val: 0.3180, Test: 0.3530
Epoch: 14, Loss: 3.9518, Train: 0.5714, Val: 0.3220, Test: 0.3550
Epoch: 15, Loss: 3.8155, Train: 0.5857, Val: 0.3300, Test: 0.3590
Epoch: 16, Loss: 3.8944, Train: 0.5929, Val: 0.3420, Test: 0.3730
Epoch: 17, Loss: 3.8403, Train: 0.6000, Val: 0.3640, Test: 0.3970
Epoch: 18, Loss: 3.6944, Train: 0.6214, Val: 0.3900, Test: 0.4320
Epoch: 19, Loss: 3.6123, Train: 0.7000, Val: 0.4440, Test: 0.4880
Epoch: 20, Loss: 3.6741, Train: 0.7500, Val: 0.4860, Test: 0.5430
Epoch: 21, Loss: 3.4778, Train: 0.7929, Val: 0.5300, Test: 0.5910
Epoch: 22, Loss: 3.4225, Train: 0.8286, Val: 0.5660, Test: 0.6250
Epoch: 23, Loss: 3.1405, Train: 0.8571, Val: 0.6180, Test: 0.6490
Epoch: 24, Loss: 3.6341, Train: 0.8857, Val: 0.6500, Test: 0.6840
Epoch: 25, Loss: 3.3423, Train: 0.9500, Val: 0.6840, Test: 0.7240
Epoch: 26, Loss: 3.1578, Train: 0.9643, Val: 0.7080, Test: 0.7520
Epoch: 27, Loss: 3.2641, Train: 0.9786, Val: 0.7340, Test: 0.7760
Epoch: 28, Loss: 3.1931, Train: 0.9929, Val: 0.7660, Test: 0.8000
Epoch: 29, Loss: 3.0279, Train: 0.9929, Val: 0.7700, Test: 0.7900
Epoch: 30, Loss: 3.0627, Train: 0.9929, Val: 0.7920, Test: 0.7820
Epoch: 31, Loss: 3.3542, Train: 0.9929, Val: 0.7760, Test: 0.7670
Epoch: 32, Loss: 3.0870, Train: 0.9929, Val: 0.7620, Test: 0.7620
Epoch: 33, Loss: 2.8214, Train: 0.9929, Val: 0.7620, Test: 0.7640
Epoch: 34, Loss: 3.2262, Train: 0.9929, Val: 0.7600, Test: 0.7610
Epoch: 35, Loss: 2.7681, Train: 0.9857, Val: 0.7620, Test: 0.7610
Epoch: 36, Loss: 2.8772, Train: 0.9929, Val: 0.7660, Test: 0.7640
Epoch: 37, Loss: 3.1055, Train: 0.9929, Val: 0.7680, Test: 0.7710
Epoch: 38, Loss: 2.8502, Train: 0.9929, Val: 0.7700, Test: 0.7710
Epoch: 39, Loss: 2.6205, Train: 0.9929, Val: 0.7700, Test: 0.7700
Epoch: 40, Loss: 2.6887, Train: 0.9929, Val: 0.7680, Test: 0.7740
Epoch: 41, Loss: 2.8881, Train: 0.9929, Val: 0.7720, Test: 0.7790
Epoch: 42, Loss: 2.8442, Train: 0.9929, Val: 0.7780, Test: 0.7880
Epoch: 43, Loss: 2.9786, Train: 0.9929, Val: 0.7800, Test: 0.7920
Epoch: 44, Loss: 2.6134, Train: 0.9929, Val: 0.7820, Test: 0.7970
Epoch: 45, Loss: 2.6474, Train: 0.9929, Val: 0.7860, Test: 0.8040
Epoch: 46, Loss: 2.3568, Train: 0.9929, Val: 0.7920, Test: 0.8090
Epoch: 47, Loss: 3.1298, Train: 0.9929, Val: 0.7960, Test: 0.8100
Epoch: 48, Loss: 2.5490, Train: 0.9929, Val: 0.7940, Test: 0.8170
Epoch: 49, Loss: 2.7719, Train: 0.9929, Val: 0.7920, Test: 0.8210
Epoch: 50, Loss: 2.5631, Train: 1.0000, Val: 0.7960, Test: 0.8210
Epoch: 51, Loss: 2.4297, Train: 1.0000, Val: 0.7980, Test: 0.8220
Epoch: 52, Loss: 2.6200, Train: 1.0000, Val: 0.7980, Test: 0.8210
Epoch: 53, Loss: 2.7306, Train: 1.0000, Val: 0.7980, Test: 0.8200
Epoch: 54, Loss: 2.3966, Train: 1.0000, Val: 0.7980, Test: 0.8170
Epoch: 55, Loss: 2.4794, Train: 1.0000, Val: 0.8000, Test: 0.8140
Epoch: 56, Loss: 2.3147, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 57, Loss: 2.6185, Train: 1.0000, Val: 0.7920, Test: 0.8070
Epoch: 58, Loss: 2.7093, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 59, Loss: 2.7135, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 60, Loss: 2.2952, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 61, Loss: 2.7343, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 62, Loss: 2.3854, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 63, Loss: 2.3950, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 64, Loss: 2.8167, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 65, Loss: 2.3972, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 66, Loss: 2.6015, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 67, Loss: 2.3628, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 68, Loss: 2.5550, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 69, Loss: 2.3438, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 70, Loss: 2.5729, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 71, Loss: 2.3018, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 72, Loss: 2.3280, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 73, Loss: 2.6615, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 74, Loss: 2.6648, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 75, Loss: 2.5071, Train: 1.0000, Val: 0.7780, Test: 0.8150
Epoch: 76, Loss: 2.4001, Train: 1.0000, Val: 0.7800, Test: 0.8170
Epoch: 77, Loss: 2.8564, Train: 1.0000, Val: 0.7800, Test: 0.8170
Epoch: 78, Loss: 2.5166, Train: 1.0000, Val: 0.7800, Test: 0.8150
Epoch: 79, Loss: 2.6938, Train: 1.0000, Val: 0.7760, Test: 0.8150
Epoch: 80, Loss: 2.4571, Train: 1.0000, Val: 0.7740, Test: 0.8160
Epoch: 81, Loss: 2.5052, Train: 1.0000, Val: 0.7760, Test: 0.8140
Epoch: 82, Loss: 2.5047, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 83, Loss: 2.2786, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 84, Loss: 2.3668, Train: 1.0000, Val: 0.7760, Test: 0.8130
Epoch: 85, Loss: 2.2482, Train: 1.0000, Val: 0.7780, Test: 0.8150
Epoch: 86, Loss: 2.5629, Train: 1.0000, Val: 0.7740, Test: 0.8160
Epoch: 87, Loss: 2.6075, Train: 1.0000, Val: 0.7740, Test: 0.8140
Epoch: 88, Loss: 2.3627, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 89, Loss: 2.3489, Train: 1.0000, Val: 0.7700, Test: 0.8130
Epoch: 90, Loss: 2.8701, Train: 1.0000, Val: 0.7680, Test: 0.8110
Epoch: 91, Loss: 2.4985, Train: 1.0000, Val: 0.7660, Test: 0.8110
Epoch: 92, Loss: 2.6280, Train: 1.0000, Val: 0.7680, Test: 0.8130
Epoch: 93, Loss: 2.6282, Train: 1.0000, Val: 0.7720, Test: 0.8130
Epoch: 94, Loss: 2.5365, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 95, Loss: 2.7487, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 96, Loss: 2.6372, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 97, Loss: 2.3672, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 98, Loss: 2.6493, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 99, Loss: 2.1618, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 100, Loss: 2.4470, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 101, Loss: 2.7029, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 102, Loss: 2.4741, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 103, Loss: 2.5300, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 104, Loss: 2.6780, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 105, Loss: 2.1252, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 106, Loss: 2.7984, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 107, Loss: 2.4640, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 108, Loss: 2.6750, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 109, Loss: 2.3264, Train: 1.0000, Val: 0.7720, Test: 0.8150
Epoch: 110, Loss: 2.2043, Train: 1.0000, Val: 0.7720, Test: 0.8150
Epoch: 111, Loss: 2.5299, Train: 1.0000, Val: 0.7760, Test: 0.8150
Epoch: 112, Loss: 2.4984, Train: 1.0000, Val: 0.7820, Test: 0.8190
Epoch: 113, Loss: 2.7055, Train: 1.0000, Val: 0.7820, Test: 0.8210
Epoch: 114, Loss: 2.7079, Train: 1.0000, Val: 0.7820, Test: 0.8240
Epoch: 115, Loss: 2.7731, Train: 1.0000, Val: 0.7820, Test: 0.8250
Epoch: 116, Loss: 2.8057, Train: 1.0000, Val: 0.7820, Test: 0.8250
Epoch: 117, Loss: 2.3950, Train: 1.0000, Val: 0.7800, Test: 0.8250
Epoch: 118, Loss: 2.4328, Train: 1.0000, Val: 0.7800, Test: 0.8230
Epoch: 119, Loss: 2.3601, Train: 1.0000, Val: 0.7760, Test: 0.8200
Epoch: 120, Loss: 2.1948, Train: 1.0000, Val: 0.7780, Test: 0.8200
Epoch: 121, Loss: 2.4936, Train: 1.0000, Val: 0.7760, Test: 0.8200
Epoch: 122, Loss: 2.6016, Train: 1.0000, Val: 0.7760, Test: 0.8160
Epoch: 123, Loss: 2.3565, Train: 1.0000, Val: 0.7780, Test: 0.8150
Epoch: 124, Loss: 2.1994, Train: 1.0000, Val: 0.7760, Test: 0.8140
Epoch: 125, Loss: 2.6128, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 126, Loss: 2.4865, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 127, Loss: 2.1927, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 128, Loss: 2.5272, Train: 1.0000, Val: 0.7760, Test: 0.8120
Epoch: 129, Loss: 2.3571, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 130, Loss: 2.6265, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 131, Loss: 2.5785, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 132, Loss: 2.3616, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 133, Loss: 2.5952, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 134, Loss: 2.1078, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 135, Loss: 2.4177, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 136, Loss: 2.6600, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 137, Loss: 2.5998, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 138, Loss: 2.5041, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 139, Loss: 2.1857, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 140, Loss: 2.3768, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 141, Loss: 2.3964, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 142, Loss: 2.3842, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 143, Loss: 2.4810, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 144, Loss: 2.2490, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 145, Loss: 2.2504, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 146, Loss: 2.4842, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 147, Loss: 2.3538, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 148, Loss: 2.5268, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 149, Loss: 2.6259, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 150, Loss: 2.5096, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 151, Loss: 2.2822, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 152, Loss: 2.2455, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 153, Loss: 2.5242, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 154, Loss: 2.5337, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 155, Loss: 2.2119, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 156, Loss: 2.5864, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 157, Loss: 2.6222, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 158, Loss: 2.3219, Train: 1.0000, Val: 0.7760, Test: 0.8050
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 159, Loss: 2.4196, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 160, Loss: 2.2505, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 161, Loss: 2.5263, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 162, Loss: 2.4209, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 163, Loss: 1.8211, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 164, Loss: 2.3437, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 165, Loss: 2.8351, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 166, Loss: 2.5221, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 167, Loss: 2.4612, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 168, Loss: 2.4854, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 169, Loss: 2.7944, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 170, Loss: 2.2350, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 171, Loss: 2.4150, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 172, Loss: 2.3888, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 173, Loss: 2.6501, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 174, Loss: 2.1731, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 175, Loss: 2.1318, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 176, Loss: 2.4809, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 177, Loss: 1.9612, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 178, Loss: 2.4525, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 179, Loss: 2.6319, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 180, Loss: 2.3761, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 181, Loss: 2.3756, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 182, Loss: 2.3146, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 183, Loss: 2.2792, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 184, Loss: 2.0099, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 185, Loss: 2.4819, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 186, Loss: 2.2768, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 187, Loss: 2.5471, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 188, Loss: 2.7551, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 189, Loss: 2.5830, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 190, Loss: 2.3431, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 191, Loss: 2.1346, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 192, Loss: 2.5139, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 193, Loss: 2.3011, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 194, Loss: 2.5090, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 195, Loss: 2.4044, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 196, Loss: 2.5418, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 197, Loss: 2.7551, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 198, Loss: 2.3061, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 199, Loss: 2.0605, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 200, Loss: 2.2664, Train: 1.0000, Val: 0.7700, Test: 0.7980
MAD:  0.6821
Best Test Accuracy: 0.8250, Val Accuracy: 0.7820, Train Accuracy: 1.0000
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8579, Train: 0.0857, Val: 0.1220, Test: 0.1380
Epoch: 2, Loss: 4.8359, Train: 0.2643, Val: 0.2660, Test: 0.3050
Epoch: 3, Loss: 4.8001, Train: 0.3929, Val: 0.3700, Test: 0.3990
Epoch: 4, Loss: 4.7786, Train: 0.4643, Val: 0.4020, Test: 0.4330
Epoch: 5, Loss: 4.7431, Train: 0.4929, Val: 0.4100, Test: 0.4520
Epoch: 6, Loss: 4.6815, Train: 0.5143, Val: 0.4200, Test: 0.4720
Epoch: 7, Loss: 4.6249, Train: 0.5143, Val: 0.4340, Test: 0.4730
Epoch: 8, Loss: 4.5989, Train: 0.5357, Val: 0.4400, Test: 0.4790
Epoch: 9, Loss: 4.6022, Train: 0.5571, Val: 0.4400, Test: 0.4830
Epoch: 10, Loss: 4.4597, Train: 0.5571, Val: 0.4460, Test: 0.4900
Epoch: 11, Loss: 4.4230, Train: 0.5714, Val: 0.4580, Test: 0.4990
Epoch: 12, Loss: 4.3215, Train: 0.5643, Val: 0.4700, Test: 0.5050
Epoch: 13, Loss: 4.1554, Train: 0.5643, Val: 0.4800, Test: 0.5110
Epoch: 14, Loss: 4.2755, Train: 0.5643, Val: 0.4840, Test: 0.5150
Epoch: 15, Loss: 4.2732, Train: 0.5714, Val: 0.4940, Test: 0.5190
Epoch: 16, Loss: 4.0803, Train: 0.5857, Val: 0.4960, Test: 0.5180
Epoch: 17, Loss: 4.0085, Train: 0.6000, Val: 0.5040, Test: 0.5230
Epoch: 18, Loss: 3.7824, Train: 0.6143, Val: 0.5080, Test: 0.5260
Epoch: 19, Loss: 3.6683, Train: 0.6286, Val: 0.5140, Test: 0.5400
Epoch: 20, Loss: 3.6883, Train: 0.6357, Val: 0.5220, Test: 0.5630
Epoch: 21, Loss: 3.7787, Train: 0.6643, Val: 0.5380, Test: 0.5730
Epoch: 22, Loss: 3.0984, Train: 0.6929, Val: 0.5540, Test: 0.5940
Epoch: 23, Loss: 3.6753, Train: 0.7286, Val: 0.5800, Test: 0.6060
Epoch: 24, Loss: 3.5052, Train: 0.7571, Val: 0.5920, Test: 0.6290
Epoch: 25, Loss: 3.3800, Train: 0.8071, Val: 0.6060, Test: 0.6690
Epoch: 26, Loss: 3.3165, Train: 0.8714, Val: 0.6460, Test: 0.6940
Epoch: 27, Loss: 3.1907, Train: 0.9286, Val: 0.6800, Test: 0.7360
Epoch: 28, Loss: 2.9824, Train: 0.9571, Val: 0.7220, Test: 0.7790
Epoch: 29, Loss: 2.9531, Train: 0.9714, Val: 0.7240, Test: 0.7750
Epoch: 30, Loss: 3.2826, Train: 0.9857, Val: 0.7340, Test: 0.7760
Epoch: 31, Loss: 3.3182, Train: 0.9857, Val: 0.7380, Test: 0.7660
Epoch: 32, Loss: 3.1908, Train: 0.9857, Val: 0.7180, Test: 0.7570
Epoch: 33, Loss: 3.2537, Train: 0.9857, Val: 0.7140, Test: 0.7380
Epoch: 34, Loss: 3.2776, Train: 0.9857, Val: 0.7140, Test: 0.7310
Epoch: 35, Loss: 2.9910, Train: 0.9857, Val: 0.7240, Test: 0.7370
Epoch: 36, Loss: 2.8642, Train: 0.9786, Val: 0.7240, Test: 0.7450
Epoch: 37, Loss: 3.0953, Train: 0.9929, Val: 0.7380, Test: 0.7550
Epoch: 38, Loss: 3.1721, Train: 0.9929, Val: 0.7400, Test: 0.7660
Epoch: 39, Loss: 3.2257, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 40, Loss: 2.7877, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 41, Loss: 2.7402, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 42, Loss: 2.7468, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 43, Loss: 3.3759, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 44, Loss: 2.8928, Train: 1.0000, Val: 0.7840, Test: 0.8210
Epoch: 45, Loss: 2.8511, Train: 1.0000, Val: 0.7800, Test: 0.8230
Epoch: 46, Loss: 2.5939, Train: 1.0000, Val: 0.7840, Test: 0.8220
Epoch: 47, Loss: 2.6229, Train: 1.0000, Val: 0.7860, Test: 0.8230
Epoch: 48, Loss: 2.8239, Train: 1.0000, Val: 0.7840, Test: 0.8260
Epoch: 49, Loss: 2.5567, Train: 1.0000, Val: 0.7860, Test: 0.8230
Epoch: 50, Loss: 2.7062, Train: 1.0000, Val: 0.7880, Test: 0.8260
Epoch: 51, Loss: 2.7899, Train: 1.0000, Val: 0.7880, Test: 0.8270
Epoch: 52, Loss: 2.6704, Train: 1.0000, Val: 0.7940, Test: 0.8200
Epoch: 53, Loss: 2.5148, Train: 1.0000, Val: 0.7820, Test: 0.8160
Epoch: 54, Loss: 2.8804, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 55, Loss: 2.5109, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 56, Loss: 2.5999, Train: 0.9929, Val: 0.7740, Test: 0.7950
Epoch: 57, Loss: 2.5229, Train: 0.9929, Val: 0.7700, Test: 0.7890
Epoch: 58, Loss: 2.8652, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 59, Loss: 2.3633, Train: 1.0000, Val: 0.7840, Test: 0.7870
Epoch: 60, Loss: 2.6961, Train: 1.0000, Val: 0.7840, Test: 0.7870
Epoch: 61, Loss: 2.6789, Train: 1.0000, Val: 0.7840, Test: 0.7900
Epoch: 62, Loss: 2.7954, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 63, Loss: 2.5526, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 64, Loss: 2.8308, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 65, Loss: 2.5997, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 66, Loss: 2.5936, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 67, Loss: 2.6070, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 68, Loss: 2.6529, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 69, Loss: 2.7740, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 70, Loss: 2.6208, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 71, Loss: 2.6483, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 72, Loss: 2.7496, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 73, Loss: 2.4065, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 74, Loss: 2.2856, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 75, Loss: 2.6247, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 76, Loss: 2.6966, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 77, Loss: 2.5024, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 78, Loss: 2.6483, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 79, Loss: 2.8514, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 80, Loss: 2.4541, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 81, Loss: 2.4760, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 82, Loss: 2.2764, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 83, Loss: 2.6580, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 84, Loss: 2.3298, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 85, Loss: 2.4620, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 86, Loss: 2.7896, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 87, Loss: 2.6440, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 88, Loss: 2.5627, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 89, Loss: 2.5310, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 90, Loss: 2.4575, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 91, Loss: 2.4719, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 92, Loss: 2.5118, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 93, Loss: 2.5258, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 94, Loss: 2.4547, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 95, Loss: 2.4116, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 96, Loss: 2.6634, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 97, Loss: 2.2230, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 98, Loss: 2.6572, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 99, Loss: 2.3811, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 100, Loss: 2.4492, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 101, Loss: 2.3755, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 102, Loss: 2.4904, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 103, Loss: 1.9841, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 104, Loss: 2.3193, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 105, Loss: 2.4732, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 106, Loss: 2.8276, Train: 1.0000, Val: 0.7940, Test: 0.8030
Epoch: 107, Loss: 2.6088, Train: 1.0000, Val: 0.7980, Test: 0.8040
Epoch: 108, Loss: 2.8469, Train: 1.0000, Val: 0.7940, Test: 0.8030
Epoch: 109, Loss: 2.4341, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 110, Loss: 2.4796, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 111, Loss: 2.4757, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 112, Loss: 2.5646, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 113, Loss: 2.4477, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 114, Loss: 2.6448, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 115, Loss: 2.7890, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 116, Loss: 2.4920, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 117, Loss: 2.2491, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 118, Loss: 2.8112, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 119, Loss: 2.8634, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 120, Loss: 2.4921, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 121, Loss: 2.5335, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 122, Loss: 2.8898, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 123, Loss: 2.2251, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 124, Loss: 2.7005, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 125, Loss: 2.3446, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 126, Loss: 2.1485, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 127, Loss: 2.7089, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 128, Loss: 2.1776, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 129, Loss: 2.5233, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 130, Loss: 2.4369, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 131, Loss: 2.1506, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 132, Loss: 2.4241, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 133, Loss: 2.5658, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 134, Loss: 2.4846, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 135, Loss: 2.4358, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 136, Loss: 2.2126, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 137, Loss: 2.3630, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 138, Loss: 2.9010, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 139, Loss: 2.4984, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 140, Loss: 2.4986, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 141, Loss: 2.3881, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 142, Loss: 2.4094, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 143, Loss: 2.6205, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 144, Loss: 2.4277, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 145, Loss: 2.7907, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 146, Loss: 2.5226, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 147, Loss: 2.1169, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 148, Loss: 2.3259, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 149, Loss: 2.3659, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 150, Loss: 2.1785, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 151, Loss: 2.2989, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 152, Loss: 2.4164, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 153, Loss: 2.1061, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 154, Loss: 2.1049, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 155, Loss: 2.4531, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 156, Loss: 2.5580, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 157, Loss: 2.4160, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 158, Loss: 2.7533, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 159, Loss: 2.7641, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 160, Loss: 2.5864, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 161, Loss: 2.3925, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 162, Loss: 2.3579, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 163, Loss: 2.6663, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 164, Loss: 2.8240, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 165, Loss: 2.3463, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 166, Loss: 2.6668, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 167, Loss: 2.3777, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 168, Loss: 2.0402, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 169, Loss: 2.4144, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 170, Loss: 2.3387, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 171, Loss: 2.3747, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 172, Loss: 2.5983, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 173, Loss: 2.4551, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 174, Loss: 2.7889, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 175, Loss: 2.7927, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 176, Loss: 2.3809, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 177, Loss: 2.5457, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 178, Loss: 2.1683, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 179, Loss: 2.3072, Train: 1.0000, Val: 0.7600, Test: 0.7870
Epoch: 180, Loss: 2.5872, Train: 1.0000, Val: 0.7600, Test: 0.7880
Epoch: 181, Loss: 2.4632, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 182, Loss: 2.5649, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 183, Loss: 2.2812, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 184, Loss: 2.0351, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 185, Loss: 2.5160, Train: 1.0000, Val: 0.7600, Test: 0.7870
Epoch: 186, Loss: 2.2054, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 187, Loss: 2.9044, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 188, Loss: 2.5809, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 189, Loss: 2.8041, Train: 1.0000, Val: 0.7600, Test: 0.7910
Epoch: 190, Loss: 2.5827, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 191, Loss: 2.6635, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 192, Loss: 2.6220, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 193, Loss: 2.4521, Train: 1.0000, Val: 0.7620, Test: 0.7850
Epoch: 194, Loss: 2.4461, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 195, Loss: 2.6866, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 196, Loss: 2.3062, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 197, Loss: 2.3779, Train: 1.0000, Val: 0.7660, Test: 0.7870
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 198, Loss: 2.3876, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 199, Loss: 2.4773, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 200, Loss: 2.0661, Train: 1.0000, Val: 0.7660, Test: 0.7900
MAD:  0.3113
Best Test Accuracy: 0.8270, Val Accuracy: 0.7880, Train Accuracy: 1.0000
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8354, Train: 0.2000, Val: 0.1200, Test: 0.1220
Epoch: 2, Loss: 4.8058, Train: 0.3857, Val: 0.2100, Test: 0.2100
Epoch: 3, Loss: 4.7721, Train: 0.4000, Val: 0.2380, Test: 0.2400
Epoch: 4, Loss: 4.7620, Train: 0.4429, Val: 0.2580, Test: 0.2620
Epoch: 5, Loss: 4.6413, Train: 0.4786, Val: 0.2740, Test: 0.2770
Epoch: 6, Loss: 4.5939, Train: 0.4857, Val: 0.2820, Test: 0.2840
Epoch: 7, Loss: 4.5577, Train: 0.4857, Val: 0.2880, Test: 0.2880
Epoch: 8, Loss: 4.3970, Train: 0.4857, Val: 0.2940, Test: 0.2870
Epoch: 9, Loss: 4.2999, Train: 0.4929, Val: 0.3100, Test: 0.2970
Epoch: 10, Loss: 4.3402, Train: 0.5000, Val: 0.3140, Test: 0.3030
Epoch: 11, Loss: 4.1466, Train: 0.5071, Val: 0.3200, Test: 0.3050
Epoch: 12, Loss: 4.1230, Train: 0.5071, Val: 0.3240, Test: 0.3160
Epoch: 13, Loss: 4.0906, Train: 0.5143, Val: 0.3300, Test: 0.3220
Epoch: 14, Loss: 3.8515, Train: 0.5071, Val: 0.3340, Test: 0.3320
Epoch: 15, Loss: 3.8280, Train: 0.5143, Val: 0.3340, Test: 0.3370
Epoch: 16, Loss: 3.9333, Train: 0.5357, Val: 0.3440, Test: 0.3500
Epoch: 17, Loss: 3.5927, Train: 0.5357, Val: 0.3440, Test: 0.3600
Epoch: 18, Loss: 3.6201, Train: 0.5786, Val: 0.3540, Test: 0.3650
Epoch: 19, Loss: 3.4750, Train: 0.6357, Val: 0.3760, Test: 0.3880
Epoch: 20, Loss: 3.1276, Train: 0.6786, Val: 0.4060, Test: 0.4110
Epoch: 21, Loss: 3.3047, Train: 0.7000, Val: 0.4180, Test: 0.4350
Epoch: 22, Loss: 3.2481, Train: 0.7214, Val: 0.4220, Test: 0.4440
Epoch: 23, Loss: 3.4165, Train: 0.7500, Val: 0.4300, Test: 0.4560
Epoch: 24, Loss: 3.2870, Train: 0.8500, Val: 0.4760, Test: 0.5020
Epoch: 25, Loss: 3.2750, Train: 0.9071, Val: 0.5840, Test: 0.5760
Epoch: 26, Loss: 3.2863, Train: 0.9429, Val: 0.6520, Test: 0.6750
Epoch: 27, Loss: 3.3713, Train: 0.9643, Val: 0.7160, Test: 0.7310
Epoch: 28, Loss: 3.6206, Train: 0.9857, Val: 0.7540, Test: 0.7660
Epoch: 29, Loss: 3.1891, Train: 0.9857, Val: 0.7780, Test: 0.7800
Epoch: 30, Loss: 3.0517, Train: 0.9857, Val: 0.7880, Test: 0.7890
Epoch: 31, Loss: 3.3126, Train: 0.9929, Val: 0.7900, Test: 0.7940
Epoch: 32, Loss: 3.5026, Train: 0.9929, Val: 0.7900, Test: 0.7940
Epoch: 33, Loss: 3.3085, Train: 0.9929, Val: 0.7940, Test: 0.7940
Epoch: 34, Loss: 2.8671, Train: 0.9929, Val: 0.7920, Test: 0.7930
Epoch: 35, Loss: 2.7786, Train: 0.9929, Val: 0.7920, Test: 0.7980
Epoch: 36, Loss: 2.9847, Train: 0.9929, Val: 0.7900, Test: 0.7920
Epoch: 37, Loss: 2.9894, Train: 0.9929, Val: 0.7880, Test: 0.7880
Epoch: 38, Loss: 2.7183, Train: 0.9929, Val: 0.7820, Test: 0.7890
Epoch: 39, Loss: 2.7688, Train: 0.9929, Val: 0.7760, Test: 0.7840
Epoch: 40, Loss: 2.9993, Train: 0.9929, Val: 0.7700, Test: 0.7800
Epoch: 41, Loss: 3.1074, Train: 0.9929, Val: 0.7660, Test: 0.7780
Epoch: 42, Loss: 3.1461, Train: 0.9929, Val: 0.7600, Test: 0.7750
Epoch: 43, Loss: 2.6585, Train: 0.9929, Val: 0.7600, Test: 0.7700
Epoch: 44, Loss: 3.0859, Train: 0.9929, Val: 0.7560, Test: 0.7660
Epoch: 45, Loss: 3.0260, Train: 0.9929, Val: 0.7540, Test: 0.7680
Epoch: 46, Loss: 2.5374, Train: 0.9929, Val: 0.7600, Test: 0.7700
Epoch: 47, Loss: 3.1215, Train: 0.9929, Val: 0.7720, Test: 0.7770
Epoch: 48, Loss: 2.8733, Train: 0.9929, Val: 0.7720, Test: 0.7790
Epoch: 49, Loss: 2.7925, Train: 0.9929, Val: 0.7740, Test: 0.7790
Epoch: 50, Loss: 2.6383, Train: 0.9929, Val: 0.7760, Test: 0.7780
Epoch: 51, Loss: 2.7892, Train: 0.9929, Val: 0.7780, Test: 0.7820
Epoch: 52, Loss: 2.8580, Train: 0.9929, Val: 0.7800, Test: 0.7840
Epoch: 53, Loss: 2.9263, Train: 0.9929, Val: 0.7880, Test: 0.7860
Epoch: 54, Loss: 2.8213, Train: 0.9929, Val: 0.7820, Test: 0.7860
Epoch: 55, Loss: 2.4948, Train: 0.9929, Val: 0.7820, Test: 0.7850
Epoch: 56, Loss: 2.4155, Train: 0.9929, Val: 0.7820, Test: 0.7850
Epoch: 57, Loss: 2.6240, Train: 0.9929, Val: 0.7800, Test: 0.7850
Epoch: 58, Loss: 2.2556, Train: 0.9929, Val: 0.7840, Test: 0.7870
Epoch: 59, Loss: 2.8618, Train: 1.0000, Val: 0.7880, Test: 0.7860
Epoch: 60, Loss: 2.6728, Train: 1.0000, Val: 0.7880, Test: 0.7860
Epoch: 61, Loss: 2.8905, Train: 1.0000, Val: 0.7840, Test: 0.7900
Epoch: 62, Loss: 2.5506, Train: 1.0000, Val: 0.7860, Test: 0.7910
Epoch: 63, Loss: 2.3165, Train: 1.0000, Val: 0.7820, Test: 0.7910
Epoch: 64, Loss: 2.4529, Train: 1.0000, Val: 0.7820, Test: 0.7880
Epoch: 65, Loss: 2.5114, Train: 1.0000, Val: 0.7820, Test: 0.7840
Epoch: 66, Loss: 2.9586, Train: 1.0000, Val: 0.7820, Test: 0.7820
Epoch: 67, Loss: 2.5364, Train: 1.0000, Val: 0.7840, Test: 0.7850
Epoch: 68, Loss: 2.4094, Train: 1.0000, Val: 0.7820, Test: 0.7850
Epoch: 69, Loss: 2.4684, Train: 1.0000, Val: 0.7820, Test: 0.7860
Epoch: 70, Loss: 2.8779, Train: 1.0000, Val: 0.7820, Test: 0.7890
Epoch: 71, Loss: 3.0186, Train: 1.0000, Val: 0.7820, Test: 0.7910
Epoch: 72, Loss: 2.6953, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 73, Loss: 2.6329, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 74, Loss: 2.4117, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 75, Loss: 2.6883, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 76, Loss: 2.5750, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 77, Loss: 2.4784, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 78, Loss: 2.4935, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 79, Loss: 2.6480, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 80, Loss: 2.3984, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 81, Loss: 2.4347, Train: 1.0000, Val: 0.7820, Test: 0.7910
Epoch: 82, Loss: 2.7417, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 83, Loss: 2.7813, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 84, Loss: 2.6887, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 85, Loss: 2.5885, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 86, Loss: 2.2640, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 87, Loss: 2.5203, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 88, Loss: 2.4474, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 89, Loss: 2.7486, Train: 1.0000, Val: 0.7780, Test: 0.7880
Epoch: 90, Loss: 2.3998, Train: 1.0000, Val: 0.7820, Test: 0.7870
Epoch: 91, Loss: 2.3375, Train: 1.0000, Val: 0.7780, Test: 0.7870
Epoch: 92, Loss: 2.5343, Train: 1.0000, Val: 0.7780, Test: 0.7870
Epoch: 93, Loss: 2.4814, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 94, Loss: 2.5621, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 95, Loss: 2.7112, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 96, Loss: 2.5112, Train: 1.0000, Val: 0.7800, Test: 0.7880
Epoch: 97, Loss: 2.3373, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 98, Loss: 2.0215, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 99, Loss: 2.5768, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 100, Loss: 2.4929, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 101, Loss: 2.5701, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 102, Loss: 2.3429, Train: 1.0000, Val: 0.7880, Test: 0.7940
Epoch: 103, Loss: 2.5883, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 104, Loss: 2.5162, Train: 1.0000, Val: 0.7880, Test: 0.7960
Epoch: 105, Loss: 2.6912, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 106, Loss: 2.4189, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 107, Loss: 2.2680, Train: 1.0000, Val: 0.7860, Test: 0.7940
Epoch: 108, Loss: 2.1357, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 109, Loss: 2.4235, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 110, Loss: 2.5383, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 111, Loss: 2.7438, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 112, Loss: 2.3620, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 113, Loss: 2.1439, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 114, Loss: 2.6365, Train: 1.0000, Val: 0.7800, Test: 0.7930
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 115, Loss: 2.5663, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 116, Loss: 2.2628, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 117, Loss: 2.6369, Train: 1.0000, Val: 0.7780, Test: 0.7880
Epoch: 118, Loss: 2.5679, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 119, Loss: 2.5276, Train: 1.0000, Val: 0.7780, Test: 0.7870
Epoch: 120, Loss: 2.4661, Train: 1.0000, Val: 0.7780, Test: 0.7870
Epoch: 121, Loss: 2.3624, Train: 1.0000, Val: 0.7780, Test: 0.7880
Epoch: 122, Loss: 2.4282, Train: 1.0000, Val: 0.7780, Test: 0.7870
Epoch: 123, Loss: 2.5418, Train: 1.0000, Val: 0.7800, Test: 0.7870
Epoch: 124, Loss: 2.4570, Train: 1.0000, Val: 0.7800, Test: 0.7860
Epoch: 125, Loss: 2.6991, Train: 1.0000, Val: 0.7800, Test: 0.7870
Epoch: 126, Loss: 2.3238, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 127, Loss: 2.6080, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 128, Loss: 2.8270, Train: 1.0000, Val: 0.7780, Test: 0.7830
Epoch: 129, Loss: 2.3535, Train: 1.0000, Val: 0.7780, Test: 0.7830
Epoch: 130, Loss: 2.4520, Train: 1.0000, Val: 0.7780, Test: 0.7840
Epoch: 131, Loss: 2.5254, Train: 1.0000, Val: 0.7780, Test: 0.7850
Epoch: 132, Loss: 2.4135, Train: 1.0000, Val: 0.7760, Test: 0.7850
Epoch: 133, Loss: 2.0727, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 134, Loss: 2.5561, Train: 1.0000, Val: 0.7760, Test: 0.7850
Epoch: 135, Loss: 2.8173, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 136, Loss: 2.6169, Train: 1.0000, Val: 0.7780, Test: 0.7870
Epoch: 137, Loss: 2.3505, Train: 1.0000, Val: 0.7800, Test: 0.7870
Epoch: 138, Loss: 3.0190, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 139, Loss: 2.1082, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 140, Loss: 2.2873, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 141, Loss: 2.3831, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 142, Loss: 2.4856, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 143, Loss: 2.5605, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 144, Loss: 2.0322, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 145, Loss: 2.3451, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 146, Loss: 2.3509, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 147, Loss: 2.5604, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 148, Loss: 2.2058, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 149, Loss: 2.8336, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 150, Loss: 2.5931, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 151, Loss: 2.2485, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 152, Loss: 2.4255, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 153, Loss: 2.1447, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 154, Loss: 2.7003, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 155, Loss: 2.1330, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 156, Loss: 2.5216, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 157, Loss: 2.4910, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 158, Loss: 2.4462, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 159, Loss: 2.6567, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 160, Loss: 2.7063, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 161, Loss: 2.5161, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 162, Loss: 2.5921, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 163, Loss: 2.7337, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 164, Loss: 2.5554, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 165, Loss: 2.9347, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 166, Loss: 2.2760, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 167, Loss: 2.5266, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 168, Loss: 2.4793, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 169, Loss: 2.4488, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 170, Loss: 2.2060, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 171, Loss: 2.6934, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 172, Loss: 2.4588, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 173, Loss: 2.1064, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 174, Loss: 2.3169, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 175, Loss: 2.4199, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 176, Loss: 2.8304, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 177, Loss: 2.3044, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 178, Loss: 2.3429, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 179, Loss: 2.4427, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 180, Loss: 2.8783, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 181, Loss: 2.3209, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 182, Loss: 2.4437, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 183, Loss: 2.0603, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 184, Loss: 2.8975, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 185, Loss: 2.2756, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 186, Loss: 2.4217, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 187, Loss: 2.2765, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 188, Loss: 2.4850, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 189, Loss: 2.4825, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 190, Loss: 2.8603, Train: 1.0000, Val: 0.7700, Test: 0.8080
Epoch: 191, Loss: 2.2419, Train: 1.0000, Val: 0.7700, Test: 0.8080
Epoch: 192, Loss: 2.5830, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 193, Loss: 2.2734, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 194, Loss: 2.3025, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 195, Loss: 2.2325, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 196, Loss: 2.6484, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 197, Loss: 2.5854, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 198, Loss: 2.3000, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 199, Loss: 2.1354, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 200, Loss: 2.2473, Train: 1.0000, Val: 0.7700, Test: 0.7970
MAD:  0.7427
Best Test Accuracy: 0.8090, Val Accuracy: 0.7740, Train Accuracy: 1.0000
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8606, Train: 0.0786, Val: 0.0920, Test: 0.0890
Epoch: 2, Loss: 4.8284, Train: 0.2071, Val: 0.1620, Test: 0.1550
Epoch: 3, Loss: 4.7807, Train: 0.2214, Val: 0.2040, Test: 0.1730
Epoch: 4, Loss: 4.7358, Train: 0.3357, Val: 0.2120, Test: 0.1990
Epoch: 5, Loss: 4.6634, Train: 0.3571, Val: 0.2280, Test: 0.2150
Epoch: 6, Loss: 4.6495, Train: 0.3714, Val: 0.2380, Test: 0.2230
Epoch: 7, Loss: 4.5466, Train: 0.3786, Val: 0.2400, Test: 0.2260
Epoch: 8, Loss: 4.4624, Train: 0.3786, Val: 0.2460, Test: 0.2280
Epoch: 9, Loss: 4.4167, Train: 0.3857, Val: 0.2440, Test: 0.2330
Epoch: 10, Loss: 4.2865, Train: 0.3857, Val: 0.2420, Test: 0.2350
Epoch: 11, Loss: 4.2677, Train: 0.3929, Val: 0.2420, Test: 0.2340
Epoch: 12, Loss: 4.0090, Train: 0.4071, Val: 0.2560, Test: 0.2410
Epoch: 13, Loss: 3.9314, Train: 0.4143, Val: 0.2560, Test: 0.2440
Epoch: 14, Loss: 3.8225, Train: 0.4429, Val: 0.2640, Test: 0.2520
Epoch: 15, Loss: 3.7426, Train: 0.4643, Val: 0.2860, Test: 0.2720
Epoch: 16, Loss: 3.7020, Train: 0.4857, Val: 0.3200, Test: 0.3110
Epoch: 17, Loss: 3.5185, Train: 0.5500, Val: 0.3580, Test: 0.3770
Epoch: 18, Loss: 3.6957, Train: 0.6429, Val: 0.4240, Test: 0.4570
Epoch: 19, Loss: 3.2209, Train: 0.7357, Val: 0.4940, Test: 0.5450
Epoch: 20, Loss: 3.4872, Train: 0.8429, Val: 0.6240, Test: 0.6550
Epoch: 21, Loss: 3.4713, Train: 0.9357, Val: 0.7320, Test: 0.7470
Epoch: 22, Loss: 3.4535, Train: 0.9571, Val: 0.7660, Test: 0.7790
Epoch: 23, Loss: 3.4018, Train: 0.9714, Val: 0.7520, Test: 0.7870
Epoch: 24, Loss: 3.3008, Train: 0.9714, Val: 0.7600, Test: 0.7850
Epoch: 25, Loss: 3.0976, Train: 0.9714, Val: 0.7520, Test: 0.7660
Epoch: 26, Loss: 2.8732, Train: 0.9786, Val: 0.7380, Test: 0.7680
Epoch: 27, Loss: 3.2573, Train: 0.9786, Val: 0.7240, Test: 0.7620
Epoch: 28, Loss: 3.5029, Train: 0.9857, Val: 0.7320, Test: 0.7530
Epoch: 29, Loss: 3.0407, Train: 0.9857, Val: 0.7400, Test: 0.7570
Epoch: 30, Loss: 2.9370, Train: 0.9929, Val: 0.7440, Test: 0.7550
Epoch: 31, Loss: 3.0938, Train: 0.9929, Val: 0.7420, Test: 0.7620
Epoch: 32, Loss: 3.1803, Train: 0.9929, Val: 0.7540, Test: 0.7690
Epoch: 33, Loss: 3.0684, Train: 0.9929, Val: 0.7620, Test: 0.7730
Epoch: 34, Loss: 2.9158, Train: 0.9929, Val: 0.7700, Test: 0.7800
Epoch: 35, Loss: 2.9674, Train: 0.9929, Val: 0.7660, Test: 0.7860
Epoch: 36, Loss: 3.0938, Train: 0.9929, Val: 0.7740, Test: 0.7880
Epoch: 37, Loss: 2.6524, Train: 0.9929, Val: 0.7720, Test: 0.7960
Epoch: 38, Loss: 2.9984, Train: 0.9929, Val: 0.7740, Test: 0.7960
Epoch: 39, Loss: 2.8867, Train: 0.9929, Val: 0.7740, Test: 0.7990
Epoch: 40, Loss: 2.8650, Train: 0.9929, Val: 0.7780, Test: 0.8000
Epoch: 41, Loss: 2.8775, Train: 0.9929, Val: 0.7860, Test: 0.8080
Epoch: 42, Loss: 2.7734, Train: 0.9929, Val: 0.7860, Test: 0.8100
Epoch: 43, Loss: 2.8300, Train: 0.9929, Val: 0.7940, Test: 0.8120
Epoch: 44, Loss: 2.7668, Train: 0.9929, Val: 0.8000, Test: 0.8160
Epoch: 45, Loss: 2.8573, Train: 0.9929, Val: 0.7980, Test: 0.8130
Epoch: 46, Loss: 2.9183, Train: 0.9929, Val: 0.7940, Test: 0.8150
Epoch: 47, Loss: 2.8324, Train: 0.9929, Val: 0.7900, Test: 0.8140
Epoch: 48, Loss: 2.8275, Train: 0.9929, Val: 0.7880, Test: 0.8130
Epoch: 49, Loss: 2.7959, Train: 0.9929, Val: 0.7860, Test: 0.8140
Epoch: 50, Loss: 2.7179, Train: 0.9929, Val: 0.7900, Test: 0.8130
Epoch: 51, Loss: 2.7015, Train: 0.9929, Val: 0.7880, Test: 0.8110
Epoch: 52, Loss: 2.3158, Train: 0.9929, Val: 0.7900, Test: 0.8090
Epoch: 53, Loss: 2.5208, Train: 0.9929, Val: 0.7960, Test: 0.8100
Epoch: 54, Loss: 2.7865, Train: 0.9929, Val: 0.7920, Test: 0.8050
Epoch: 55, Loss: 2.7736, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 56, Loss: 2.4552, Train: 1.0000, Val: 0.7940, Test: 0.8020
Epoch: 57, Loss: 2.7552, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 58, Loss: 3.0535, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 59, Loss: 2.8107, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 60, Loss: 2.4527, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 61, Loss: 2.5457, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 62, Loss: 2.8166, Train: 1.0000, Val: 0.7900, Test: 0.8140
Epoch: 63, Loss: 2.8266, Train: 1.0000, Val: 0.7880, Test: 0.8190
Epoch: 64, Loss: 2.4319, Train: 1.0000, Val: 0.7920, Test: 0.8200
Epoch: 65, Loss: 2.6152, Train: 1.0000, Val: 0.7920, Test: 0.8200
Epoch: 66, Loss: 2.4597, Train: 1.0000, Val: 0.7920, Test: 0.8180
Epoch: 67, Loss: 2.4712, Train: 1.0000, Val: 0.7900, Test: 0.8190
Epoch: 68, Loss: 2.6207, Train: 1.0000, Val: 0.7760, Test: 0.8190
Epoch: 69, Loss: 2.6207, Train: 1.0000, Val: 0.7800, Test: 0.8190
Epoch: 70, Loss: 2.0465, Train: 1.0000, Val: 0.7840, Test: 0.8160
Epoch: 71, Loss: 2.5939, Train: 1.0000, Val: 0.7780, Test: 0.8170
Epoch: 72, Loss: 2.3991, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 73, Loss: 2.4222, Train: 1.0000, Val: 0.7800, Test: 0.8140
Epoch: 74, Loss: 2.1499, Train: 1.0000, Val: 0.7780, Test: 0.8150
Epoch: 75, Loss: 2.4427, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 76, Loss: 2.6424, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 77, Loss: 2.7230, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 78, Loss: 2.5917, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 79, Loss: 2.9262, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 80, Loss: 2.4005, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 81, Loss: 2.3759, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 82, Loss: 2.3378, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 83, Loss: 2.7361, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 84, Loss: 2.4037, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 85, Loss: 2.8147, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 86, Loss: 2.4627, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 87, Loss: 2.5219, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 88, Loss: 2.6322, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 89, Loss: 2.3378, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 90, Loss: 2.6965, Train: 1.0000, Val: 0.7700, Test: 0.8080
Epoch: 91, Loss: 3.0641, Train: 1.0000, Val: 0.7700, Test: 0.8090
Epoch: 92, Loss: 2.3579, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 93, Loss: 2.2846, Train: 1.0000, Val: 0.7680, Test: 0.8100
Epoch: 94, Loss: 2.7574, Train: 1.0000, Val: 0.7700, Test: 0.8130
Epoch: 95, Loss: 2.2072, Train: 1.0000, Val: 0.7700, Test: 0.8130
Epoch: 96, Loss: 2.7704, Train: 1.0000, Val: 0.7680, Test: 0.8130
Epoch: 97, Loss: 2.6397, Train: 1.0000, Val: 0.7700, Test: 0.8150
Epoch: 98, Loss: 2.5792, Train: 1.0000, Val: 0.7700, Test: 0.8160
Epoch: 99, Loss: 2.4059, Train: 1.0000, Val: 0.7700, Test: 0.8150
Epoch: 100, Loss: 2.6154, Train: 1.0000, Val: 0.7700, Test: 0.8160
Epoch: 101, Loss: 2.0971, Train: 1.0000, Val: 0.7700, Test: 0.8140
Epoch: 102, Loss: 1.9874, Train: 1.0000, Val: 0.7700, Test: 0.8130
Epoch: 103, Loss: 2.0658, Train: 1.0000, Val: 0.7720, Test: 0.8110
Epoch: 104, Loss: 2.5414, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 105, Loss: 2.3568, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 106, Loss: 2.4708, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 107, Loss: 2.7120, Train: 1.0000, Val: 0.7700, Test: 0.8090
Epoch: 108, Loss: 2.4328, Train: 1.0000, Val: 0.7700, Test: 0.8100
Epoch: 109, Loss: 2.4579, Train: 1.0000, Val: 0.7700, Test: 0.8100
Epoch: 110, Loss: 2.4089, Train: 1.0000, Val: 0.7700, Test: 0.8090
Epoch: 111, Loss: 2.5082, Train: 1.0000, Val: 0.7700, Test: 0.8090
Epoch: 112, Loss: 2.4643, Train: 1.0000, Val: 0.7700, Test: 0.8100
Epoch: 113, Loss: 2.5025, Train: 1.0000, Val: 0.7700, Test: 0.8100
Epoch: 114, Loss: 2.2994, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 115, Loss: 2.7437, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 116, Loss: 2.3208, Train: 1.0000, Val: 0.7700, Test: 0.8110
Epoch: 117, Loss: 2.5228, Train: 1.0000, Val: 0.7700, Test: 0.8100
Epoch: 118, Loss: 2.4591, Train: 1.0000, Val: 0.7700, Test: 0.8080
Epoch: 119, Loss: 2.6677, Train: 1.0000, Val: 0.7700, Test: 0.8080
Epoch: 120, Loss: 2.1881, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 121, Loss: 2.4396, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 122, Loss: 2.5475, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 123, Loss: 2.0767, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 124, Loss: 2.2474, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 125, Loss: 2.7675, Train: 1.0000, Val: 0.7700, Test: 0.8090
Epoch: 126, Loss: 3.0470, Train: 1.0000, Val: 0.7700, Test: 0.8090
Epoch: 127, Loss: 2.5311, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 128, Loss: 2.3745, Train: 1.0000, Val: 0.7680, Test: 0.8080
Epoch: 129, Loss: 2.3571, Train: 1.0000, Val: 0.7680, Test: 0.8070
Epoch: 130, Loss: 2.6480, Train: 1.0000, Val: 0.7660, Test: 0.8070
Epoch: 131, Loss: 2.5099, Train: 1.0000, Val: 0.7660, Test: 0.8080
Epoch: 132, Loss: 2.3917, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 133, Loss: 2.4563, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 134, Loss: 2.0938, Train: 1.0000, Val: 0.7680, Test: 0.8080
Epoch: 135, Loss: 2.5000, Train: 1.0000, Val: 0.7660, Test: 0.8080
Epoch: 136, Loss: 2.5527, Train: 1.0000, Val: 0.7660, Test: 0.8080
Epoch: 137, Loss: 2.5696, Train: 1.0000, Val: 0.7680, Test: 0.8070
Epoch: 138, Loss: 2.6380, Train: 1.0000, Val: 0.7680, Test: 0.8070
Epoch: 139, Loss: 2.3867, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 140, Loss: 2.5286, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 141, Loss: 2.5186, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 142, Loss: 2.5539, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 143, Loss: 2.5457, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 144, Loss: 2.6605, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 145, Loss: 2.7786, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 146, Loss: 2.2672, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 147, Loss: 2.2790, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 148, Loss: 2.5612, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 149, Loss: 2.5574, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 150, Loss: 2.5228, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 151, Loss: 2.6913, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 152, Loss: 2.6594, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 153, Loss: 2.4587, Train: 1.0000, Val: 0.7740, Test: 0.8080
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 2.8668, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 155, Loss: 2.3815, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 156, Loss: 2.2768, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 157, Loss: 2.5480, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 158, Loss: 2.5135, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 159, Loss: 2.2069, Train: 1.0000, Val: 0.7620, Test: 0.8000
Epoch: 160, Loss: 2.8936, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 161, Loss: 2.1692, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 162, Loss: 2.7923, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 163, Loss: 2.3031, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 164, Loss: 2.4813, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 165, Loss: 2.4874, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 166, Loss: 2.4443, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 167, Loss: 2.2714, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 168, Loss: 2.3416, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 169, Loss: 2.6612, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 170, Loss: 2.3123, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 171, Loss: 2.2022, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 172, Loss: 2.6212, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 173, Loss: 2.2055, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 174, Loss: 2.6601, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 175, Loss: 2.2475, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 176, Loss: 2.3808, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 177, Loss: 2.6212, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 178, Loss: 2.0698, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 179, Loss: 2.5198, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 180, Loss: 2.3759, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 181, Loss: 2.5506, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 182, Loss: 2.4787, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 183, Loss: 2.6881, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 184, Loss: 2.4422, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 185, Loss: 2.5470, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 186, Loss: 2.5107, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 187, Loss: 2.1645, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 188, Loss: 2.5776, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 189, Loss: 2.4355, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 190, Loss: 2.2745, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 191, Loss: 2.4557, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 192, Loss: 2.5126, Train: 1.0000, Val: 0.7660, Test: 0.8050
Epoch: 193, Loss: 2.1314, Train: 1.0000, Val: 0.7620, Test: 0.8080
Epoch: 194, Loss: 2.8513, Train: 1.0000, Val: 0.7620, Test: 0.8070
Epoch: 195, Loss: 2.5171, Train: 1.0000, Val: 0.7620, Test: 0.8060
Epoch: 196, Loss: 2.4055, Train: 1.0000, Val: 0.7620, Test: 0.8070
Epoch: 197, Loss: 2.6588, Train: 1.0000, Val: 0.7660, Test: 0.8090
Epoch: 198, Loss: 2.5510, Train: 1.0000, Val: 0.7680, Test: 0.8100
Epoch: 199, Loss: 2.8591, Train: 1.0000, Val: 0.7700, Test: 0.8120
Epoch: 200, Loss: 2.3383, Train: 1.0000, Val: 0.7720, Test: 0.8130
MAD:  0.4447
Best Test Accuracy: 0.8200, Val Accuracy: 0.7920, Train Accuracy: 1.0000
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8549, Train: 0.1429, Val: 0.0540, Test: 0.0530
Epoch: 2, Loss: 4.8281, Train: 0.2786, Val: 0.1300, Test: 0.1470
Epoch: 3, Loss: 4.7729, Train: 0.2929, Val: 0.1640, Test: 0.1700
Epoch: 4, Loss: 4.7180, Train: 0.3000, Val: 0.1640, Test: 0.1720
Epoch: 5, Loss: 4.6754, Train: 0.3214, Val: 0.1700, Test: 0.1780
Epoch: 6, Loss: 4.6297, Train: 0.3500, Val: 0.1900, Test: 0.1860
Epoch: 7, Loss: 4.5958, Train: 0.3571, Val: 0.1880, Test: 0.1910
Epoch: 8, Loss: 4.3917, Train: 0.3643, Val: 0.1900, Test: 0.1920
Epoch: 9, Loss: 4.5180, Train: 0.3571, Val: 0.1860, Test: 0.1910
Epoch: 10, Loss: 4.5033, Train: 0.3571, Val: 0.1840, Test: 0.1920
Epoch: 11, Loss: 4.3804, Train: 0.3571, Val: 0.1900, Test: 0.1980
Epoch: 12, Loss: 4.0899, Train: 0.3714, Val: 0.1940, Test: 0.2030
Epoch: 13, Loss: 4.1114, Train: 0.3714, Val: 0.1980, Test: 0.2070
Epoch: 14, Loss: 4.1551, Train: 0.3857, Val: 0.2080, Test: 0.2160
Epoch: 15, Loss: 3.9140, Train: 0.4071, Val: 0.2160, Test: 0.2320
Epoch: 16, Loss: 3.8149, Train: 0.4286, Val: 0.2260, Test: 0.2430
Epoch: 17, Loss: 3.7960, Train: 0.4571, Val: 0.2500, Test: 0.2620
Epoch: 18, Loss: 3.5181, Train: 0.4929, Val: 0.2860, Test: 0.2980
Epoch: 19, Loss: 3.8826, Train: 0.5286, Val: 0.3300, Test: 0.3580
Epoch: 20, Loss: 3.5506, Train: 0.6714, Val: 0.4100, Test: 0.4270
Epoch: 21, Loss: 3.3573, Train: 0.7429, Val: 0.5040, Test: 0.5020
Epoch: 22, Loss: 3.6534, Train: 0.8286, Val: 0.5600, Test: 0.5920
Epoch: 23, Loss: 3.4668, Train: 0.9000, Val: 0.6480, Test: 0.6560
Epoch: 24, Loss: 3.0446, Train: 0.9286, Val: 0.6800, Test: 0.7050
Epoch: 25, Loss: 3.4604, Train: 0.9429, Val: 0.7200, Test: 0.7360
Epoch: 26, Loss: 3.1814, Train: 0.9500, Val: 0.7400, Test: 0.7580
Epoch: 27, Loss: 3.3798, Train: 0.9500, Val: 0.7640, Test: 0.7700
Epoch: 28, Loss: 3.1470, Train: 0.9571, Val: 0.7760, Test: 0.7740
Epoch: 29, Loss: 2.9643, Train: 0.9643, Val: 0.7800, Test: 0.7820
Epoch: 30, Loss: 3.2555, Train: 0.9714, Val: 0.7760, Test: 0.7890
Epoch: 31, Loss: 2.9917, Train: 0.9714, Val: 0.7740, Test: 0.7870
Epoch: 32, Loss: 3.2772, Train: 0.9786, Val: 0.7660, Test: 0.7850
Epoch: 33, Loss: 3.1571, Train: 0.9714, Val: 0.7580, Test: 0.7870
Epoch: 34, Loss: 3.3734, Train: 0.9714, Val: 0.7640, Test: 0.7830
Epoch: 35, Loss: 2.8437, Train: 0.9714, Val: 0.7660, Test: 0.7850
Epoch: 36, Loss: 2.9882, Train: 0.9786, Val: 0.7700, Test: 0.7910
Epoch: 37, Loss: 2.9965, Train: 0.9786, Val: 0.7760, Test: 0.7930
Epoch: 38, Loss: 2.7115, Train: 0.9857, Val: 0.7840, Test: 0.7960
Epoch: 39, Loss: 2.9858, Train: 1.0000, Val: 0.7880, Test: 0.7940
Epoch: 40, Loss: 2.9234, Train: 1.0000, Val: 0.7900, Test: 0.7930
Epoch: 41, Loss: 2.6862, Train: 1.0000, Val: 0.7920, Test: 0.7930
Epoch: 42, Loss: 2.8274, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 43, Loss: 3.1566, Train: 1.0000, Val: 0.7900, Test: 0.7960
Epoch: 44, Loss: 2.5805, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 45, Loss: 2.8108, Train: 1.0000, Val: 0.7860, Test: 0.7910
Epoch: 46, Loss: 2.7675, Train: 1.0000, Val: 0.7880, Test: 0.7880
Epoch: 47, Loss: 2.7967, Train: 1.0000, Val: 0.7860, Test: 0.7890
Epoch: 48, Loss: 2.8712, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 49, Loss: 2.7585, Train: 1.0000, Val: 0.7800, Test: 0.7860
Epoch: 50, Loss: 2.2130, Train: 1.0000, Val: 0.7800, Test: 0.7840
Epoch: 51, Loss: 3.1706, Train: 1.0000, Val: 0.7800, Test: 0.7850
Epoch: 52, Loss: 2.8817, Train: 1.0000, Val: 0.7840, Test: 0.7890
Epoch: 53, Loss: 2.7415, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 54, Loss: 2.9116, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 55, Loss: 2.4650, Train: 1.0000, Val: 0.7960, Test: 0.8000
Epoch: 56, Loss: 2.6745, Train: 1.0000, Val: 0.7940, Test: 0.8000
Epoch: 57, Loss: 2.7723, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 58, Loss: 2.5560, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 59, Loss: 2.4581, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 60, Loss: 2.5674, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 61, Loss: 2.5024, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 62, Loss: 2.4983, Train: 1.0000, Val: 0.7960, Test: 0.8030
Epoch: 63, Loss: 2.8595, Train: 1.0000, Val: 0.7980, Test: 0.8020
Epoch: 64, Loss: 2.6846, Train: 1.0000, Val: 0.7960, Test: 0.8040
Epoch: 65, Loss: 2.9087, Train: 1.0000, Val: 0.7960, Test: 0.8030
Epoch: 66, Loss: 2.8331, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 67, Loss: 2.3305, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 68, Loss: 2.8487, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 69, Loss: 2.7087, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 70, Loss: 2.4434, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 71, Loss: 2.7639, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 72, Loss: 2.8511, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 73, Loss: 2.1790, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 74, Loss: 2.5739, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 75, Loss: 2.2133, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 76, Loss: 2.2482, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 77, Loss: 2.7661, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 78, Loss: 2.5599, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 79, Loss: 2.2996, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 80, Loss: 2.5855, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 81, Loss: 2.1610, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 82, Loss: 2.5261, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 83, Loss: 2.7576, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 84, Loss: 2.2998, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 85, Loss: 2.5190, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 86, Loss: 2.4933, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 87, Loss: 2.4180, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 88, Loss: 2.6423, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 89, Loss: 2.6444, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 90, Loss: 2.2371, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 91, Loss: 2.6636, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 92, Loss: 2.4280, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 93, Loss: 2.6965, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 94, Loss: 2.3466, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 95, Loss: 2.3823, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 96, Loss: 2.3888, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 97, Loss: 2.5874, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 98, Loss: 2.5608, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 99, Loss: 2.2007, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 100, Loss: 2.8183, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 101, Loss: 2.4663, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 102, Loss: 2.3286, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 103, Loss: 2.2665, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 104, Loss: 2.6733, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 105, Loss: 2.6669, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 106, Loss: 2.6837, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 107, Loss: 2.2895, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 108, Loss: 3.1727, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 109, Loss: 3.0269, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 110, Loss: 2.2738, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 111, Loss: 2.4801, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 112, Loss: 2.7590, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 113, Loss: 2.3851, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 114, Loss: 2.6289, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 115, Loss: 2.6697, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 116, Loss: 2.5328, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 117, Loss: 2.3771, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 118, Loss: 2.1472, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 119, Loss: 2.2995, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 120, Loss: 2.3165, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 121, Loss: 2.1897, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 122, Loss: 2.5031, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 123, Loss: 2.7721, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 124, Loss: 2.4287, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 125, Loss: 2.5668, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 126, Loss: 2.4314, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 127, Loss: 2.4654, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 128, Loss: 2.4996, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 129, Loss: 2.4045, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 130, Loss: 2.3549, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 131, Loss: 2.6266, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 132, Loss: 2.4612, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 133, Loss: 2.5609, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 134, Loss: 2.6968, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 135, Loss: 2.7007, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 136, Loss: 2.2884, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 137, Loss: 2.5909, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 138, Loss: 2.2209, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 139, Loss: 2.5956, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 140, Loss: 2.1737, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 141, Loss: 2.5243, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 142, Loss: 2.7976, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 143, Loss: 2.5903, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 144, Loss: 2.4569, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 145, Loss: 2.6130, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 146, Loss: 2.4663, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 147, Loss: 2.4518, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 148, Loss: 2.7775, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 149, Loss: 2.5154, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 150, Loss: 2.2793, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 151, Loss: 2.3098, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 152, Loss: 2.4394, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 153, Loss: 2.6609, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 154, Loss: 2.4509, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 155, Loss: 2.5166, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 156, Loss: 2.2076, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 157, Loss: 2.5954, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 158, Loss: 2.4560, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 159, Loss: 2.3113, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 160, Loss: 2.5191, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 161, Loss: 2.4909, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 162, Loss: 2.5550, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 163, Loss: 2.3872, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 164, Loss: 2.2829, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 165, Loss: 2.7020, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 166, Loss: 2.5483, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 167, Loss: 2.5253, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 168, Loss: 2.4528, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 169, Loss: 2.4131, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 170, Loss: 2.6921, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 171, Loss: 2.5542, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 172, Loss: 2.4570, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 173, Loss: 2.4834, Train: 1.0000, Val: 0.7840, Test: 0.7920
Epoch: 174, Loss: 2.4513, Train: 1.0000, Val: 0.7880, Test: 0.7930
Epoch: 175, Loss: 2.1036, Train: 1.0000, Val: 0.7880, Test: 0.7910
Epoch: 176, Loss: 2.4242, Train: 1.0000, Val: 0.7860, Test: 0.7910
Epoch: 177, Loss: 2.3473, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 178, Loss: 2.3829, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 179, Loss: 2.8327, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 180, Loss: 2.4817, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 181, Loss: 2.2792, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 182, Loss: 2.5802, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 183, Loss: 2.4833, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 184, Loss: 2.3520, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 185, Loss: 2.5285, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 186, Loss: 2.6149, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 187, Loss: 2.5132, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 188, Loss: 2.8202, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 189, Loss: 2.6245, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 190, Loss: 2.7580, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 191, Loss: 2.5484, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 192, Loss: 2.4812, Train: 1.0000, Val: 0.7780, Test: 0.8030
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 2.6880, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 194, Loss: 2.4811, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 195, Loss: 2.6522, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 196, Loss: 2.5467, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 197, Loss: 2.7577, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 198, Loss: 2.1376, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 199, Loss: 2.2664, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 200, Loss: 2.0627, Train: 1.0000, Val: 0.7780, Test: 0.8030
MAD:  0.7319
Best Test Accuracy: 0.8070, Val Accuracy: 0.7800, Train Accuracy: 1.0000
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8384, Train: 0.1857, Val: 0.0700, Test: 0.0780
Epoch: 2, Loss: 4.8169, Train: 0.4214, Val: 0.1840, Test: 0.2010
Epoch: 3, Loss: 4.7631, Train: 0.5857, Val: 0.2620, Test: 0.2820
Epoch: 4, Loss: 4.7164, Train: 0.6214, Val: 0.3460, Test: 0.3510
Epoch: 5, Loss: 4.6653, Train: 0.6857, Val: 0.4120, Test: 0.4010
Epoch: 6, Loss: 4.6026, Train: 0.7357, Val: 0.4340, Test: 0.4430
Epoch: 7, Loss: 4.5696, Train: 0.7643, Val: 0.4700, Test: 0.4770
Epoch: 8, Loss: 4.4718, Train: 0.8000, Val: 0.5040, Test: 0.5130
Epoch: 9, Loss: 4.3719, Train: 0.8071, Val: 0.5240, Test: 0.5510
Epoch: 10, Loss: 4.2617, Train: 0.8214, Val: 0.5540, Test: 0.5740
Epoch: 11, Loss: 4.2619, Train: 0.8286, Val: 0.5640, Test: 0.5890
Epoch: 12, Loss: 4.1549, Train: 0.8286, Val: 0.5740, Test: 0.5940
Epoch: 13, Loss: 4.0839, Train: 0.8357, Val: 0.5780, Test: 0.6040
Epoch: 14, Loss: 3.9762, Train: 0.8286, Val: 0.5860, Test: 0.6120
Epoch: 15, Loss: 3.9250, Train: 0.8214, Val: 0.6020, Test: 0.6240
Epoch: 16, Loss: 3.7005, Train: 0.8214, Val: 0.6080, Test: 0.6340
Epoch: 17, Loss: 3.6417, Train: 0.8214, Val: 0.6180, Test: 0.6420
Epoch: 18, Loss: 3.4319, Train: 0.8214, Val: 0.6240, Test: 0.6460
Epoch: 19, Loss: 3.7060, Train: 0.8214, Val: 0.6360, Test: 0.6570
Epoch: 20, Loss: 3.6411, Train: 0.8429, Val: 0.6580, Test: 0.6670
Epoch: 21, Loss: 3.6317, Train: 0.8429, Val: 0.6780, Test: 0.6810
Epoch: 22, Loss: 3.4824, Train: 0.8429, Val: 0.6740, Test: 0.6930
Epoch: 23, Loss: 3.4984, Train: 0.8429, Val: 0.6800, Test: 0.6960
Epoch: 24, Loss: 3.4332, Train: 0.8429, Val: 0.6760, Test: 0.6960
Epoch: 25, Loss: 3.1401, Train: 0.8429, Val: 0.6760, Test: 0.6970
Epoch: 26, Loss: 3.5345, Train: 0.8429, Val: 0.6720, Test: 0.6980
Epoch: 27, Loss: 3.6289, Train: 0.8429, Val: 0.6680, Test: 0.6950
Epoch: 28, Loss: 3.1516, Train: 0.8500, Val: 0.6540, Test: 0.6910
Epoch: 29, Loss: 3.1801, Train: 0.8500, Val: 0.6420, Test: 0.6780
Epoch: 30, Loss: 3.2878, Train: 0.8786, Val: 0.6480, Test: 0.6790
Epoch: 31, Loss: 2.8760, Train: 0.9071, Val: 0.6560, Test: 0.6800
Epoch: 32, Loss: 2.9705, Train: 0.9429, Val: 0.6680, Test: 0.7090
Epoch: 33, Loss: 2.9340, Train: 0.9643, Val: 0.7000, Test: 0.7330
Epoch: 34, Loss: 2.8872, Train: 0.9929, Val: 0.7200, Test: 0.7560
Epoch: 35, Loss: 2.9411, Train: 0.9929, Val: 0.7380, Test: 0.7550
Epoch: 36, Loss: 3.1872, Train: 0.9929, Val: 0.7300, Test: 0.7390
Epoch: 37, Loss: 3.1091, Train: 0.9929, Val: 0.7060, Test: 0.7310
Epoch: 38, Loss: 3.2868, Train: 0.9929, Val: 0.7040, Test: 0.7260
Epoch: 39, Loss: 3.2275, Train: 0.9929, Val: 0.7200, Test: 0.7290
Epoch: 40, Loss: 3.2569, Train: 0.9929, Val: 0.7300, Test: 0.7460
Epoch: 41, Loss: 2.7543, Train: 0.9929, Val: 0.7520, Test: 0.7560
Epoch: 42, Loss: 2.6071, Train: 0.9929, Val: 0.7640, Test: 0.7730
Epoch: 43, Loss: 2.9689, Train: 0.9929, Val: 0.7780, Test: 0.7800
Epoch: 44, Loss: 2.6522, Train: 0.9929, Val: 0.7860, Test: 0.7920
Epoch: 45, Loss: 2.8358, Train: 0.9929, Val: 0.7860, Test: 0.7950
Epoch: 46, Loss: 2.5890, Train: 0.9929, Val: 0.7920, Test: 0.8080
Epoch: 47, Loss: 2.7315, Train: 0.9929, Val: 0.7920, Test: 0.8130
Epoch: 48, Loss: 2.7624, Train: 0.9929, Val: 0.7840, Test: 0.8060
Epoch: 49, Loss: 2.7911, Train: 0.9929, Val: 0.7860, Test: 0.8020
Epoch: 50, Loss: 2.7176, Train: 0.9929, Val: 0.7860, Test: 0.7990
Epoch: 51, Loss: 2.6562, Train: 0.9929, Val: 0.7820, Test: 0.7980
Epoch: 52, Loss: 2.5916, Train: 0.9929, Val: 0.7860, Test: 0.7970
Epoch: 53, Loss: 2.9344, Train: 0.9929, Val: 0.7860, Test: 0.7990
Epoch: 54, Loss: 2.8719, Train: 0.9929, Val: 0.7820, Test: 0.7970
Epoch: 55, Loss: 2.7521, Train: 0.9929, Val: 0.7820, Test: 0.7950
Epoch: 56, Loss: 2.6234, Train: 0.9929, Val: 0.7800, Test: 0.7920
Epoch: 57, Loss: 2.7597, Train: 0.9929, Val: 0.7800, Test: 0.7910
Epoch: 58, Loss: 2.4053, Train: 0.9929, Val: 0.7800, Test: 0.7910
Epoch: 59, Loss: 2.8138, Train: 0.9929, Val: 0.7800, Test: 0.7890
Epoch: 60, Loss: 2.4417, Train: 0.9929, Val: 0.7780, Test: 0.7930
Epoch: 61, Loss: 2.4135, Train: 0.9929, Val: 0.7780, Test: 0.7940
Epoch: 62, Loss: 2.8875, Train: 0.9929, Val: 0.7740, Test: 0.7920
Epoch: 63, Loss: 2.9718, Train: 0.9929, Val: 0.7760, Test: 0.7890
Epoch: 64, Loss: 2.6719, Train: 0.9929, Val: 0.7760, Test: 0.7920
Epoch: 65, Loss: 3.1684, Train: 0.9929, Val: 0.7740, Test: 0.7950
Epoch: 66, Loss: 2.0619, Train: 0.9929, Val: 0.7720, Test: 0.7970
Epoch: 67, Loss: 2.4278, Train: 0.9929, Val: 0.7740, Test: 0.8000
Epoch: 68, Loss: 2.7370, Train: 0.9929, Val: 0.7760, Test: 0.8020
Epoch: 69, Loss: 2.4251, Train: 0.9929, Val: 0.7760, Test: 0.8050
Epoch: 70, Loss: 2.5512, Train: 0.9929, Val: 0.7780, Test: 0.8050
Epoch: 71, Loss: 2.8335, Train: 0.9929, Val: 0.7760, Test: 0.8060
Epoch: 72, Loss: 2.6196, Train: 0.9929, Val: 0.7740, Test: 0.8040
Epoch: 73, Loss: 2.6859, Train: 0.9929, Val: 0.7720, Test: 0.8030
Epoch: 74, Loss: 2.8455, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 75, Loss: 2.4350, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 76, Loss: 2.6892, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 77, Loss: 2.5329, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 78, Loss: 2.1218, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 79, Loss: 2.2962, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 80, Loss: 2.0524, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 81, Loss: 2.4106, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 82, Loss: 2.2753, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 83, Loss: 2.3971, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 84, Loss: 2.3026, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 85, Loss: 2.4056, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 86, Loss: 2.6179, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 87, Loss: 2.7095, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 88, Loss: 2.5285, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 89, Loss: 2.3989, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 90, Loss: 2.3352, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 91, Loss: 2.7028, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 92, Loss: 2.2153, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 93, Loss: 2.5545, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 94, Loss: 2.6715, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 95, Loss: 2.3731, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 96, Loss: 2.3486, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 97, Loss: 2.6939, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 98, Loss: 2.6003, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 99, Loss: 2.2262, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 100, Loss: 2.3105, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 101, Loss: 2.2337, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 102, Loss: 2.5862, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 103, Loss: 2.8586, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 104, Loss: 2.4437, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 105, Loss: 2.3402, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 106, Loss: 2.4630, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 107, Loss: 2.3648, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 108, Loss: 2.4681, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 109, Loss: 2.1860, Train: 1.0000, Val: 0.7680, Test: 0.8000
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 110, Loss: 2.5643, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 111, Loss: 2.2615, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 112, Loss: 2.4491, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 113, Loss: 2.2894, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 114, Loss: 2.6742, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 115, Loss: 2.5581, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 116, Loss: 2.4700, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 117, Loss: 2.0919, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 118, Loss: 2.7466, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 119, Loss: 2.3218, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 120, Loss: 2.5674, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 121, Loss: 2.7694, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 122, Loss: 2.3510, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 123, Loss: 2.4717, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 124, Loss: 2.3640, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 125, Loss: 2.4746, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 126, Loss: 2.3270, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 127, Loss: 2.6425, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 128, Loss: 2.3857, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 129, Loss: 2.3110, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 130, Loss: 2.4176, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 131, Loss: 2.5525, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 132, Loss: 2.6029, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 133, Loss: 2.3905, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 134, Loss: 2.5196, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 135, Loss: 2.3216, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 136, Loss: 2.1752, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 137, Loss: 2.4961, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 138, Loss: 2.6351, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 139, Loss: 2.5279, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 140, Loss: 2.4437, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 141, Loss: 2.4395, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 142, Loss: 2.5231, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 143, Loss: 2.4200, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 144, Loss: 2.5277, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 145, Loss: 2.7998, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 146, Loss: 2.2852, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 147, Loss: 2.7641, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 148, Loss: 2.0056, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 149, Loss: 2.3545, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 150, Loss: 2.6903, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 151, Loss: 2.7025, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 152, Loss: 2.4179, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 153, Loss: 2.6197, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 154, Loss: 2.4835, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 155, Loss: 2.6985, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 156, Loss: 2.6646, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 157, Loss: 2.6996, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 158, Loss: 2.5953, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 159, Loss: 2.2104, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 160, Loss: 2.5869, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 161, Loss: 2.5810, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 162, Loss: 2.5559, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 163, Loss: 2.3103, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 164, Loss: 2.3526, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 165, Loss: 2.4459, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 166, Loss: 2.2492, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 167, Loss: 2.5498, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 168, Loss: 2.3180, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 169, Loss: 2.5607, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 170, Loss: 2.7451, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 171, Loss: 2.5542, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 172, Loss: 2.3473, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 173, Loss: 2.2681, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 174, Loss: 2.6990, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 175, Loss: 2.2046, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 176, Loss: 2.5547, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 177, Loss: 2.4535, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 178, Loss: 2.5175, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 179, Loss: 2.2090, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 180, Loss: 2.7653, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 181, Loss: 2.4115, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 182, Loss: 2.6125, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 183, Loss: 2.7545, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 184, Loss: 2.8309, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 185, Loss: 2.3084, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 186, Loss: 2.4076, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 187, Loss: 2.5923, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 188, Loss: 2.3041, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 189, Loss: 2.4788, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 190, Loss: 2.2704, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 191, Loss: 2.8220, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 192, Loss: 2.3708, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 193, Loss: 2.8259, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 194, Loss: 2.5184, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 195, Loss: 2.5086, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 196, Loss: 2.0702, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 197, Loss: 2.5831, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 198, Loss: 2.4811, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 199, Loss: 2.4415, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 200, Loss: 2.2007, Train: 1.0000, Val: 0.7760, Test: 0.7980
MAD:  0.2411
Best Test Accuracy: 0.8130, Val Accuracy: 0.7920, Train Accuracy: 0.9929
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8579, Train: 0.0857, Val: 0.0500, Test: 0.0510
Epoch: 2, Loss: 4.8300, Train: 0.2286, Val: 0.1520, Test: 0.1930
Epoch: 3, Loss: 4.8013, Train: 0.3357, Val: 0.2140, Test: 0.2600
Epoch: 4, Loss: 4.7766, Train: 0.3857, Val: 0.2500, Test: 0.3030
Epoch: 5, Loss: 4.6861, Train: 0.4429, Val: 0.2940, Test: 0.3400
Epoch: 6, Loss: 4.6325, Train: 0.4714, Val: 0.3160, Test: 0.3760
Epoch: 7, Loss: 4.5873, Train: 0.5000, Val: 0.3300, Test: 0.3910
Epoch: 8, Loss: 4.4767, Train: 0.5071, Val: 0.3400, Test: 0.3950
Epoch: 9, Loss: 4.4554, Train: 0.5071, Val: 0.3460, Test: 0.4030
Epoch: 10, Loss: 4.2619, Train: 0.5071, Val: 0.3540, Test: 0.4080
Epoch: 11, Loss: 4.2040, Train: 0.5071, Val: 0.3480, Test: 0.4040
Epoch: 12, Loss: 4.1809, Train: 0.5071, Val: 0.3320, Test: 0.4030
Epoch: 13, Loss: 4.1671, Train: 0.5071, Val: 0.3280, Test: 0.3970
Epoch: 14, Loss: 3.8991, Train: 0.5071, Val: 0.3200, Test: 0.3810
Epoch: 15, Loss: 3.9326, Train: 0.5071, Val: 0.3180, Test: 0.3770
Epoch: 16, Loss: 4.0127, Train: 0.5071, Val: 0.3200, Test: 0.3750
Epoch: 17, Loss: 3.6380, Train: 0.5071, Val: 0.3220, Test: 0.3750
Epoch: 18, Loss: 3.5409, Train: 0.5214, Val: 0.3160, Test: 0.3840
Epoch: 19, Loss: 3.5554, Train: 0.5286, Val: 0.3400, Test: 0.3950
Epoch: 20, Loss: 3.6041, Train: 0.5643, Val: 0.3640, Test: 0.4240
Epoch: 21, Loss: 3.3946, Train: 0.6500, Val: 0.4060, Test: 0.4500
Epoch: 22, Loss: 3.6227, Train: 0.8214, Val: 0.4580, Test: 0.5280
Epoch: 23, Loss: 3.1235, Train: 0.9071, Val: 0.5540, Test: 0.6170
Epoch: 24, Loss: 3.6830, Train: 0.9571, Val: 0.6300, Test: 0.6940
Epoch: 25, Loss: 3.4831, Train: 0.9714, Val: 0.6840, Test: 0.7400
Epoch: 26, Loss: 3.2485, Train: 0.9786, Val: 0.7240, Test: 0.7520
Epoch: 27, Loss: 3.2651, Train: 0.9786, Val: 0.7300, Test: 0.7580
Epoch: 28, Loss: 2.9627, Train: 0.9714, Val: 0.7360, Test: 0.7590
Epoch: 29, Loss: 3.0379, Train: 0.9714, Val: 0.7400, Test: 0.7620
Epoch: 30, Loss: 3.0038, Train: 0.9714, Val: 0.7440, Test: 0.7550
Epoch: 31, Loss: 3.0872, Train: 0.9714, Val: 0.7500, Test: 0.7530
Epoch: 32, Loss: 2.9145, Train: 0.9714, Val: 0.7540, Test: 0.7560
Epoch: 33, Loss: 3.0864, Train: 0.9714, Val: 0.7580, Test: 0.7600
Epoch: 34, Loss: 3.1937, Train: 0.9857, Val: 0.7580, Test: 0.7700
Epoch: 35, Loss: 3.2373, Train: 0.9857, Val: 0.7620, Test: 0.7770
Epoch: 36, Loss: 3.3044, Train: 0.9857, Val: 0.7640, Test: 0.7870
Epoch: 37, Loss: 3.0610, Train: 0.9786, Val: 0.7740, Test: 0.7920
Epoch: 38, Loss: 3.2641, Train: 0.9786, Val: 0.7820, Test: 0.7910
Epoch: 39, Loss: 2.9332, Train: 0.9857, Val: 0.7680, Test: 0.8030
Epoch: 40, Loss: 2.7226, Train: 0.9857, Val: 0.7760, Test: 0.7950
Epoch: 41, Loss: 2.8144, Train: 0.9857, Val: 0.7700, Test: 0.7980
Epoch: 42, Loss: 3.0193, Train: 0.9929, Val: 0.7700, Test: 0.7970
Epoch: 43, Loss: 2.6412, Train: 0.9929, Val: 0.7780, Test: 0.8000
Epoch: 44, Loss: 2.6771, Train: 0.9929, Val: 0.7800, Test: 0.8020
Epoch: 45, Loss: 2.6851, Train: 0.9929, Val: 0.7780, Test: 0.8070
Epoch: 46, Loss: 2.9387, Train: 0.9929, Val: 0.7780, Test: 0.8040
Epoch: 47, Loss: 2.7484, Train: 0.9929, Val: 0.7780, Test: 0.8020
Epoch: 48, Loss: 2.6376, Train: 0.9929, Val: 0.7780, Test: 0.8060
Epoch: 49, Loss: 2.7262, Train: 0.9929, Val: 0.7800, Test: 0.8040
Epoch: 50, Loss: 2.9462, Train: 0.9929, Val: 0.7820, Test: 0.8000
Epoch: 51, Loss: 2.5837, Train: 0.9929, Val: 0.7840, Test: 0.8020
Epoch: 52, Loss: 2.8401, Train: 0.9929, Val: 0.7840, Test: 0.8060
Epoch: 53, Loss: 2.3511, Train: 0.9929, Val: 0.7780, Test: 0.8010
Epoch: 54, Loss: 2.8607, Train: 0.9929, Val: 0.7800, Test: 0.7980
Epoch: 55, Loss: 2.7586, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 56, Loss: 2.7567, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 57, Loss: 2.2621, Train: 1.0000, Val: 0.7820, Test: 0.7910
Epoch: 58, Loss: 2.3623, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 59, Loss: 2.7054, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 60, Loss: 2.7836, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 61, Loss: 2.5594, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 62, Loss: 2.6172, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 63, Loss: 2.8215, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 64, Loss: 2.5810, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 65, Loss: 2.6334, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 66, Loss: 2.7458, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 67, Loss: 2.5655, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 68, Loss: 2.5818, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 69, Loss: 2.6350, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 70, Loss: 2.5962, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 71, Loss: 2.8250, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 72, Loss: 2.5910, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 73, Loss: 2.4772, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 74, Loss: 2.5332, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 75, Loss: 2.5676, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 76, Loss: 2.6223, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 77, Loss: 2.3694, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 78, Loss: 2.4127, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 79, Loss: 2.5501, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 80, Loss: 2.1249, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 81, Loss: 2.6097, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 82, Loss: 2.5788, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 83, Loss: 2.3234, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 84, Loss: 2.6586, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 85, Loss: 2.8551, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 86, Loss: 2.3760, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 87, Loss: 2.5307, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 88, Loss: 2.4395, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 89, Loss: 2.4298, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 90, Loss: 2.5668, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 91, Loss: 3.0173, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 92, Loss: 2.3485, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 93, Loss: 2.5847, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 94, Loss: 2.8687, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 95, Loss: 2.4950, Train: 1.0000, Val: 0.7740, Test: 0.8110
Epoch: 96, Loss: 2.3634, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 97, Loss: 2.0895, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 98, Loss: 2.7737, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 99, Loss: 2.7588, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 100, Loss: 2.1950, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 101, Loss: 2.7812, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 102, Loss: 2.5364, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 103, Loss: 2.5466, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 104, Loss: 2.4127, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 105, Loss: 2.4162, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 106, Loss: 2.8318, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 107, Loss: 2.5648, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 108, Loss: 2.3841, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 109, Loss: 2.2812, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 110, Loss: 2.5424, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 111, Loss: 2.2705, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 112, Loss: 2.5706, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 113, Loss: 2.3718, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 114, Loss: 2.4162, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 115, Loss: 2.1464, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 116, Loss: 2.6495, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 117, Loss: 2.7471, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 118, Loss: 2.2787, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 119, Loss: 2.5737, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 120, Loss: 2.2616, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 121, Loss: 2.2801, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 122, Loss: 2.7387, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 123, Loss: 2.6906, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 124, Loss: 2.5642, Train: 1.0000, Val: 0.7700, Test: 0.8080
Epoch: 125, Loss: 2.3123, Train: 1.0000, Val: 0.7700, Test: 0.8100
Epoch: 126, Loss: 2.8504, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 127, Loss: 2.8155, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 128, Loss: 2.4911, Train: 1.0000, Val: 0.7720, Test: 0.8110
Epoch: 129, Loss: 2.4965, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 130, Loss: 2.3965, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 131, Loss: 2.5219, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 132, Loss: 2.8416, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 133, Loss: 2.0773, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 134, Loss: 2.7328, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 135, Loss: 2.7038, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 136, Loss: 2.0765, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 137, Loss: 2.3475, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 138, Loss: 2.7712, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 139, Loss: 2.4955, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 140, Loss: 2.5902, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 141, Loss: 2.3441, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 142, Loss: 2.5054, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 143, Loss: 2.2452, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 144, Loss: 2.2534, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 145, Loss: 2.4221, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 146, Loss: 2.4839, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 147, Loss: 2.5354, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 148, Loss: 2.6913, Train: 1.0000, Val: 0.7780, Test: 0.8090
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 149, Loss: 2.4451, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 150, Loss: 2.6531, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 151, Loss: 2.4319, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 152, Loss: 2.6639, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 153, Loss: 2.6339, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 154, Loss: 2.4484, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 155, Loss: 2.4532, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 156, Loss: 2.4441, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 157, Loss: 2.9017, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 158, Loss: 2.5128, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 159, Loss: 2.4105, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 160, Loss: 2.1406, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 161, Loss: 2.2057, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 162, Loss: 2.4105, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 163, Loss: 2.1353, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 164, Loss: 2.4573, Train: 1.0000, Val: 0.7680, Test: 0.8080
Epoch: 165, Loss: 2.6186, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 166, Loss: 2.1016, Train: 1.0000, Val: 0.7680, Test: 0.8110
Epoch: 167, Loss: 2.6932, Train: 1.0000, Val: 0.7700, Test: 0.8100
Epoch: 168, Loss: 2.4105, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 169, Loss: 2.1378, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 170, Loss: 2.4798, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 171, Loss: 2.4804, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 172, Loss: 2.7173, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 173, Loss: 2.2446, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 174, Loss: 2.3717, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 175, Loss: 2.7942, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 176, Loss: 2.3064, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 177, Loss: 2.4086, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 178, Loss: 2.5559, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 179, Loss: 2.7676, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 180, Loss: 2.4062, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 181, Loss: 2.2732, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 182, Loss: 2.3403, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 183, Loss: 3.0310, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 184, Loss: 2.6890, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 185, Loss: 2.4467, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 186, Loss: 2.6877, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 187, Loss: 2.2428, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 188, Loss: 2.7881, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 189, Loss: 2.8255, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 190, Loss: 2.3757, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 191, Loss: 2.4174, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 192, Loss: 2.2715, Train: 1.0000, Val: 0.7660, Test: 0.8050
Epoch: 193, Loss: 2.1402, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 194, Loss: 2.5193, Train: 1.0000, Val: 0.7620, Test: 0.8030
Epoch: 195, Loss: 2.3376, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 196, Loss: 2.2005, Train: 1.0000, Val: 0.7660, Test: 0.8060
Epoch: 197, Loss: 2.2732, Train: 1.0000, Val: 0.7660, Test: 0.8050
Epoch: 198, Loss: 2.4091, Train: 1.0000, Val: 0.7660, Test: 0.8060
Epoch: 199, Loss: 1.9255, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 200, Loss: 2.4790, Train: 1.0000, Val: 0.7660, Test: 0.8070
MAD:  0.6782
Best Test Accuracy: 0.8130, Val Accuracy: 0.7740, Train Accuracy: 1.0000
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8638, Train: 0.1000, Val: 0.0540, Test: 0.0540
Epoch: 2, Loss: 4.8419, Train: 0.2929, Val: 0.2000, Test: 0.2460
Epoch: 3, Loss: 4.8064, Train: 0.3357, Val: 0.3260, Test: 0.3700
Epoch: 4, Loss: 4.7803, Train: 0.3571, Val: 0.3340, Test: 0.3830
Epoch: 5, Loss: 4.7350, Train: 0.3643, Val: 0.3360, Test: 0.3750
Epoch: 6, Loss: 4.7662, Train: 0.3786, Val: 0.3340, Test: 0.3690
Epoch: 7, Loss: 4.6866, Train: 0.3786, Val: 0.3320, Test: 0.3690
Epoch: 8, Loss: 4.6149, Train: 0.3786, Val: 0.3260, Test: 0.3630
Epoch: 9, Loss: 4.5676, Train: 0.3786, Val: 0.3200, Test: 0.3510
Epoch: 10, Loss: 4.4962, Train: 0.3857, Val: 0.3140, Test: 0.3460
Epoch: 11, Loss: 4.4618, Train: 0.3857, Val: 0.3140, Test: 0.3380
Epoch: 12, Loss: 4.2834, Train: 0.3857, Val: 0.3160, Test: 0.3400
Epoch: 13, Loss: 4.3094, Train: 0.3929, Val: 0.3160, Test: 0.3480
Epoch: 14, Loss: 4.2553, Train: 0.3929, Val: 0.3200, Test: 0.3510
Epoch: 15, Loss: 4.0721, Train: 0.3929, Val: 0.3280, Test: 0.3610
Epoch: 16, Loss: 4.1664, Train: 0.4071, Val: 0.3440, Test: 0.3680
Epoch: 17, Loss: 4.0567, Train: 0.4071, Val: 0.3480, Test: 0.3770
Epoch: 18, Loss: 4.0723, Train: 0.4071, Val: 0.3580, Test: 0.4000
Epoch: 19, Loss: 3.9454, Train: 0.4357, Val: 0.3860, Test: 0.4170
Epoch: 20, Loss: 3.8856, Train: 0.4714, Val: 0.4240, Test: 0.4540
Epoch: 21, Loss: 4.1129, Train: 0.5000, Val: 0.4480, Test: 0.4850
Epoch: 22, Loss: 3.9103, Train: 0.5643, Val: 0.4960, Test: 0.5240
Epoch: 23, Loss: 3.8386, Train: 0.6071, Val: 0.5460, Test: 0.5650
Epoch: 24, Loss: 3.5007, Train: 0.6571, Val: 0.5800, Test: 0.5930
Epoch: 25, Loss: 3.5280, Train: 0.7071, Val: 0.6300, Test: 0.6380
Epoch: 26, Loss: 3.2434, Train: 0.7357, Val: 0.6700, Test: 0.6820
Epoch: 27, Loss: 3.5172, Train: 0.7786, Val: 0.7040, Test: 0.7150
Epoch: 28, Loss: 3.2685, Train: 0.8000, Val: 0.7220, Test: 0.7280
Epoch: 29, Loss: 3.2298, Train: 0.8286, Val: 0.7280, Test: 0.7420
Epoch: 30, Loss: 3.4887, Train: 0.8571, Val: 0.7380, Test: 0.7350
Epoch: 31, Loss: 3.2920, Train: 0.8786, Val: 0.7140, Test: 0.7380
Epoch: 32, Loss: 3.2061, Train: 0.9286, Val: 0.7320, Test: 0.7430
Epoch: 33, Loss: 3.4688, Train: 0.9500, Val: 0.7400, Test: 0.7560
Epoch: 34, Loss: 3.0384, Train: 0.9643, Val: 0.7420, Test: 0.7660
Epoch: 35, Loss: 3.0750, Train: 0.9643, Val: 0.7460, Test: 0.7700
Epoch: 36, Loss: 3.3605, Train: 0.9643, Val: 0.7440, Test: 0.7670
Epoch: 37, Loss: 3.2563, Train: 0.9857, Val: 0.7440, Test: 0.7640
Epoch: 38, Loss: 2.7023, Train: 0.9857, Val: 0.7480, Test: 0.7640
Epoch: 39, Loss: 3.2837, Train: 0.9786, Val: 0.7500, Test: 0.7690
Epoch: 40, Loss: 3.3066, Train: 0.9786, Val: 0.7500, Test: 0.7720
Epoch: 41, Loss: 2.9881, Train: 0.9786, Val: 0.7540, Test: 0.7810
Epoch: 42, Loss: 2.9030, Train: 0.9857, Val: 0.7580, Test: 0.7850
Epoch: 43, Loss: 2.6997, Train: 0.9857, Val: 0.7580, Test: 0.7860
Epoch: 44, Loss: 2.6919, Train: 0.9857, Val: 0.7620, Test: 0.7930
Epoch: 45, Loss: 2.7892, Train: 0.9857, Val: 0.7640, Test: 0.7980
Epoch: 46, Loss: 3.0794, Train: 0.9857, Val: 0.7700, Test: 0.8060
Epoch: 47, Loss: 2.8700, Train: 0.9857, Val: 0.7780, Test: 0.8050
Epoch: 48, Loss: 3.1179, Train: 0.9929, Val: 0.7920, Test: 0.8080
Epoch: 49, Loss: 2.9535, Train: 0.9929, Val: 0.7900, Test: 0.8090
Epoch: 50, Loss: 2.7207, Train: 0.9929, Val: 0.7920, Test: 0.8120
Epoch: 51, Loss: 2.5841, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 52, Loss: 2.7992, Train: 1.0000, Val: 0.7980, Test: 0.8160
Epoch: 53, Loss: 2.8127, Train: 1.0000, Val: 0.7980, Test: 0.8180
Epoch: 54, Loss: 2.9803, Train: 1.0000, Val: 0.7980, Test: 0.8180
Epoch: 55, Loss: 2.5675, Train: 1.0000, Val: 0.7960, Test: 0.8180
Epoch: 56, Loss: 2.7183, Train: 1.0000, Val: 0.8000, Test: 0.8150
Epoch: 57, Loss: 2.8282, Train: 1.0000, Val: 0.7920, Test: 0.8140
Epoch: 58, Loss: 2.6382, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 59, Loss: 2.8447, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 60, Loss: 2.4932, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 61, Loss: 2.6695, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 62, Loss: 2.3610, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 63, Loss: 2.7009, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 64, Loss: 2.9711, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 65, Loss: 2.7373, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 66, Loss: 2.3953, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 67, Loss: 2.4680, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 68, Loss: 2.6285, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 69, Loss: 2.4038, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 70, Loss: 2.4736, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 71, Loss: 2.6330, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 72, Loss: 2.6135, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 73, Loss: 2.3375, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 74, Loss: 2.8212, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 75, Loss: 2.3260, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 76, Loss: 2.5135, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 77, Loss: 2.7585, Train: 1.0000, Val: 0.7800, Test: 0.8140
Epoch: 78, Loss: 2.7708, Train: 1.0000, Val: 0.7800, Test: 0.8140
Epoch: 79, Loss: 2.2289, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 80, Loss: 2.8210, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 81, Loss: 2.2400, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 82, Loss: 2.8252, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 83, Loss: 2.6422, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 84, Loss: 2.5294, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 85, Loss: 2.2684, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 86, Loss: 2.5017, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 87, Loss: 2.3214, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 88, Loss: 2.5487, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 89, Loss: 2.8901, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 90, Loss: 2.4970, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 91, Loss: 2.6722, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 92, Loss: 2.6003, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 93, Loss: 2.4522, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 94, Loss: 2.2901, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 95, Loss: 2.3924, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 96, Loss: 2.6845, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 97, Loss: 2.5120, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 98, Loss: 2.4897, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 99, Loss: 2.4067, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 100, Loss: 2.5757, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 101, Loss: 2.6033, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 102, Loss: 2.5488, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 103, Loss: 2.6770, Train: 1.0000, Val: 0.7620, Test: 0.8010
Epoch: 104, Loss: 2.4663, Train: 1.0000, Val: 0.7620, Test: 0.8000
Epoch: 105, Loss: 2.4472, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 106, Loss: 2.5764, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 107, Loss: 2.6106, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 108, Loss: 2.8679, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 109, Loss: 2.3257, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 110, Loss: 2.1556, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 111, Loss: 2.3038, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 112, Loss: 2.5332, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 113, Loss: 2.3690, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 114, Loss: 2.3290, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 115, Loss: 2.4560, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 116, Loss: 2.3640, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 117, Loss: 2.1158, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 118, Loss: 2.3953, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 119, Loss: 2.5631, Train: 1.0000, Val: 0.7620, Test: 0.7990
Epoch: 120, Loss: 2.5028, Train: 1.0000, Val: 0.7620, Test: 0.7990
Epoch: 121, Loss: 2.5881, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 122, Loss: 2.5290, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 123, Loss: 2.2787, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 124, Loss: 2.8323, Train: 1.0000, Val: 0.7600, Test: 0.8000
Epoch: 125, Loss: 3.0057, Train: 1.0000, Val: 0.7620, Test: 0.8010
Epoch: 126, Loss: 2.3130, Train: 1.0000, Val: 0.7620, Test: 0.8020
Epoch: 127, Loss: 2.2107, Train: 1.0000, Val: 0.7620, Test: 0.8030
Epoch: 128, Loss: 2.2302, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 129, Loss: 2.2515, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 130, Loss: 2.6906, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 131, Loss: 2.4324, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 132, Loss: 2.4527, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 133, Loss: 2.5902, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 134, Loss: 2.5923, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 135, Loss: 2.5227, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 136, Loss: 2.2518, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 137, Loss: 2.4654, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 138, Loss: 2.5648, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 139, Loss: 2.4907, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 140, Loss: 2.5148, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 141, Loss: 2.5257, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 142, Loss: 2.3507, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 143, Loss: 2.4843, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 144, Loss: 2.2401, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 145, Loss: 2.3557, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 146, Loss: 2.9807, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 147, Loss: 2.2840, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 148, Loss: 2.2060, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 149, Loss: 2.5869, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 150, Loss: 2.5903, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 151, Loss: 2.4516, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 152, Loss: 2.2373, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 153, Loss: 2.6628, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 154, Loss: 2.6972, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 155, Loss: 2.5191, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 156, Loss: 2.4148, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 157, Loss: 2.4818, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 158, Loss: 1.8601, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 159, Loss: 2.5948, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 160, Loss: 2.4948, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 161, Loss: 2.6594, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 162, Loss: 2.3478, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 163, Loss: 2.0353, Train: 1.0000, Val: 0.7660, Test: 0.8050
Epoch: 164, Loss: 2.4871, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 165, Loss: 2.3955, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 166, Loss: 1.9669, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 167, Loss: 2.4813, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 168, Loss: 2.3817, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 169, Loss: 2.4129, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 170, Loss: 2.9027, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 171, Loss: 2.5549, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 172, Loss: 2.2089, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 173, Loss: 2.8249, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 174, Loss: 2.6669, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 175, Loss: 2.5840, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 176, Loss: 2.4848, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 177, Loss: 2.1332, Train: 1.0000, Val: 0.7660, Test: 0.8050
Epoch: 178, Loss: 2.4075, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 179, Loss: 2.2712, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 180, Loss: 2.2709, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 181, Loss: 2.3127, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 182, Loss: 2.7580, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 183, Loss: 2.5461, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 184, Loss: 2.1735, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 185, Loss: 2.5079, Train: 1.0000, Val: 0.7660, Test: 0.8050
Epoch: 186, Loss: 2.2717, Train: 1.0000, Val: 0.7680, Test: 0.8070
Epoch: 187, Loss: 2.4451, Train: 1.0000, Val: 0.7700, Test: 0.8080
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 188, Loss: 2.2303, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 189, Loss: 2.8929, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 190, Loss: 2.2406, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 191, Loss: 2.1376, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 192, Loss: 2.2688, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 193, Loss: 2.1641, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 194, Loss: 2.2777, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 195, Loss: 2.1679, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 196, Loss: 2.8643, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 197, Loss: 2.6867, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 198, Loss: 2.4495, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 199, Loss: 2.4740, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 200, Loss: 2.5540, Train: 1.0000, Val: 0.7820, Test: 0.8080
MAD:  0.3326
Best Test Accuracy: 0.8180, Val Accuracy: 0.7980, Train Accuracy: 1.0000
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8544, Train: 0.1071, Val: 0.0340, Test: 0.0460
Epoch: 2, Loss: 4.8274, Train: 0.4143, Val: 0.2460, Test: 0.2730
Epoch: 3, Loss: 4.7876, Train: 0.5786, Val: 0.3900, Test: 0.4110
Epoch: 4, Loss: 4.7149, Train: 0.6500, Val: 0.4000, Test: 0.4430
Epoch: 5, Loss: 4.7111, Train: 0.6643, Val: 0.3960, Test: 0.4370
Epoch: 6, Loss: 4.5795, Train: 0.6714, Val: 0.3820, Test: 0.4250
Epoch: 7, Loss: 4.5628, Train: 0.6786, Val: 0.3920, Test: 0.4300
Epoch: 8, Loss: 4.4937, Train: 0.6714, Val: 0.3900, Test: 0.4210
Epoch: 9, Loss: 4.4419, Train: 0.6643, Val: 0.3780, Test: 0.4140
Epoch: 10, Loss: 4.2729, Train: 0.6786, Val: 0.3700, Test: 0.4030
Epoch: 11, Loss: 4.1267, Train: 0.6786, Val: 0.3640, Test: 0.4050
Epoch: 12, Loss: 4.1624, Train: 0.6857, Val: 0.3620, Test: 0.3960
Epoch: 13, Loss: 3.9343, Train: 0.6786, Val: 0.3720, Test: 0.4070
Epoch: 14, Loss: 3.9667, Train: 0.7071, Val: 0.3820, Test: 0.4150
Epoch: 15, Loss: 3.8199, Train: 0.7357, Val: 0.4000, Test: 0.4270
Epoch: 16, Loss: 3.7022, Train: 0.7786, Val: 0.4120, Test: 0.4510
Epoch: 17, Loss: 3.6871, Train: 0.7857, Val: 0.4340, Test: 0.4690
Epoch: 18, Loss: 3.5918, Train: 0.8357, Val: 0.4820, Test: 0.5200
Epoch: 19, Loss: 3.2962, Train: 0.8643, Val: 0.5380, Test: 0.5640
Epoch: 20, Loss: 3.5828, Train: 0.8857, Val: 0.6020, Test: 0.6270
Epoch: 21, Loss: 3.3674, Train: 0.9214, Val: 0.6720, Test: 0.6970
Epoch: 22, Loss: 3.7110, Train: 0.9571, Val: 0.7340, Test: 0.7530
Epoch: 23, Loss: 3.2386, Train: 0.9714, Val: 0.7680, Test: 0.7860
Epoch: 24, Loss: 3.3531, Train: 0.9786, Val: 0.7780, Test: 0.8020
Epoch: 25, Loss: 3.0114, Train: 0.9786, Val: 0.7700, Test: 0.8010
Epoch: 26, Loss: 3.5022, Train: 0.9786, Val: 0.7500, Test: 0.7840
Epoch: 27, Loss: 3.3255, Train: 0.9786, Val: 0.7480, Test: 0.7790
Epoch: 28, Loss: 3.3748, Train: 0.9714, Val: 0.7500, Test: 0.7770
Epoch: 29, Loss: 3.1440, Train: 0.9714, Val: 0.7520, Test: 0.7790
Epoch: 30, Loss: 2.9599, Train: 0.9786, Val: 0.7540, Test: 0.7860
Epoch: 31, Loss: 2.8018, Train: 0.9714, Val: 0.7560, Test: 0.7920
Epoch: 32, Loss: 3.2404, Train: 0.9714, Val: 0.7560, Test: 0.7970
Epoch: 33, Loss: 3.1337, Train: 0.9714, Val: 0.7680, Test: 0.8000
Epoch: 34, Loss: 2.9667, Train: 0.9714, Val: 0.7740, Test: 0.8060
Epoch: 35, Loss: 3.0481, Train: 0.9786, Val: 0.7860, Test: 0.8060
Epoch: 36, Loss: 2.8438, Train: 0.9786, Val: 0.7900, Test: 0.8050
Epoch: 37, Loss: 2.7134, Train: 0.9857, Val: 0.7940, Test: 0.8090
Epoch: 38, Loss: 2.3616, Train: 0.9857, Val: 0.7920, Test: 0.8130
Epoch: 39, Loss: 2.9355, Train: 0.9857, Val: 0.7980, Test: 0.8160
Epoch: 40, Loss: 2.8475, Train: 0.9857, Val: 0.7960, Test: 0.8070
Epoch: 41, Loss: 2.7943, Train: 0.9929, Val: 0.7960, Test: 0.8080
Epoch: 42, Loss: 2.7128, Train: 0.9929, Val: 0.8000, Test: 0.8080
Epoch: 43, Loss: 2.5018, Train: 0.9929, Val: 0.7880, Test: 0.8060
Epoch: 44, Loss: 2.4919, Train: 0.9929, Val: 0.7800, Test: 0.8020
Epoch: 45, Loss: 2.7397, Train: 0.9929, Val: 0.7760, Test: 0.8040
Epoch: 46, Loss: 2.6768, Train: 0.9929, Val: 0.7760, Test: 0.8060
Epoch: 47, Loss: 2.6147, Train: 0.9929, Val: 0.7740, Test: 0.8080
Epoch: 48, Loss: 2.7549, Train: 0.9929, Val: 0.7820, Test: 0.8110
Epoch: 49, Loss: 2.6074, Train: 1.0000, Val: 0.7800, Test: 0.8170
Epoch: 50, Loss: 2.5832, Train: 1.0000, Val: 0.7800, Test: 0.8140
Epoch: 51, Loss: 2.9433, Train: 1.0000, Val: 0.7740, Test: 0.8160
Epoch: 52, Loss: 2.6851, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 53, Loss: 2.5110, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 54, Loss: 2.4240, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 55, Loss: 2.9654, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 56, Loss: 2.5815, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 57, Loss: 3.0654, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 58, Loss: 2.7568, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 59, Loss: 2.9441, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 60, Loss: 2.4156, Train: 1.0000, Val: 0.7760, Test: 0.8190
Epoch: 61, Loss: 2.6152, Train: 1.0000, Val: 0.7820, Test: 0.8160
Epoch: 62, Loss: 2.5117, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 63, Loss: 2.8292, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 64, Loss: 2.3664, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 65, Loss: 2.5255, Train: 1.0000, Val: 0.7820, Test: 0.8150
Epoch: 66, Loss: 3.1171, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 67, Loss: 2.3517, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 68, Loss: 2.5342, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 69, Loss: 2.4906, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 70, Loss: 2.8098, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 71, Loss: 2.4585, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 72, Loss: 2.8581, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 73, Loss: 2.6512, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 74, Loss: 2.5501, Train: 1.0000, Val: 0.7740, Test: 0.8110
Epoch: 75, Loss: 2.4866, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 76, Loss: 2.7577, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 77, Loss: 2.6555, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 78, Loss: 2.3018, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 79, Loss: 2.4839, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 80, Loss: 2.7038, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 81, Loss: 2.3351, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 82, Loss: 2.5752, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 83, Loss: 2.4347, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 84, Loss: 2.2258, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 85, Loss: 2.2172, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 86, Loss: 2.5256, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 87, Loss: 2.3314, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 88, Loss: 2.3341, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 89, Loss: 2.4855, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 90, Loss: 2.9686, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 91, Loss: 2.8328, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 92, Loss: 2.5209, Train: 1.0000, Val: 0.7840, Test: 0.8160
Epoch: 93, Loss: 2.4185, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 94, Loss: 2.7717, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 95, Loss: 2.7103, Train: 1.0000, Val: 0.7800, Test: 0.8160
Epoch: 96, Loss: 2.5131, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 97, Loss: 2.2479, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 98, Loss: 2.5800, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 99, Loss: 2.5825, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 100, Loss: 2.5563, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 101, Loss: 2.1549, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 102, Loss: 2.5077, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 103, Loss: 2.7803, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 104, Loss: 2.6506, Train: 1.0000, Val: 0.7760, Test: 0.8100
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 105, Loss: 2.5420, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 106, Loss: 2.3692, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 107, Loss: 2.5117, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 108, Loss: 2.6693, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 109, Loss: 2.4880, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 110, Loss: 2.5305, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 111, Loss: 2.5466, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 112, Loss: 2.7127, Train: 1.0000, Val: 0.7760, Test: 0.8140
Epoch: 113, Loss: 2.3650, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 114, Loss: 2.3696, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 115, Loss: 2.6086, Train: 1.0000, Val: 0.7760, Test: 0.8120
Epoch: 116, Loss: 2.6950, Train: 1.0000, Val: 0.7760, Test: 0.8130
Epoch: 117, Loss: 2.5131, Train: 1.0000, Val: 0.7760, Test: 0.8120
Epoch: 118, Loss: 2.2635, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 119, Loss: 2.4644, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 120, Loss: 2.4193, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 121, Loss: 2.3966, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 122, Loss: 2.3176, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 123, Loss: 2.5803, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 124, Loss: 2.2197, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 125, Loss: 2.8008, Train: 1.0000, Val: 0.7740, Test: 0.8110
Epoch: 126, Loss: 2.2639, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 127, Loss: 2.1113, Train: 1.0000, Val: 0.7700, Test: 0.8100
Epoch: 128, Loss: 2.6344, Train: 1.0000, Val: 0.7720, Test: 0.8110
Epoch: 129, Loss: 2.4565, Train: 1.0000, Val: 0.7680, Test: 0.8110
Epoch: 130, Loss: 2.2835, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 131, Loss: 2.3812, Train: 1.0000, Val: 0.7660, Test: 0.8100
Epoch: 132, Loss: 2.1517, Train: 1.0000, Val: 0.7640, Test: 0.8100
Epoch: 133, Loss: 2.5144, Train: 1.0000, Val: 0.7660, Test: 0.8080
Epoch: 134, Loss: 2.3566, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 135, Loss: 2.1491, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 136, Loss: 2.6015, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 137, Loss: 2.6355, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 138, Loss: 2.2460, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 139, Loss: 2.3724, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 140, Loss: 2.5951, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 141, Loss: 2.3876, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 142, Loss: 2.4495, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 143, Loss: 2.2493, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 144, Loss: 2.5893, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 145, Loss: 2.5558, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 146, Loss: 2.3874, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 147, Loss: 2.6322, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 148, Loss: 2.2969, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 149, Loss: 2.5594, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 150, Loss: 2.1454, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 151, Loss: 2.2360, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 152, Loss: 2.5870, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 153, Loss: 2.5187, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 154, Loss: 2.5861, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 155, Loss: 2.5558, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 156, Loss: 2.5929, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 157, Loss: 2.3815, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 158, Loss: 2.6934, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 159, Loss: 2.3791, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 160, Loss: 2.2470, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 161, Loss: 2.8298, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 162, Loss: 2.0662, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 163, Loss: 2.5821, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 164, Loss: 2.0303, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 165, Loss: 2.5852, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 166, Loss: 2.7636, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 167, Loss: 2.6522, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 168, Loss: 2.5512, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 169, Loss: 2.6846, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 170, Loss: 2.5906, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 171, Loss: 2.6926, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 172, Loss: 2.4854, Train: 1.0000, Val: 0.7800, Test: 0.8120
Epoch: 173, Loss: 2.3453, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 174, Loss: 2.7598, Train: 1.0000, Val: 0.7800, Test: 0.8140
Epoch: 175, Loss: 2.4942, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 176, Loss: 2.4575, Train: 1.0000, Val: 0.7800, Test: 0.8160
Epoch: 177, Loss: 2.3111, Train: 1.0000, Val: 0.7820, Test: 0.8170
Epoch: 178, Loss: 2.3118, Train: 1.0000, Val: 0.7820, Test: 0.8170
Epoch: 179, Loss: 2.4491, Train: 1.0000, Val: 0.7820, Test: 0.8170
Epoch: 180, Loss: 2.3036, Train: 1.0000, Val: 0.7820, Test: 0.8170
Epoch: 181, Loss: 2.3181, Train: 1.0000, Val: 0.7800, Test: 0.8140
Epoch: 182, Loss: 2.3702, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 183, Loss: 2.5664, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 184, Loss: 2.6193, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 185, Loss: 2.3171, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 186, Loss: 2.3091, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 187, Loss: 2.2978, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 188, Loss: 2.4052, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 189, Loss: 2.8295, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 190, Loss: 2.4162, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 191, Loss: 2.8633, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 192, Loss: 2.3027, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 193, Loss: 2.2037, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 194, Loss: 2.5154, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 195, Loss: 2.3412, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 196, Loss: 2.4516, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 197, Loss: 2.5485, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 198, Loss: 2.4137, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 199, Loss: 2.3339, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 200, Loss: 2.7212, Train: 1.0000, Val: 0.7680, Test: 0.8020
MAD:  0.4304
Best Test Accuracy: 0.8190, Val Accuracy: 0.7760, Train Accuracy: 1.0000
Training completed.
Average Test Accuracy:  0.817 ± 0.006148170459575732
Average MAD:  0.479 ± 0.2011898257864945
