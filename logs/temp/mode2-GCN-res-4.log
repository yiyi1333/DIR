Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9128, Train: 0.0643, Val: 0.0080, Test: 0.0150
Epoch: 2, Loss: 4.8422, Train: 0.1571, Val: 0.0580, Test: 0.0600
Epoch: 3, Loss: 4.8702, Train: 0.2857, Val: 0.0940, Test: 0.1230
Epoch: 4, Loss: 4.7081, Train: 0.3429, Val: 0.1460, Test: 0.1640
Epoch: 5, Loss: 4.8142, Train: 0.3786, Val: 0.1640, Test: 0.1820
Epoch: 6, Loss: 4.5914, Train: 0.4000, Val: 0.1760, Test: 0.2000
Epoch: 7, Loss: 4.7610, Train: 0.4286, Val: 0.1860, Test: 0.2020
Epoch: 8, Loss: 4.7758, Train: 0.4357, Val: 0.2040, Test: 0.2190
Epoch: 9, Loss: 4.6487, Train: 0.5000, Val: 0.2260, Test: 0.2330
Epoch: 10, Loss: 4.7700, Train: 0.5357, Val: 0.2620, Test: 0.2540
Epoch: 11, Loss: 4.5849, Train: 0.5714, Val: 0.3020, Test: 0.2860
Epoch: 12, Loss: 4.7838, Train: 0.6000, Val: 0.3460, Test: 0.3190
Epoch: 13, Loss: 4.7061, Train: 0.6571, Val: 0.3980, Test: 0.3540
Epoch: 14, Loss: 4.5182, Train: 0.7214, Val: 0.4320, Test: 0.4020
Epoch: 15, Loss: 4.6678, Train: 0.7429, Val: 0.4720, Test: 0.4380
Epoch: 16, Loss: 4.5867, Train: 0.7714, Val: 0.4980, Test: 0.4880
Epoch: 17, Loss: 4.5175, Train: 0.8000, Val: 0.5240, Test: 0.5220
Epoch: 18, Loss: 4.4490, Train: 0.8286, Val: 0.5620, Test: 0.5550
Epoch: 19, Loss: 4.2939, Train: 0.8571, Val: 0.5900, Test: 0.5900
Epoch: 20, Loss: 4.4671, Train: 0.8714, Val: 0.6080, Test: 0.6180
Epoch: 21, Loss: 4.5107, Train: 0.8857, Val: 0.6180, Test: 0.6350
Epoch: 22, Loss: 4.5090, Train: 0.9000, Val: 0.6280, Test: 0.6530
Epoch: 23, Loss: 4.6449, Train: 0.9000, Val: 0.6260, Test: 0.6590
Epoch: 24, Loss: 4.4422, Train: 0.9000, Val: 0.6220, Test: 0.6570
Epoch: 25, Loss: 4.5891, Train: 0.9000, Val: 0.6120, Test: 0.6590
Epoch: 26, Loss: 4.5444, Train: 0.9071, Val: 0.6200, Test: 0.6680
Epoch: 27, Loss: 4.3967, Train: 0.9071, Val: 0.6240, Test: 0.6570
Epoch: 28, Loss: 4.5216, Train: 0.9214, Val: 0.6220, Test: 0.6530
Epoch: 29, Loss: 4.3479, Train: 0.9214, Val: 0.6140, Test: 0.6550
Epoch: 30, Loss: 4.3520, Train: 0.9286, Val: 0.5980, Test: 0.6550
Epoch: 31, Loss: 4.5816, Train: 0.9286, Val: 0.6020, Test: 0.6520
Epoch: 32, Loss: 4.3610, Train: 0.9357, Val: 0.5980, Test: 0.6490
Epoch: 33, Loss: 4.5018, Train: 0.9357, Val: 0.5960, Test: 0.6520
Epoch: 34, Loss: 4.1131, Train: 0.9500, Val: 0.6040, Test: 0.6510
Epoch: 35, Loss: 4.4618, Train: 0.9571, Val: 0.6260, Test: 0.6550
Epoch: 36, Loss: 4.3334, Train: 0.9643, Val: 0.6380, Test: 0.6730
Epoch: 37, Loss: 4.4014, Train: 0.9643, Val: 0.6520, Test: 0.6840
Epoch: 38, Loss: 4.2452, Train: 0.9786, Val: 0.6580, Test: 0.6920
Epoch: 39, Loss: 4.4442, Train: 0.9857, Val: 0.6580, Test: 0.7000
Epoch: 40, Loss: 4.2994, Train: 0.9857, Val: 0.6660, Test: 0.7030
Epoch: 41, Loss: 4.3019, Train: 0.9857, Val: 0.6660, Test: 0.7070
Epoch: 42, Loss: 4.4791, Train: 0.9857, Val: 0.6760, Test: 0.7120
Epoch: 43, Loss: 4.1350, Train: 0.9857, Val: 0.6860, Test: 0.7190
Epoch: 44, Loss: 4.1955, Train: 0.9857, Val: 0.6840, Test: 0.7220
Epoch: 45, Loss: 4.3537, Train: 0.9857, Val: 0.6980, Test: 0.7290
Epoch: 46, Loss: 4.2584, Train: 0.9857, Val: 0.6960, Test: 0.7290
Epoch: 47, Loss: 4.2613, Train: 0.9857, Val: 0.7020, Test: 0.7310
Epoch: 48, Loss: 3.9646, Train: 0.9857, Val: 0.7000, Test: 0.7300
Epoch: 49, Loss: 4.1208, Train: 0.9857, Val: 0.7020, Test: 0.7280
Epoch: 50, Loss: 4.3843, Train: 0.9786, Val: 0.7020, Test: 0.7280
Epoch: 51, Loss: 4.1050, Train: 0.9786, Val: 0.7080, Test: 0.7300
Epoch: 52, Loss: 4.3285, Train: 0.9857, Val: 0.7060, Test: 0.7320
Epoch: 53, Loss: 3.9452, Train: 0.9857, Val: 0.7080, Test: 0.7350
Epoch: 54, Loss: 4.0598, Train: 0.9857, Val: 0.7080, Test: 0.7370
Epoch: 55, Loss: 4.2612, Train: 0.9857, Val: 0.7100, Test: 0.7380
Epoch: 56, Loss: 4.2137, Train: 0.9857, Val: 0.7180, Test: 0.7470
Epoch: 57, Loss: 4.2031, Train: 0.9857, Val: 0.7220, Test: 0.7560
Epoch: 58, Loss: 4.2388, Train: 0.9857, Val: 0.7300, Test: 0.7570
Epoch: 59, Loss: 3.9066, Train: 0.9929, Val: 0.7420, Test: 0.7640
Epoch: 60, Loss: 4.1258, Train: 0.9929, Val: 0.7520, Test: 0.7690
Epoch: 61, Loss: 3.8943, Train: 0.9929, Val: 0.7600, Test: 0.7740
Epoch: 62, Loss: 4.2464, Train: 0.9929, Val: 0.7620, Test: 0.7760
Epoch: 63, Loss: 3.9305, Train: 0.9929, Val: 0.7560, Test: 0.7800
Epoch: 64, Loss: 4.0921, Train: 0.9929, Val: 0.7520, Test: 0.7830
Epoch: 65, Loss: 3.7888, Train: 0.9929, Val: 0.7580, Test: 0.7880
Epoch: 66, Loss: 3.7733, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 67, Loss: 4.0683, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 68, Loss: 4.2853, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 69, Loss: 3.9282, Train: 1.0000, Val: 0.7560, Test: 0.7940
Epoch: 70, Loss: 4.0605, Train: 1.0000, Val: 0.7580, Test: 0.7940
Epoch: 71, Loss: 4.1476, Train: 1.0000, Val: 0.7540, Test: 0.7920
Epoch: 72, Loss: 4.1702, Train: 1.0000, Val: 0.7500, Test: 0.7900
Epoch: 73, Loss: 3.9478, Train: 1.0000, Val: 0.7500, Test: 0.7850
Epoch: 74, Loss: 4.2246, Train: 1.0000, Val: 0.7500, Test: 0.7850
Epoch: 75, Loss: 4.0383, Train: 1.0000, Val: 0.7560, Test: 0.7860
Epoch: 76, Loss: 3.9354, Train: 1.0000, Val: 0.7580, Test: 0.7850
Epoch: 77, Loss: 3.7629, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 78, Loss: 4.0511, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 79, Loss: 3.8222, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 80, Loss: 4.1754, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 81, Loss: 4.1633, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 82, Loss: 3.8852, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 83, Loss: 4.1270, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 84, Loss: 4.0524, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 85, Loss: 3.7631, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 86, Loss: 3.7461, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 87, Loss: 3.9864, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 88, Loss: 3.9549, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 89, Loss: 3.9076, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 90, Loss: 3.9098, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 91, Loss: 3.7972, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 92, Loss: 3.8830, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 93, Loss: 4.1458, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 94, Loss: 3.5154, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 95, Loss: 3.6619, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 96, Loss: 3.9120, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 97, Loss: 3.7998, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 98, Loss: 3.4646, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 99, Loss: 3.4155, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 100, Loss: 3.8233, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 101, Loss: 3.6403, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 102, Loss: 3.4870, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 103, Loss: 3.7404, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 104, Loss: 3.4684, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 105, Loss: 3.8652, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 106, Loss: 3.9863, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 107, Loss: 3.6253, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 108, Loss: 3.6841, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 109, Loss: 3.7424, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 110, Loss: 3.6244, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 111, Loss: 3.6862, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 112, Loss: 3.6212, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 113, Loss: 3.9574, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 114, Loss: 3.7048, Train: 1.0000, Val: 0.7920, Test: 0.8070
Epoch: 115, Loss: 3.6304, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 116, Loss: 4.1598, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 117, Loss: 4.0356, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 118, Loss: 3.7581, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 119, Loss: 3.8313, Train: 1.0000, Val: 0.7840, Test: 0.8060
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 3.8633, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 121, Loss: 3.8469, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 122, Loss: 3.9780, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 123, Loss: 3.5455, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 124, Loss: 3.9521, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 125, Loss: 3.5775, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 126, Loss: 3.8329, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 127, Loss: 4.0580, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 128, Loss: 3.5837, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 129, Loss: 3.3666, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 130, Loss: 3.4758, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 131, Loss: 3.6105, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 132, Loss: 3.7913, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 133, Loss: 3.6339, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 134, Loss: 3.8514, Train: 1.0000, Val: 0.7960, Test: 0.8100
Epoch: 135, Loss: 3.8744, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 136, Loss: 3.5938, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 137, Loss: 3.9536, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 138, Loss: 3.9459, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 139, Loss: 3.6689, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 140, Loss: 3.6598, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 141, Loss: 3.4656, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 142, Loss: 4.0323, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 143, Loss: 3.7681, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 144, Loss: 3.5278, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 145, Loss: 3.8591, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 146, Loss: 4.0451, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 147, Loss: 4.0097, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 148, Loss: 4.0007, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 149, Loss: 3.8195, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 150, Loss: 3.4806, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 151, Loss: 3.6648, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 152, Loss: 3.5341, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 153, Loss: 3.7454, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 154, Loss: 3.5313, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 155, Loss: 3.6592, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 156, Loss: 3.6599, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 157, Loss: 3.6831, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 158, Loss: 3.6475, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 159, Loss: 3.9129, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 160, Loss: 3.9503, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 161, Loss: 3.6928, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 162, Loss: 4.0738, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 163, Loss: 3.9044, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 164, Loss: 3.8141, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 165, Loss: 3.3313, Train: 1.0000, Val: 0.7960, Test: 0.8050
Epoch: 166, Loss: 3.9119, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 167, Loss: 3.6824, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 168, Loss: 3.2687, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 169, Loss: 3.6258, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 170, Loss: 3.7182, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 171, Loss: 3.7086, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 172, Loss: 3.5140, Train: 1.0000, Val: 0.7940, Test: 0.8120
Epoch: 173, Loss: 3.4922, Train: 1.0000, Val: 0.7960, Test: 0.8170
Epoch: 174, Loss: 3.6096, Train: 1.0000, Val: 0.7980, Test: 0.8200
Epoch: 175, Loss: 3.7465, Train: 1.0000, Val: 0.7980, Test: 0.8220
Epoch: 176, Loss: 3.4085, Train: 1.0000, Val: 0.7980, Test: 0.8220
Epoch: 177, Loss: 3.7792, Train: 1.0000, Val: 0.8000, Test: 0.8210
Epoch: 178, Loss: 3.7441, Train: 1.0000, Val: 0.7980, Test: 0.8200
Epoch: 179, Loss: 3.9250, Train: 1.0000, Val: 0.7980, Test: 0.8180
Epoch: 180, Loss: 3.6354, Train: 1.0000, Val: 0.7980, Test: 0.8170
Epoch: 181, Loss: 3.8574, Train: 1.0000, Val: 0.8000, Test: 0.8160
Epoch: 182, Loss: 3.7381, Train: 1.0000, Val: 0.7980, Test: 0.8150
Epoch: 183, Loss: 3.6400, Train: 1.0000, Val: 0.7980, Test: 0.8150
Epoch: 184, Loss: 3.7047, Train: 1.0000, Val: 0.7980, Test: 0.8140
Epoch: 185, Loss: 3.7462, Train: 1.0000, Val: 0.7980, Test: 0.8120
Epoch: 186, Loss: 3.7467, Train: 1.0000, Val: 0.7980, Test: 0.8080
Epoch: 187, Loss: 3.2499, Train: 1.0000, Val: 0.8000, Test: 0.8050
Epoch: 188, Loss: 3.7174, Train: 1.0000, Val: 0.8000, Test: 0.8060
Epoch: 189, Loss: 3.4344, Train: 1.0000, Val: 0.7980, Test: 0.8040
Epoch: 190, Loss: 3.6035, Train: 1.0000, Val: 0.7960, Test: 0.8030
Epoch: 191, Loss: 3.6670, Train: 1.0000, Val: 0.7960, Test: 0.8030
Epoch: 192, Loss: 3.6064, Train: 1.0000, Val: 0.8000, Test: 0.8010
Epoch: 193, Loss: 3.5644, Train: 1.0000, Val: 0.7980, Test: 0.8020
Epoch: 194, Loss: 3.6983, Train: 1.0000, Val: 0.7960, Test: 0.8040
Epoch: 195, Loss: 3.5733, Train: 1.0000, Val: 0.7940, Test: 0.8040
Epoch: 196, Loss: 3.5723, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 197, Loss: 3.3216, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 198, Loss: 3.7685, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 199, Loss: 3.7361, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 200, Loss: 3.7470, Train: 1.0000, Val: 0.7900, Test: 0.8040
MAD:  0.6703
Best Test Accuracy: 0.8220, Val Accuracy: 0.7980, Train Accuracy: 1.0000
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9079, Train: 0.1000, Val: 0.0440, Test: 0.0300
Epoch: 2, Loss: 4.8565, Train: 0.1929, Val: 0.1020, Test: 0.0860
Epoch: 3, Loss: 4.8683, Train: 0.2643, Val: 0.1460, Test: 0.1380
Epoch: 4, Loss: 4.8374, Train: 0.3071, Val: 0.1740, Test: 0.1790
Epoch: 5, Loss: 4.8006, Train: 0.3286, Val: 0.2020, Test: 0.2170
Epoch: 6, Loss: 4.7808, Train: 0.3714, Val: 0.2360, Test: 0.2520
Epoch: 7, Loss: 4.7874, Train: 0.4214, Val: 0.2560, Test: 0.2760
Epoch: 8, Loss: 4.6197, Train: 0.4429, Val: 0.2660, Test: 0.3110
Epoch: 9, Loss: 4.7670, Train: 0.4857, Val: 0.2940, Test: 0.3430
Epoch: 10, Loss: 4.7194, Train: 0.5286, Val: 0.3100, Test: 0.3640
Epoch: 11, Loss: 4.6931, Train: 0.5714, Val: 0.3400, Test: 0.3920
Epoch: 12, Loss: 4.5972, Train: 0.5857, Val: 0.3640, Test: 0.4160
Epoch: 13, Loss: 4.7078, Train: 0.6071, Val: 0.4020, Test: 0.4550
Epoch: 14, Loss: 4.4324, Train: 0.6643, Val: 0.4360, Test: 0.4770
Epoch: 15, Loss: 4.6677, Train: 0.7143, Val: 0.4720, Test: 0.5040
Epoch: 16, Loss: 4.4568, Train: 0.7286, Val: 0.5000, Test: 0.5230
Epoch: 17, Loss: 4.3705, Train: 0.7857, Val: 0.5220, Test: 0.5390
Epoch: 18, Loss: 4.5311, Train: 0.8000, Val: 0.5300, Test: 0.5570
Epoch: 19, Loss: 4.4536, Train: 0.8286, Val: 0.5500, Test: 0.5720
Epoch: 20, Loss: 4.4614, Train: 0.8571, Val: 0.5660, Test: 0.5820
Epoch: 21, Loss: 4.4646, Train: 0.8714, Val: 0.5560, Test: 0.5970
Epoch: 22, Loss: 4.4472, Train: 0.9000, Val: 0.5660, Test: 0.6100
Epoch: 23, Loss: 4.4595, Train: 0.9286, Val: 0.5740, Test: 0.6170
Epoch: 24, Loss: 4.4913, Train: 0.9357, Val: 0.5820, Test: 0.6170
Epoch: 25, Loss: 4.2765, Train: 0.9571, Val: 0.5740, Test: 0.6060
Epoch: 26, Loss: 4.3677, Train: 0.9643, Val: 0.5720, Test: 0.6040
Epoch: 27, Loss: 4.2112, Train: 0.9714, Val: 0.5720, Test: 0.6070
Epoch: 28, Loss: 4.3738, Train: 0.9786, Val: 0.5820, Test: 0.6090
Epoch: 29, Loss: 4.1955, Train: 0.9786, Val: 0.5860, Test: 0.6190
Epoch: 30, Loss: 4.2109, Train: 0.9857, Val: 0.5880, Test: 0.6280
Epoch: 31, Loss: 4.3563, Train: 0.9857, Val: 0.6020, Test: 0.6370
Epoch: 32, Loss: 4.4557, Train: 0.9857, Val: 0.6080, Test: 0.6450
Epoch: 33, Loss: 4.3049, Train: 0.9857, Val: 0.6140, Test: 0.6480
Epoch: 34, Loss: 4.3097, Train: 0.9857, Val: 0.6280, Test: 0.6620
Epoch: 35, Loss: 4.0369, Train: 0.9929, Val: 0.6560, Test: 0.6780
Epoch: 36, Loss: 4.2684, Train: 0.9929, Val: 0.6640, Test: 0.6920
Epoch: 37, Loss: 4.3356, Train: 0.9929, Val: 0.6700, Test: 0.7100
Epoch: 38, Loss: 4.3411, Train: 0.9929, Val: 0.6800, Test: 0.7220
Epoch: 39, Loss: 4.1827, Train: 0.9929, Val: 0.6880, Test: 0.7280
Epoch: 40, Loss: 4.4069, Train: 0.9929, Val: 0.6980, Test: 0.7320
Epoch: 41, Loss: 4.2983, Train: 0.9929, Val: 0.7040, Test: 0.7350
Epoch: 42, Loss: 3.9386, Train: 0.9929, Val: 0.7060, Test: 0.7360
Epoch: 43, Loss: 4.1300, Train: 0.9929, Val: 0.7120, Test: 0.7390
Epoch: 44, Loss: 4.4780, Train: 0.9929, Val: 0.7180, Test: 0.7400
Epoch: 45, Loss: 3.9047, Train: 0.9929, Val: 0.7240, Test: 0.7390
Epoch: 46, Loss: 4.4379, Train: 0.9929, Val: 0.7240, Test: 0.7380
Epoch: 47, Loss: 3.9020, Train: 0.9929, Val: 0.7260, Test: 0.7410
Epoch: 48, Loss: 4.2994, Train: 0.9929, Val: 0.7240, Test: 0.7470
Epoch: 49, Loss: 4.0443, Train: 0.9929, Val: 0.7220, Test: 0.7550
Epoch: 50, Loss: 3.7264, Train: 0.9929, Val: 0.7340, Test: 0.7590
Epoch: 51, Loss: 3.9132, Train: 0.9929, Val: 0.7360, Test: 0.7670
Epoch: 52, Loss: 4.0606, Train: 0.9929, Val: 0.7420, Test: 0.7700
Epoch: 53, Loss: 3.8933, Train: 0.9929, Val: 0.7380, Test: 0.7730
Epoch: 54, Loss: 4.0344, Train: 0.9929, Val: 0.7480, Test: 0.7800
Epoch: 55, Loss: 4.2411, Train: 1.0000, Val: 0.7520, Test: 0.7820
Epoch: 56, Loss: 3.9953, Train: 1.0000, Val: 0.7480, Test: 0.7820
Epoch: 57, Loss: 4.0078, Train: 1.0000, Val: 0.7540, Test: 0.7870
Epoch: 58, Loss: 4.3306, Train: 1.0000, Val: 0.7500, Test: 0.7850
Epoch: 59, Loss: 4.0453, Train: 1.0000, Val: 0.7480, Test: 0.7870
Epoch: 60, Loss: 3.8192, Train: 1.0000, Val: 0.7480, Test: 0.7840
Epoch: 61, Loss: 4.2471, Train: 1.0000, Val: 0.7440, Test: 0.7820
Epoch: 62, Loss: 3.9347, Train: 1.0000, Val: 0.7500, Test: 0.7800
Epoch: 63, Loss: 3.8624, Train: 1.0000, Val: 0.7500, Test: 0.7800
Epoch: 64, Loss: 3.9101, Train: 1.0000, Val: 0.7480, Test: 0.7810
Epoch: 65, Loss: 4.2868, Train: 1.0000, Val: 0.7540, Test: 0.7820
Epoch: 66, Loss: 4.1130, Train: 1.0000, Val: 0.7520, Test: 0.7860
Epoch: 67, Loss: 4.1315, Train: 1.0000, Val: 0.7520, Test: 0.7840
Epoch: 68, Loss: 4.0596, Train: 1.0000, Val: 0.7560, Test: 0.7890
Epoch: 69, Loss: 4.1139, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 70, Loss: 4.0898, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 71, Loss: 3.9052, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 72, Loss: 3.9272, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 73, Loss: 3.7837, Train: 1.0000, Val: 0.7600, Test: 0.7880
Epoch: 74, Loss: 3.6390, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 75, Loss: 3.9733, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 76, Loss: 4.3088, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 77, Loss: 4.0979, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 78, Loss: 4.1081, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 79, Loss: 3.5780, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 80, Loss: 3.6118, Train: 1.0000, Val: 0.7600, Test: 0.8010
Epoch: 81, Loss: 4.0573, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 82, Loss: 3.6628, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 83, Loss: 3.8887, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 84, Loss: 3.6988, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 85, Loss: 3.8511, Train: 1.0000, Val: 0.7620, Test: 0.8030
Epoch: 86, Loss: 3.7415, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 87, Loss: 4.0171, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 88, Loss: 3.7701, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 89, Loss: 3.8747, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 90, Loss: 3.6341, Train: 1.0000, Val: 0.7620, Test: 0.8010
Epoch: 91, Loss: 3.5768, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 92, Loss: 3.7140, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 93, Loss: 3.8537, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 94, Loss: 4.2482, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 95, Loss: 4.1138, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 96, Loss: 3.7725, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 97, Loss: 4.0029, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 98, Loss: 3.7994, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 99, Loss: 3.7154, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 100, Loss: 3.9832, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 101, Loss: 3.5946, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 102, Loss: 3.8885, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 103, Loss: 3.6666, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 104, Loss: 3.6901, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 105, Loss: 3.9375, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 106, Loss: 3.4082, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 107, Loss: 3.8818, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 108, Loss: 3.6596, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 109, Loss: 3.6790, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 110, Loss: 3.7392, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 111, Loss: 3.7955, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 112, Loss: 3.9317, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 113, Loss: 3.8600, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 114, Loss: 3.4874, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 115, Loss: 3.9137, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 116, Loss: 3.5849, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 117, Loss: 3.8978, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 118, Loss: 3.7020, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 119, Loss: 3.7459, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 120, Loss: 3.6553, Train: 1.0000, Val: 0.7960, Test: 0.8090
Epoch: 121, Loss: 3.8376, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 122, Loss: 3.8404, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 123, Loss: 3.7790, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 124, Loss: 3.9745, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 125, Loss: 3.8249, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 126, Loss: 3.8536, Train: 1.0000, Val: 0.7940, Test: 0.8120
Epoch: 127, Loss: 3.9913, Train: 1.0000, Val: 0.7920, Test: 0.8120
Epoch: 128, Loss: 3.6038, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 129, Loss: 3.6733, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 130, Loss: 3.9103, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 131, Loss: 3.7025, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 132, Loss: 3.5865, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 133, Loss: 3.1803, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 134, Loss: 3.8002, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 135, Loss: 3.6953, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 136, Loss: 3.7615, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 137, Loss: 3.6179, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 138, Loss: 3.2304, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 139, Loss: 3.7790, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 140, Loss: 3.6935, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 141, Loss: 3.8772, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 142, Loss: 3.6545, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 143, Loss: 3.7764, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 144, Loss: 3.8488, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 145, Loss: 3.7240, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 146, Loss: 3.7595, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 147, Loss: 3.6942, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 148, Loss: 3.9691, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 149, Loss: 3.5837, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 150, Loss: 3.7587, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 151, Loss: 3.7301, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 152, Loss: 3.7924, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 153, Loss: 3.9398, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 154, Loss: 3.5147, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 155, Loss: 3.8956, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 156, Loss: 3.5164, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 157, Loss: 3.3833, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 158, Loss: 3.8177, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 159, Loss: 3.6116, Train: 1.0000, Val: 0.7820, Test: 0.8070
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 160, Loss: 3.9279, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 161, Loss: 3.7246, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 162, Loss: 4.0583, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 163, Loss: 3.6117, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 164, Loss: 3.5458, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 165, Loss: 3.9037, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 166, Loss: 3.6847, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 167, Loss: 3.7987, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 168, Loss: 3.6022, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 169, Loss: 3.6057, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 170, Loss: 3.5350, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 171, Loss: 3.7593, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 172, Loss: 3.5066, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 173, Loss: 4.0124, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 174, Loss: 3.7737, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 175, Loss: 3.6273, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 176, Loss: 3.7033, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 177, Loss: 3.8502, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 178, Loss: 3.8072, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 179, Loss: 3.6706, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 180, Loss: 3.3637, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 181, Loss: 3.3260, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 182, Loss: 3.6644, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 183, Loss: 3.6617, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 184, Loss: 3.6504, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 185, Loss: 4.1527, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 186, Loss: 3.5315, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 187, Loss: 3.6023, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 188, Loss: 3.7075, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 189, Loss: 3.3624, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 190, Loss: 3.9466, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 191, Loss: 3.6397, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 192, Loss: 3.7405, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 193, Loss: 3.7024, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 194, Loss: 3.9046, Train: 1.0000, Val: 0.7680, Test: 0.8080
Epoch: 195, Loss: 3.7310, Train: 1.0000, Val: 0.7660, Test: 0.8090
Epoch: 196, Loss: 3.5738, Train: 1.0000, Val: 0.7640, Test: 0.8080
Epoch: 197, Loss: 3.7747, Train: 1.0000, Val: 0.7660, Test: 0.8100
Epoch: 198, Loss: 3.6626, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 199, Loss: 3.8105, Train: 1.0000, Val: 0.7680, Test: 0.8080
Epoch: 200, Loss: 3.5389, Train: 1.0000, Val: 0.7720, Test: 0.8050
MAD:  0.5064
Best Test Accuracy: 0.8120, Val Accuracy: 0.7900, Train Accuracy: 1.0000
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9141, Train: 0.0071, Val: 0.0080, Test: 0.0140
Epoch: 2, Loss: 4.9006, Train: 0.0500, Val: 0.0140, Test: 0.0320
Epoch: 3, Loss: 4.8410, Train: 0.1286, Val: 0.0540, Test: 0.0680
Epoch: 4, Loss: 4.8349, Train: 0.2143, Val: 0.0960, Test: 0.1150
Epoch: 5, Loss: 4.7211, Train: 0.3286, Val: 0.1320, Test: 0.1570
Epoch: 6, Loss: 4.7718, Train: 0.3714, Val: 0.1480, Test: 0.1930
Epoch: 7, Loss: 4.8322, Train: 0.4214, Val: 0.1760, Test: 0.2300
Epoch: 8, Loss: 4.6319, Train: 0.4786, Val: 0.2080, Test: 0.2510
Epoch: 9, Loss: 4.6790, Train: 0.5286, Val: 0.2380, Test: 0.2710
Epoch: 10, Loss: 4.6343, Train: 0.5857, Val: 0.2620, Test: 0.2980
Epoch: 11, Loss: 4.7732, Train: 0.6357, Val: 0.2700, Test: 0.3250
Epoch: 12, Loss: 4.6445, Train: 0.6571, Val: 0.2860, Test: 0.3460
Epoch: 13, Loss: 4.6380, Train: 0.6786, Val: 0.3100, Test: 0.3640
Epoch: 14, Loss: 4.7013, Train: 0.7429, Val: 0.3460, Test: 0.3950
Epoch: 15, Loss: 4.4649, Train: 0.7714, Val: 0.3840, Test: 0.4270
Epoch: 16, Loss: 4.4633, Train: 0.8143, Val: 0.4160, Test: 0.4610
Epoch: 17, Loss: 4.2981, Train: 0.8571, Val: 0.4440, Test: 0.5000
Epoch: 18, Loss: 4.6142, Train: 0.8571, Val: 0.4700, Test: 0.5200
Epoch: 19, Loss: 4.4507, Train: 0.8714, Val: 0.4980, Test: 0.5500
Epoch: 20, Loss: 4.4528, Train: 0.8714, Val: 0.5140, Test: 0.5820
Epoch: 21, Loss: 4.4257, Train: 0.8857, Val: 0.5320, Test: 0.5950
Epoch: 22, Loss: 4.4786, Train: 0.8929, Val: 0.5440, Test: 0.6090
Epoch: 23, Loss: 4.5528, Train: 0.8929, Val: 0.5540, Test: 0.6230
Epoch: 24, Loss: 4.4327, Train: 0.9071, Val: 0.5620, Test: 0.6370
Epoch: 25, Loss: 4.4355, Train: 0.9143, Val: 0.5740, Test: 0.6480
Epoch: 26, Loss: 4.4278, Train: 0.9214, Val: 0.5800, Test: 0.6590
Epoch: 27, Loss: 4.3710, Train: 0.9286, Val: 0.5940, Test: 0.6670
Epoch: 28, Loss: 4.5370, Train: 0.9357, Val: 0.6000, Test: 0.6650
Epoch: 29, Loss: 4.3726, Train: 0.9500, Val: 0.6080, Test: 0.6670
Epoch: 30, Loss: 4.3362, Train: 0.9500, Val: 0.6100, Test: 0.6670
Epoch: 31, Loss: 4.2714, Train: 0.9571, Val: 0.6120, Test: 0.6750
Epoch: 32, Loss: 4.3391, Train: 0.9643, Val: 0.5960, Test: 0.6790
Epoch: 33, Loss: 4.4065, Train: 0.9714, Val: 0.5860, Test: 0.6660
Epoch: 34, Loss: 4.3214, Train: 0.9714, Val: 0.5840, Test: 0.6600
Epoch: 35, Loss: 4.3734, Train: 0.9714, Val: 0.5820, Test: 0.6560
Epoch: 36, Loss: 4.3626, Train: 0.9786, Val: 0.5920, Test: 0.6580
Epoch: 37, Loss: 4.3863, Train: 0.9857, Val: 0.6020, Test: 0.6570
Epoch: 38, Loss: 4.3133, Train: 0.9857, Val: 0.6100, Test: 0.6620
Epoch: 39, Loss: 4.3776, Train: 0.9857, Val: 0.6180, Test: 0.6720
Epoch: 40, Loss: 4.0116, Train: 0.9786, Val: 0.6240, Test: 0.6820
Epoch: 41, Loss: 4.2499, Train: 0.9786, Val: 0.6400, Test: 0.6930
Epoch: 42, Loss: 4.1683, Train: 0.9786, Val: 0.6560, Test: 0.7080
Epoch: 43, Loss: 4.2238, Train: 0.9857, Val: 0.6680, Test: 0.7240
Epoch: 44, Loss: 4.4234, Train: 0.9857, Val: 0.6780, Test: 0.7320
Epoch: 45, Loss: 4.2713, Train: 0.9857, Val: 0.7000, Test: 0.7430
Epoch: 46, Loss: 4.1855, Train: 0.9929, Val: 0.7100, Test: 0.7510
Epoch: 47, Loss: 4.1754, Train: 0.9929, Val: 0.7120, Test: 0.7600
Epoch: 48, Loss: 4.2158, Train: 0.9929, Val: 0.7220, Test: 0.7640
Epoch: 49, Loss: 4.1684, Train: 0.9929, Val: 0.7240, Test: 0.7680
Epoch: 50, Loss: 4.1983, Train: 0.9929, Val: 0.7300, Test: 0.7700
Epoch: 51, Loss: 4.3833, Train: 0.9929, Val: 0.7300, Test: 0.7680
Epoch: 52, Loss: 4.0068, Train: 0.9929, Val: 0.7300, Test: 0.7650
Epoch: 53, Loss: 4.1030, Train: 0.9929, Val: 0.7240, Test: 0.7630
Epoch: 54, Loss: 4.3036, Train: 0.9929, Val: 0.7240, Test: 0.7660
Epoch: 55, Loss: 3.8438, Train: 0.9929, Val: 0.7280, Test: 0.7660
Epoch: 56, Loss: 4.4121, Train: 0.9929, Val: 0.7300, Test: 0.7680
Epoch: 57, Loss: 4.3068, Train: 0.9929, Val: 0.7300, Test: 0.7710
Epoch: 58, Loss: 3.8108, Train: 0.9929, Val: 0.7340, Test: 0.7700
Epoch: 59, Loss: 4.2317, Train: 0.9929, Val: 0.7340, Test: 0.7710
Epoch: 60, Loss: 4.0725, Train: 0.9929, Val: 0.7440, Test: 0.7810
Epoch: 61, Loss: 3.7961, Train: 0.9929, Val: 0.7480, Test: 0.7810
Epoch: 62, Loss: 4.0017, Train: 0.9929, Val: 0.7560, Test: 0.7830
Epoch: 63, Loss: 3.8781, Train: 0.9929, Val: 0.7700, Test: 0.7880
Epoch: 64, Loss: 3.7267, Train: 0.9929, Val: 0.7660, Test: 0.7930
Epoch: 65, Loss: 4.3301, Train: 0.9929, Val: 0.7740, Test: 0.7950
Epoch: 66, Loss: 3.8602, Train: 0.9929, Val: 0.7760, Test: 0.7990
Epoch: 67, Loss: 4.1057, Train: 0.9929, Val: 0.7800, Test: 0.7980
Epoch: 68, Loss: 3.9686, Train: 0.9929, Val: 0.7880, Test: 0.7980
Epoch: 69, Loss: 4.1222, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 70, Loss: 4.0072, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 71, Loss: 4.1362, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 72, Loss: 4.1570, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 73, Loss: 3.6296, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 74, Loss: 3.7502, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 75, Loss: 3.8295, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 76, Loss: 3.8290, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 77, Loss: 3.5233, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 78, Loss: 3.7951, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 79, Loss: 3.8491, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 80, Loss: 3.8363, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 81, Loss: 4.2096, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 82, Loss: 3.8577, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 83, Loss: 3.7540, Train: 1.0000, Val: 0.7580, Test: 0.7870
Epoch: 84, Loss: 3.9575, Train: 1.0000, Val: 0.7600, Test: 0.7860
Epoch: 85, Loss: 4.0025, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 86, Loss: 3.7237, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 87, Loss: 3.8599, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 88, Loss: 3.8411, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 89, Loss: 3.7609, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 90, Loss: 3.6964, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 91, Loss: 3.7764, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 92, Loss: 3.6427, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 93, Loss: 4.0488, Train: 1.0000, Val: 0.7980, Test: 0.8030
Epoch: 94, Loss: 3.7421, Train: 1.0000, Val: 0.7980, Test: 0.8030
Epoch: 95, Loss: 3.8931, Train: 1.0000, Val: 0.7960, Test: 0.8060
Epoch: 96, Loss: 3.5712, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 97, Loss: 3.9290, Train: 1.0000, Val: 0.7940, Test: 0.8070
Epoch: 98, Loss: 4.1654, Train: 1.0000, Val: 0.7960, Test: 0.8080
Epoch: 99, Loss: 3.8740, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 100, Loss: 3.7017, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 101, Loss: 4.1067, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 102, Loss: 3.8203, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 103, Loss: 3.8516, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 104, Loss: 3.8150, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 105, Loss: 3.7701, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 106, Loss: 3.4708, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 107, Loss: 3.9499, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 108, Loss: 3.6274, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 109, Loss: 3.9076, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 110, Loss: 3.8681, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 111, Loss: 3.6583, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 112, Loss: 3.8387, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 113, Loss: 3.7457, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 114, Loss: 3.8350, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 115, Loss: 3.4477, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 116, Loss: 3.8044, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 117, Loss: 3.5632, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 118, Loss: 3.5561, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 119, Loss: 4.0551, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 120, Loss: 3.6729, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 121, Loss: 3.8231, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 122, Loss: 3.7821, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 123, Loss: 3.8645, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 124, Loss: 3.6909, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 125, Loss: 3.7868, Train: 1.0000, Val: 0.7960, Test: 0.8050
Epoch: 126, Loss: 3.4971, Train: 1.0000, Val: 0.7940, Test: 0.8040
Epoch: 127, Loss: 3.9422, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 128, Loss: 3.7264, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 129, Loss: 3.8769, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 130, Loss: 3.9059, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 131, Loss: 3.6326, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 132, Loss: 3.5029, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 133, Loss: 3.7187, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 134, Loss: 3.7049, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 135, Loss: 3.5962, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 136, Loss: 3.8477, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 137, Loss: 3.8719, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 138, Loss: 3.5332, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 139, Loss: 3.4668, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 140, Loss: 3.6973, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 141, Loss: 3.6632, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 142, Loss: 3.8334, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 143, Loss: 3.9641, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 144, Loss: 3.4947, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 145, Loss: 3.7306, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 146, Loss: 3.7433, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 147, Loss: 3.6932, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 148, Loss: 3.4477, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 149, Loss: 3.4696, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 150, Loss: 3.3837, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 151, Loss: 3.9595, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 152, Loss: 3.7642, Train: 1.0000, Val: 0.7940, Test: 0.8130
Epoch: 153, Loss: 3.7272, Train: 1.0000, Val: 0.7960, Test: 0.8110
Epoch: 154, Loss: 3.8994, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 155, Loss: 3.7807, Train: 1.0000, Val: 0.7920, Test: 0.8170
Epoch: 156, Loss: 3.7265, Train: 1.0000, Val: 0.7960, Test: 0.8150
Epoch: 157, Loss: 3.8483, Train: 1.0000, Val: 0.7960, Test: 0.8150
Epoch: 158, Loss: 3.7594, Train: 1.0000, Val: 0.7940, Test: 0.8150
Epoch: 159, Loss: 3.8502, Train: 1.0000, Val: 0.7920, Test: 0.8150
Epoch: 160, Loss: 3.4037, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 161, Loss: 3.4087, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 162, Loss: 3.3826, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 163, Loss: 3.5450, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 164, Loss: 3.7831, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 165, Loss: 3.7636, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 166, Loss: 3.6442, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 167, Loss: 3.6716, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 168, Loss: 3.4378, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 169, Loss: 3.8211, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 170, Loss: 3.7153, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 171, Loss: 3.3288, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 172, Loss: 3.7874, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 173, Loss: 3.5052, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 174, Loss: 3.7143, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 175, Loss: 3.6062, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 176, Loss: 3.7074, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 177, Loss: 3.6727, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 178, Loss: 3.7428, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 179, Loss: 3.6752, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 180, Loss: 4.0511, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 181, Loss: 3.6278, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 182, Loss: 3.8405, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 183, Loss: 3.6139, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 184, Loss: 3.6986, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 185, Loss: 3.8134, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 186, Loss: 3.5979, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 187, Loss: 3.7659, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 188, Loss: 3.9029, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 189, Loss: 3.7730, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 190, Loss: 4.1335, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 191, Loss: 3.8180, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 192, Loss: 3.8344, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 193, Loss: 3.6366, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 194, Loss: 3.8568, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 195, Loss: 3.4935, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 196, Loss: 3.8814, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 197, Loss: 3.8672, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 198, Loss: 3.6716, Train: 1.0000, Val: 0.7800, Test: 0.7990
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 199, Loss: 3.6971, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 200, Loss: 3.5592, Train: 1.0000, Val: 0.7760, Test: 0.7990
MAD:  0.63
Best Test Accuracy: 0.8170, Val Accuracy: 0.7920, Train Accuracy: 1.0000
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9152, Train: 0.0786, Val: 0.0360, Test: 0.0350
Epoch: 2, Loss: 4.8855, Train: 0.1500, Val: 0.1000, Test: 0.0960
Epoch: 3, Loss: 4.8885, Train: 0.2000, Val: 0.1460, Test: 0.1210
Epoch: 4, Loss: 4.8637, Train: 0.2214, Val: 0.1620, Test: 0.1470
Epoch: 5, Loss: 4.7915, Train: 0.2357, Val: 0.1960, Test: 0.1670
Epoch: 6, Loss: 4.7782, Train: 0.2571, Val: 0.2060, Test: 0.1960
Epoch: 7, Loss: 4.7633, Train: 0.2786, Val: 0.2180, Test: 0.2080
Epoch: 8, Loss: 4.6681, Train: 0.3357, Val: 0.2300, Test: 0.2190
Epoch: 9, Loss: 4.6919, Train: 0.3929, Val: 0.2400, Test: 0.2370
Epoch: 10, Loss: 4.7853, Train: 0.4643, Val: 0.2640, Test: 0.2570
Epoch: 11, Loss: 4.6961, Train: 0.5214, Val: 0.2860, Test: 0.2890
Epoch: 12, Loss: 4.6652, Train: 0.5929, Val: 0.3160, Test: 0.3260
Epoch: 13, Loss: 4.6726, Train: 0.6786, Val: 0.3580, Test: 0.3540
Epoch: 14, Loss: 4.6620, Train: 0.7643, Val: 0.4300, Test: 0.4040
Epoch: 15, Loss: 4.3846, Train: 0.8071, Val: 0.4580, Test: 0.4390
Epoch: 16, Loss: 4.5760, Train: 0.8500, Val: 0.4840, Test: 0.4780
Epoch: 17, Loss: 4.5971, Train: 0.8500, Val: 0.5140, Test: 0.5000
Epoch: 18, Loss: 4.4550, Train: 0.8714, Val: 0.5360, Test: 0.5160
Epoch: 19, Loss: 4.4926, Train: 0.8929, Val: 0.5440, Test: 0.5270
Epoch: 20, Loss: 4.4574, Train: 0.9000, Val: 0.5500, Test: 0.5300
Epoch: 21, Loss: 4.5474, Train: 0.9214, Val: 0.5580, Test: 0.5300
Epoch: 22, Loss: 4.5032, Train: 0.9214, Val: 0.5460, Test: 0.5320
Epoch: 23, Loss: 4.3678, Train: 0.9286, Val: 0.5540, Test: 0.5310
Epoch: 24, Loss: 4.6422, Train: 0.9286, Val: 0.5520, Test: 0.5290
Epoch: 25, Loss: 4.5415, Train: 0.9214, Val: 0.5560, Test: 0.5320
Epoch: 26, Loss: 4.2537, Train: 0.9214, Val: 0.5620, Test: 0.5410
Epoch: 27, Loss: 4.3614, Train: 0.9214, Val: 0.5660, Test: 0.5510
Epoch: 28, Loss: 4.3141, Train: 0.9214, Val: 0.5680, Test: 0.5550
Epoch: 29, Loss: 4.1208, Train: 0.9214, Val: 0.5660, Test: 0.5660
Epoch: 30, Loss: 4.3543, Train: 0.9286, Val: 0.5860, Test: 0.5760
Epoch: 31, Loss: 4.4050, Train: 0.9357, Val: 0.5900, Test: 0.5760
Epoch: 32, Loss: 4.5118, Train: 0.9357, Val: 0.5800, Test: 0.5790
Epoch: 33, Loss: 4.3174, Train: 0.9429, Val: 0.5760, Test: 0.5870
Epoch: 34, Loss: 4.3423, Train: 0.9429, Val: 0.5800, Test: 0.5920
Epoch: 35, Loss: 4.3879, Train: 0.9429, Val: 0.5920, Test: 0.6060
Epoch: 36, Loss: 4.3107, Train: 0.9571, Val: 0.5980, Test: 0.6190
Epoch: 37, Loss: 4.3152, Train: 0.9714, Val: 0.6040, Test: 0.6250
Epoch: 38, Loss: 4.4066, Train: 0.9714, Val: 0.6280, Test: 0.6400
Epoch: 39, Loss: 4.3446, Train: 0.9857, Val: 0.6380, Test: 0.6570
Epoch: 40, Loss: 4.3241, Train: 0.9857, Val: 0.6480, Test: 0.6660
Epoch: 41, Loss: 4.2084, Train: 1.0000, Val: 0.6540, Test: 0.6740
Epoch: 42, Loss: 4.1980, Train: 1.0000, Val: 0.6580, Test: 0.6790
Epoch: 43, Loss: 4.1346, Train: 1.0000, Val: 0.6620, Test: 0.6860
Epoch: 44, Loss: 3.9765, Train: 1.0000, Val: 0.6700, Test: 0.6830
Epoch: 45, Loss: 4.2886, Train: 1.0000, Val: 0.6820, Test: 0.6930
Epoch: 46, Loss: 4.2346, Train: 1.0000, Val: 0.6840, Test: 0.7060
Epoch: 47, Loss: 4.1177, Train: 1.0000, Val: 0.6900, Test: 0.7120
Epoch: 48, Loss: 4.0583, Train: 1.0000, Val: 0.6940, Test: 0.7160
Epoch: 49, Loss: 4.0933, Train: 1.0000, Val: 0.7000, Test: 0.7260
Epoch: 50, Loss: 3.8939, Train: 1.0000, Val: 0.7040, Test: 0.7290
Epoch: 51, Loss: 4.0379, Train: 1.0000, Val: 0.7100, Test: 0.7340
Epoch: 52, Loss: 3.8151, Train: 1.0000, Val: 0.7200, Test: 0.7360
Epoch: 53, Loss: 4.0319, Train: 1.0000, Val: 0.7280, Test: 0.7400
Epoch: 54, Loss: 4.0495, Train: 1.0000, Val: 0.7300, Test: 0.7430
Epoch: 55, Loss: 4.1582, Train: 1.0000, Val: 0.7320, Test: 0.7490
Epoch: 56, Loss: 4.0262, Train: 1.0000, Val: 0.7400, Test: 0.7540
Epoch: 57, Loss: 3.7621, Train: 1.0000, Val: 0.7420, Test: 0.7590
Epoch: 58, Loss: 3.9266, Train: 1.0000, Val: 0.7500, Test: 0.7680
Epoch: 59, Loss: 4.1740, Train: 1.0000, Val: 0.7480, Test: 0.7710
Epoch: 60, Loss: 3.9553, Train: 1.0000, Val: 0.7460, Test: 0.7700
Epoch: 61, Loss: 3.9110, Train: 1.0000, Val: 0.7500, Test: 0.7700
Epoch: 62, Loss: 4.0827, Train: 1.0000, Val: 0.7560, Test: 0.7740
Epoch: 63, Loss: 4.1515, Train: 1.0000, Val: 0.7620, Test: 0.7750
Epoch: 64, Loss: 3.9198, Train: 1.0000, Val: 0.7640, Test: 0.7750
Epoch: 65, Loss: 3.6991, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 66, Loss: 4.0393, Train: 1.0000, Val: 0.7720, Test: 0.7810
Epoch: 67, Loss: 3.9987, Train: 1.0000, Val: 0.7760, Test: 0.7800
Epoch: 68, Loss: 4.1743, Train: 1.0000, Val: 0.7780, Test: 0.7820
Epoch: 69, Loss: 4.1907, Train: 1.0000, Val: 0.7760, Test: 0.7820
Epoch: 70, Loss: 3.6808, Train: 1.0000, Val: 0.7800, Test: 0.7850
Epoch: 71, Loss: 3.8882, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 72, Loss: 3.9791, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 73, Loss: 3.6286, Train: 1.0000, Val: 0.7720, Test: 0.7870
Epoch: 74, Loss: 4.3246, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 75, Loss: 3.7719, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 76, Loss: 3.8163, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 77, Loss: 3.8311, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 78, Loss: 3.8035, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 79, Loss: 3.9385, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 80, Loss: 3.5642, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 81, Loss: 3.5821, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 82, Loss: 3.9439, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 83, Loss: 3.8443, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 84, Loss: 3.6986, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 85, Loss: 3.8568, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 86, Loss: 3.8669, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 87, Loss: 3.6628, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 88, Loss: 3.8637, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 89, Loss: 3.8807, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 90, Loss: 3.6705, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 91, Loss: 3.8399, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 92, Loss: 3.7256, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 93, Loss: 3.9139, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 94, Loss: 3.8899, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 95, Loss: 3.7780, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 96, Loss: 4.0620, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 97, Loss: 3.7403, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 98, Loss: 3.8529, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 99, Loss: 3.8843, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 100, Loss: 3.5734, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 101, Loss: 3.9086, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 102, Loss: 4.0209, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 103, Loss: 3.8175, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 104, Loss: 3.7577, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 105, Loss: 3.7035, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 106, Loss: 3.7427, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 107, Loss: 3.6466, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 108, Loss: 3.7940, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 109, Loss: 3.7697, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 110, Loss: 3.7643, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 111, Loss: 3.6139, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 112, Loss: 3.9217, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 113, Loss: 3.6178, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 114, Loss: 3.5919, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 115, Loss: 3.6330, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 116, Loss: 3.3120, Train: 1.0000, Val: 0.7820, Test: 0.7940
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 117, Loss: 3.8007, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 118, Loss: 3.7645, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 119, Loss: 3.9924, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 120, Loss: 3.8029, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 121, Loss: 3.6247, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 122, Loss: 3.4883, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 123, Loss: 3.8298, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 124, Loss: 3.9517, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 125, Loss: 3.4864, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 126, Loss: 3.7541, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 127, Loss: 3.5958, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 128, Loss: 3.8326, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 129, Loss: 3.7216, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 130, Loss: 3.6254, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 131, Loss: 3.6989, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 132, Loss: 3.8421, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 133, Loss: 3.4126, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 134, Loss: 3.7091, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 135, Loss: 3.7850, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 136, Loss: 3.6850, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 137, Loss: 3.3601, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 138, Loss: 4.0945, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 139, Loss: 3.7453, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 140, Loss: 3.9424, Train: 1.0000, Val: 0.7760, Test: 0.7840
Epoch: 141, Loss: 3.7972, Train: 1.0000, Val: 0.7800, Test: 0.7850
Epoch: 142, Loss: 3.6773, Train: 1.0000, Val: 0.7800, Test: 0.7850
Epoch: 143, Loss: 4.1381, Train: 1.0000, Val: 0.7800, Test: 0.7850
Epoch: 144, Loss: 3.8333, Train: 1.0000, Val: 0.7820, Test: 0.7850
Epoch: 145, Loss: 3.4634, Train: 1.0000, Val: 0.7800, Test: 0.7850
Epoch: 146, Loss: 3.6410, Train: 1.0000, Val: 0.7820, Test: 0.7910
Epoch: 147, Loss: 3.8855, Train: 1.0000, Val: 0.7840, Test: 0.7920
Epoch: 148, Loss: 3.8520, Train: 1.0000, Val: 0.7860, Test: 0.7920
Epoch: 149, Loss: 3.5217, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 150, Loss: 3.5781, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 151, Loss: 3.7236, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 152, Loss: 3.6929, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 153, Loss: 3.5486, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 154, Loss: 3.5783, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 155, Loss: 3.6226, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 156, Loss: 3.5923, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 157, Loss: 3.7358, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 158, Loss: 3.6627, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 159, Loss: 4.0988, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 160, Loss: 3.7466, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 161, Loss: 3.1003, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 162, Loss: 3.9515, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 163, Loss: 3.8571, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 164, Loss: 3.5491, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 165, Loss: 3.8400, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 166, Loss: 3.5702, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 167, Loss: 3.5426, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 168, Loss: 3.9507, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 169, Loss: 3.6314, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 170, Loss: 3.4378, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 171, Loss: 3.8461, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 172, Loss: 3.4025, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 173, Loss: 3.5082, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 174, Loss: 3.7462, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 175, Loss: 3.8860, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 176, Loss: 3.9044, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 177, Loss: 3.4811, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 178, Loss: 3.8835, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 179, Loss: 3.5327, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 180, Loss: 3.6719, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 181, Loss: 3.8690, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 182, Loss: 3.9887, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 183, Loss: 3.8363, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 184, Loss: 3.4659, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 185, Loss: 4.0819, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 186, Loss: 3.6300, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 187, Loss: 3.4927, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 188, Loss: 3.8760, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 189, Loss: 3.6117, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 190, Loss: 4.0128, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 191, Loss: 3.8118, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 192, Loss: 3.6670, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 193, Loss: 3.5542, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 194, Loss: 3.8782, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 195, Loss: 3.8379, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 196, Loss: 3.5252, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 197, Loss: 3.7673, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 198, Loss: 3.7724, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 199, Loss: 3.5664, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 200, Loss: 3.5243, Train: 1.0000, Val: 0.7740, Test: 0.8000
MAD:  0.3752
Best Test Accuracy: 0.8040, Val Accuracy: 0.7800, Train Accuracy: 1.0000
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9435, Train: 0.0429, Val: 0.0300, Test: 0.0200
Epoch: 2, Loss: 4.8678, Train: 0.0857, Val: 0.0600, Test: 0.0550
Epoch: 3, Loss: 4.8283, Train: 0.1286, Val: 0.0980, Test: 0.0870
Epoch: 4, Loss: 4.8266, Train: 0.2071, Val: 0.1480, Test: 0.1330
Epoch: 5, Loss: 4.7310, Train: 0.2571, Val: 0.1940, Test: 0.2030
Epoch: 6, Loss: 4.6886, Train: 0.3214, Val: 0.2440, Test: 0.2570
Epoch: 7, Loss: 4.6831, Train: 0.3786, Val: 0.2780, Test: 0.2900
Epoch: 8, Loss: 4.5859, Train: 0.4357, Val: 0.3000, Test: 0.3260
Epoch: 9, Loss: 4.6600, Train: 0.5000, Val: 0.3380, Test: 0.3620
Epoch: 10, Loss: 4.7023, Train: 0.5429, Val: 0.3680, Test: 0.3840
Epoch: 11, Loss: 4.7385, Train: 0.5857, Val: 0.4000, Test: 0.4050
Epoch: 12, Loss: 4.6002, Train: 0.6000, Val: 0.4400, Test: 0.4260
Epoch: 13, Loss: 4.6134, Train: 0.6429, Val: 0.4900, Test: 0.4670
Epoch: 14, Loss: 4.6180, Train: 0.7000, Val: 0.5260, Test: 0.5110
Epoch: 15, Loss: 4.6223, Train: 0.7643, Val: 0.5540, Test: 0.5400
Epoch: 16, Loss: 4.6081, Train: 0.8214, Val: 0.5860, Test: 0.5700
Epoch: 17, Loss: 4.5643, Train: 0.8643, Val: 0.6160, Test: 0.5980
Epoch: 18, Loss: 4.5753, Train: 0.9071, Val: 0.6440, Test: 0.6180
Epoch: 19, Loss: 4.5138, Train: 0.9143, Val: 0.6520, Test: 0.6350
Epoch: 20, Loss: 4.6141, Train: 0.9286, Val: 0.6660, Test: 0.6530
Epoch: 21, Loss: 4.6321, Train: 0.9214, Val: 0.6720, Test: 0.6510
Epoch: 22, Loss: 4.4584, Train: 0.9286, Val: 0.6800, Test: 0.6530
Epoch: 23, Loss: 4.4382, Train: 0.9286, Val: 0.6740, Test: 0.6490
Epoch: 24, Loss: 4.4156, Train: 0.9357, Val: 0.6760, Test: 0.6550
Epoch: 25, Loss: 4.3983, Train: 0.9357, Val: 0.6800, Test: 0.6640
Epoch: 26, Loss: 4.3672, Train: 0.9429, Val: 0.6940, Test: 0.6740
Epoch: 27, Loss: 4.5646, Train: 0.9429, Val: 0.7060, Test: 0.6920
Epoch: 28, Loss: 4.1726, Train: 0.9500, Val: 0.7180, Test: 0.7050
Epoch: 29, Loss: 4.1855, Train: 0.9571, Val: 0.7200, Test: 0.7170
Epoch: 30, Loss: 4.2177, Train: 0.9571, Val: 0.7320, Test: 0.7300
Epoch: 31, Loss: 4.4200, Train: 0.9786, Val: 0.7380, Test: 0.7360
Epoch: 32, Loss: 4.3723, Train: 0.9857, Val: 0.7360, Test: 0.7420
Epoch: 33, Loss: 4.2967, Train: 0.9857, Val: 0.7380, Test: 0.7440
Epoch: 34, Loss: 4.3519, Train: 0.9857, Val: 0.7360, Test: 0.7500
Epoch: 35, Loss: 4.2694, Train: 0.9857, Val: 0.7380, Test: 0.7500
Epoch: 36, Loss: 4.2981, Train: 0.9857, Val: 0.7380, Test: 0.7580
Epoch: 37, Loss: 4.2732, Train: 0.9857, Val: 0.7420, Test: 0.7620
Epoch: 38, Loss: 4.2617, Train: 0.9857, Val: 0.7480, Test: 0.7650
Epoch: 39, Loss: 4.0025, Train: 0.9786, Val: 0.7480, Test: 0.7670
Epoch: 40, Loss: 3.9778, Train: 0.9857, Val: 0.7540, Test: 0.7680
Epoch: 41, Loss: 4.2259, Train: 0.9857, Val: 0.7580, Test: 0.7690
Epoch: 42, Loss: 4.2755, Train: 0.9857, Val: 0.7580, Test: 0.7650
Epoch: 43, Loss: 4.2820, Train: 0.9857, Val: 0.7540, Test: 0.7660
Epoch: 44, Loss: 4.3575, Train: 0.9857, Val: 0.7580, Test: 0.7760
Epoch: 45, Loss: 4.2593, Train: 0.9857, Val: 0.7620, Test: 0.7850
Epoch: 46, Loss: 4.1842, Train: 0.9929, Val: 0.7620, Test: 0.7880
Epoch: 47, Loss: 4.2631, Train: 1.0000, Val: 0.7600, Test: 0.7910
Epoch: 48, Loss: 4.1164, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 49, Loss: 4.1953, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 50, Loss: 3.9389, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 51, Loss: 4.1799, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 52, Loss: 4.1687, Train: 1.0000, Val: 0.7640, Test: 0.7950
Epoch: 53, Loss: 4.0767, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 54, Loss: 4.0771, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 55, Loss: 3.8582, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 56, Loss: 4.1402, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 57, Loss: 3.9544, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 58, Loss: 4.2145, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 59, Loss: 3.8068, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 60, Loss: 4.0652, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 61, Loss: 4.1113, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 62, Loss: 3.7752, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 63, Loss: 3.8849, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 64, Loss: 4.2304, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 65, Loss: 3.7627, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 66, Loss: 4.1739, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 67, Loss: 3.8992, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 68, Loss: 3.8971, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 69, Loss: 3.8619, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 70, Loss: 3.8237, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 71, Loss: 3.8403, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 72, Loss: 4.0310, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 73, Loss: 4.0499, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 74, Loss: 3.8198, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 75, Loss: 3.9928, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 76, Loss: 3.2639, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 77, Loss: 4.1272, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 78, Loss: 3.8429, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 79, Loss: 4.0201, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 80, Loss: 3.7960, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 81, Loss: 3.9358, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 82, Loss: 3.7952, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 83, Loss: 3.8860, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 84, Loss: 3.7512, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 85, Loss: 3.8290, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 86, Loss: 3.6397, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 87, Loss: 3.6847, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 88, Loss: 3.7834, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 89, Loss: 3.7790, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 90, Loss: 3.8642, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 91, Loss: 3.7790, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 92, Loss: 3.9700, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 93, Loss: 3.6366, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 94, Loss: 3.9681, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 95, Loss: 3.7843, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 96, Loss: 3.8847, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 97, Loss: 3.7830, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 98, Loss: 4.1873, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 99, Loss: 3.7834, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 100, Loss: 3.5540, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 101, Loss: 3.6968, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 102, Loss: 3.7836, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 103, Loss: 3.9255, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 104, Loss: 3.7158, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 105, Loss: 3.6927, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 106, Loss: 3.7608, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 107, Loss: 3.6822, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 108, Loss: 3.9325, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 109, Loss: 4.1164, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 110, Loss: 3.5255, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 111, Loss: 3.7358, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 112, Loss: 3.8627, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 113, Loss: 3.8654, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 114, Loss: 3.7751, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 115, Loss: 3.8410, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 116, Loss: 3.6563, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 117, Loss: 3.6979, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 118, Loss: 3.8662, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 119, Loss: 4.0101, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 120, Loss: 3.7834, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 121, Loss: 3.7967, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 122, Loss: 3.4471, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 123, Loss: 3.4499, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 124, Loss: 3.8018, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 125, Loss: 3.8464, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 126, Loss: 3.7480, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 127, Loss: 3.6549, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 128, Loss: 3.8430, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 129, Loss: 3.7105, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 130, Loss: 3.5041, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 131, Loss: 3.5057, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 132, Loss: 3.7351, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 133, Loss: 3.7512, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 134, Loss: 3.8440, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 135, Loss: 3.7868, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 136, Loss: 3.7483, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 137, Loss: 3.6093, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 138, Loss: 3.4872, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 139, Loss: 3.5890, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 140, Loss: 3.6080, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 141, Loss: 3.9451, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 142, Loss: 3.3894, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 143, Loss: 3.6871, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 144, Loss: 3.6241, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 145, Loss: 3.5486, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 146, Loss: 3.8007, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 147, Loss: 3.5494, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 148, Loss: 3.7638, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 149, Loss: 3.6647, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 150, Loss: 3.7222, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 151, Loss: 3.7608, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 152, Loss: 3.8697, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 153, Loss: 3.7011, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 154, Loss: 3.3818, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 155, Loss: 3.5517, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 156, Loss: 3.8133, Train: 1.0000, Val: 0.7800, Test: 0.7970
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 157, Loss: 3.6062, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 158, Loss: 3.6166, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 159, Loss: 3.7905, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 160, Loss: 4.0264, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 161, Loss: 3.6522, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 162, Loss: 3.5888, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 163, Loss: 3.4805, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 164, Loss: 3.7771, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 165, Loss: 3.7166, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 166, Loss: 3.7614, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 167, Loss: 3.6229, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 168, Loss: 3.7208, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 169, Loss: 3.9225, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 170, Loss: 3.7066, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 171, Loss: 3.5218, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 172, Loss: 3.7586, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 173, Loss: 3.3320, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 174, Loss: 3.8179, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 175, Loss: 3.6204, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 176, Loss: 3.7412, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 177, Loss: 4.0101, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 178, Loss: 3.6371, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 179, Loss: 3.6472, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 180, Loss: 3.3380, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 181, Loss: 3.8400, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 182, Loss: 3.9837, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 183, Loss: 3.8175, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 184, Loss: 3.6383, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 185, Loss: 3.8878, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 186, Loss: 3.5965, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 187, Loss: 3.4364, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 188, Loss: 3.7698, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 189, Loss: 3.6698, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 190, Loss: 3.7491, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 191, Loss: 3.6673, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 192, Loss: 3.6332, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 193, Loss: 3.3206, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 194, Loss: 3.8230, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 195, Loss: 3.7769, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 196, Loss: 3.8770, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 197, Loss: 3.4348, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 198, Loss: 3.7400, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 199, Loss: 4.0547, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 200, Loss: 3.6106, Train: 1.0000, Val: 0.7780, Test: 0.7970
MAD:  0.1926
Best Test Accuracy: 0.8130, Val Accuracy: 0.7820, Train Accuracy: 1.0000
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9264, Train: 0.0214, Val: 0.0060, Test: 0.0120
Epoch: 2, Loss: 4.8964, Train: 0.0571, Val: 0.0220, Test: 0.0230
Epoch: 3, Loss: 4.8607, Train: 0.1143, Val: 0.0500, Test: 0.0510
Epoch: 4, Loss: 4.8108, Train: 0.2071, Val: 0.0940, Test: 0.0840
Epoch: 5, Loss: 4.7812, Train: 0.3286, Val: 0.1400, Test: 0.1390
Epoch: 6, Loss: 4.6759, Train: 0.3857, Val: 0.1720, Test: 0.1770
Epoch: 7, Loss: 4.7247, Train: 0.4286, Val: 0.2000, Test: 0.2140
Epoch: 8, Loss: 4.7916, Train: 0.4857, Val: 0.2320, Test: 0.2420
Epoch: 9, Loss: 4.6671, Train: 0.5143, Val: 0.2720, Test: 0.2670
Epoch: 10, Loss: 4.6977, Train: 0.5714, Val: 0.3020, Test: 0.3100
Epoch: 11, Loss: 4.6892, Train: 0.6143, Val: 0.3500, Test: 0.3410
Epoch: 12, Loss: 4.7209, Train: 0.6429, Val: 0.3720, Test: 0.3610
Epoch: 13, Loss: 4.6463, Train: 0.7000, Val: 0.4080, Test: 0.3990
Epoch: 14, Loss: 4.5977, Train: 0.7143, Val: 0.4300, Test: 0.4290
Epoch: 15, Loss: 4.5743, Train: 0.7643, Val: 0.4540, Test: 0.4600
Epoch: 16, Loss: 4.4671, Train: 0.7714, Val: 0.4860, Test: 0.4880
Epoch: 17, Loss: 4.4975, Train: 0.8143, Val: 0.5080, Test: 0.5100
Epoch: 18, Loss: 4.4885, Train: 0.8357, Val: 0.5220, Test: 0.5290
Epoch: 19, Loss: 4.4623, Train: 0.8500, Val: 0.5480, Test: 0.5490
Epoch: 20, Loss: 4.5301, Train: 0.8714, Val: 0.5560, Test: 0.5650
Epoch: 21, Loss: 4.4715, Train: 0.9071, Val: 0.5680, Test: 0.5760
Epoch: 22, Loss: 4.5099, Train: 0.9071, Val: 0.5820, Test: 0.5950
Epoch: 23, Loss: 4.5201, Train: 0.9143, Val: 0.5880, Test: 0.6190
Epoch: 24, Loss: 4.4050, Train: 0.9286, Val: 0.6160, Test: 0.6310
Epoch: 25, Loss: 4.4905, Train: 0.9429, Val: 0.6400, Test: 0.6550
Epoch: 26, Loss: 4.4719, Train: 0.9429, Val: 0.6660, Test: 0.6730
Epoch: 27, Loss: 4.5461, Train: 0.9429, Val: 0.6760, Test: 0.6830
Epoch: 28, Loss: 4.5001, Train: 0.9571, Val: 0.6940, Test: 0.6950
Epoch: 29, Loss: 4.3507, Train: 0.9714, Val: 0.7000, Test: 0.7040
Epoch: 30, Loss: 4.4354, Train: 0.9643, Val: 0.7080, Test: 0.7110
Epoch: 31, Loss: 4.2815, Train: 0.9571, Val: 0.7180, Test: 0.7160
Epoch: 32, Loss: 4.4710, Train: 0.9571, Val: 0.7220, Test: 0.7170
Epoch: 33, Loss: 4.4058, Train: 0.9643, Val: 0.7160, Test: 0.7220
Epoch: 34, Loss: 4.4197, Train: 0.9714, Val: 0.7160, Test: 0.7320
Epoch: 35, Loss: 4.3052, Train: 0.9714, Val: 0.7140, Test: 0.7360
Epoch: 36, Loss: 4.4380, Train: 0.9714, Val: 0.7120, Test: 0.7300
Epoch: 37, Loss: 4.5152, Train: 0.9714, Val: 0.7140, Test: 0.7380
Epoch: 38, Loss: 4.3287, Train: 0.9786, Val: 0.7180, Test: 0.7360
Epoch: 39, Loss: 4.2974, Train: 0.9857, Val: 0.7300, Test: 0.7380
Epoch: 40, Loss: 4.2832, Train: 0.9857, Val: 0.7300, Test: 0.7410
Epoch: 41, Loss: 4.0257, Train: 0.9857, Val: 0.7360, Test: 0.7460
Epoch: 42, Loss: 4.2794, Train: 0.9857, Val: 0.7380, Test: 0.7500
Epoch: 43, Loss: 4.2259, Train: 0.9929, Val: 0.7320, Test: 0.7460
Epoch: 44, Loss: 4.0860, Train: 0.9929, Val: 0.7340, Test: 0.7420
Epoch: 45, Loss: 4.2430, Train: 0.9929, Val: 0.7300, Test: 0.7380
Epoch: 46, Loss: 4.2974, Train: 0.9929, Val: 0.7220, Test: 0.7320
Epoch: 47, Loss: 4.1358, Train: 0.9929, Val: 0.7240, Test: 0.7270
Epoch: 48, Loss: 4.2005, Train: 1.0000, Val: 0.7180, Test: 0.7250
Epoch: 49, Loss: 4.5945, Train: 1.0000, Val: 0.7120, Test: 0.7300
Epoch: 50, Loss: 4.0381, Train: 1.0000, Val: 0.7140, Test: 0.7330
Epoch: 51, Loss: 4.1471, Train: 1.0000, Val: 0.7160, Test: 0.7280
Epoch: 52, Loss: 4.0574, Train: 1.0000, Val: 0.7220, Test: 0.7300
Epoch: 53, Loss: 4.3202, Train: 1.0000, Val: 0.7320, Test: 0.7380
Epoch: 54, Loss: 4.2821, Train: 1.0000, Val: 0.7360, Test: 0.7470
Epoch: 55, Loss: 3.9872, Train: 1.0000, Val: 0.7380, Test: 0.7480
Epoch: 56, Loss: 4.0143, Train: 1.0000, Val: 0.7380, Test: 0.7520
Epoch: 57, Loss: 3.7287, Train: 1.0000, Val: 0.7440, Test: 0.7600
Epoch: 58, Loss: 4.1800, Train: 1.0000, Val: 0.7520, Test: 0.7670
Epoch: 59, Loss: 3.8533, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 60, Loss: 4.0382, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 61, Loss: 3.7672, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 62, Loss: 3.9992, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 63, Loss: 3.8327, Train: 1.0000, Val: 0.7640, Test: 0.7900
Epoch: 64, Loss: 4.0238, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 65, Loss: 3.9693, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 66, Loss: 3.8298, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 67, Loss: 4.0293, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 68, Loss: 4.1087, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 69, Loss: 4.0397, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 70, Loss: 4.0307, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 71, Loss: 3.7856, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 72, Loss: 3.7664, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 73, Loss: 3.9467, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 74, Loss: 4.1144, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 75, Loss: 3.7604, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 76, Loss: 3.6437, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 77, Loss: 3.7431, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 78, Loss: 3.8032, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 79, Loss: 3.8769, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 80, Loss: 3.8954, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 81, Loss: 4.2357, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 82, Loss: 4.2742, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 83, Loss: 3.8176, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 84, Loss: 3.8496, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 85, Loss: 3.8951, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 86, Loss: 3.6832, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 87, Loss: 3.8054, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 88, Loss: 3.5394, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 89, Loss: 3.7388, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 90, Loss: 3.8157, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 91, Loss: 3.7296, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 92, Loss: 3.8132, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 93, Loss: 3.8954, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 94, Loss: 3.8248, Train: 1.0000, Val: 0.7880, Test: 0.7960
Epoch: 95, Loss: 3.8243, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 96, Loss: 3.6701, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 97, Loss: 3.9505, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 98, Loss: 3.7569, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 99, Loss: 3.9416, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 100, Loss: 3.7289, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 101, Loss: 4.0211, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 102, Loss: 3.6709, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 103, Loss: 3.8288, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 104, Loss: 3.8019, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 105, Loss: 3.8287, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 106, Loss: 3.8809, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 107, Loss: 3.8326, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 108, Loss: 3.9401, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 109, Loss: 4.0453, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 110, Loss: 3.6357, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 111, Loss: 3.9292, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 112, Loss: 3.8571, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 113, Loss: 3.6120, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 114, Loss: 3.7594, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 115, Loss: 3.9850, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 116, Loss: 3.4966, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 117, Loss: 3.3025, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 118, Loss: 3.6959, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 119, Loss: 3.7977, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 120, Loss: 3.5738, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 121, Loss: 3.7088, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 122, Loss: 3.9533, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 123, Loss: 3.5735, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 124, Loss: 3.9126, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 125, Loss: 3.2764, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 126, Loss: 3.5308, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 127, Loss: 3.7830, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 128, Loss: 3.5448, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 129, Loss: 3.9250, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 130, Loss: 3.6855, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 131, Loss: 3.6472, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 132, Loss: 3.8114, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 133, Loss: 3.8595, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 134, Loss: 3.7650, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 135, Loss: 3.6532, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 136, Loss: 3.6750, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 137, Loss: 3.6515, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 138, Loss: 3.7056, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 139, Loss: 3.7944, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 140, Loss: 3.5969, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 141, Loss: 3.8876, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 142, Loss: 3.7552, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 143, Loss: 3.5850, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 144, Loss: 3.4454, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 145, Loss: 3.9481, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 146, Loss: 3.6179, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 147, Loss: 3.6850, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 148, Loss: 3.7262, Train: 1.0000, Val: 0.7780, Test: 0.7880
Epoch: 149, Loss: 3.5717, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 150, Loss: 3.7705, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 151, Loss: 3.6409, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 152, Loss: 3.3456, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 153, Loss: 3.7176, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 154, Loss: 3.7157, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 155, Loss: 3.6101, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 156, Loss: 3.4425, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 157, Loss: 3.2108, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 158, Loss: 3.8151, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 159, Loss: 3.5393, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 160, Loss: 3.6687, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 161, Loss: 3.4315, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 162, Loss: 3.6029, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 163, Loss: 3.8485, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 164, Loss: 3.8429, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 165, Loss: 3.9152, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 166, Loss: 3.6067, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 167, Loss: 3.7288, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 168, Loss: 3.6378, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 169, Loss: 3.8121, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 170, Loss: 3.4422, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 171, Loss: 3.9498, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 172, Loss: 3.8531, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 173, Loss: 3.3889, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 174, Loss: 3.5020, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 175, Loss: 3.8872, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 176, Loss: 3.2084, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 177, Loss: 3.6057, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 178, Loss: 3.9158, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 179, Loss: 3.7110, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 180, Loss: 3.4977, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 181, Loss: 3.6736, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 182, Loss: 3.4571, Train: 1.0000, Val: 0.7660, Test: 0.7820
Epoch: 183, Loss: 3.5627, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 184, Loss: 3.6008, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 185, Loss: 3.7631, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 186, Loss: 3.7056, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 187, Loss: 3.4415, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 188, Loss: 3.8720, Train: 1.0000, Val: 0.7720, Test: 0.7860
Epoch: 189, Loss: 3.3396, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 190, Loss: 3.5192, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 191, Loss: 3.7473, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 192, Loss: 3.6615, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 193, Loss: 3.6013, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 194, Loss: 3.5611, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 195, Loss: 3.5670, Train: 1.0000, Val: 0.7760, Test: 0.8010
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 196, Loss: 3.4883, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 197, Loss: 3.5646, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 198, Loss: 3.8745, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 199, Loss: 3.5253, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 200, Loss: 3.7346, Train: 1.0000, Val: 0.7800, Test: 0.8010
MAD:  0.4006
Best Test Accuracy: 0.8090, Val Accuracy: 0.7880, Train Accuracy: 1.0000
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8827, Train: 0.1357, Val: 0.0620, Test: 0.0800
Epoch: 2, Loss: 4.8377, Train: 0.2000, Val: 0.0960, Test: 0.1150
Epoch: 3, Loss: 4.7782, Train: 0.2429, Val: 0.1160, Test: 0.1580
Epoch: 4, Loss: 4.7893, Train: 0.3357, Val: 0.1520, Test: 0.1870
Epoch: 5, Loss: 4.7915, Train: 0.3929, Val: 0.1860, Test: 0.2320
Epoch: 6, Loss: 4.7337, Train: 0.4714, Val: 0.2180, Test: 0.2720
Epoch: 7, Loss: 4.6558, Train: 0.5429, Val: 0.2680, Test: 0.3040
Epoch: 8, Loss: 4.6589, Train: 0.5929, Val: 0.3200, Test: 0.3640
Epoch: 9, Loss: 4.7133, Train: 0.6786, Val: 0.3900, Test: 0.3950
Epoch: 10, Loss: 4.5904, Train: 0.7071, Val: 0.4380, Test: 0.4320
Epoch: 11, Loss: 4.7102, Train: 0.7429, Val: 0.4880, Test: 0.4840
Epoch: 12, Loss: 4.5393, Train: 0.7929, Val: 0.5080, Test: 0.5210
Epoch: 13, Loss: 4.5438, Train: 0.8143, Val: 0.5380, Test: 0.5470
Epoch: 14, Loss: 4.2877, Train: 0.8357, Val: 0.5560, Test: 0.5690
Epoch: 15, Loss: 4.5845, Train: 0.8786, Val: 0.5760, Test: 0.5840
Epoch: 16, Loss: 4.4732, Train: 0.8857, Val: 0.5940, Test: 0.6010
Epoch: 17, Loss: 4.5771, Train: 0.8929, Val: 0.5900, Test: 0.6170
Epoch: 18, Loss: 4.5693, Train: 0.9071, Val: 0.5920, Test: 0.6190
Epoch: 19, Loss: 4.4522, Train: 0.9071, Val: 0.5920, Test: 0.6220
Epoch: 20, Loss: 4.4067, Train: 0.9286, Val: 0.6000, Test: 0.6200
Epoch: 21, Loss: 4.5401, Train: 0.9286, Val: 0.6100, Test: 0.6350
Epoch: 22, Loss: 4.5083, Train: 0.9286, Val: 0.6280, Test: 0.6420
Epoch: 23, Loss: 4.4768, Train: 0.9429, Val: 0.6420, Test: 0.6580
Epoch: 24, Loss: 4.3339, Train: 0.9500, Val: 0.6540, Test: 0.6730
Epoch: 25, Loss: 4.4531, Train: 0.9643, Val: 0.6620, Test: 0.6800
Epoch: 26, Loss: 4.5553, Train: 0.9643, Val: 0.6620, Test: 0.6870
Epoch: 27, Loss: 4.4597, Train: 0.9643, Val: 0.6680, Test: 0.6900
Epoch: 28, Loss: 4.5141, Train: 0.9643, Val: 0.6780, Test: 0.6940
Epoch: 29, Loss: 4.5507, Train: 0.9643, Val: 0.6900, Test: 0.7000
Epoch: 30, Loss: 4.4530, Train: 0.9714, Val: 0.6940, Test: 0.7090
Epoch: 31, Loss: 4.3046, Train: 0.9786, Val: 0.7020, Test: 0.7150
Epoch: 32, Loss: 4.5657, Train: 0.9786, Val: 0.7080, Test: 0.7170
Epoch: 33, Loss: 4.3538, Train: 0.9786, Val: 0.7080, Test: 0.7190
Epoch: 34, Loss: 4.4113, Train: 0.9786, Val: 0.7100, Test: 0.7250
Epoch: 35, Loss: 4.3038, Train: 0.9786, Val: 0.7100, Test: 0.7320
Epoch: 36, Loss: 4.3372, Train: 0.9786, Val: 0.7140, Test: 0.7360
Epoch: 37, Loss: 4.2042, Train: 0.9786, Val: 0.7180, Test: 0.7410
Epoch: 38, Loss: 4.1526, Train: 0.9786, Val: 0.7200, Test: 0.7370
Epoch: 39, Loss: 4.2078, Train: 0.9786, Val: 0.7180, Test: 0.7430
Epoch: 40, Loss: 4.2871, Train: 0.9786, Val: 0.7240, Test: 0.7470
Epoch: 41, Loss: 4.1706, Train: 0.9857, Val: 0.7280, Test: 0.7500
Epoch: 42, Loss: 4.2713, Train: 0.9857, Val: 0.7320, Test: 0.7500
Epoch: 43, Loss: 4.4391, Train: 0.9857, Val: 0.7340, Test: 0.7540
Epoch: 44, Loss: 4.3068, Train: 0.9857, Val: 0.7320, Test: 0.7470
Epoch: 45, Loss: 4.0871, Train: 0.9857, Val: 0.7360, Test: 0.7420
Epoch: 46, Loss: 4.1445, Train: 0.9857, Val: 0.7340, Test: 0.7440
Epoch: 47, Loss: 4.2484, Train: 0.9857, Val: 0.7280, Test: 0.7420
Epoch: 48, Loss: 4.4425, Train: 0.9857, Val: 0.7240, Test: 0.7420
Epoch: 49, Loss: 4.3706, Train: 0.9857, Val: 0.7240, Test: 0.7390
Epoch: 50, Loss: 3.9756, Train: 0.9857, Val: 0.7320, Test: 0.7380
Epoch: 51, Loss: 4.4050, Train: 0.9857, Val: 0.7340, Test: 0.7460
Epoch: 52, Loss: 4.2118, Train: 0.9857, Val: 0.7380, Test: 0.7510
Epoch: 53, Loss: 3.9371, Train: 0.9857, Val: 0.7420, Test: 0.7530
Epoch: 54, Loss: 3.9033, Train: 0.9857, Val: 0.7480, Test: 0.7580
Epoch: 55, Loss: 4.0627, Train: 0.9857, Val: 0.7480, Test: 0.7600
Epoch: 56, Loss: 4.1000, Train: 0.9857, Val: 0.7480, Test: 0.7610
Epoch: 57, Loss: 3.9512, Train: 0.9857, Val: 0.7500, Test: 0.7660
Epoch: 58, Loss: 3.9963, Train: 0.9929, Val: 0.7520, Test: 0.7660
Epoch: 59, Loss: 3.7736, Train: 0.9929, Val: 0.7500, Test: 0.7680
Epoch: 60, Loss: 3.6543, Train: 0.9929, Val: 0.7480, Test: 0.7690
Epoch: 61, Loss: 4.0616, Train: 0.9929, Val: 0.7500, Test: 0.7690
Epoch: 62, Loss: 3.8036, Train: 0.9929, Val: 0.7600, Test: 0.7720
Epoch: 63, Loss: 3.9910, Train: 0.9929, Val: 0.7600, Test: 0.7720
Epoch: 64, Loss: 3.9852, Train: 0.9929, Val: 0.7620, Test: 0.7770
Epoch: 65, Loss: 3.8720, Train: 0.9929, Val: 0.7620, Test: 0.7760
Epoch: 66, Loss: 3.7271, Train: 0.9929, Val: 0.7600, Test: 0.7790
Epoch: 67, Loss: 3.8285, Train: 0.9929, Val: 0.7600, Test: 0.7830
Epoch: 68, Loss: 4.0771, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 69, Loss: 3.8249, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 70, Loss: 3.9416, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 71, Loss: 3.9447, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 72, Loss: 3.5743, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 73, Loss: 3.8925, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 74, Loss: 3.6253, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 75, Loss: 3.6963, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 76, Loss: 3.7032, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 77, Loss: 4.0014, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 78, Loss: 3.9963, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 79, Loss: 4.0010, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 80, Loss: 3.9836, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 81, Loss: 3.9192, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 82, Loss: 3.7367, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 83, Loss: 3.8584, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 84, Loss: 3.9959, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 85, Loss: 3.5424, Train: 1.0000, Val: 0.7880, Test: 0.7960
Epoch: 86, Loss: 3.7724, Train: 1.0000, Val: 0.7880, Test: 0.7950
Epoch: 87, Loss: 3.9005, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 88, Loss: 3.6934, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 89, Loss: 3.9728, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 90, Loss: 4.0262, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 91, Loss: 4.0508, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 92, Loss: 3.5070, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 93, Loss: 4.0221, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 94, Loss: 3.9420, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 95, Loss: 3.7850, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 96, Loss: 3.8218, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 97, Loss: 3.5763, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 98, Loss: 4.0521, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 99, Loss: 3.6690, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 100, Loss: 3.8669, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 101, Loss: 3.6964, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 102, Loss: 3.4736, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 103, Loss: 3.7281, Train: 1.0000, Val: 0.7880, Test: 0.8050
Epoch: 104, Loss: 3.7138, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 105, Loss: 4.0329, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 106, Loss: 3.8439, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 107, Loss: 3.8704, Train: 1.0000, Val: 0.7860, Test: 0.7910
Epoch: 108, Loss: 3.7559, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 109, Loss: 4.1337, Train: 1.0000, Val: 0.7840, Test: 0.7910
Epoch: 110, Loss: 3.9156, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 111, Loss: 3.4434, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 112, Loss: 3.7571, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 113, Loss: 3.8246, Train: 1.0000, Val: 0.7880, Test: 0.7990
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 114, Loss: 3.5570, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 115, Loss: 4.1538, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 116, Loss: 4.0076, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 117, Loss: 3.8792, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 118, Loss: 3.8945, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 119, Loss: 3.7446, Train: 1.0000, Val: 0.7940, Test: 0.8000
Epoch: 120, Loss: 3.8483, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 121, Loss: 3.6507, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 122, Loss: 3.3990, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 123, Loss: 3.7378, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 124, Loss: 3.5717, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 125, Loss: 3.7915, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 126, Loss: 3.2210, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 127, Loss: 3.6738, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 128, Loss: 3.7834, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 129, Loss: 3.7002, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 130, Loss: 3.6088, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 131, Loss: 3.9244, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 132, Loss: 3.5755, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 133, Loss: 3.6698, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 134, Loss: 3.4362, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 135, Loss: 3.9763, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 136, Loss: 3.7392, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 137, Loss: 3.8018, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 138, Loss: 3.8279, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 139, Loss: 3.6836, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 140, Loss: 3.3221, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 141, Loss: 3.5570, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 142, Loss: 3.7232, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 143, Loss: 3.6385, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 144, Loss: 3.7356, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 145, Loss: 3.9615, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 146, Loss: 3.5993, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 147, Loss: 3.4739, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 148, Loss: 3.8613, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 149, Loss: 3.9693, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 150, Loss: 3.6492, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 151, Loss: 3.6228, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 152, Loss: 3.7511, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 153, Loss: 3.5466, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 154, Loss: 3.5370, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 155, Loss: 3.6087, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 156, Loss: 3.7100, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 157, Loss: 3.7539, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 158, Loss: 3.5771, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 159, Loss: 3.5239, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 160, Loss: 3.7058, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 161, Loss: 3.5785, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 162, Loss: 3.8235, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 163, Loss: 3.6836, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 164, Loss: 3.3997, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 165, Loss: 3.5776, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 166, Loss: 3.4684, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 167, Loss: 3.7183, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 168, Loss: 3.8499, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 169, Loss: 3.8466, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 170, Loss: 3.7901, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 171, Loss: 3.9520, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 172, Loss: 3.5006, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 173, Loss: 3.7171, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 174, Loss: 3.5047, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 175, Loss: 3.7376, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 176, Loss: 3.5361, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 177, Loss: 3.6407, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 178, Loss: 3.2918, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 179, Loss: 3.6418, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 180, Loss: 3.5985, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 181, Loss: 3.8817, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 182, Loss: 3.9779, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 183, Loss: 3.8410, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 184, Loss: 3.8056, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 185, Loss: 3.4988, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 186, Loss: 3.7734, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 187, Loss: 3.4163, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 188, Loss: 3.5414, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 189, Loss: 3.8430, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 190, Loss: 3.7209, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 191, Loss: 3.8742, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 192, Loss: 3.5639, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 193, Loss: 3.6773, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 194, Loss: 3.5982, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 195, Loss: 3.6979, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 196, Loss: 3.8080, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 197, Loss: 3.6369, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 198, Loss: 3.7753, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 199, Loss: 3.9698, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 200, Loss: 3.6975, Train: 1.0000, Val: 0.7740, Test: 0.7940
MAD:  0.3433
Best Test Accuracy: 0.8080, Val Accuracy: 0.7760, Train Accuracy: 1.0000
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8965, Train: 0.0500, Val: 0.0060, Test: 0.0240
Epoch: 2, Loss: 4.9084, Train: 0.1286, Val: 0.0380, Test: 0.0740
Epoch: 3, Loss: 4.8742, Train: 0.1786, Val: 0.1040, Test: 0.1200
Epoch: 4, Loss: 4.8638, Train: 0.2214, Val: 0.1340, Test: 0.1700
Epoch: 5, Loss: 4.8248, Train: 0.3000, Val: 0.1720, Test: 0.2030
Epoch: 6, Loss: 4.8120, Train: 0.3286, Val: 0.2040, Test: 0.2370
Epoch: 7, Loss: 4.7051, Train: 0.3643, Val: 0.2260, Test: 0.2610
Epoch: 8, Loss: 4.7467, Train: 0.4000, Val: 0.2420, Test: 0.2930
Epoch: 9, Loss: 4.7030, Train: 0.4429, Val: 0.2800, Test: 0.3250
Epoch: 10, Loss: 4.7239, Train: 0.4714, Val: 0.3060, Test: 0.3600
Epoch: 11, Loss: 4.6314, Train: 0.5500, Val: 0.3400, Test: 0.3980
Epoch: 12, Loss: 4.7776, Train: 0.6071, Val: 0.3700, Test: 0.4380
Epoch: 13, Loss: 4.6237, Train: 0.6286, Val: 0.3940, Test: 0.4720
Epoch: 14, Loss: 4.6738, Train: 0.6643, Val: 0.4380, Test: 0.5070
Epoch: 15, Loss: 4.5694, Train: 0.7429, Val: 0.4640, Test: 0.5360
Epoch: 16, Loss: 4.5280, Train: 0.7429, Val: 0.4920, Test: 0.5610
Epoch: 17, Loss: 4.6341, Train: 0.7857, Val: 0.5120, Test: 0.5830
Epoch: 18, Loss: 4.6104, Train: 0.7929, Val: 0.5320, Test: 0.6070
Epoch: 19, Loss: 4.6462, Train: 0.8143, Val: 0.5460, Test: 0.6230
Epoch: 20, Loss: 4.4649, Train: 0.8500, Val: 0.5580, Test: 0.6360
Epoch: 21, Loss: 4.3951, Train: 0.8643, Val: 0.5700, Test: 0.6440
Epoch: 22, Loss: 4.4558, Train: 0.8857, Val: 0.5880, Test: 0.6570
Epoch: 23, Loss: 4.3098, Train: 0.8929, Val: 0.5880, Test: 0.6580
Epoch: 24, Loss: 4.5443, Train: 0.9000, Val: 0.5900, Test: 0.6550
Epoch: 25, Loss: 4.4752, Train: 0.9000, Val: 0.5960, Test: 0.6610
Epoch: 26, Loss: 4.4318, Train: 0.9071, Val: 0.5960, Test: 0.6620
Epoch: 27, Loss: 4.3436, Train: 0.9143, Val: 0.6080, Test: 0.6640
Epoch: 28, Loss: 4.4455, Train: 0.9143, Val: 0.6080, Test: 0.6700
Epoch: 29, Loss: 4.4753, Train: 0.9286, Val: 0.6060, Test: 0.6690
Epoch: 30, Loss: 4.2260, Train: 0.9357, Val: 0.6140, Test: 0.6720
Epoch: 31, Loss: 4.3264, Train: 0.9429, Val: 0.6140, Test: 0.6690
Epoch: 32, Loss: 4.2932, Train: 0.9429, Val: 0.6160, Test: 0.6720
Epoch: 33, Loss: 4.3204, Train: 0.9500, Val: 0.6240, Test: 0.6820
Epoch: 34, Loss: 4.2677, Train: 0.9643, Val: 0.6360, Test: 0.6910
Epoch: 35, Loss: 4.3930, Train: 0.9714, Val: 0.6460, Test: 0.7000
Epoch: 36, Loss: 4.2100, Train: 0.9714, Val: 0.6480, Test: 0.7130
Epoch: 37, Loss: 4.1326, Train: 0.9786, Val: 0.6560, Test: 0.7170
Epoch: 38, Loss: 4.2207, Train: 0.9786, Val: 0.6700, Test: 0.7270
Epoch: 39, Loss: 4.4066, Train: 0.9786, Val: 0.6780, Test: 0.7360
Epoch: 40, Loss: 4.2687, Train: 0.9857, Val: 0.6860, Test: 0.7360
Epoch: 41, Loss: 4.0869, Train: 0.9857, Val: 0.6900, Test: 0.7410
Epoch: 42, Loss: 4.2213, Train: 0.9857, Val: 0.6960, Test: 0.7480
Epoch: 43, Loss: 4.1755, Train: 0.9857, Val: 0.7000, Test: 0.7500
Epoch: 44, Loss: 4.1333, Train: 0.9857, Val: 0.7080, Test: 0.7580
Epoch: 45, Loss: 4.1902, Train: 0.9929, Val: 0.7160, Test: 0.7560
Epoch: 46, Loss: 4.0952, Train: 0.9929, Val: 0.7180, Test: 0.7650
Epoch: 47, Loss: 4.1749, Train: 0.9929, Val: 0.7240, Test: 0.7680
Epoch: 48, Loss: 4.2383, Train: 0.9929, Val: 0.7260, Test: 0.7730
Epoch: 49, Loss: 3.9349, Train: 0.9929, Val: 0.7280, Test: 0.7800
Epoch: 50, Loss: 4.0973, Train: 0.9929, Val: 0.7240, Test: 0.7800
Epoch: 51, Loss: 4.1207, Train: 0.9929, Val: 0.7280, Test: 0.7820
Epoch: 52, Loss: 4.1364, Train: 1.0000, Val: 0.7400, Test: 0.7870
Epoch: 53, Loss: 4.0892, Train: 1.0000, Val: 0.7480, Test: 0.7890
Epoch: 54, Loss: 4.1531, Train: 1.0000, Val: 0.7440, Test: 0.7850
Epoch: 55, Loss: 4.1356, Train: 1.0000, Val: 0.7460, Test: 0.7840
Epoch: 56, Loss: 4.0749, Train: 1.0000, Val: 0.7440, Test: 0.7850
Epoch: 57, Loss: 4.1254, Train: 1.0000, Val: 0.7500, Test: 0.7840
Epoch: 58, Loss: 3.8483, Train: 1.0000, Val: 0.7520, Test: 0.7820
Epoch: 59, Loss: 3.9419, Train: 0.9929, Val: 0.7520, Test: 0.7820
Epoch: 60, Loss: 3.9291, Train: 1.0000, Val: 0.7540, Test: 0.7830
Epoch: 61, Loss: 4.0505, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 62, Loss: 4.2166, Train: 1.0000, Val: 0.7580, Test: 0.7770
Epoch: 63, Loss: 4.1768, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 64, Loss: 3.9990, Train: 1.0000, Val: 0.7600, Test: 0.7910
Epoch: 65, Loss: 4.0173, Train: 1.0000, Val: 0.7600, Test: 0.7900
Epoch: 66, Loss: 4.0747, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 67, Loss: 4.0016, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 68, Loss: 3.8546, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 69, Loss: 3.9745, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 70, Loss: 3.7930, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 71, Loss: 4.1153, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 72, Loss: 4.0033, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 73, Loss: 3.6693, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 74, Loss: 3.8092, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 75, Loss: 3.6933, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 76, Loss: 3.9811, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 77, Loss: 3.9366, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 78, Loss: 4.0173, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 79, Loss: 3.6844, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 80, Loss: 3.8776, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 81, Loss: 3.9933, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 82, Loss: 3.9534, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 83, Loss: 4.1688, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 84, Loss: 3.8594, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 85, Loss: 4.0003, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 86, Loss: 3.5901, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 87, Loss: 3.9848, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 88, Loss: 4.2314, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 89, Loss: 3.6950, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 90, Loss: 3.8111, Train: 0.9929, Val: 0.7700, Test: 0.8010
Epoch: 91, Loss: 3.6916, Train: 0.9929, Val: 0.7780, Test: 0.8000
Epoch: 92, Loss: 3.7275, Train: 0.9929, Val: 0.7760, Test: 0.7980
Epoch: 93, Loss: 4.0467, Train: 0.9929, Val: 0.7700, Test: 0.7990
Epoch: 94, Loss: 3.3630, Train: 0.9929, Val: 0.7700, Test: 0.7990
Epoch: 95, Loss: 3.8047, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 96, Loss: 3.9426, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 97, Loss: 3.9301, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 98, Loss: 3.8947, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 99, Loss: 3.9758, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 100, Loss: 3.6013, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 101, Loss: 3.7678, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 102, Loss: 3.6371, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 103, Loss: 3.8043, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 104, Loss: 3.7897, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 105, Loss: 3.7628, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 106, Loss: 3.7422, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 107, Loss: 3.6748, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 108, Loss: 3.6515, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 109, Loss: 4.0889, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 110, Loss: 3.9858, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 111, Loss: 3.8698, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 112, Loss: 3.5730, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 113, Loss: 3.6850, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 114, Loss: 3.7811, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 115, Loss: 3.9427, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 116, Loss: 3.4500, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 117, Loss: 3.9540, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 118, Loss: 3.9277, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 119, Loss: 3.6165, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 120, Loss: 3.7007, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 121, Loss: 3.7168, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 122, Loss: 3.7665, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 123, Loss: 3.8525, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 124, Loss: 3.6997, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 125, Loss: 3.5014, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 126, Loss: 3.6658, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 127, Loss: 3.5684, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 128, Loss: 4.0178, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 129, Loss: 3.9368, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 130, Loss: 3.6522, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 131, Loss: 3.4379, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 132, Loss: 3.6723, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 133, Loss: 3.7392, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 134, Loss: 4.3320, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 135, Loss: 3.5323, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 136, Loss: 3.6336, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 137, Loss: 3.6029, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 138, Loss: 3.7685, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 139, Loss: 3.5643, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 140, Loss: 3.7247, Train: 1.0000, Val: 0.7860, Test: 0.7940
Epoch: 141, Loss: 3.7812, Train: 1.0000, Val: 0.7880, Test: 0.7950
Epoch: 142, Loss: 3.8521, Train: 1.0000, Val: 0.7880, Test: 0.7950
Epoch: 143, Loss: 3.4961, Train: 1.0000, Val: 0.7900, Test: 0.7970
Epoch: 144, Loss: 3.6820, Train: 1.0000, Val: 0.7900, Test: 0.7960
Epoch: 145, Loss: 3.4252, Train: 1.0000, Val: 0.7920, Test: 0.7970
Epoch: 146, Loss: 3.7025, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 147, Loss: 3.6537, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 148, Loss: 3.4678, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 149, Loss: 3.7029, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 150, Loss: 3.5013, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 151, Loss: 3.7932, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 152, Loss: 3.8554, Train: 1.0000, Val: 0.7920, Test: 0.7990
Epoch: 153, Loss: 3.5561, Train: 1.0000, Val: 0.7920, Test: 0.8000
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 3.6159, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 155, Loss: 3.7930, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 156, Loss: 3.7977, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 157, Loss: 3.4195, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 158, Loss: 3.4439, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 159, Loss: 3.7311, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 160, Loss: 3.9761, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 161, Loss: 3.8228, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 162, Loss: 3.4365, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 163, Loss: 3.5966, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 164, Loss: 3.6402, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 165, Loss: 3.7177, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 166, Loss: 3.5232, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 167, Loss: 3.6764, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 168, Loss: 3.7526, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 169, Loss: 3.7821, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 170, Loss: 3.5720, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 171, Loss: 3.8968, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 172, Loss: 3.6046, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 173, Loss: 3.4296, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 174, Loss: 3.8806, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 175, Loss: 3.6696, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 176, Loss: 3.8091, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 177, Loss: 3.6409, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 178, Loss: 3.4708, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 179, Loss: 4.0103, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 180, Loss: 3.4954, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 181, Loss: 3.8835, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 182, Loss: 3.9866, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 183, Loss: 3.8168, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 184, Loss: 3.6663, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 185, Loss: 3.9138, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 186, Loss: 3.8424, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 187, Loss: 3.8583, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 188, Loss: 3.9033, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 189, Loss: 3.8800, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 190, Loss: 3.7784, Train: 1.0000, Val: 0.7800, Test: 0.7890
Epoch: 191, Loss: 3.7404, Train: 1.0000, Val: 0.7840, Test: 0.7910
Epoch: 192, Loss: 3.4649, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 193, Loss: 3.3707, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 194, Loss: 3.3811, Train: 1.0000, Val: 0.7840, Test: 0.7910
Epoch: 195, Loss: 3.6781, Train: 1.0000, Val: 0.7860, Test: 0.7890
Epoch: 196, Loss: 3.1900, Train: 1.0000, Val: 0.7840, Test: 0.7900
Epoch: 197, Loss: 3.5613, Train: 1.0000, Val: 0.7840, Test: 0.7910
Epoch: 198, Loss: 3.6983, Train: 1.0000, Val: 0.7840, Test: 0.7920
Epoch: 199, Loss: 3.8074, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 200, Loss: 3.5743, Train: 1.0000, Val: 0.7820, Test: 0.7920
MAD:  0.4903
Best Test Accuracy: 0.8050, Val Accuracy: 0.7900, Train Accuracy: 1.0000
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9043, Train: 0.0429, Val: 0.0280, Test: 0.0350
Epoch: 2, Loss: 4.8550, Train: 0.1071, Val: 0.0860, Test: 0.0810
Epoch: 3, Loss: 4.7876, Train: 0.2286, Val: 0.1440, Test: 0.1690
Epoch: 4, Loss: 4.7830, Train: 0.3357, Val: 0.2060, Test: 0.2320
Epoch: 5, Loss: 4.8229, Train: 0.4143, Val: 0.2680, Test: 0.2780
Epoch: 6, Loss: 4.8407, Train: 0.5000, Val: 0.2880, Test: 0.3280
Epoch: 7, Loss: 4.6998, Train: 0.5214, Val: 0.3120, Test: 0.3500
Epoch: 8, Loss: 4.7644, Train: 0.5643, Val: 0.3480, Test: 0.3770
Epoch: 9, Loss: 4.5625, Train: 0.6143, Val: 0.3720, Test: 0.4110
Epoch: 10, Loss: 4.7488, Train: 0.6429, Val: 0.4080, Test: 0.4480
Epoch: 11, Loss: 4.7359, Train: 0.6714, Val: 0.4360, Test: 0.4720
Epoch: 12, Loss: 4.6937, Train: 0.7214, Val: 0.4540, Test: 0.5000
Epoch: 13, Loss: 4.6864, Train: 0.7643, Val: 0.4800, Test: 0.5160
Epoch: 14, Loss: 4.8121, Train: 0.7786, Val: 0.5080, Test: 0.5290
Epoch: 15, Loss: 4.6096, Train: 0.7929, Val: 0.5380, Test: 0.5540
Epoch: 16, Loss: 4.7163, Train: 0.8071, Val: 0.5560, Test: 0.5660
Epoch: 17, Loss: 4.6854, Train: 0.8571, Val: 0.5820, Test: 0.5860
Epoch: 18, Loss: 4.4989, Train: 0.8786, Val: 0.5980, Test: 0.5970
Epoch: 19, Loss: 4.5899, Train: 0.8929, Val: 0.5960, Test: 0.6130
Epoch: 20, Loss: 4.4401, Train: 0.9000, Val: 0.6160, Test: 0.6270
Epoch: 21, Loss: 4.5895, Train: 0.9000, Val: 0.6220, Test: 0.6410
Epoch: 22, Loss: 4.6394, Train: 0.9071, Val: 0.6200, Test: 0.6580
Epoch: 23, Loss: 4.5161, Train: 0.9143, Val: 0.6260, Test: 0.6620
Epoch: 24, Loss: 4.4856, Train: 0.9286, Val: 0.6320, Test: 0.6650
Epoch: 25, Loss: 4.5424, Train: 0.9357, Val: 0.6380, Test: 0.6660
Epoch: 26, Loss: 4.4922, Train: 0.9286, Val: 0.6340, Test: 0.6630
Epoch: 27, Loss: 4.5915, Train: 0.9286, Val: 0.6420, Test: 0.6630
Epoch: 28, Loss: 4.3771, Train: 0.9500, Val: 0.6460, Test: 0.6680
Epoch: 29, Loss: 4.4548, Train: 0.9571, Val: 0.6520, Test: 0.6770
Epoch: 30, Loss: 4.4208, Train: 0.9643, Val: 0.6620, Test: 0.6730
Epoch: 31, Loss: 4.4140, Train: 0.9643, Val: 0.6660, Test: 0.6750
Epoch: 32, Loss: 4.2949, Train: 0.9643, Val: 0.6700, Test: 0.6770
Epoch: 33, Loss: 4.3276, Train: 0.9786, Val: 0.6740, Test: 0.6770
Epoch: 34, Loss: 4.2563, Train: 0.9786, Val: 0.6900, Test: 0.6900
Epoch: 35, Loss: 4.4483, Train: 0.9857, Val: 0.6920, Test: 0.6950
Epoch: 36, Loss: 4.3950, Train: 0.9857, Val: 0.6980, Test: 0.7050
Epoch: 37, Loss: 4.4849, Train: 0.9857, Val: 0.7060, Test: 0.7170
Epoch: 38, Loss: 4.4597, Train: 0.9929, Val: 0.7160, Test: 0.7300
Epoch: 39, Loss: 4.3541, Train: 0.9929, Val: 0.7240, Test: 0.7380
Epoch: 40, Loss: 4.3361, Train: 0.9929, Val: 0.7280, Test: 0.7480
Epoch: 41, Loss: 4.4634, Train: 0.9929, Val: 0.7300, Test: 0.7510
Epoch: 42, Loss: 4.2240, Train: 0.9929, Val: 0.7320, Test: 0.7530
Epoch: 43, Loss: 4.3272, Train: 0.9929, Val: 0.7280, Test: 0.7570
Epoch: 44, Loss: 4.2836, Train: 0.9929, Val: 0.7280, Test: 0.7530
Epoch: 45, Loss: 4.2209, Train: 0.9929, Val: 0.7240, Test: 0.7510
Epoch: 46, Loss: 4.1489, Train: 0.9929, Val: 0.7240, Test: 0.7520
Epoch: 47, Loss: 4.1311, Train: 0.9929, Val: 0.7260, Test: 0.7540
Epoch: 48, Loss: 4.3548, Train: 0.9929, Val: 0.7240, Test: 0.7550
Epoch: 49, Loss: 4.2332, Train: 0.9929, Val: 0.7260, Test: 0.7610
Epoch: 50, Loss: 4.2459, Train: 0.9929, Val: 0.7280, Test: 0.7630
Epoch: 51, Loss: 4.2059, Train: 0.9929, Val: 0.7240, Test: 0.7660
Epoch: 52, Loss: 3.8990, Train: 0.9929, Val: 0.7280, Test: 0.7690
Epoch: 53, Loss: 4.4179, Train: 0.9929, Val: 0.7360, Test: 0.7740
Epoch: 54, Loss: 4.4033, Train: 0.9929, Val: 0.7440, Test: 0.7760
Epoch: 55, Loss: 4.0870, Train: 0.9929, Val: 0.7440, Test: 0.7690
Epoch: 56, Loss: 4.0728, Train: 0.9929, Val: 0.7480, Test: 0.7700
Epoch: 57, Loss: 4.1373, Train: 0.9929, Val: 0.7500, Test: 0.7730
Epoch: 58, Loss: 4.1993, Train: 0.9929, Val: 0.7600, Test: 0.7780
Epoch: 59, Loss: 4.1492, Train: 0.9929, Val: 0.7640, Test: 0.7800
Epoch: 60, Loss: 4.1088, Train: 0.9929, Val: 0.7660, Test: 0.7830
Epoch: 61, Loss: 3.9381, Train: 0.9929, Val: 0.7680, Test: 0.7870
Epoch: 62, Loss: 4.0517, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 63, Loss: 3.9384, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 64, Loss: 4.1683, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 65, Loss: 3.8791, Train: 1.0000, Val: 0.7660, Test: 0.8060
Epoch: 66, Loss: 3.9060, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 67, Loss: 4.2029, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 68, Loss: 3.9356, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 69, Loss: 4.0063, Train: 1.0000, Val: 0.7620, Test: 0.8000
Epoch: 70, Loss: 4.1065, Train: 1.0000, Val: 0.7620, Test: 0.8030
Epoch: 71, Loss: 4.0514, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 72, Loss: 4.0621, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 73, Loss: 3.9965, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 74, Loss: 3.8946, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 75, Loss: 3.9266, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 76, Loss: 3.8073, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 77, Loss: 4.1152, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 78, Loss: 3.8651, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 79, Loss: 3.8126, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 80, Loss: 3.9939, Train: 1.0000, Val: 0.7580, Test: 0.7890
Epoch: 81, Loss: 4.2522, Train: 1.0000, Val: 0.7580, Test: 0.7900
Epoch: 82, Loss: 3.9417, Train: 1.0000, Val: 0.7580, Test: 0.7920
Epoch: 83, Loss: 3.8549, Train: 1.0000, Val: 0.7560, Test: 0.7920
Epoch: 84, Loss: 3.8843, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 85, Loss: 3.8586, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 86, Loss: 3.6835, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 87, Loss: 3.8757, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 88, Loss: 3.6956, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 89, Loss: 3.9410, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 90, Loss: 3.6934, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 91, Loss: 4.0039, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 92, Loss: 3.5571, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 93, Loss: 3.9895, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 94, Loss: 3.9767, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 95, Loss: 4.0418, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 96, Loss: 3.6942, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 97, Loss: 3.6338, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 98, Loss: 3.9215, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 99, Loss: 3.8327, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 100, Loss: 3.8328, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 101, Loss: 3.8086, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 102, Loss: 3.7162, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 103, Loss: 3.9233, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 104, Loss: 3.8903, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 105, Loss: 3.6647, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 106, Loss: 3.7881, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 107, Loss: 3.7274, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 108, Loss: 3.7743, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 109, Loss: 3.4867, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 110, Loss: 4.1681, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 111, Loss: 3.7121, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 112, Loss: 3.7846, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 113, Loss: 4.0380, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 114, Loss: 3.7656, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 115, Loss: 3.7192, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 116, Loss: 3.8109, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 117, Loss: 3.6415, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 118, Loss: 3.5594, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 119, Loss: 3.5143, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 120, Loss: 3.6414, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 121, Loss: 3.7266, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 122, Loss: 3.5550, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 123, Loss: 3.6745, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 124, Loss: 3.6142, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 125, Loss: 3.4607, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 126, Loss: 3.7561, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 127, Loss: 3.5278, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 128, Loss: 3.7814, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 129, Loss: 3.4966, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 130, Loss: 3.9311, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 131, Loss: 3.6548, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 132, Loss: 3.4870, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 133, Loss: 3.4577, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 134, Loss: 3.6587, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 135, Loss: 3.7400, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 136, Loss: 3.2376, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 137, Loss: 3.7488, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 138, Loss: 3.4667, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 139, Loss: 3.8456, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 140, Loss: 3.7505, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 141, Loss: 3.7550, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 142, Loss: 3.9685, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 143, Loss: 3.7986, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 144, Loss: 3.7411, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 145, Loss: 3.6889, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 146, Loss: 3.6330, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 147, Loss: 3.9987, Train: 1.0000, Val: 0.7620, Test: 0.7990
Epoch: 148, Loss: 3.9654, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 149, Loss: 3.6286, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 150, Loss: 3.6080, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 151, Loss: 3.7676, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 152, Loss: 3.9591, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 153, Loss: 3.4809, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 154, Loss: 3.5529, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 155, Loss: 3.6420, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 156, Loss: 3.8212, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 157, Loss: 3.7249, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 158, Loss: 3.5863, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 159, Loss: 3.6178, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 160, Loss: 3.8962, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 161, Loss: 3.6196, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 162, Loss: 3.7469, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 163, Loss: 3.9366, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 164, Loss: 3.7118, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 165, Loss: 3.6585, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 166, Loss: 3.6514, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 167, Loss: 3.7265, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 168, Loss: 3.7537, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 169, Loss: 3.6748, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 170, Loss: 3.7838, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 171, Loss: 3.4740, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 172, Loss: 3.6806, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 173, Loss: 3.7082, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 174, Loss: 3.3277, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 175, Loss: 3.5659, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 176, Loss: 3.5809, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 177, Loss: 3.6416, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 178, Loss: 3.4236, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 179, Loss: 3.4410, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 180, Loss: 3.4726, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 181, Loss: 3.8829, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 182, Loss: 3.6272, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 183, Loss: 3.4911, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 184, Loss: 3.3966, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 185, Loss: 3.6113, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 186, Loss: 3.6363, Train: 1.0000, Val: 0.7600, Test: 0.8000
Epoch: 187, Loss: 3.9543, Train: 1.0000, Val: 0.7600, Test: 0.7970
Epoch: 188, Loss: 3.5024, Train: 1.0000, Val: 0.7620, Test: 0.7980
Epoch: 189, Loss: 3.6737, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 190, Loss: 3.2923, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 191, Loss: 3.7324, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 192, Loss: 3.8855, Train: 1.0000, Val: 0.7660, Test: 0.7980
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 3.4979, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 194, Loss: 3.4952, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 195, Loss: 3.7986, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 196, Loss: 3.5994, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 197, Loss: 3.8039, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 198, Loss: 3.6055, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 199, Loss: 3.2910, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 200, Loss: 3.3530, Train: 1.0000, Val: 0.7760, Test: 0.8060
MAD:  0.4475
Best Test Accuracy: 0.8120, Val Accuracy: 0.7720, Train Accuracy: 1.0000
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9350, Train: 0.0571, Val: 0.0260, Test: 0.0380
Epoch: 2, Loss: 4.8569, Train: 0.1357, Val: 0.0600, Test: 0.0930
Epoch: 3, Loss: 4.8615, Train: 0.1857, Val: 0.1060, Test: 0.1350
Epoch: 4, Loss: 4.8604, Train: 0.2714, Val: 0.1560, Test: 0.1690
Epoch: 5, Loss: 4.7686, Train: 0.3214, Val: 0.2080, Test: 0.2090
Epoch: 6, Loss: 4.7707, Train: 0.3571, Val: 0.2480, Test: 0.2360
Epoch: 7, Loss: 4.7292, Train: 0.3857, Val: 0.2820, Test: 0.2600
Epoch: 8, Loss: 4.6715, Train: 0.4500, Val: 0.3060, Test: 0.2850
Epoch: 9, Loss: 4.7206, Train: 0.4929, Val: 0.3320, Test: 0.2980
Epoch: 10, Loss: 4.5939, Train: 0.5071, Val: 0.3420, Test: 0.3080
Epoch: 11, Loss: 4.5365, Train: 0.5357, Val: 0.3460, Test: 0.3190
Epoch: 12, Loss: 4.6193, Train: 0.5643, Val: 0.3360, Test: 0.3290
Epoch: 13, Loss: 4.6949, Train: 0.6071, Val: 0.3420, Test: 0.3370
Epoch: 14, Loss: 4.5355, Train: 0.6571, Val: 0.3720, Test: 0.3700
Epoch: 15, Loss: 4.5432, Train: 0.6929, Val: 0.4240, Test: 0.4210
Epoch: 16, Loss: 4.5918, Train: 0.7286, Val: 0.4680, Test: 0.4690
Epoch: 17, Loss: 4.6835, Train: 0.7857, Val: 0.5320, Test: 0.5370
Epoch: 18, Loss: 4.5779, Train: 0.8286, Val: 0.5760, Test: 0.5860
Epoch: 19, Loss: 4.5633, Train: 0.8500, Val: 0.6100, Test: 0.6090
Epoch: 20, Loss: 4.5297, Train: 0.8714, Val: 0.6240, Test: 0.6280
Epoch: 21, Loss: 4.5392, Train: 0.8857, Val: 0.6400, Test: 0.6400
Epoch: 22, Loss: 4.4422, Train: 0.8929, Val: 0.6540, Test: 0.6600
Epoch: 23, Loss: 4.3923, Train: 0.9143, Val: 0.6700, Test: 0.6720
Epoch: 24, Loss: 4.4928, Train: 0.9286, Val: 0.6740, Test: 0.6790
Epoch: 25, Loss: 4.5603, Train: 0.9214, Val: 0.6820, Test: 0.6860
Epoch: 26, Loss: 4.2357, Train: 0.9357, Val: 0.6880, Test: 0.6920
Epoch: 27, Loss: 4.4198, Train: 0.9429, Val: 0.6900, Test: 0.6990
Epoch: 28, Loss: 4.2392, Train: 0.9714, Val: 0.6960, Test: 0.6990
Epoch: 29, Loss: 4.5211, Train: 0.9714, Val: 0.7060, Test: 0.7040
Epoch: 30, Loss: 4.4335, Train: 0.9714, Val: 0.7080, Test: 0.7060
Epoch: 31, Loss: 4.4148, Train: 0.9714, Val: 0.7020, Test: 0.7110
Epoch: 32, Loss: 4.4811, Train: 0.9643, Val: 0.6980, Test: 0.7130
Epoch: 33, Loss: 4.2396, Train: 0.9643, Val: 0.6960, Test: 0.7160
Epoch: 34, Loss: 4.4570, Train: 0.9714, Val: 0.6980, Test: 0.7170
Epoch: 35, Loss: 4.4614, Train: 0.9786, Val: 0.7020, Test: 0.7200
Epoch: 36, Loss: 4.2679, Train: 0.9857, Val: 0.7060, Test: 0.7220
Epoch: 37, Loss: 4.2693, Train: 0.9857, Val: 0.6980, Test: 0.7240
Epoch: 38, Loss: 4.4600, Train: 0.9857, Val: 0.6980, Test: 0.7210
Epoch: 39, Loss: 4.4380, Train: 0.9857, Val: 0.6960, Test: 0.7200
Epoch: 40, Loss: 3.9771, Train: 0.9929, Val: 0.7020, Test: 0.7170
Epoch: 41, Loss: 4.4861, Train: 0.9929, Val: 0.7000, Test: 0.7230
Epoch: 42, Loss: 4.4388, Train: 0.9929, Val: 0.7100, Test: 0.7250
Epoch: 43, Loss: 4.5108, Train: 0.9929, Val: 0.7080, Test: 0.7300
Epoch: 44, Loss: 4.1111, Train: 0.9929, Val: 0.7100, Test: 0.7330
Epoch: 45, Loss: 4.1228, Train: 0.9929, Val: 0.7140, Test: 0.7370
Epoch: 46, Loss: 4.3336, Train: 0.9929, Val: 0.7200, Test: 0.7400
Epoch: 47, Loss: 4.3404, Train: 0.9929, Val: 0.7220, Test: 0.7420
Epoch: 48, Loss: 4.0249, Train: 1.0000, Val: 0.7240, Test: 0.7480
Epoch: 49, Loss: 3.9281, Train: 1.0000, Val: 0.7300, Test: 0.7530
Epoch: 50, Loss: 4.1527, Train: 1.0000, Val: 0.7300, Test: 0.7550
Epoch: 51, Loss: 4.1760, Train: 1.0000, Val: 0.7280, Test: 0.7560
Epoch: 52, Loss: 3.8997, Train: 1.0000, Val: 0.7300, Test: 0.7570
Epoch: 53, Loss: 4.2450, Train: 1.0000, Val: 0.7360, Test: 0.7680
Epoch: 54, Loss: 4.2454, Train: 1.0000, Val: 0.7440, Test: 0.7730
Epoch: 55, Loss: 4.1639, Train: 1.0000, Val: 0.7440, Test: 0.7760
Epoch: 56, Loss: 3.8625, Train: 1.0000, Val: 0.7520, Test: 0.7750
Epoch: 57, Loss: 4.2303, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 58, Loss: 4.0466, Train: 1.0000, Val: 0.7560, Test: 0.7760
Epoch: 59, Loss: 3.9678, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 60, Loss: 3.8696, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 61, Loss: 3.6929, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 62, Loss: 4.0560, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 63, Loss: 3.9889, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 64, Loss: 3.5835, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 65, Loss: 3.9569, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 66, Loss: 3.8379, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 67, Loss: 3.6630, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 68, Loss: 4.2067, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 69, Loss: 3.8773, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 70, Loss: 3.9445, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 71, Loss: 3.9438, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 72, Loss: 3.7623, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 73, Loss: 3.8150, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 74, Loss: 4.0792, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 75, Loss: 3.8466, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 76, Loss: 3.8564, Train: 1.0000, Val: 0.7720, Test: 0.8130
Epoch: 77, Loss: 4.1490, Train: 1.0000, Val: 0.7700, Test: 0.8130
Epoch: 78, Loss: 3.8972, Train: 1.0000, Val: 0.7720, Test: 0.8130
Epoch: 79, Loss: 3.9893, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 80, Loss: 4.0026, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 81, Loss: 3.9656, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 82, Loss: 3.8687, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 83, Loss: 3.8380, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 84, Loss: 3.9580, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 85, Loss: 3.7286, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 86, Loss: 4.0604, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 87, Loss: 4.0203, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 88, Loss: 3.6717, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 89, Loss: 3.8779, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 90, Loss: 3.6932, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 91, Loss: 3.7077, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 92, Loss: 3.7107, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 93, Loss: 3.8108, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 94, Loss: 3.8594, Train: 1.0000, Val: 0.7920, Test: 0.8140
Epoch: 95, Loss: 3.7503, Train: 1.0000, Val: 0.7880, Test: 0.8160
Epoch: 96, Loss: 3.8389, Train: 1.0000, Val: 0.7860, Test: 0.8130
Epoch: 97, Loss: 4.0255, Train: 1.0000, Val: 0.7860, Test: 0.8150
Epoch: 98, Loss: 4.1285, Train: 1.0000, Val: 0.7860, Test: 0.8150
Epoch: 99, Loss: 3.7418, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 100, Loss: 3.6949, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 101, Loss: 3.6460, Train: 1.0000, Val: 0.7800, Test: 0.8120
Epoch: 102, Loss: 3.8588, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 103, Loss: 3.7811, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 104, Loss: 3.9397, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 105, Loss: 3.9314, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 106, Loss: 3.5057, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 107, Loss: 4.1549, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 108, Loss: 3.9141, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 109, Loss: 3.8457, Train: 1.0000, Val: 0.7860, Test: 0.8150
Epoch: 110, Loss: 3.7402, Train: 1.0000, Val: 0.7880, Test: 0.8130
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 111, Loss: 3.9000, Train: 1.0000, Val: 0.7900, Test: 0.8140
Epoch: 112, Loss: 3.9790, Train: 1.0000, Val: 0.7940, Test: 0.8130
Epoch: 113, Loss: 3.7306, Train: 1.0000, Val: 0.7940, Test: 0.8150
Epoch: 114, Loss: 3.7678, Train: 1.0000, Val: 0.7960, Test: 0.8130
Epoch: 115, Loss: 3.6739, Train: 1.0000, Val: 0.7960, Test: 0.8110
Epoch: 116, Loss: 3.6352, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 117, Loss: 3.7296, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 118, Loss: 3.6098, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 119, Loss: 3.7828, Train: 1.0000, Val: 0.7960, Test: 0.8110
Epoch: 120, Loss: 3.6756, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 121, Loss: 3.9028, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 122, Loss: 3.7234, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 123, Loss: 3.3329, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 124, Loss: 3.7446, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 125, Loss: 3.5710, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 126, Loss: 3.9475, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 127, Loss: 3.8035, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 128, Loss: 3.6699, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 129, Loss: 3.7171, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 130, Loss: 3.7451, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 131, Loss: 3.6277, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 132, Loss: 3.7404, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 133, Loss: 3.4341, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 134, Loss: 3.4421, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 135, Loss: 3.6893, Train: 1.0000, Val: 0.7880, Test: 0.8150
Epoch: 136, Loss: 3.6442, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 137, Loss: 3.8444, Train: 1.0000, Val: 0.7900, Test: 0.8140
Epoch: 138, Loss: 3.7682, Train: 1.0000, Val: 0.7880, Test: 0.8140
Epoch: 139, Loss: 3.5986, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 140, Loss: 3.7053, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 141, Loss: 3.8047, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 142, Loss: 3.6931, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 143, Loss: 3.5273, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 144, Loss: 3.5588, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 145, Loss: 3.5616, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 146, Loss: 3.4592, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 147, Loss: 3.6944, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 148, Loss: 3.6206, Train: 1.0000, Val: 0.7940, Test: 0.8130
Epoch: 149, Loss: 4.0560, Train: 1.0000, Val: 0.7900, Test: 0.8140
Epoch: 150, Loss: 3.8563, Train: 1.0000, Val: 0.7880, Test: 0.8140
Epoch: 151, Loss: 3.5880, Train: 1.0000, Val: 0.7900, Test: 0.8140
Epoch: 152, Loss: 3.6195, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 153, Loss: 3.8571, Train: 1.0000, Val: 0.7940, Test: 0.8160
Epoch: 154, Loss: 3.9252, Train: 1.0000, Val: 0.7920, Test: 0.8180
Epoch: 155, Loss: 3.8617, Train: 1.0000, Val: 0.7900, Test: 0.8200
Epoch: 156, Loss: 3.9238, Train: 1.0000, Val: 0.7880, Test: 0.8180
Epoch: 157, Loss: 3.7156, Train: 1.0000, Val: 0.7920, Test: 0.8180
Epoch: 158, Loss: 3.6238, Train: 1.0000, Val: 0.7900, Test: 0.8140
Epoch: 159, Loss: 3.6133, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 160, Loss: 3.4754, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 161, Loss: 3.5290, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 162, Loss: 3.7742, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 163, Loss: 3.4306, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 164, Loss: 3.8109, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 165, Loss: 3.5086, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 166, Loss: 3.8636, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 167, Loss: 3.7529, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 168, Loss: 3.6220, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 169, Loss: 3.8690, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 170, Loss: 3.6759, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 171, Loss: 3.4325, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 172, Loss: 3.8187, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 173, Loss: 3.5824, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 174, Loss: 3.7140, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 175, Loss: 3.7998, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 176, Loss: 3.7885, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 177, Loss: 3.8819, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 178, Loss: 3.4998, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 179, Loss: 3.5379, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 180, Loss: 3.8805, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 181, Loss: 3.8606, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 182, Loss: 3.7274, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 183, Loss: 3.7774, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 184, Loss: 3.7847, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 185, Loss: 3.8463, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 186, Loss: 3.9215, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 187, Loss: 3.6277, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 188, Loss: 3.8365, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 189, Loss: 3.8134, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 190, Loss: 4.0144, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 191, Loss: 3.5217, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 192, Loss: 3.5752, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 193, Loss: 3.4666, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 194, Loss: 3.5628, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 195, Loss: 3.5516, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 196, Loss: 3.1898, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 197, Loss: 3.6315, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 198, Loss: 3.7143, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 199, Loss: 3.8698, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 200, Loss: 3.7146, Train: 1.0000, Val: 0.7860, Test: 0.8040
MAD:  0.6177
Best Test Accuracy: 0.8200, Val Accuracy: 0.7900, Train Accuracy: 1.0000
Training completed.
Average Test Accuracy:  0.8131111111111111 ± 0.005300826863056209
Average MAD:  0.4979222222222222 ± 0.1118620755690564
