Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8578, Train: 0.1357, Val: 0.0820, Test: 0.0860
Epoch: 2, Loss: 4.8360, Train: 0.3143, Val: 0.2320, Test: 0.2710
Epoch: 3, Loss: 4.8105, Train: 0.4929, Val: 0.3760, Test: 0.4070
Epoch: 4, Loss: 4.7679, Train: 0.6357, Val: 0.4740, Test: 0.5050
Epoch: 5, Loss: 4.7472, Train: 0.7286, Val: 0.5160, Test: 0.5710
Epoch: 6, Loss: 4.7075, Train: 0.7429, Val: 0.5440, Test: 0.5910
Epoch: 7, Loss: 4.6538, Train: 0.7714, Val: 0.5820, Test: 0.6200
Epoch: 8, Loss: 4.5999, Train: 0.7786, Val: 0.6040, Test: 0.6310
Epoch: 9, Loss: 4.5239, Train: 0.7786, Val: 0.5960, Test: 0.6200
Epoch: 10, Loss: 4.4741, Train: 0.7929, Val: 0.5920, Test: 0.6070
Epoch: 11, Loss: 4.3979, Train: 0.7929, Val: 0.5900, Test: 0.5990
Epoch: 12, Loss: 4.4383, Train: 0.7714, Val: 0.5840, Test: 0.5890
Epoch: 13, Loss: 4.2421, Train: 0.7857, Val: 0.5880, Test: 0.5860
Epoch: 14, Loss: 4.1312, Train: 0.7857, Val: 0.5820, Test: 0.5890
Epoch: 15, Loss: 4.1390, Train: 0.7929, Val: 0.5800, Test: 0.5910
Epoch: 16, Loss: 4.1304, Train: 0.7929, Val: 0.5840, Test: 0.5950
Epoch: 17, Loss: 4.0580, Train: 0.7929, Val: 0.5840, Test: 0.6000
Epoch: 18, Loss: 3.7920, Train: 0.8000, Val: 0.5860, Test: 0.6070
Epoch: 19, Loss: 3.5939, Train: 0.8071, Val: 0.6000, Test: 0.6190
Epoch: 20, Loss: 3.6777, Train: 0.8143, Val: 0.6040, Test: 0.6270
Epoch: 21, Loss: 3.4277, Train: 0.8214, Val: 0.6040, Test: 0.6270
Epoch: 22, Loss: 3.6775, Train: 0.8286, Val: 0.5980, Test: 0.6330
Epoch: 23, Loss: 3.3531, Train: 0.8500, Val: 0.6120, Test: 0.6470
Epoch: 24, Loss: 3.5923, Train: 0.8929, Val: 0.6280, Test: 0.6690
Epoch: 25, Loss: 3.5134, Train: 0.9500, Val: 0.6660, Test: 0.7090
Epoch: 26, Loss: 3.5621, Train: 0.9571, Val: 0.7120, Test: 0.7440
Epoch: 27, Loss: 3.1859, Train: 0.9643, Val: 0.7540, Test: 0.7850
Epoch: 28, Loss: 3.3779, Train: 0.9786, Val: 0.7780, Test: 0.7870
Epoch: 29, Loss: 3.3301, Train: 0.9857, Val: 0.7740, Test: 0.7910
Epoch: 30, Loss: 2.8817, Train: 0.9786, Val: 0.7640, Test: 0.7890
Epoch: 31, Loss: 3.1582, Train: 0.9786, Val: 0.7620, Test: 0.7930
Epoch: 32, Loss: 3.1798, Train: 0.9786, Val: 0.7720, Test: 0.7970
Epoch: 33, Loss: 3.3697, Train: 0.9857, Val: 0.7760, Test: 0.8030
Epoch: 34, Loss: 3.2874, Train: 0.9857, Val: 0.7860, Test: 0.8060
Epoch: 35, Loss: 2.9423, Train: 0.9857, Val: 0.7860, Test: 0.8060
Epoch: 36, Loss: 3.1022, Train: 0.9786, Val: 0.7920, Test: 0.8050
Epoch: 37, Loss: 3.1418, Train: 0.9786, Val: 0.7940, Test: 0.8050
Epoch: 38, Loss: 2.8792, Train: 0.9786, Val: 0.7980, Test: 0.8050
Epoch: 39, Loss: 2.9202, Train: 0.9786, Val: 0.8000, Test: 0.8070
Epoch: 40, Loss: 2.8154, Train: 0.9786, Val: 0.8040, Test: 0.8120
Epoch: 41, Loss: 2.8654, Train: 0.9786, Val: 0.7980, Test: 0.8140
Epoch: 42, Loss: 2.7776, Train: 0.9786, Val: 0.8040, Test: 0.8210
Epoch: 43, Loss: 2.9171, Train: 0.9786, Val: 0.8080, Test: 0.8220
Epoch: 44, Loss: 2.7244, Train: 0.9786, Val: 0.8060, Test: 0.8180
Epoch: 45, Loss: 2.6182, Train: 0.9786, Val: 0.8040, Test: 0.8170
Epoch: 46, Loss: 2.7968, Train: 0.9857, Val: 0.8040, Test: 0.8140
Epoch: 47, Loss: 2.5804, Train: 0.9929, Val: 0.8020, Test: 0.8170
Epoch: 48, Loss: 2.7065, Train: 0.9929, Val: 0.8040, Test: 0.8200
Epoch: 49, Loss: 2.9032, Train: 0.9929, Val: 0.7940, Test: 0.8210
Epoch: 50, Loss: 2.3911, Train: 0.9929, Val: 0.7920, Test: 0.8170
Epoch: 51, Loss: 2.6381, Train: 0.9929, Val: 0.7880, Test: 0.8110
Epoch: 52, Loss: 2.9865, Train: 0.9929, Val: 0.7840, Test: 0.8060
Epoch: 53, Loss: 2.6713, Train: 0.9929, Val: 0.7840, Test: 0.8030
Epoch: 54, Loss: 2.5973, Train: 0.9929, Val: 0.7800, Test: 0.7980
Epoch: 55, Loss: 2.5762, Train: 0.9929, Val: 0.7800, Test: 0.7970
Epoch: 56, Loss: 3.1029, Train: 0.9929, Val: 0.7840, Test: 0.7970
Epoch: 57, Loss: 2.7625, Train: 0.9929, Val: 0.7840, Test: 0.7980
Epoch: 58, Loss: 2.4681, Train: 0.9929, Val: 0.7860, Test: 0.8030
Epoch: 59, Loss: 2.6247, Train: 0.9929, Val: 0.7840, Test: 0.8040
Epoch: 60, Loss: 3.0094, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 61, Loss: 2.6164, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 62, Loss: 2.7207, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 63, Loss: 2.5633, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 64, Loss: 2.2711, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 65, Loss: 2.6437, Train: 1.0000, Val: 0.7940, Test: 0.8040
Epoch: 66, Loss: 2.5238, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 67, Loss: 2.6350, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 68, Loss: 2.7265, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 69, Loss: 2.7302, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 70, Loss: 2.2600, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 71, Loss: 2.4027, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 72, Loss: 2.6057, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 73, Loss: 2.5881, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 74, Loss: 2.6534, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 75, Loss: 2.3525, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 76, Loss: 2.8034, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 77, Loss: 2.8126, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 78, Loss: 2.7201, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 79, Loss: 2.7045, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 80, Loss: 2.5528, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 81, Loss: 2.3368, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 82, Loss: 2.6536, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 83, Loss: 2.6769, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 84, Loss: 2.1629, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 85, Loss: 2.3792, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 86, Loss: 2.6735, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 87, Loss: 2.3418, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 88, Loss: 2.4599, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 89, Loss: 2.7253, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 90, Loss: 2.5119, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 91, Loss: 2.5539, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 92, Loss: 2.2834, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 93, Loss: 2.2228, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 94, Loss: 2.5406, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 95, Loss: 2.4118, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 96, Loss: 2.3490, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 97, Loss: 2.5573, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 98, Loss: 2.7524, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 99, Loss: 2.3106, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 100, Loss: 2.5082, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 101, Loss: 2.5865, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 102, Loss: 2.3346, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 103, Loss: 2.4496, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 104, Loss: 2.3595, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 105, Loss: 2.1958, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 106, Loss: 2.6304, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 107, Loss: 2.6842, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 108, Loss: 2.3579, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 109, Loss: 2.5451, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 110, Loss: 2.1072, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 111, Loss: 2.6405, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 112, Loss: 2.5086, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 113, Loss: 2.4881, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 114, Loss: 2.5335, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 115, Loss: 2.6453, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 116, Loss: 2.3938, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 117, Loss: 2.6050, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 118, Loss: 2.6713, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 119, Loss: 2.1984, Train: 1.0000, Val: 0.7820, Test: 0.8030
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 2.5984, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 121, Loss: 2.3133, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 122, Loss: 2.4328, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 123, Loss: 2.3572, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 124, Loss: 2.5422, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 125, Loss: 2.1907, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 126, Loss: 2.2329, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 127, Loss: 2.4654, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 128, Loss: 2.5626, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 129, Loss: 2.3513, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 130, Loss: 2.3285, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 131, Loss: 2.3926, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 132, Loss: 2.2471, Train: 1.0000, Val: 0.7920, Test: 0.8010
Epoch: 133, Loss: 2.5259, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 134, Loss: 2.1555, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 135, Loss: 2.3527, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 136, Loss: 2.2216, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 137, Loss: 2.4919, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 138, Loss: 2.5972, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 139, Loss: 2.4939, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 140, Loss: 2.3871, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 141, Loss: 2.6594, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 142, Loss: 2.4300, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 143, Loss: 2.6305, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 144, Loss: 2.2139, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 145, Loss: 2.4108, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 146, Loss: 2.7316, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 147, Loss: 2.6327, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 148, Loss: 2.3221, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 149, Loss: 2.2168, Train: 1.0000, Val: 0.7880, Test: 0.7940
Epoch: 150, Loss: 2.4631, Train: 1.0000, Val: 0.7880, Test: 0.7930
Epoch: 151, Loss: 2.6358, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 152, Loss: 2.6298, Train: 1.0000, Val: 0.7880, Test: 0.7950
Epoch: 153, Loss: 2.3541, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 154, Loss: 2.8354, Train: 1.0000, Val: 0.7880, Test: 0.7960
Epoch: 155, Loss: 2.3149, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 156, Loss: 2.5201, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 157, Loss: 2.4177, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 158, Loss: 2.2118, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 159, Loss: 2.4189, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 160, Loss: 2.4833, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 161, Loss: 2.4485, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 162, Loss: 2.8296, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 163, Loss: 2.2765, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 164, Loss: 2.4426, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 165, Loss: 2.5811, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 166, Loss: 2.3849, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 167, Loss: 2.2633, Train: 1.0000, Val: 0.7900, Test: 0.7980
Epoch: 168, Loss: 2.5924, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 169, Loss: 2.3916, Train: 1.0000, Val: 0.7900, Test: 0.7970
Epoch: 170, Loss: 2.3131, Train: 1.0000, Val: 0.7900, Test: 0.7970
Epoch: 171, Loss: 2.2361, Train: 1.0000, Val: 0.7920, Test: 0.7980
Epoch: 172, Loss: 2.1009, Train: 1.0000, Val: 0.7920, Test: 0.7990
Epoch: 173, Loss: 2.4849, Train: 1.0000, Val: 0.7920, Test: 0.7990
Epoch: 174, Loss: 2.0681, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 175, Loss: 2.5816, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 176, Loss: 2.3121, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 177, Loss: 2.0732, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 178, Loss: 2.4390, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 179, Loss: 2.4153, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 180, Loss: 2.1620, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 181, Loss: 2.3438, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 182, Loss: 2.2118, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 183, Loss: 2.3037, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 184, Loss: 2.6569, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 185, Loss: 2.4808, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 186, Loss: 2.6523, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 187, Loss: 2.4223, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 188, Loss: 2.4452, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 189, Loss: 2.8313, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 190, Loss: 2.2716, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 191, Loss: 2.5180, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 192, Loss: 2.2675, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 193, Loss: 2.4739, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 194, Loss: 2.5797, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 195, Loss: 2.3466, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 196, Loss: 2.5570, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 197, Loss: 2.6543, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 198, Loss: 2.2718, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 199, Loss: 2.2374, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 200, Loss: 2.3008, Train: 1.0000, Val: 0.7840, Test: 0.8030
MAD:  0.2011
Best Test Accuracy: 0.8220, Val Accuracy: 0.8080, Train Accuracy: 0.9786
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8478, Train: 0.2429, Val: 0.1260, Test: 0.1520
Epoch: 2, Loss: 4.8166, Train: 0.3143, Val: 0.1740, Test: 0.1880
Epoch: 3, Loss: 4.7820, Train: 0.4071, Val: 0.2000, Test: 0.2130
Epoch: 4, Loss: 4.7617, Train: 0.4500, Val: 0.2140, Test: 0.2410
Epoch: 5, Loss: 4.7025, Train: 0.4786, Val: 0.2460, Test: 0.2600
Epoch: 6, Loss: 4.6412, Train: 0.4786, Val: 0.2440, Test: 0.2610
Epoch: 7, Loss: 4.5983, Train: 0.4786, Val: 0.2380, Test: 0.2660
Epoch: 8, Loss: 4.5672, Train: 0.4929, Val: 0.2380, Test: 0.2660
Epoch: 9, Loss: 4.5567, Train: 0.5000, Val: 0.2400, Test: 0.2730
Epoch: 10, Loss: 4.4043, Train: 0.5071, Val: 0.2440, Test: 0.2790
Epoch: 11, Loss: 4.4291, Train: 0.5071, Val: 0.2500, Test: 0.2840
Epoch: 12, Loss: 4.2402, Train: 0.5214, Val: 0.2540, Test: 0.2880
Epoch: 13, Loss: 4.1832, Train: 0.5286, Val: 0.2760, Test: 0.2980
Epoch: 14, Loss: 3.9854, Train: 0.5286, Val: 0.2880, Test: 0.3050
Epoch: 15, Loss: 3.8314, Train: 0.5500, Val: 0.3100, Test: 0.3190
Epoch: 16, Loss: 3.9329, Train: 0.5714, Val: 0.3220, Test: 0.3380
Epoch: 17, Loss: 3.8511, Train: 0.5857, Val: 0.3300, Test: 0.3680
Epoch: 18, Loss: 3.7244, Train: 0.6286, Val: 0.3640, Test: 0.4170
Epoch: 19, Loss: 3.6310, Train: 0.6857, Val: 0.4340, Test: 0.4850
Epoch: 20, Loss: 3.6751, Train: 0.7714, Val: 0.4760, Test: 0.5410
Epoch: 21, Loss: 3.4923, Train: 0.7929, Val: 0.5480, Test: 0.5990
Epoch: 22, Loss: 3.4350, Train: 0.8214, Val: 0.5860, Test: 0.6380
Epoch: 23, Loss: 3.1442, Train: 0.8500, Val: 0.6440, Test: 0.6810
Epoch: 24, Loss: 3.6650, Train: 0.9071, Val: 0.6940, Test: 0.7250
Epoch: 25, Loss: 3.3821, Train: 0.9286, Val: 0.7380, Test: 0.7600
Epoch: 26, Loss: 3.2087, Train: 0.9429, Val: 0.7500, Test: 0.7980
Epoch: 27, Loss: 3.3283, Train: 0.9643, Val: 0.7820, Test: 0.8170
Epoch: 28, Loss: 3.2117, Train: 0.9714, Val: 0.7880, Test: 0.8080
Epoch: 29, Loss: 3.0627, Train: 0.9857, Val: 0.7900, Test: 0.7970
Epoch: 30, Loss: 3.1153, Train: 0.9857, Val: 0.7780, Test: 0.7850
Epoch: 31, Loss: 3.3784, Train: 0.9786, Val: 0.7780, Test: 0.7710
Epoch: 32, Loss: 3.1252, Train: 0.9714, Val: 0.7740, Test: 0.7680
Epoch: 33, Loss: 2.8565, Train: 0.9714, Val: 0.7720, Test: 0.7650
Epoch: 34, Loss: 3.2543, Train: 0.9714, Val: 0.7700, Test: 0.7630
Epoch: 35, Loss: 2.8090, Train: 0.9714, Val: 0.7620, Test: 0.7650
Epoch: 36, Loss: 2.9398, Train: 0.9714, Val: 0.7660, Test: 0.7690
Epoch: 37, Loss: 3.1351, Train: 0.9714, Val: 0.7780, Test: 0.7750
Epoch: 38, Loss: 2.8803, Train: 0.9714, Val: 0.7780, Test: 0.7780
Epoch: 39, Loss: 2.6660, Train: 0.9714, Val: 0.7800, Test: 0.7800
Epoch: 40, Loss: 2.7272, Train: 0.9714, Val: 0.7820, Test: 0.7840
Epoch: 41, Loss: 2.8980, Train: 0.9714, Val: 0.7840, Test: 0.7880
Epoch: 42, Loss: 2.8867, Train: 0.9786, Val: 0.7820, Test: 0.7920
Epoch: 43, Loss: 3.0301, Train: 0.9857, Val: 0.7840, Test: 0.7980
Epoch: 44, Loss: 2.6443, Train: 0.9857, Val: 0.7880, Test: 0.8000
Epoch: 45, Loss: 2.6704, Train: 0.9857, Val: 0.7880, Test: 0.8010
Epoch: 46, Loss: 2.3904, Train: 0.9857, Val: 0.7900, Test: 0.8090
Epoch: 47, Loss: 3.1548, Train: 0.9929, Val: 0.7920, Test: 0.8100
Epoch: 48, Loss: 2.5693, Train: 0.9929, Val: 0.7940, Test: 0.8120
Epoch: 49, Loss: 2.7943, Train: 0.9929, Val: 0.8000, Test: 0.8140
Epoch: 50, Loss: 2.5872, Train: 0.9929, Val: 0.8020, Test: 0.8160
Epoch: 51, Loss: 2.4293, Train: 1.0000, Val: 0.7940, Test: 0.8160
Epoch: 52, Loss: 2.6444, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 53, Loss: 2.7727, Train: 1.0000, Val: 0.7980, Test: 0.8090
Epoch: 54, Loss: 2.4152, Train: 1.0000, Val: 0.7980, Test: 0.8080
Epoch: 55, Loss: 2.5075, Train: 1.0000, Val: 0.7960, Test: 0.8070
Epoch: 56, Loss: 2.3311, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 57, Loss: 2.6381, Train: 1.0000, Val: 0.7920, Test: 0.8010
Epoch: 58, Loss: 2.7214, Train: 1.0000, Val: 0.7960, Test: 0.8010
Epoch: 59, Loss: 2.7450, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 60, Loss: 2.3113, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 61, Loss: 2.7438, Train: 1.0000, Val: 0.7920, Test: 0.7950
Epoch: 62, Loss: 2.3947, Train: 1.0000, Val: 0.7900, Test: 0.7960
Epoch: 63, Loss: 2.4243, Train: 1.0000, Val: 0.7920, Test: 0.7980
Epoch: 64, Loss: 2.8333, Train: 1.0000, Val: 0.7920, Test: 0.7980
Epoch: 65, Loss: 2.4181, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 66, Loss: 2.6042, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 67, Loss: 2.3744, Train: 1.0000, Val: 0.7940, Test: 0.8040
Epoch: 68, Loss: 2.5667, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 69, Loss: 2.3522, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 70, Loss: 2.5948, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 71, Loss: 2.2950, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 72, Loss: 2.3429, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 73, Loss: 2.6673, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 74, Loss: 2.6786, Train: 1.0000, Val: 0.7940, Test: 0.8070
Epoch: 75, Loss: 2.5160, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 76, Loss: 2.4148, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 77, Loss: 2.8685, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 78, Loss: 2.5239, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 79, Loss: 2.6976, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 80, Loss: 2.4765, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 81, Loss: 2.5105, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 82, Loss: 2.5211, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 83, Loss: 2.2837, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 84, Loss: 2.3814, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 85, Loss: 2.2582, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 86, Loss: 2.5706, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 87, Loss: 2.6069, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 88, Loss: 2.3643, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 89, Loss: 2.3615, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 90, Loss: 2.8838, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 91, Loss: 2.5055, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 92, Loss: 2.6380, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 93, Loss: 2.6279, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 94, Loss: 2.5463, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 95, Loss: 2.7626, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 96, Loss: 2.6403, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 97, Loss: 2.3805, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 98, Loss: 2.6546, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 99, Loss: 2.1674, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 100, Loss: 2.4526, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 101, Loss: 2.7091, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 102, Loss: 2.4739, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 103, Loss: 2.5320, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 104, Loss: 2.6826, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 105, Loss: 2.1353, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 106, Loss: 2.8021, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 107, Loss: 2.4679, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 108, Loss: 2.6821, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 109, Loss: 2.3326, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 110, Loss: 2.1976, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 111, Loss: 2.5368, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 112, Loss: 2.5039, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 113, Loss: 2.7102, Train: 1.0000, Val: 0.7840, Test: 0.8120
Epoch: 114, Loss: 2.7049, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 115, Loss: 2.7907, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 116, Loss: 2.8114, Train: 1.0000, Val: 0.7840, Test: 0.8170
Epoch: 117, Loss: 2.3990, Train: 1.0000, Val: 0.7840, Test: 0.8160
Epoch: 118, Loss: 2.4293, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 119, Loss: 2.3646, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 120, Loss: 2.1966, Train: 1.0000, Val: 0.7860, Test: 0.8130
Epoch: 121, Loss: 2.4965, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 122, Loss: 2.6065, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 123, Loss: 2.3603, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 124, Loss: 2.1974, Train: 1.0000, Val: 0.7880, Test: 0.8050
Epoch: 125, Loss: 2.6163, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 126, Loss: 2.4887, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 127, Loss: 2.1932, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 128, Loss: 2.5325, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 129, Loss: 2.3587, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 130, Loss: 2.6283, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 131, Loss: 2.5717, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 132, Loss: 2.3647, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 133, Loss: 2.6046, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 134, Loss: 2.1160, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 135, Loss: 2.4225, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 136, Loss: 2.6655, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 137, Loss: 2.6122, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 138, Loss: 2.5060, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 139, Loss: 2.1903, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 140, Loss: 2.3824, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 141, Loss: 2.3947, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 142, Loss: 2.3870, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 143, Loss: 2.4919, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 144, Loss: 2.2509, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 145, Loss: 2.2535, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 146, Loss: 2.4870, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 147, Loss: 2.3582, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 148, Loss: 2.5244, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 149, Loss: 2.6275, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 150, Loss: 2.5130, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 151, Loss: 2.2842, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 152, Loss: 2.2478, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 153, Loss: 2.5300, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 154, Loss: 2.5353, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 155, Loss: 2.2248, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 156, Loss: 2.5893, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 157, Loss: 2.6263, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 158, Loss: 2.3181, Train: 1.0000, Val: 0.7740, Test: 0.7970
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 159, Loss: 2.4233, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 160, Loss: 2.2500, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 161, Loss: 2.5284, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 162, Loss: 2.4180, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 163, Loss: 1.8194, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 164, Loss: 2.3466, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 165, Loss: 2.8342, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 166, Loss: 2.5263, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 167, Loss: 2.4618, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 168, Loss: 2.4844, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 169, Loss: 2.7948, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 170, Loss: 2.2438, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 171, Loss: 2.4173, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 172, Loss: 2.3920, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 173, Loss: 2.6526, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 174, Loss: 2.1853, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 175, Loss: 2.1325, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 176, Loss: 2.4812, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 177, Loss: 1.9614, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 178, Loss: 2.4584, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 179, Loss: 2.6255, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 180, Loss: 2.3805, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 181, Loss: 2.3797, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 182, Loss: 2.3158, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 183, Loss: 2.2787, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 184, Loss: 2.0085, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 185, Loss: 2.4843, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 186, Loss: 2.2801, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 187, Loss: 2.5458, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 188, Loss: 2.7635, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 189, Loss: 2.5900, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 190, Loss: 2.3485, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 191, Loss: 2.1402, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 192, Loss: 2.5187, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 193, Loss: 2.3069, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 194, Loss: 2.5120, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 195, Loss: 2.4064, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 196, Loss: 2.5458, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 197, Loss: 2.7582, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 198, Loss: 2.3079, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 199, Loss: 2.0608, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 200, Loss: 2.2707, Train: 1.0000, Val: 0.7740, Test: 0.8020
MAD:  0.04
Best Test Accuracy: 0.8170, Val Accuracy: 0.7820, Train Accuracy: 0.9643
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8566, Train: 0.2071, Val: 0.1320, Test: 0.1230
Epoch: 2, Loss: 4.8261, Train: 0.2929, Val: 0.2460, Test: 0.2360
Epoch: 3, Loss: 4.8016, Train: 0.3286, Val: 0.2380, Test: 0.2370
Epoch: 4, Loss: 4.7912, Train: 0.3357, Val: 0.2240, Test: 0.2280
Epoch: 5, Loss: 4.7494, Train: 0.3500, Val: 0.2220, Test: 0.2200
Epoch: 6, Loss: 4.7040, Train: 0.3643, Val: 0.2400, Test: 0.2320
Epoch: 7, Loss: 4.6466, Train: 0.3786, Val: 0.2520, Test: 0.2540
Epoch: 8, Loss: 4.6164, Train: 0.4071, Val: 0.2820, Test: 0.2790
Epoch: 9, Loss: 4.5945, Train: 0.4143, Val: 0.2920, Test: 0.2900
Epoch: 10, Loss: 4.4939, Train: 0.4214, Val: 0.3020, Test: 0.2990
Epoch: 11, Loss: 4.4243, Train: 0.4429, Val: 0.3080, Test: 0.3070
Epoch: 12, Loss: 4.3326, Train: 0.4429, Val: 0.3140, Test: 0.3200
Epoch: 13, Loss: 4.1951, Train: 0.4429, Val: 0.3280, Test: 0.3390
Epoch: 14, Loss: 4.2971, Train: 0.4429, Val: 0.3240, Test: 0.3340
Epoch: 15, Loss: 4.2778, Train: 0.4500, Val: 0.3280, Test: 0.3410
Epoch: 16, Loss: 4.0815, Train: 0.4571, Val: 0.3260, Test: 0.3370
Epoch: 17, Loss: 4.0175, Train: 0.4786, Val: 0.3360, Test: 0.3540
Epoch: 18, Loss: 3.7833, Train: 0.4857, Val: 0.3800, Test: 0.3790
Epoch: 19, Loss: 3.7319, Train: 0.5286, Val: 0.3980, Test: 0.4300
Epoch: 20, Loss: 3.6791, Train: 0.5929, Val: 0.4380, Test: 0.4780
Epoch: 21, Loss: 3.7631, Train: 0.6643, Val: 0.5200, Test: 0.5450
Epoch: 22, Loss: 3.0686, Train: 0.7143, Val: 0.5780, Test: 0.6020
Epoch: 23, Loss: 3.7480, Train: 0.8000, Val: 0.6220, Test: 0.6700
Epoch: 24, Loss: 3.5793, Train: 0.8500, Val: 0.6520, Test: 0.7000
Epoch: 25, Loss: 3.4528, Train: 0.8857, Val: 0.6760, Test: 0.7070
Epoch: 26, Loss: 3.3663, Train: 0.9429, Val: 0.6960, Test: 0.7280
Epoch: 27, Loss: 3.2961, Train: 0.9571, Val: 0.7240, Test: 0.7550
Epoch: 28, Loss: 3.0539, Train: 0.9714, Val: 0.7360, Test: 0.7560
Epoch: 29, Loss: 3.0533, Train: 0.9786, Val: 0.7420, Test: 0.7590
Epoch: 30, Loss: 3.3814, Train: 0.9786, Val: 0.7500, Test: 0.7580
Epoch: 31, Loss: 3.3813, Train: 0.9786, Val: 0.7540, Test: 0.7620
Epoch: 32, Loss: 3.2617, Train: 0.9786, Val: 0.7460, Test: 0.7660
Epoch: 33, Loss: 3.3112, Train: 0.9714, Val: 0.7440, Test: 0.7720
Epoch: 34, Loss: 3.3052, Train: 0.9786, Val: 0.7400, Test: 0.7720
Epoch: 35, Loss: 3.0392, Train: 0.9714, Val: 0.7480, Test: 0.7790
Epoch: 36, Loss: 2.9213, Train: 0.9786, Val: 0.7560, Test: 0.7820
Epoch: 37, Loss: 3.1708, Train: 0.9857, Val: 0.7720, Test: 0.7880
Epoch: 38, Loss: 3.2119, Train: 0.9929, Val: 0.7820, Test: 0.7920
Epoch: 39, Loss: 3.2773, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 40, Loss: 2.8792, Train: 1.0000, Val: 0.7980, Test: 0.8000
Epoch: 41, Loss: 2.7930, Train: 1.0000, Val: 0.7960, Test: 0.8050
Epoch: 42, Loss: 2.8112, Train: 1.0000, Val: 0.7980, Test: 0.8130
Epoch: 43, Loss: 3.4034, Train: 1.0000, Val: 0.8000, Test: 0.8130
Epoch: 44, Loss: 2.9352, Train: 0.9929, Val: 0.8000, Test: 0.8190
Epoch: 45, Loss: 2.9034, Train: 0.9857, Val: 0.8040, Test: 0.8210
Epoch: 46, Loss: 2.6328, Train: 0.9857, Val: 0.8000, Test: 0.8210
Epoch: 47, Loss: 2.6269, Train: 0.9857, Val: 0.7980, Test: 0.8250
Epoch: 48, Loss: 2.8576, Train: 0.9857, Val: 0.8060, Test: 0.8250
Epoch: 49, Loss: 2.6083, Train: 0.9857, Val: 0.8060, Test: 0.8250
Epoch: 50, Loss: 2.7334, Train: 0.9857, Val: 0.8040, Test: 0.8240
Epoch: 51, Loss: 2.8023, Train: 0.9857, Val: 0.8000, Test: 0.8250
Epoch: 52, Loss: 2.6863, Train: 0.9857, Val: 0.7960, Test: 0.8230
Epoch: 53, Loss: 2.5201, Train: 0.9857, Val: 0.7940, Test: 0.8180
Epoch: 54, Loss: 2.9017, Train: 0.9857, Val: 0.7940, Test: 0.8150
Epoch: 55, Loss: 2.5263, Train: 0.9857, Val: 0.7940, Test: 0.8070
Epoch: 56, Loss: 2.6152, Train: 0.9857, Val: 0.7920, Test: 0.8030
Epoch: 57, Loss: 2.5647, Train: 0.9929, Val: 0.7940, Test: 0.8050
Epoch: 58, Loss: 2.8824, Train: 0.9929, Val: 0.7940, Test: 0.8050
Epoch: 59, Loss: 2.3708, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 60, Loss: 2.7088, Train: 1.0000, Val: 0.7960, Test: 0.8080
Epoch: 61, Loss: 2.6821, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 62, Loss: 2.8114, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 63, Loss: 2.5603, Train: 1.0000, Val: 0.8000, Test: 0.8120
Epoch: 64, Loss: 2.8503, Train: 1.0000, Val: 0.8040, Test: 0.8140
Epoch: 65, Loss: 2.6035, Train: 1.0000, Val: 0.8000, Test: 0.8120
Epoch: 66, Loss: 2.5959, Train: 1.0000, Val: 0.8000, Test: 0.8140
Epoch: 67, Loss: 2.6102, Train: 1.0000, Val: 0.8000, Test: 0.8160
Epoch: 68, Loss: 2.6737, Train: 1.0000, Val: 0.7940, Test: 0.8210
Epoch: 69, Loss: 2.7830, Train: 1.0000, Val: 0.7940, Test: 0.8180
Epoch: 70, Loss: 2.6396, Train: 1.0000, Val: 0.7960, Test: 0.8190
Epoch: 71, Loss: 2.6503, Train: 1.0000, Val: 0.7960, Test: 0.8170
Epoch: 72, Loss: 2.7643, Train: 1.0000, Val: 0.8000, Test: 0.8170
Epoch: 73, Loss: 2.4086, Train: 1.0000, Val: 0.7980, Test: 0.8130
Epoch: 74, Loss: 2.2881, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 75, Loss: 2.6353, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 76, Loss: 2.7108, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 77, Loss: 2.5071, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 78, Loss: 2.6560, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 79, Loss: 2.8558, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 80, Loss: 2.4610, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 81, Loss: 2.4855, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 82, Loss: 2.2831, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 83, Loss: 2.6593, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 84, Loss: 2.3415, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 85, Loss: 2.4767, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 86, Loss: 2.8057, Train: 1.0000, Val: 0.7940, Test: 0.8130
Epoch: 87, Loss: 2.6397, Train: 1.0000, Val: 0.7940, Test: 0.8130
Epoch: 88, Loss: 2.5570, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 89, Loss: 2.5287, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 90, Loss: 2.4581, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 91, Loss: 2.4654, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 92, Loss: 2.5275, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 93, Loss: 2.5275, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 94, Loss: 2.4541, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 95, Loss: 2.4028, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 96, Loss: 2.6607, Train: 1.0000, Val: 0.7920, Test: 0.8140
Epoch: 97, Loss: 2.2335, Train: 1.0000, Val: 0.7940, Test: 0.8110
Epoch: 98, Loss: 2.6580, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 99, Loss: 2.3871, Train: 1.0000, Val: 0.7960, Test: 0.8100
Epoch: 100, Loss: 2.4508, Train: 1.0000, Val: 0.7960, Test: 0.8100
Epoch: 101, Loss: 2.3781, Train: 1.0000, Val: 0.7960, Test: 0.8090
Epoch: 102, Loss: 2.4902, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 103, Loss: 1.9916, Train: 1.0000, Val: 0.7960, Test: 0.8100
Epoch: 104, Loss: 2.3201, Train: 1.0000, Val: 0.7960, Test: 0.8110
Epoch: 105, Loss: 2.4891, Train: 1.0000, Val: 0.8000, Test: 0.8090
Epoch: 106, Loss: 2.8242, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 107, Loss: 2.6149, Train: 1.0000, Val: 0.7940, Test: 0.8150
Epoch: 108, Loss: 2.8538, Train: 1.0000, Val: 0.8000, Test: 0.8140
Epoch: 109, Loss: 2.4354, Train: 1.0000, Val: 0.7960, Test: 0.8130
Epoch: 110, Loss: 2.4742, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 111, Loss: 2.4809, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 112, Loss: 2.5708, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 113, Loss: 2.4613, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 114, Loss: 2.6452, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 115, Loss: 2.7885, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 116, Loss: 2.4961, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 117, Loss: 2.2498, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 118, Loss: 2.8163, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 119, Loss: 2.8554, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 120, Loss: 2.4955, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 121, Loss: 2.5354, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 122, Loss: 2.8981, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 123, Loss: 2.2308, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 124, Loss: 2.7090, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 125, Loss: 2.3390, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 126, Loss: 2.1552, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 127, Loss: 2.7033, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 128, Loss: 2.1837, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 129, Loss: 2.5286, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 130, Loss: 2.4349, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 131, Loss: 2.1577, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 132, Loss: 2.4250, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 133, Loss: 2.5633, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 134, Loss: 2.4888, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 135, Loss: 2.4292, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 136, Loss: 2.2156, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 137, Loss: 2.3668, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 138, Loss: 2.9008, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 139, Loss: 2.4887, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 140, Loss: 2.5057, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 141, Loss: 2.3888, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 142, Loss: 2.4111, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 143, Loss: 2.6252, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 144, Loss: 2.4276, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 145, Loss: 2.7927, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 146, Loss: 2.5205, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 147, Loss: 2.1141, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 148, Loss: 2.3243, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 149, Loss: 2.3620, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 150, Loss: 2.1771, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 151, Loss: 2.2934, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 152, Loss: 2.4324, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 153, Loss: 2.1093, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 154, Loss: 2.1070, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 155, Loss: 2.4508, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 156, Loss: 2.5634, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 157, Loss: 2.4109, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 158, Loss: 2.7554, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 159, Loss: 2.7686, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 160, Loss: 2.5845, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 161, Loss: 2.3850, Train: 1.0000, Val: 0.7840, Test: 0.8120
Epoch: 162, Loss: 2.3590, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 163, Loss: 2.6626, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 164, Loss: 2.8240, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 165, Loss: 2.3568, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 166, Loss: 2.6625, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 167, Loss: 2.3751, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 168, Loss: 2.0426, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 169, Loss: 2.4149, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 170, Loss: 2.3397, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 171, Loss: 2.3731, Train: 1.0000, Val: 0.7740, Test: 0.8110
Epoch: 172, Loss: 2.5992, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 173, Loss: 2.4548, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 174, Loss: 2.7875, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 175, Loss: 2.7945, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 176, Loss: 2.3833, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 177, Loss: 2.5464, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 178, Loss: 2.1710, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 179, Loss: 2.3069, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 180, Loss: 2.5960, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 181, Loss: 2.4619, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 182, Loss: 2.5665, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 183, Loss: 2.2813, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 184, Loss: 2.0366, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 185, Loss: 2.5141, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 186, Loss: 2.2103, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 187, Loss: 2.9018, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 188, Loss: 2.5822, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 189, Loss: 2.8066, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 190, Loss: 2.5852, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 191, Loss: 2.6564, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 192, Loss: 2.6199, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 193, Loss: 2.4547, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 194, Loss: 2.4489, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 195, Loss: 2.6839, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 196, Loss: 2.3078, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 197, Loss: 2.3884, Train: 1.0000, Val: 0.7740, Test: 0.8000
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 198, Loss: 2.3888, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 199, Loss: 2.4811, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 200, Loss: 2.0690, Train: 1.0000, Val: 0.7700, Test: 0.8030
MAD:  0.2521
Best Test Accuracy: 0.8250, Val Accuracy: 0.7980, Train Accuracy: 0.9857
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8489, Train: 0.2500, Val: 0.1660, Test: 0.1610
Epoch: 2, Loss: 4.8240, Train: 0.4357, Val: 0.2880, Test: 0.2730
Epoch: 3, Loss: 4.7846, Train: 0.4929, Val: 0.3260, Test: 0.3080
Epoch: 4, Loss: 4.7735, Train: 0.5500, Val: 0.3500, Test: 0.3470
Epoch: 5, Loss: 4.6797, Train: 0.5571, Val: 0.3560, Test: 0.3580
Epoch: 6, Loss: 4.6649, Train: 0.5571, Val: 0.3580, Test: 0.3800
Epoch: 7, Loss: 4.5907, Train: 0.5786, Val: 0.3640, Test: 0.3890
Epoch: 8, Loss: 4.4735, Train: 0.5857, Val: 0.3640, Test: 0.3810
Epoch: 9, Loss: 4.3890, Train: 0.5714, Val: 0.3680, Test: 0.3790
Epoch: 10, Loss: 4.3795, Train: 0.5571, Val: 0.3680, Test: 0.3750
Epoch: 11, Loss: 4.2208, Train: 0.5643, Val: 0.3700, Test: 0.3680
Epoch: 12, Loss: 4.1789, Train: 0.5643, Val: 0.3680, Test: 0.3690
Epoch: 13, Loss: 4.1257, Train: 0.5643, Val: 0.3620, Test: 0.3690
Epoch: 14, Loss: 3.9435, Train: 0.5714, Val: 0.3660, Test: 0.3730
Epoch: 15, Loss: 3.8982, Train: 0.5643, Val: 0.3680, Test: 0.3710
Epoch: 16, Loss: 3.9561, Train: 0.5643, Val: 0.3740, Test: 0.3750
Epoch: 17, Loss: 3.6375, Train: 0.5643, Val: 0.3720, Test: 0.3810
Epoch: 18, Loss: 3.6279, Train: 0.6071, Val: 0.3720, Test: 0.3850
Epoch: 19, Loss: 3.4765, Train: 0.6429, Val: 0.3860, Test: 0.4020
Epoch: 20, Loss: 3.1359, Train: 0.6643, Val: 0.4160, Test: 0.4180
Epoch: 21, Loss: 3.3179, Train: 0.7857, Val: 0.4740, Test: 0.4810
Epoch: 22, Loss: 3.2860, Train: 0.8143, Val: 0.5080, Test: 0.5160
Epoch: 23, Loss: 3.4443, Train: 0.8214, Val: 0.5240, Test: 0.5480
Epoch: 24, Loss: 3.3415, Train: 0.8571, Val: 0.5500, Test: 0.5590
Epoch: 25, Loss: 3.3023, Train: 0.8643, Val: 0.5640, Test: 0.5710
Epoch: 26, Loss: 3.2956, Train: 0.8929, Val: 0.6060, Test: 0.6070
Epoch: 27, Loss: 3.3805, Train: 0.9357, Val: 0.6520, Test: 0.6680
Epoch: 28, Loss: 3.6086, Train: 0.9429, Val: 0.7180, Test: 0.7220
Epoch: 29, Loss: 3.1957, Train: 0.9500, Val: 0.7540, Test: 0.7560
Epoch: 30, Loss: 3.0916, Train: 0.9571, Val: 0.7740, Test: 0.7770
Epoch: 31, Loss: 3.3327, Train: 0.9643, Val: 0.7980, Test: 0.7990
Epoch: 32, Loss: 3.5213, Train: 0.9714, Val: 0.7960, Test: 0.8010
Epoch: 33, Loss: 3.3100, Train: 0.9714, Val: 0.7960, Test: 0.8050
Epoch: 34, Loss: 2.9003, Train: 0.9643, Val: 0.7980, Test: 0.8090
Epoch: 35, Loss: 2.7890, Train: 0.9643, Val: 0.8040, Test: 0.8110
Epoch: 36, Loss: 3.0118, Train: 0.9643, Val: 0.7940, Test: 0.8040
Epoch: 37, Loss: 3.0213, Train: 0.9786, Val: 0.7880, Test: 0.7980
Epoch: 38, Loss: 2.7078, Train: 0.9786, Val: 0.7800, Test: 0.7920
Epoch: 39, Loss: 2.7687, Train: 0.9786, Val: 0.7640, Test: 0.7890
Epoch: 40, Loss: 3.0421, Train: 0.9786, Val: 0.7620, Test: 0.7820
Epoch: 41, Loss: 3.1240, Train: 0.9857, Val: 0.7640, Test: 0.7750
Epoch: 42, Loss: 3.1792, Train: 0.9857, Val: 0.7620, Test: 0.7710
Epoch: 43, Loss: 2.6742, Train: 0.9857, Val: 0.7620, Test: 0.7690
Epoch: 44, Loss: 3.1046, Train: 0.9857, Val: 0.7620, Test: 0.7620
Epoch: 45, Loss: 3.0313, Train: 0.9857, Val: 0.7620, Test: 0.7590
Epoch: 46, Loss: 2.5512, Train: 0.9857, Val: 0.7620, Test: 0.7610
Epoch: 47, Loss: 3.1177, Train: 0.9929, Val: 0.7680, Test: 0.7700
Epoch: 48, Loss: 2.8684, Train: 0.9929, Val: 0.7660, Test: 0.7760
Epoch: 49, Loss: 2.8200, Train: 0.9929, Val: 0.7720, Test: 0.7760
Epoch: 50, Loss: 2.6513, Train: 0.9929, Val: 0.7740, Test: 0.7780
Epoch: 51, Loss: 2.8236, Train: 0.9929, Val: 0.7780, Test: 0.7770
Epoch: 52, Loss: 2.8929, Train: 0.9929, Val: 0.7800, Test: 0.7760
Epoch: 53, Loss: 2.9350, Train: 0.9929, Val: 0.7840, Test: 0.7760
Epoch: 54, Loss: 2.8398, Train: 0.9929, Val: 0.7840, Test: 0.7790
Epoch: 55, Loss: 2.5011, Train: 0.9929, Val: 0.7840, Test: 0.7780
Epoch: 56, Loss: 2.4370, Train: 0.9929, Val: 0.7860, Test: 0.7810
Epoch: 57, Loss: 2.6363, Train: 0.9929, Val: 0.7920, Test: 0.7840
Epoch: 58, Loss: 2.2878, Train: 0.9929, Val: 0.7920, Test: 0.7850
Epoch: 59, Loss: 2.8840, Train: 0.9929, Val: 0.7900, Test: 0.7900
Epoch: 60, Loss: 2.6797, Train: 0.9929, Val: 0.7900, Test: 0.7900
Epoch: 61, Loss: 2.9066, Train: 0.9929, Val: 0.7900, Test: 0.7920
Epoch: 62, Loss: 2.5490, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 63, Loss: 2.3505, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 64, Loss: 2.4540, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 65, Loss: 2.5429, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 66, Loss: 2.9947, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 67, Loss: 2.5553, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 68, Loss: 2.4335, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 69, Loss: 2.4941, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 70, Loss: 2.8897, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 71, Loss: 3.0224, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 72, Loss: 2.7107, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 73, Loss: 2.6533, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 74, Loss: 2.4212, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 75, Loss: 2.7027, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 76, Loss: 2.5616, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 77, Loss: 2.4882, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 78, Loss: 2.4974, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 79, Loss: 2.6515, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 80, Loss: 2.4213, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 81, Loss: 2.4551, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 82, Loss: 2.7429, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 83, Loss: 2.7880, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 84, Loss: 2.6973, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 85, Loss: 2.5928, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 86, Loss: 2.2738, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 87, Loss: 2.5284, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 88, Loss: 2.4418, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 89, Loss: 2.7644, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 90, Loss: 2.4156, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 91, Loss: 2.3481, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 92, Loss: 2.5376, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 93, Loss: 2.4851, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 94, Loss: 2.5722, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 95, Loss: 2.7133, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 96, Loss: 2.5155, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 97, Loss: 2.3368, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 98, Loss: 2.0273, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 99, Loss: 2.5839, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 100, Loss: 2.5053, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 101, Loss: 2.5765, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 102, Loss: 2.3513, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 103, Loss: 2.5871, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 104, Loss: 2.5209, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 105, Loss: 2.6911, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 106, Loss: 2.4249, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 107, Loss: 2.2672, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 108, Loss: 2.1575, Train: 1.0000, Val: 0.7740, Test: 0.7850
Epoch: 109, Loss: 2.4347, Train: 1.0000, Val: 0.7720, Test: 0.7860
Epoch: 110, Loss: 2.5433, Train: 1.0000, Val: 0.7700, Test: 0.7830
Epoch: 111, Loss: 2.7554, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 112, Loss: 2.3603, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 113, Loss: 2.1502, Train: 1.0000, Val: 0.7680, Test: 0.7830
Epoch: 114, Loss: 2.6417, Train: 1.0000, Val: 0.7700, Test: 0.7820
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 115, Loss: 2.5685, Train: 1.0000, Val: 0.7680, Test: 0.7830
Epoch: 116, Loss: 2.2691, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 117, Loss: 2.6399, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 118, Loss: 2.5685, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 119, Loss: 2.5251, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 120, Loss: 2.4828, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 121, Loss: 2.3728, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 122, Loss: 2.4280, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 123, Loss: 2.5364, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 124, Loss: 2.4616, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 125, Loss: 2.7004, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 126, Loss: 2.3233, Train: 1.0000, Val: 0.7740, Test: 0.7850
Epoch: 127, Loss: 2.6083, Train: 1.0000, Val: 0.7740, Test: 0.7860
Epoch: 128, Loss: 2.8352, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 129, Loss: 2.3562, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 130, Loss: 2.4516, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 131, Loss: 2.5284, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 132, Loss: 2.4076, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 133, Loss: 2.0733, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 134, Loss: 2.5552, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 135, Loss: 2.8222, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 136, Loss: 2.6144, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 137, Loss: 2.3518, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 138, Loss: 3.0214, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 139, Loss: 2.1128, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 140, Loss: 2.2858, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 141, Loss: 2.3942, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 142, Loss: 2.4824, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 143, Loss: 2.5564, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 144, Loss: 2.0368, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 145, Loss: 2.3485, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 146, Loss: 2.3474, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 147, Loss: 2.5607, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 148, Loss: 2.2087, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 149, Loss: 2.8331, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 150, Loss: 2.5975, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 151, Loss: 2.2467, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 152, Loss: 2.4252, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 153, Loss: 2.1409, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 154, Loss: 2.7001, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 155, Loss: 2.1398, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 156, Loss: 2.5229, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 157, Loss: 2.4839, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 158, Loss: 2.4444, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 159, Loss: 2.6563, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 160, Loss: 2.6960, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 161, Loss: 2.5129, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 162, Loss: 2.5972, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 163, Loss: 2.7324, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 164, Loss: 2.5573, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 165, Loss: 2.9367, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 166, Loss: 2.2756, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 167, Loss: 2.5268, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 168, Loss: 2.4794, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 169, Loss: 2.4509, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 170, Loss: 2.2116, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 171, Loss: 2.6912, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 172, Loss: 2.4621, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 173, Loss: 2.1095, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 174, Loss: 2.3138, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 175, Loss: 2.4257, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 176, Loss: 2.8369, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 177, Loss: 2.3039, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 178, Loss: 2.3449, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 179, Loss: 2.4448, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 180, Loss: 2.8780, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 181, Loss: 2.3188, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 182, Loss: 2.4442, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 183, Loss: 2.0651, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 184, Loss: 2.8976, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 185, Loss: 2.2737, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 186, Loss: 2.4188, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 187, Loss: 2.2870, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 188, Loss: 2.4883, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 189, Loss: 2.4795, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 190, Loss: 2.8564, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 191, Loss: 2.2395, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 192, Loss: 2.5926, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 193, Loss: 2.2726, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 194, Loss: 2.3053, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 195, Loss: 2.2313, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 196, Loss: 2.6519, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 197, Loss: 2.5789, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 198, Loss: 2.3020, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 199, Loss: 2.1338, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 200, Loss: 2.2460, Train: 1.0000, Val: 0.7760, Test: 0.7940
MAD:  0.13
Best Test Accuracy: 0.8110, Val Accuracy: 0.8040, Train Accuracy: 0.9643
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8535, Train: 0.1643, Val: 0.1600, Test: 0.1480
Epoch: 2, Loss: 4.8260, Train: 0.2571, Val: 0.2120, Test: 0.1990
Epoch: 3, Loss: 4.7806, Train: 0.3786, Val: 0.2740, Test: 0.2610
Epoch: 4, Loss: 4.7452, Train: 0.4714, Val: 0.3420, Test: 0.3620
Epoch: 5, Loss: 4.6866, Train: 0.4786, Val: 0.3860, Test: 0.4210
Epoch: 6, Loss: 4.6618, Train: 0.5071, Val: 0.4140, Test: 0.4480
Epoch: 7, Loss: 4.5853, Train: 0.5214, Val: 0.4200, Test: 0.4650
Epoch: 8, Loss: 4.5221, Train: 0.5286, Val: 0.4300, Test: 0.4700
Epoch: 9, Loss: 4.4799, Train: 0.4929, Val: 0.4160, Test: 0.4530
Epoch: 10, Loss: 4.3352, Train: 0.4857, Val: 0.4160, Test: 0.4510
Epoch: 11, Loss: 4.3401, Train: 0.4857, Val: 0.4140, Test: 0.4510
Epoch: 12, Loss: 4.1229, Train: 0.4786, Val: 0.4060, Test: 0.4420
Epoch: 13, Loss: 4.0329, Train: 0.4714, Val: 0.3860, Test: 0.4330
Epoch: 14, Loss: 3.9495, Train: 0.4571, Val: 0.3840, Test: 0.4280
Epoch: 15, Loss: 3.8295, Train: 0.4500, Val: 0.3820, Test: 0.4250
Epoch: 16, Loss: 3.7945, Train: 0.4786, Val: 0.3780, Test: 0.4250
Epoch: 17, Loss: 3.5943, Train: 0.4929, Val: 0.3920, Test: 0.4290
Epoch: 18, Loss: 3.7359, Train: 0.5071, Val: 0.4280, Test: 0.4610
Epoch: 19, Loss: 3.3099, Train: 0.5857, Val: 0.4860, Test: 0.5020
Epoch: 20, Loss: 3.6007, Train: 0.6929, Val: 0.5740, Test: 0.5840
Epoch: 21, Loss: 3.5303, Train: 0.7500, Val: 0.6560, Test: 0.6670
Epoch: 22, Loss: 3.5390, Train: 0.8357, Val: 0.7200, Test: 0.7290
Epoch: 23, Loss: 3.4689, Train: 0.9000, Val: 0.7740, Test: 0.7770
Epoch: 24, Loss: 3.3919, Train: 0.9643, Val: 0.7840, Test: 0.7970
Epoch: 25, Loss: 3.1620, Train: 0.9714, Val: 0.7700, Test: 0.7900
Epoch: 26, Loss: 2.9630, Train: 0.9714, Val: 0.7540, Test: 0.7720
Epoch: 27, Loss: 3.3490, Train: 0.9786, Val: 0.7380, Test: 0.7400
Epoch: 28, Loss: 3.5577, Train: 0.9714, Val: 0.7180, Test: 0.7270
Epoch: 29, Loss: 3.1188, Train: 0.9643, Val: 0.7080, Test: 0.7120
Epoch: 30, Loss: 3.0460, Train: 0.9643, Val: 0.7180, Test: 0.7130
Epoch: 31, Loss: 3.1762, Train: 0.9714, Val: 0.7220, Test: 0.7300
Epoch: 32, Loss: 3.2715, Train: 0.9786, Val: 0.7280, Test: 0.7390
Epoch: 33, Loss: 3.1600, Train: 0.9786, Val: 0.7440, Test: 0.7610
Epoch: 34, Loss: 3.0008, Train: 0.9786, Val: 0.7520, Test: 0.7720
Epoch: 35, Loss: 3.0588, Train: 0.9857, Val: 0.7640, Test: 0.7910
Epoch: 36, Loss: 3.1449, Train: 0.9857, Val: 0.7740, Test: 0.8010
Epoch: 37, Loss: 2.7221, Train: 0.9857, Val: 0.7820, Test: 0.8060
Epoch: 38, Loss: 3.1006, Train: 0.9857, Val: 0.7920, Test: 0.8100
Epoch: 39, Loss: 2.9273, Train: 0.9857, Val: 0.7900, Test: 0.8130
Epoch: 40, Loss: 2.9257, Train: 0.9857, Val: 0.7960, Test: 0.8110
Epoch: 41, Loss: 2.9583, Train: 0.9929, Val: 0.8000, Test: 0.8140
Epoch: 42, Loss: 2.8504, Train: 0.9929, Val: 0.8060, Test: 0.8170
Epoch: 43, Loss: 2.8904, Train: 0.9857, Val: 0.8020, Test: 0.8190
Epoch: 44, Loss: 2.8287, Train: 0.9857, Val: 0.8060, Test: 0.8210
Epoch: 45, Loss: 2.9129, Train: 0.9857, Val: 0.8060, Test: 0.8190
Epoch: 46, Loss: 2.9545, Train: 0.9857, Val: 0.8000, Test: 0.8190
Epoch: 47, Loss: 2.8696, Train: 0.9857, Val: 0.8040, Test: 0.8200
Epoch: 48, Loss: 2.8914, Train: 0.9857, Val: 0.8000, Test: 0.8200
Epoch: 49, Loss: 2.8515, Train: 0.9857, Val: 0.8000, Test: 0.8220
Epoch: 50, Loss: 2.7790, Train: 0.9857, Val: 0.7960, Test: 0.8220
Epoch: 51, Loss: 2.7688, Train: 0.9857, Val: 0.7980, Test: 0.8190
Epoch: 52, Loss: 2.3738, Train: 0.9857, Val: 0.7940, Test: 0.8160
Epoch: 53, Loss: 2.5826, Train: 0.9857, Val: 0.7880, Test: 0.8180
Epoch: 54, Loss: 2.8473, Train: 0.9857, Val: 0.7840, Test: 0.8080
Epoch: 55, Loss: 2.8464, Train: 0.9857, Val: 0.7780, Test: 0.8020
Epoch: 56, Loss: 2.4917, Train: 0.9929, Val: 0.7800, Test: 0.7950
Epoch: 57, Loss: 2.7788, Train: 0.9929, Val: 0.7800, Test: 0.7930
Epoch: 58, Loss: 3.0713, Train: 0.9929, Val: 0.7860, Test: 0.7920
Epoch: 59, Loss: 2.8510, Train: 1.0000, Val: 0.7860, Test: 0.7910
Epoch: 60, Loss: 2.4770, Train: 1.0000, Val: 0.7900, Test: 0.7920
Epoch: 61, Loss: 2.5887, Train: 1.0000, Val: 0.7940, Test: 0.7970
Epoch: 62, Loss: 2.8530, Train: 1.0000, Val: 0.7980, Test: 0.8050
Epoch: 63, Loss: 2.8545, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 64, Loss: 2.4540, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 65, Loss: 2.6464, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 66, Loss: 2.4924, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 67, Loss: 2.5114, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 68, Loss: 2.6469, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 69, Loss: 2.6324, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 70, Loss: 2.0827, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 71, Loss: 2.6167, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 72, Loss: 2.4213, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 73, Loss: 2.4538, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 74, Loss: 2.1694, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 75, Loss: 2.4667, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 76, Loss: 2.6718, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 77, Loss: 2.7354, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 78, Loss: 2.6016, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 79, Loss: 2.9498, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 80, Loss: 2.4310, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 81, Loss: 2.3956, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 82, Loss: 2.3517, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 83, Loss: 2.7464, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 84, Loss: 2.4202, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 85, Loss: 2.8325, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 86, Loss: 2.4740, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 87, Loss: 2.5400, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 88, Loss: 2.6439, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 89, Loss: 2.3412, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 90, Loss: 2.7042, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 91, Loss: 3.0764, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 92, Loss: 2.3765, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 93, Loss: 2.2879, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 94, Loss: 2.7642, Train: 1.0000, Val: 0.7920, Test: 0.8120
Epoch: 95, Loss: 2.2222, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 96, Loss: 2.7777, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 97, Loss: 2.6527, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 98, Loss: 2.5904, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 99, Loss: 2.4115, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 100, Loss: 2.6236, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 101, Loss: 2.1113, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 102, Loss: 1.9894, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 103, Loss: 2.0793, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 104, Loss: 2.5497, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 105, Loss: 2.3729, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 106, Loss: 2.4710, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 107, Loss: 2.7103, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 108, Loss: 2.4407, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 109, Loss: 2.4622, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 110, Loss: 2.4132, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 111, Loss: 2.5227, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 112, Loss: 2.4679, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 113, Loss: 2.5162, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 114, Loss: 2.3112, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 115, Loss: 2.7502, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 116, Loss: 2.3222, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 117, Loss: 2.5322, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 118, Loss: 2.4644, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 119, Loss: 2.6808, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 120, Loss: 2.1910, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 121, Loss: 2.4381, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 122, Loss: 2.5564, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 123, Loss: 2.0801, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 124, Loss: 2.2538, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 125, Loss: 2.7698, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 126, Loss: 3.0454, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 127, Loss: 2.5328, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 128, Loss: 2.3766, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 129, Loss: 2.3586, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 130, Loss: 2.6549, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 131, Loss: 2.5105, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 132, Loss: 2.4122, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 133, Loss: 2.4597, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 134, Loss: 2.0880, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 135, Loss: 2.5116, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 136, Loss: 2.5556, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 137, Loss: 2.5757, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 138, Loss: 2.6523, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 139, Loss: 2.3985, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 140, Loss: 2.5297, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 141, Loss: 2.5197, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 142, Loss: 2.5647, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 143, Loss: 2.5493, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 144, Loss: 2.6720, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 145, Loss: 2.7763, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 146, Loss: 2.2706, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 147, Loss: 2.2875, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 148, Loss: 2.5658, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 149, Loss: 2.5583, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 150, Loss: 2.5270, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 151, Loss: 2.6942, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 152, Loss: 2.6575, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 153, Loss: 2.4685, Train: 1.0000, Val: 0.7880, Test: 0.8040
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 2.8705, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 155, Loss: 2.3853, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 156, Loss: 2.2778, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 157, Loss: 2.5553, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 158, Loss: 2.5125, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 159, Loss: 2.2102, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 160, Loss: 2.8957, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 161, Loss: 2.1774, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 162, Loss: 2.7991, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 163, Loss: 2.3080, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 164, Loss: 2.4902, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 165, Loss: 2.4956, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 166, Loss: 2.4477, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 167, Loss: 2.2784, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 168, Loss: 2.3507, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 169, Loss: 2.6694, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 170, Loss: 2.3111, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 171, Loss: 2.2051, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 172, Loss: 2.6253, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 173, Loss: 2.2110, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 174, Loss: 2.6617, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 175, Loss: 2.2491, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 176, Loss: 2.3835, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 177, Loss: 2.6262, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 178, Loss: 2.0792, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 179, Loss: 2.5197, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 180, Loss: 2.3781, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 181, Loss: 2.5501, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 182, Loss: 2.4810, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 183, Loss: 2.6917, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 184, Loss: 2.4445, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 185, Loss: 2.5564, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 186, Loss: 2.5168, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 187, Loss: 2.1669, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 188, Loss: 2.5791, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 189, Loss: 2.4385, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 190, Loss: 2.2782, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 191, Loss: 2.4534, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 192, Loss: 2.5143, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 193, Loss: 2.1389, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 194, Loss: 2.8531, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 195, Loss: 2.5245, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 196, Loss: 2.4110, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 197, Loss: 2.6619, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 198, Loss: 2.5528, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 199, Loss: 2.8632, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 200, Loss: 2.3435, Train: 1.0000, Val: 0.7760, Test: 0.8000
MAD:  0.2477
Best Test Accuracy: 0.8220, Val Accuracy: 0.8000, Train Accuracy: 0.9857
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8554, Train: 0.2214, Val: 0.0940, Test: 0.0840
Epoch: 2, Loss: 4.8366, Train: 0.2929, Val: 0.2240, Test: 0.2040
Epoch: 3, Loss: 4.7971, Train: 0.3643, Val: 0.2500, Test: 0.2460
Epoch: 4, Loss: 4.7542, Train: 0.3714, Val: 0.2600, Test: 0.2540
Epoch: 5, Loss: 4.7224, Train: 0.4000, Val: 0.2680, Test: 0.2580
Epoch: 6, Loss: 4.6730, Train: 0.4071, Val: 0.2600, Test: 0.2610
Epoch: 7, Loss: 4.6506, Train: 0.4143, Val: 0.2580, Test: 0.2580
Epoch: 8, Loss: 4.5164, Train: 0.4071, Val: 0.2580, Test: 0.2500
Epoch: 9, Loss: 4.5842, Train: 0.3929, Val: 0.2380, Test: 0.2380
Epoch: 10, Loss: 4.5614, Train: 0.3857, Val: 0.2360, Test: 0.2320
Epoch: 11, Loss: 4.4494, Train: 0.3857, Val: 0.2360, Test: 0.2370
Epoch: 12, Loss: 4.2277, Train: 0.4000, Val: 0.2300, Test: 0.2360
Epoch: 13, Loss: 4.2292, Train: 0.4000, Val: 0.2320, Test: 0.2390
Epoch: 14, Loss: 4.2371, Train: 0.4071, Val: 0.2380, Test: 0.2410
Epoch: 15, Loss: 4.0354, Train: 0.4214, Val: 0.2440, Test: 0.2430
Epoch: 16, Loss: 3.9520, Train: 0.4286, Val: 0.2520, Test: 0.2540
Epoch: 17, Loss: 3.8835, Train: 0.4429, Val: 0.2600, Test: 0.2700
Epoch: 18, Loss: 3.6413, Train: 0.4786, Val: 0.2860, Test: 0.2960
Epoch: 19, Loss: 3.9824, Train: 0.5286, Val: 0.3360, Test: 0.3420
Epoch: 20, Loss: 3.6415, Train: 0.5714, Val: 0.3860, Test: 0.4090
Epoch: 21, Loss: 3.4640, Train: 0.6571, Val: 0.4700, Test: 0.4630
Epoch: 22, Loss: 3.7391, Train: 0.7714, Val: 0.5820, Test: 0.5780
Epoch: 23, Loss: 3.5637, Train: 0.8857, Val: 0.6600, Test: 0.6880
Epoch: 24, Loss: 3.1083, Train: 0.9286, Val: 0.7260, Test: 0.7330
Epoch: 25, Loss: 3.5584, Train: 0.9357, Val: 0.7480, Test: 0.7540
Epoch: 26, Loss: 3.2892, Train: 0.9357, Val: 0.7520, Test: 0.7660
Epoch: 27, Loss: 3.4927, Train: 0.9357, Val: 0.7600, Test: 0.7610
Epoch: 28, Loss: 3.2551, Train: 0.9357, Val: 0.7560, Test: 0.7640
Epoch: 29, Loss: 3.1016, Train: 0.9429, Val: 0.7560, Test: 0.7670
Epoch: 30, Loss: 3.3829, Train: 0.9429, Val: 0.7620, Test: 0.7680
Epoch: 31, Loss: 3.1047, Train: 0.9714, Val: 0.7720, Test: 0.7670
Epoch: 32, Loss: 3.3900, Train: 0.9643, Val: 0.7680, Test: 0.7700
Epoch: 33, Loss: 3.2994, Train: 0.9643, Val: 0.7680, Test: 0.7680
Epoch: 34, Loss: 3.4729, Train: 0.9714, Val: 0.7780, Test: 0.7780
Epoch: 35, Loss: 2.9665, Train: 0.9714, Val: 0.7860, Test: 0.7910
Epoch: 36, Loss: 3.0986, Train: 0.9643, Val: 0.7940, Test: 0.7980
Epoch: 37, Loss: 3.0868, Train: 0.9714, Val: 0.7920, Test: 0.8000
Epoch: 38, Loss: 2.8307, Train: 0.9786, Val: 0.7920, Test: 0.8000
Epoch: 39, Loss: 3.0874, Train: 0.9786, Val: 0.7940, Test: 0.7930
Epoch: 40, Loss: 3.0221, Train: 0.9786, Val: 0.8040, Test: 0.7960
Epoch: 41, Loss: 2.7631, Train: 0.9857, Val: 0.8100, Test: 0.7960
Epoch: 42, Loss: 2.9436, Train: 0.9857, Val: 0.8080, Test: 0.7970
Epoch: 43, Loss: 3.2241, Train: 0.9857, Val: 0.8060, Test: 0.7950
Epoch: 44, Loss: 2.6787, Train: 0.9857, Val: 0.8020, Test: 0.7950
Epoch: 45, Loss: 2.8777, Train: 0.9786, Val: 0.8000, Test: 0.7950
Epoch: 46, Loss: 2.8321, Train: 0.9929, Val: 0.7920, Test: 0.8010
Epoch: 47, Loss: 2.8813, Train: 0.9857, Val: 0.7900, Test: 0.8040
Epoch: 48, Loss: 2.9488, Train: 0.9857, Val: 0.7920, Test: 0.8040
Epoch: 49, Loss: 2.8207, Train: 0.9857, Val: 0.7960, Test: 0.8070
Epoch: 50, Loss: 2.2847, Train: 0.9857, Val: 0.7980, Test: 0.8080
Epoch: 51, Loss: 3.2360, Train: 0.9857, Val: 0.7920, Test: 0.8080
Epoch: 52, Loss: 2.9558, Train: 0.9857, Val: 0.7920, Test: 0.8040
Epoch: 53, Loss: 2.8097, Train: 0.9857, Val: 0.7900, Test: 0.8020
Epoch: 54, Loss: 2.9662, Train: 0.9857, Val: 0.7900, Test: 0.8020
Epoch: 55, Loss: 2.5195, Train: 0.9857, Val: 0.7820, Test: 0.8000
Epoch: 56, Loss: 2.7244, Train: 0.9857, Val: 0.7800, Test: 0.8040
Epoch: 57, Loss: 2.8272, Train: 0.9929, Val: 0.7740, Test: 0.8070
Epoch: 58, Loss: 2.6221, Train: 0.9929, Val: 0.7740, Test: 0.8030
Epoch: 59, Loss: 2.5288, Train: 0.9929, Val: 0.7740, Test: 0.8020
Epoch: 60, Loss: 2.6093, Train: 0.9929, Val: 0.7800, Test: 0.8070
Epoch: 61, Loss: 2.5385, Train: 0.9929, Val: 0.7820, Test: 0.8110
Epoch: 62, Loss: 2.5468, Train: 0.9929, Val: 0.7880, Test: 0.8080
Epoch: 63, Loss: 2.9147, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 64, Loss: 2.7284, Train: 1.0000, Val: 0.7960, Test: 0.8070
Epoch: 65, Loss: 2.9376, Train: 1.0000, Val: 0.8000, Test: 0.8020
Epoch: 66, Loss: 2.8782, Train: 1.0000, Val: 0.8000, Test: 0.8010
Epoch: 67, Loss: 2.3679, Train: 1.0000, Val: 0.7980, Test: 0.8010
Epoch: 68, Loss: 2.8760, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 69, Loss: 2.7495, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 70, Loss: 2.4723, Train: 1.0000, Val: 0.7860, Test: 0.7930
Epoch: 71, Loss: 2.7735, Train: 1.0000, Val: 0.7860, Test: 0.7930
Epoch: 72, Loss: 2.8968, Train: 1.0000, Val: 0.7860, Test: 0.7940
Epoch: 73, Loss: 2.2083, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 74, Loss: 2.6020, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 75, Loss: 2.2420, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 76, Loss: 2.2739, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 77, Loss: 2.7899, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 78, Loss: 2.5892, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 79, Loss: 2.3210, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 80, Loss: 2.6095, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 81, Loss: 2.1881, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 82, Loss: 2.5438, Train: 1.0000, Val: 0.7860, Test: 0.7940
Epoch: 83, Loss: 2.7818, Train: 1.0000, Val: 0.7880, Test: 0.7940
Epoch: 84, Loss: 2.3218, Train: 1.0000, Val: 0.7880, Test: 0.7950
Epoch: 85, Loss: 2.5471, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 86, Loss: 2.5056, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 87, Loss: 2.4386, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 88, Loss: 2.6540, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 89, Loss: 2.6670, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 90, Loss: 2.2626, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 91, Loss: 2.6837, Train: 1.0000, Val: 0.7800, Test: 0.7890
Epoch: 92, Loss: 2.4395, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 93, Loss: 2.7087, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 94, Loss: 2.3631, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 95, Loss: 2.3910, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 96, Loss: 2.4093, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 97, Loss: 2.5932, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 98, Loss: 2.5680, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 99, Loss: 2.2060, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 100, Loss: 2.8256, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 101, Loss: 2.4794, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 102, Loss: 2.3369, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 103, Loss: 2.2791, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 104, Loss: 2.6825, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 105, Loss: 2.6666, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 106, Loss: 2.6943, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 107, Loss: 2.2933, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 108, Loss: 3.1735, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 109, Loss: 3.0345, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 110, Loss: 2.2853, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 111, Loss: 2.4864, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 112, Loss: 2.7680, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 113, Loss: 2.3975, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 114, Loss: 2.6298, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 115, Loss: 2.6800, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 116, Loss: 2.5361, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 117, Loss: 2.3833, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 118, Loss: 2.1485, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 119, Loss: 2.3031, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 120, Loss: 2.3234, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 121, Loss: 2.1937, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 122, Loss: 2.4994, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 123, Loss: 2.7809, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 124, Loss: 2.4348, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 125, Loss: 2.5708, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 126, Loss: 2.4364, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 127, Loss: 2.4616, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 128, Loss: 2.5004, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 129, Loss: 2.4077, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 130, Loss: 2.3634, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 131, Loss: 2.6370, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 132, Loss: 2.4590, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 133, Loss: 2.5673, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 134, Loss: 2.7006, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 135, Loss: 2.7024, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 136, Loss: 2.2833, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 137, Loss: 2.5968, Train: 1.0000, Val: 0.7920, Test: 0.7980
Epoch: 138, Loss: 2.2243, Train: 1.0000, Val: 0.7900, Test: 0.7980
Epoch: 139, Loss: 2.6013, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 140, Loss: 2.1843, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 141, Loss: 2.5252, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 142, Loss: 2.8028, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 143, Loss: 2.5955, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 144, Loss: 2.4599, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 145, Loss: 2.6218, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 146, Loss: 2.4697, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 147, Loss: 2.4559, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 148, Loss: 2.7902, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 149, Loss: 2.5209, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 150, Loss: 2.2792, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 151, Loss: 2.3130, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 152, Loss: 2.4373, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 153, Loss: 2.6636, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 154, Loss: 2.4549, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 155, Loss: 2.5209, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 156, Loss: 2.2143, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 157, Loss: 2.6046, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 158, Loss: 2.4617, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 159, Loss: 2.3133, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 160, Loss: 2.5319, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 161, Loss: 2.4889, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 162, Loss: 2.5554, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 163, Loss: 2.3943, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 164, Loss: 2.2842, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 165, Loss: 2.7084, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 166, Loss: 2.5509, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 167, Loss: 2.5312, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 168, Loss: 2.4594, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 169, Loss: 2.4141, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 170, Loss: 2.6935, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 171, Loss: 2.5524, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 172, Loss: 2.4569, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 173, Loss: 2.4887, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 174, Loss: 2.4504, Train: 1.0000, Val: 0.7840, Test: 0.7910
Epoch: 175, Loss: 2.1045, Train: 1.0000, Val: 0.7840, Test: 0.7920
Epoch: 176, Loss: 2.4241, Train: 1.0000, Val: 0.7840, Test: 0.7920
Epoch: 177, Loss: 2.3465, Train: 1.0000, Val: 0.7900, Test: 0.7940
Epoch: 178, Loss: 2.3809, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 179, Loss: 2.8367, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 180, Loss: 2.4828, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 181, Loss: 2.2824, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 182, Loss: 2.5796, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 183, Loss: 2.4854, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 184, Loss: 2.3479, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 185, Loss: 2.5304, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 186, Loss: 2.6197, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 187, Loss: 2.5118, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 188, Loss: 2.8231, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 189, Loss: 2.6235, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 190, Loss: 2.7552, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 191, Loss: 2.5512, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 192, Loss: 2.4889, Train: 1.0000, Val: 0.7760, Test: 0.8010
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 2.6921, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 194, Loss: 2.4786, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 195, Loss: 2.6531, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 196, Loss: 2.5493, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 197, Loss: 2.7639, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 198, Loss: 2.1418, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 199, Loss: 2.2658, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 200, Loss: 2.0632, Train: 1.0000, Val: 0.7720, Test: 0.8010
MAD:  0.3972
Best Test Accuracy: 0.8110, Val Accuracy: 0.7820, Train Accuracy: 0.9929
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8470, Train: 0.2500, Val: 0.1020, Test: 0.1160
Epoch: 2, Loss: 4.8286, Train: 0.4286, Val: 0.2140, Test: 0.2300
Epoch: 3, Loss: 4.7864, Train: 0.5214, Val: 0.2920, Test: 0.2900
Epoch: 4, Loss: 4.7502, Train: 0.6143, Val: 0.3600, Test: 0.3680
Epoch: 5, Loss: 4.7036, Train: 0.7000, Val: 0.4440, Test: 0.4470
Epoch: 6, Loss: 4.6572, Train: 0.7429, Val: 0.5060, Test: 0.5020
Epoch: 7, Loss: 4.6282, Train: 0.7714, Val: 0.5600, Test: 0.5480
Epoch: 8, Loss: 4.5500, Train: 0.7929, Val: 0.5800, Test: 0.5760
Epoch: 9, Loss: 4.4532, Train: 0.7929, Val: 0.5880, Test: 0.5940
Epoch: 10, Loss: 4.3810, Train: 0.8000, Val: 0.6060, Test: 0.6080
Epoch: 11, Loss: 4.3597, Train: 0.8143, Val: 0.6100, Test: 0.6150
Epoch: 12, Loss: 4.2745, Train: 0.8214, Val: 0.6060, Test: 0.6110
Epoch: 13, Loss: 4.1888, Train: 0.8286, Val: 0.6020, Test: 0.6100
Epoch: 14, Loss: 4.1089, Train: 0.8286, Val: 0.6040, Test: 0.6160
Epoch: 15, Loss: 4.0407, Train: 0.8286, Val: 0.5960, Test: 0.6110
Epoch: 16, Loss: 3.7821, Train: 0.8286, Val: 0.6020, Test: 0.6140
Epoch: 17, Loss: 3.7407, Train: 0.8286, Val: 0.5960, Test: 0.6070
Epoch: 18, Loss: 3.5108, Train: 0.8071, Val: 0.5880, Test: 0.5980
Epoch: 19, Loss: 3.6884, Train: 0.8071, Val: 0.5940, Test: 0.6040
Epoch: 20, Loss: 3.6559, Train: 0.8143, Val: 0.6040, Test: 0.6140
Epoch: 21, Loss: 3.5921, Train: 0.8214, Val: 0.6020, Test: 0.6190
Epoch: 22, Loss: 3.4042, Train: 0.8214, Val: 0.6160, Test: 0.6310
Epoch: 23, Loss: 3.4555, Train: 0.8643, Val: 0.6320, Test: 0.6520
Epoch: 24, Loss: 3.3491, Train: 0.9000, Val: 0.6480, Test: 0.6840
Epoch: 25, Loss: 3.0589, Train: 0.9214, Val: 0.6800, Test: 0.7230
Epoch: 26, Loss: 3.5145, Train: 0.9357, Val: 0.7300, Test: 0.7560
Epoch: 27, Loss: 3.6517, Train: 0.9643, Val: 0.7620, Test: 0.7690
Epoch: 28, Loss: 3.1286, Train: 0.9714, Val: 0.7700, Test: 0.7820
Epoch: 29, Loss: 3.1680, Train: 0.9714, Val: 0.7720, Test: 0.7800
Epoch: 30, Loss: 3.3756, Train: 0.9714, Val: 0.7460, Test: 0.7660
Epoch: 31, Loss: 2.8913, Train: 0.9643, Val: 0.7320, Test: 0.7510
Epoch: 32, Loss: 2.9952, Train: 0.9643, Val: 0.7260, Test: 0.7380
Epoch: 33, Loss: 2.9112, Train: 0.9643, Val: 0.7160, Test: 0.7360
Epoch: 34, Loss: 2.8572, Train: 0.9643, Val: 0.7260, Test: 0.7370
Epoch: 35, Loss: 2.9491, Train: 0.9643, Val: 0.7300, Test: 0.7510
Epoch: 36, Loss: 3.2466, Train: 0.9714, Val: 0.7440, Test: 0.7600
Epoch: 37, Loss: 3.1124, Train: 0.9786, Val: 0.7580, Test: 0.7750
Epoch: 38, Loss: 3.2842, Train: 0.9857, Val: 0.7760, Test: 0.7810
Epoch: 39, Loss: 3.2358, Train: 0.9857, Val: 0.7840, Test: 0.7900
Epoch: 40, Loss: 3.2674, Train: 0.9857, Val: 0.8000, Test: 0.7940
Epoch: 41, Loss: 2.7831, Train: 0.9857, Val: 0.8020, Test: 0.7910
Epoch: 42, Loss: 2.6315, Train: 0.9857, Val: 0.8080, Test: 0.7970
Epoch: 43, Loss: 2.9642, Train: 0.9857, Val: 0.8160, Test: 0.8050
Epoch: 44, Loss: 2.6659, Train: 0.9857, Val: 0.8200, Test: 0.8060
Epoch: 45, Loss: 2.8543, Train: 0.9857, Val: 0.8160, Test: 0.8080
Epoch: 46, Loss: 2.6397, Train: 0.9857, Val: 0.8180, Test: 0.8040
Epoch: 47, Loss: 2.7866, Train: 0.9857, Val: 0.8060, Test: 0.8020
Epoch: 48, Loss: 2.7787, Train: 0.9857, Val: 0.7980, Test: 0.7970
Epoch: 49, Loss: 2.8003, Train: 0.9857, Val: 0.7880, Test: 0.7930
Epoch: 50, Loss: 2.7115, Train: 0.9857, Val: 0.7880, Test: 0.7920
Epoch: 51, Loss: 2.6877, Train: 0.9857, Val: 0.7840, Test: 0.7970
Epoch: 52, Loss: 2.6028, Train: 0.9857, Val: 0.7820, Test: 0.7990
Epoch: 53, Loss: 2.9364, Train: 0.9857, Val: 0.7780, Test: 0.7980
Epoch: 54, Loss: 2.8592, Train: 0.9857, Val: 0.7800, Test: 0.8010
Epoch: 55, Loss: 2.7777, Train: 0.9857, Val: 0.7800, Test: 0.8060
Epoch: 56, Loss: 2.6293, Train: 0.9857, Val: 0.7800, Test: 0.8030
Epoch: 57, Loss: 2.7587, Train: 0.9929, Val: 0.7760, Test: 0.8040
Epoch: 58, Loss: 2.4084, Train: 0.9929, Val: 0.7820, Test: 0.8010
Epoch: 59, Loss: 2.8207, Train: 0.9929, Val: 0.7800, Test: 0.8020
Epoch: 60, Loss: 2.4544, Train: 0.9929, Val: 0.7800, Test: 0.8030
Epoch: 61, Loss: 2.4436, Train: 0.9929, Val: 0.7800, Test: 0.8030
Epoch: 62, Loss: 2.8819, Train: 0.9929, Val: 0.7820, Test: 0.8030
Epoch: 63, Loss: 2.9790, Train: 0.9929, Val: 0.7800, Test: 0.8020
Epoch: 64, Loss: 2.6870, Train: 0.9929, Val: 0.7800, Test: 0.8030
Epoch: 65, Loss: 3.1796, Train: 0.9929, Val: 0.7780, Test: 0.8030
Epoch: 66, Loss: 2.0677, Train: 0.9929, Val: 0.7760, Test: 0.8040
Epoch: 67, Loss: 2.4395, Train: 0.9929, Val: 0.7780, Test: 0.8050
Epoch: 68, Loss: 2.7552, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 69, Loss: 2.4314, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 70, Loss: 2.5727, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 71, Loss: 2.8218, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 72, Loss: 2.6230, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 73, Loss: 2.6820, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 74, Loss: 2.8534, Train: 1.0000, Val: 0.7940, Test: 0.8030
Epoch: 75, Loss: 2.4339, Train: 1.0000, Val: 0.7940, Test: 0.8020
Epoch: 76, Loss: 2.6953, Train: 1.0000, Val: 0.7920, Test: 0.8010
Epoch: 77, Loss: 2.5280, Train: 1.0000, Val: 0.7920, Test: 0.7980
Epoch: 78, Loss: 2.1326, Train: 1.0000, Val: 0.7900, Test: 0.7970
Epoch: 79, Loss: 2.3131, Train: 1.0000, Val: 0.7900, Test: 0.7980
Epoch: 80, Loss: 2.0544, Train: 1.0000, Val: 0.7900, Test: 0.7980
Epoch: 81, Loss: 2.4085, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 82, Loss: 2.2824, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 83, Loss: 2.4156, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 84, Loss: 2.3139, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 85, Loss: 2.4261, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 86, Loss: 2.6120, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 87, Loss: 2.7290, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 88, Loss: 2.5503, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 89, Loss: 2.4201, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 90, Loss: 2.3363, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 91, Loss: 2.7016, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 92, Loss: 2.2198, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 93, Loss: 2.5579, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 94, Loss: 2.6721, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 95, Loss: 2.3864, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 96, Loss: 2.3409, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 97, Loss: 2.6936, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 98, Loss: 2.6168, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 99, Loss: 2.2315, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 100, Loss: 2.3251, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 101, Loss: 2.2344, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 102, Loss: 2.5870, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 103, Loss: 2.8574, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 104, Loss: 2.4470, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 105, Loss: 2.3553, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 106, Loss: 2.4693, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 107, Loss: 2.3663, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 108, Loss: 2.4694, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 109, Loss: 2.1920, Train: 1.0000, Val: 0.7760, Test: 0.7960
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 110, Loss: 2.5706, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 111, Loss: 2.2630, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 112, Loss: 2.4605, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 113, Loss: 2.2962, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 114, Loss: 2.6794, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 115, Loss: 2.5614, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 116, Loss: 2.4786, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 117, Loss: 2.0894, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 118, Loss: 2.7557, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 119, Loss: 2.3238, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 120, Loss: 2.5776, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 121, Loss: 2.7745, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 122, Loss: 2.3540, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 123, Loss: 2.4736, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 124, Loss: 2.3730, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 125, Loss: 2.4819, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 126, Loss: 2.3405, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 127, Loss: 2.6469, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 128, Loss: 2.3883, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 129, Loss: 2.3142, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 130, Loss: 2.4264, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 131, Loss: 2.5574, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 132, Loss: 2.6145, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 133, Loss: 2.3956, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 134, Loss: 2.5328, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 135, Loss: 2.3286, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 136, Loss: 2.1820, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 137, Loss: 2.4960, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 138, Loss: 2.6369, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 139, Loss: 2.5340, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 140, Loss: 2.4455, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 141, Loss: 2.4340, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 142, Loss: 2.5282, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 143, Loss: 2.4218, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 144, Loss: 2.5289, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 145, Loss: 2.8093, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 146, Loss: 2.2896, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 147, Loss: 2.7695, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 148, Loss: 2.0000, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 149, Loss: 2.3542, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 150, Loss: 2.6914, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 151, Loss: 2.7052, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 152, Loss: 2.4163, Train: 1.0000, Val: 0.7960, Test: 0.8080
Epoch: 153, Loss: 2.6222, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 154, Loss: 2.4893, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 155, Loss: 2.6963, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 156, Loss: 2.6700, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 157, Loss: 2.7016, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 158, Loss: 2.5999, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 159, Loss: 2.2090, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 160, Loss: 2.5849, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 161, Loss: 2.5823, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 162, Loss: 2.5604, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 163, Loss: 2.3146, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 164, Loss: 2.3547, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 165, Loss: 2.4501, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 166, Loss: 2.2596, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 167, Loss: 2.5566, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 168, Loss: 2.3212, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 169, Loss: 2.5630, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 170, Loss: 2.7453, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 171, Loss: 2.5541, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 172, Loss: 2.3462, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 173, Loss: 2.2698, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 174, Loss: 2.7109, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 175, Loss: 2.2077, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 176, Loss: 2.5618, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 177, Loss: 2.4603, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 178, Loss: 2.5334, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 179, Loss: 2.2066, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 180, Loss: 2.7607, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 181, Loss: 2.4189, Train: 1.0000, Val: 0.7900, Test: 0.8160
Epoch: 182, Loss: 2.6174, Train: 1.0000, Val: 0.7920, Test: 0.8160
Epoch: 183, Loss: 2.7605, Train: 1.0000, Val: 0.7940, Test: 0.8150
Epoch: 184, Loss: 2.8370, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 185, Loss: 2.3141, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 186, Loss: 2.4136, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 187, Loss: 2.5942, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 188, Loss: 2.3045, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 189, Loss: 2.4808, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 190, Loss: 2.2711, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 191, Loss: 2.8288, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 192, Loss: 2.3737, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 193, Loss: 2.8313, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 194, Loss: 2.5185, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 195, Loss: 2.5154, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 196, Loss: 2.0693, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 197, Loss: 2.5864, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 198, Loss: 2.4835, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 199, Loss: 2.4435, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 200, Loss: 2.2052, Train: 1.0000, Val: 0.7700, Test: 0.7960
MAD:  0.7366
Best Test Accuracy: 0.8160, Val Accuracy: 0.7900, Train Accuracy: 1.0000
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8504, Train: 0.2000, Val: 0.1480, Test: 0.1800
Epoch: 2, Loss: 4.8267, Train: 0.3429, Val: 0.3080, Test: 0.3120
Epoch: 3, Loss: 4.7982, Train: 0.3929, Val: 0.3560, Test: 0.3810
Epoch: 4, Loss: 4.7677, Train: 0.4143, Val: 0.3920, Test: 0.4050
Epoch: 5, Loss: 4.6922, Train: 0.4500, Val: 0.4040, Test: 0.4150
Epoch: 6, Loss: 4.6416, Train: 0.4571, Val: 0.4080, Test: 0.4140
Epoch: 7, Loss: 4.6154, Train: 0.4643, Val: 0.4160, Test: 0.4270
Epoch: 8, Loss: 4.5113, Train: 0.4643, Val: 0.4180, Test: 0.4290
Epoch: 9, Loss: 4.4786, Train: 0.4786, Val: 0.4120, Test: 0.4310
Epoch: 10, Loss: 4.3128, Train: 0.4857, Val: 0.4220, Test: 0.4370
Epoch: 11, Loss: 4.2577, Train: 0.5143, Val: 0.4240, Test: 0.4460
Epoch: 12, Loss: 4.2268, Train: 0.5143, Val: 0.4280, Test: 0.4570
Epoch: 13, Loss: 4.2049, Train: 0.5286, Val: 0.4440, Test: 0.4730
Epoch: 14, Loss: 3.9514, Train: 0.5286, Val: 0.4380, Test: 0.4850
Epoch: 15, Loss: 3.9701, Train: 0.5429, Val: 0.4420, Test: 0.4990
Epoch: 16, Loss: 4.0525, Train: 0.5500, Val: 0.4380, Test: 0.4950
Epoch: 17, Loss: 3.7088, Train: 0.5500, Val: 0.4280, Test: 0.4860
Epoch: 18, Loss: 3.6236, Train: 0.5429, Val: 0.4180, Test: 0.4700
Epoch: 19, Loss: 3.5881, Train: 0.5429, Val: 0.3960, Test: 0.4550
Epoch: 20, Loss: 3.6575, Train: 0.5714, Val: 0.4000, Test: 0.4510
Epoch: 21, Loss: 3.4522, Train: 0.6357, Val: 0.4060, Test: 0.4500
Epoch: 22, Loss: 3.6908, Train: 0.7500, Val: 0.4500, Test: 0.5040
Epoch: 23, Loss: 3.2172, Train: 0.8429, Val: 0.5220, Test: 0.5910
Epoch: 24, Loss: 3.7865, Train: 0.9429, Val: 0.6320, Test: 0.6980
Epoch: 25, Loss: 3.5721, Train: 0.9571, Val: 0.6940, Test: 0.7470
Epoch: 26, Loss: 3.3336, Train: 0.9714, Val: 0.7640, Test: 0.7650
Epoch: 27, Loss: 3.3718, Train: 0.9714, Val: 0.7740, Test: 0.7850
Epoch: 28, Loss: 3.0100, Train: 0.9786, Val: 0.7760, Test: 0.7910
Epoch: 29, Loss: 3.1159, Train: 0.9786, Val: 0.7880, Test: 0.8050
Epoch: 30, Loss: 3.0491, Train: 0.9857, Val: 0.7840, Test: 0.8030
Epoch: 31, Loss: 3.1589, Train: 0.9857, Val: 0.7880, Test: 0.8050
Epoch: 32, Loss: 2.9622, Train: 0.9857, Val: 0.7900, Test: 0.8050
Epoch: 33, Loss: 3.1471, Train: 0.9857, Val: 0.7940, Test: 0.8080
Epoch: 34, Loss: 3.2156, Train: 0.9786, Val: 0.7940, Test: 0.8160
Epoch: 35, Loss: 3.2991, Train: 0.9714, Val: 0.7980, Test: 0.8170
Epoch: 36, Loss: 3.3465, Train: 0.9714, Val: 0.8020, Test: 0.8130
Epoch: 37, Loss: 3.1273, Train: 0.9714, Val: 0.8040, Test: 0.8160
Epoch: 38, Loss: 3.3173, Train: 0.9643, Val: 0.8000, Test: 0.8140
Epoch: 39, Loss: 2.9837, Train: 0.9786, Val: 0.8000, Test: 0.8120
Epoch: 40, Loss: 2.7786, Train: 0.9786, Val: 0.7980, Test: 0.8080
Epoch: 41, Loss: 2.8464, Train: 0.9786, Val: 0.7860, Test: 0.8060
Epoch: 42, Loss: 3.0626, Train: 0.9786, Val: 0.7820, Test: 0.8030
Epoch: 43, Loss: 2.6932, Train: 0.9786, Val: 0.7760, Test: 0.8030
Epoch: 44, Loss: 2.7386, Train: 0.9786, Val: 0.7740, Test: 0.8030
Epoch: 45, Loss: 2.7426, Train: 0.9786, Val: 0.7720, Test: 0.8020
Epoch: 46, Loss: 2.9730, Train: 0.9786, Val: 0.7740, Test: 0.8030
Epoch: 47, Loss: 2.7931, Train: 0.9786, Val: 0.7800, Test: 0.8010
Epoch: 48, Loss: 2.6654, Train: 0.9786, Val: 0.7860, Test: 0.8030
Epoch: 49, Loss: 2.7550, Train: 0.9786, Val: 0.7880, Test: 0.8050
Epoch: 50, Loss: 2.9877, Train: 0.9929, Val: 0.7900, Test: 0.8080
Epoch: 51, Loss: 2.6259, Train: 0.9929, Val: 0.7900, Test: 0.8060
Epoch: 52, Loss: 2.8740, Train: 0.9929, Val: 0.7960, Test: 0.8050
Epoch: 53, Loss: 2.3972, Train: 0.9929, Val: 0.8000, Test: 0.8030
Epoch: 54, Loss: 2.9061, Train: 0.9929, Val: 0.7940, Test: 0.8030
Epoch: 55, Loss: 2.7979, Train: 0.9929, Val: 0.7900, Test: 0.8000
Epoch: 56, Loss: 2.7703, Train: 0.9929, Val: 0.7840, Test: 0.8030
Epoch: 57, Loss: 2.2980, Train: 0.9929, Val: 0.7840, Test: 0.8020
Epoch: 58, Loss: 2.3895, Train: 0.9929, Val: 0.7800, Test: 0.7990
Epoch: 59, Loss: 2.7294, Train: 0.9929, Val: 0.7820, Test: 0.7970
Epoch: 60, Loss: 2.8193, Train: 0.9929, Val: 0.7820, Test: 0.8010
Epoch: 61, Loss: 2.6196, Train: 0.9929, Val: 0.7880, Test: 0.8010
Epoch: 62, Loss: 2.6446, Train: 0.9929, Val: 0.7900, Test: 0.7990
Epoch: 63, Loss: 2.8455, Train: 0.9929, Val: 0.7880, Test: 0.8010
Epoch: 64, Loss: 2.6030, Train: 0.9929, Val: 0.7880, Test: 0.8040
Epoch: 65, Loss: 2.6545, Train: 0.9929, Val: 0.7900, Test: 0.8080
Epoch: 66, Loss: 2.7622, Train: 0.9929, Val: 0.7860, Test: 0.8050
Epoch: 67, Loss: 2.5815, Train: 0.9929, Val: 0.7880, Test: 0.8090
Epoch: 68, Loss: 2.6007, Train: 0.9929, Val: 0.7880, Test: 0.8090
Epoch: 69, Loss: 2.6681, Train: 0.9929, Val: 0.7900, Test: 0.8100
Epoch: 70, Loss: 2.6242, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 71, Loss: 2.8508, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 72, Loss: 2.6115, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 73, Loss: 2.5051, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 74, Loss: 2.5622, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 75, Loss: 2.5985, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 76, Loss: 2.6501, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 77, Loss: 2.3847, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 78, Loss: 2.3991, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 79, Loss: 2.5676, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 80, Loss: 2.1518, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 81, Loss: 2.6218, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 82, Loss: 2.5782, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 83, Loss: 2.3469, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 84, Loss: 2.6687, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 85, Loss: 2.8591, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 86, Loss: 2.3854, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 87, Loss: 2.5503, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 88, Loss: 2.4499, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 89, Loss: 2.4362, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 90, Loss: 2.5699, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 91, Loss: 3.0272, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 92, Loss: 2.3590, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 93, Loss: 2.5909, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 94, Loss: 2.8721, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 95, Loss: 2.4974, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 96, Loss: 2.3690, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 97, Loss: 2.1010, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 98, Loss: 2.7786, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 99, Loss: 2.7664, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 100, Loss: 2.1912, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 101, Loss: 2.7829, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 102, Loss: 2.5458, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 103, Loss: 2.5498, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 104, Loss: 2.4107, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 105, Loss: 2.4191, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 106, Loss: 2.8377, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 107, Loss: 2.5592, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 108, Loss: 2.3954, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 109, Loss: 2.2954, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 110, Loss: 2.5463, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 111, Loss: 2.2806, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 112, Loss: 2.5690, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 113, Loss: 2.3745, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 114, Loss: 2.4241, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 115, Loss: 2.1568, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 116, Loss: 2.6488, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 117, Loss: 2.7511, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 118, Loss: 2.2869, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 119, Loss: 2.5826, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 120, Loss: 2.2599, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 121, Loss: 2.2850, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 122, Loss: 2.7448, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 123, Loss: 2.7031, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 124, Loss: 2.5655, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 125, Loss: 2.3157, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 126, Loss: 2.8557, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 127, Loss: 2.8167, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 128, Loss: 2.4995, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 129, Loss: 2.4923, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 130, Loss: 2.3967, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 131, Loss: 2.5309, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 132, Loss: 2.8430, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 133, Loss: 2.0824, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 134, Loss: 2.7431, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 135, Loss: 2.7033, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 136, Loss: 2.0756, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 137, Loss: 2.3544, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 138, Loss: 2.7738, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 139, Loss: 2.5045, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 140, Loss: 2.5922, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 141, Loss: 2.3440, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 142, Loss: 2.5075, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 143, Loss: 2.2477, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 144, Loss: 2.2582, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 145, Loss: 2.4267, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 146, Loss: 2.4910, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 147, Loss: 2.5469, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 148, Loss: 2.6961, Train: 1.0000, Val: 0.7760, Test: 0.7970
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 149, Loss: 2.4481, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 150, Loss: 2.6589, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 151, Loss: 2.4315, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 152, Loss: 2.6651, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 153, Loss: 2.6315, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 154, Loss: 2.4481, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 155, Loss: 2.4506, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 156, Loss: 2.4450, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 157, Loss: 2.9017, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 158, Loss: 2.5145, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 159, Loss: 2.4156, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 160, Loss: 2.1466, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 161, Loss: 2.2113, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 162, Loss: 2.4169, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 163, Loss: 2.1305, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 164, Loss: 2.4601, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 165, Loss: 2.6201, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 166, Loss: 2.1016, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 167, Loss: 2.6904, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 168, Loss: 2.4101, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 169, Loss: 2.1398, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 170, Loss: 2.4848, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 171, Loss: 2.4786, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 172, Loss: 2.7179, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 173, Loss: 2.2415, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 174, Loss: 2.3741, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 175, Loss: 2.8000, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 176, Loss: 2.3074, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 177, Loss: 2.4093, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 178, Loss: 2.5501, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 179, Loss: 2.7639, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 180, Loss: 2.4060, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 181, Loss: 2.2771, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 182, Loss: 2.3463, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 183, Loss: 3.0305, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 184, Loss: 2.6950, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 185, Loss: 2.4459, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 186, Loss: 2.6914, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 187, Loss: 2.2464, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 188, Loss: 2.7911, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 189, Loss: 2.8291, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 190, Loss: 2.3786, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 191, Loss: 2.4222, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 192, Loss: 2.2716, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 193, Loss: 2.1370, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 194, Loss: 2.5202, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 195, Loss: 2.3388, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 196, Loss: 2.2037, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 197, Loss: 2.2777, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 198, Loss: 2.4103, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 199, Loss: 1.9344, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 200, Loss: 2.4800, Train: 1.0000, Val: 0.7700, Test: 0.8000
MAD:  0.0818
Best Test Accuracy: 0.8170, Val Accuracy: 0.7980, Train Accuracy: 0.9714
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8600, Train: 0.1500, Val: 0.0580, Test: 0.0700
Epoch: 2, Loss: 4.8454, Train: 0.3500, Val: 0.2820, Test: 0.2970
Epoch: 3, Loss: 4.8124, Train: 0.3857, Val: 0.3640, Test: 0.3730
Epoch: 4, Loss: 4.7851, Train: 0.3786, Val: 0.3600, Test: 0.3700
Epoch: 5, Loss: 4.7529, Train: 0.3786, Val: 0.3540, Test: 0.3710
Epoch: 6, Loss: 4.7616, Train: 0.3857, Val: 0.3540, Test: 0.3700
Epoch: 7, Loss: 4.6996, Train: 0.3857, Val: 0.3560, Test: 0.3730
Epoch: 8, Loss: 4.6346, Train: 0.3857, Val: 0.3580, Test: 0.3730
Epoch: 9, Loss: 4.5939, Train: 0.3929, Val: 0.3620, Test: 0.3770
Epoch: 10, Loss: 4.5262, Train: 0.3929, Val: 0.3620, Test: 0.3800
Epoch: 11, Loss: 4.4761, Train: 0.4000, Val: 0.3600, Test: 0.3790
Epoch: 12, Loss: 4.3391, Train: 0.3929, Val: 0.3580, Test: 0.3810
Epoch: 13, Loss: 4.3205, Train: 0.3929, Val: 0.3620, Test: 0.3850
Epoch: 14, Loss: 4.2654, Train: 0.4000, Val: 0.3640, Test: 0.3880
Epoch: 15, Loss: 4.0702, Train: 0.4286, Val: 0.3660, Test: 0.3920
Epoch: 16, Loss: 4.1369, Train: 0.4571, Val: 0.3780, Test: 0.4030
Epoch: 17, Loss: 4.0313, Train: 0.4714, Val: 0.3780, Test: 0.4050
Epoch: 18, Loss: 4.0036, Train: 0.4714, Val: 0.3940, Test: 0.4130
Epoch: 19, Loss: 3.8574, Train: 0.5000, Val: 0.4180, Test: 0.4240
Epoch: 20, Loss: 3.7761, Train: 0.5286, Val: 0.4660, Test: 0.4690
Epoch: 21, Loss: 4.0272, Train: 0.5500, Val: 0.4780, Test: 0.5120
Epoch: 22, Loss: 3.8431, Train: 0.5929, Val: 0.4980, Test: 0.5470
Epoch: 23, Loss: 3.6817, Train: 0.6286, Val: 0.5500, Test: 0.5770
Epoch: 24, Loss: 3.3572, Train: 0.7214, Val: 0.5700, Test: 0.6160
Epoch: 25, Loss: 3.3679, Train: 0.8286, Val: 0.6180, Test: 0.6650
Epoch: 26, Loss: 3.1221, Train: 0.9071, Val: 0.7080, Test: 0.7310
Epoch: 27, Loss: 3.3791, Train: 0.9143, Val: 0.7520, Test: 0.7680
Epoch: 28, Loss: 3.2325, Train: 0.9500, Val: 0.7780, Test: 0.8030
Epoch: 29, Loss: 3.1493, Train: 0.9786, Val: 0.7880, Test: 0.7950
Epoch: 30, Loss: 3.4739, Train: 0.9643, Val: 0.7640, Test: 0.7690
Epoch: 31, Loss: 3.2721, Train: 0.9571, Val: 0.7440, Test: 0.7460
Epoch: 32, Loss: 3.2050, Train: 0.9714, Val: 0.7240, Test: 0.7440
Epoch: 33, Loss: 3.5001, Train: 0.9714, Val: 0.7260, Test: 0.7550
Epoch: 34, Loss: 3.0317, Train: 0.9643, Val: 0.7360, Test: 0.7540
Epoch: 35, Loss: 3.0656, Train: 0.9714, Val: 0.7420, Test: 0.7660
Epoch: 36, Loss: 3.3449, Train: 0.9786, Val: 0.7500, Test: 0.7800
Epoch: 37, Loss: 3.1912, Train: 0.9857, Val: 0.7520, Test: 0.7870
Epoch: 38, Loss: 2.6514, Train: 0.9857, Val: 0.7560, Test: 0.7930
Epoch: 39, Loss: 3.1960, Train: 0.9857, Val: 0.7580, Test: 0.8030
Epoch: 40, Loss: 3.2714, Train: 0.9786, Val: 0.7620, Test: 0.7960
Epoch: 41, Loss: 2.9410, Train: 0.9714, Val: 0.7620, Test: 0.8010
Epoch: 42, Loss: 2.8660, Train: 0.9714, Val: 0.7680, Test: 0.8040
Epoch: 43, Loss: 2.6783, Train: 0.9714, Val: 0.7740, Test: 0.8050
Epoch: 44, Loss: 2.6695, Train: 0.9786, Val: 0.7780, Test: 0.8080
Epoch: 45, Loss: 2.7757, Train: 0.9786, Val: 0.7820, Test: 0.8100
Epoch: 46, Loss: 3.0579, Train: 0.9786, Val: 0.7820, Test: 0.8090
Epoch: 47, Loss: 2.8508, Train: 0.9786, Val: 0.7860, Test: 0.8120
Epoch: 48, Loss: 3.0789, Train: 0.9786, Val: 0.7940, Test: 0.8100
Epoch: 49, Loss: 2.9211, Train: 0.9786, Val: 0.7900, Test: 0.8130
Epoch: 50, Loss: 2.7154, Train: 0.9857, Val: 0.7880, Test: 0.8120
Epoch: 51, Loss: 2.5477, Train: 0.9929, Val: 0.7900, Test: 0.8130
Epoch: 52, Loss: 2.7578, Train: 0.9929, Val: 0.7860, Test: 0.8090
Epoch: 53, Loss: 2.7998, Train: 0.9929, Val: 0.7840, Test: 0.8100
Epoch: 54, Loss: 2.9584, Train: 0.9929, Val: 0.7900, Test: 0.8100
Epoch: 55, Loss: 2.5566, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 56, Loss: 2.7148, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 57, Loss: 2.8099, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 58, Loss: 2.6412, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 59, Loss: 2.8111, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 60, Loss: 2.4937, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 61, Loss: 2.6781, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 62, Loss: 2.3462, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 63, Loss: 2.6905, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 64, Loss: 2.9685, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 65, Loss: 2.7338, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 66, Loss: 2.3903, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 67, Loss: 2.4584, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 68, Loss: 2.6103, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 69, Loss: 2.4052, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 70, Loss: 2.4736, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 71, Loss: 2.6179, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 72, Loss: 2.6219, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 73, Loss: 2.3440, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 74, Loss: 2.8229, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 75, Loss: 2.3334, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 76, Loss: 2.5208, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 77, Loss: 2.7477, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 78, Loss: 2.7747, Train: 1.0000, Val: 0.7820, Test: 0.8150
Epoch: 79, Loss: 2.2354, Train: 1.0000, Val: 0.7820, Test: 0.8150
Epoch: 80, Loss: 2.8212, Train: 1.0000, Val: 0.7820, Test: 0.8160
Epoch: 81, Loss: 2.2541, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 82, Loss: 2.8389, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 83, Loss: 2.6426, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 84, Loss: 2.5470, Train: 1.0000, Val: 0.7760, Test: 0.8120
Epoch: 85, Loss: 2.2719, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 86, Loss: 2.5041, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 87, Loss: 2.3241, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 88, Loss: 2.5647, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 89, Loss: 2.8840, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 90, Loss: 2.5123, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 91, Loss: 2.6693, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 92, Loss: 2.6046, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 93, Loss: 2.4601, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 94, Loss: 2.2951, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 95, Loss: 2.3903, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 96, Loss: 2.6879, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 97, Loss: 2.5181, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 98, Loss: 2.4938, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 99, Loss: 2.4131, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 100, Loss: 2.5786, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 101, Loss: 2.6124, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 102, Loss: 2.5529, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 103, Loss: 2.6840, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 104, Loss: 2.4711, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 105, Loss: 2.4486, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 106, Loss: 2.5741, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 107, Loss: 2.6188, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 108, Loss: 2.8771, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 109, Loss: 2.3460, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 110, Loss: 2.1616, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 111, Loss: 2.3114, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 112, Loss: 2.5410, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 113, Loss: 2.3718, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 114, Loss: 2.3399, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 115, Loss: 2.4621, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 116, Loss: 2.3702, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 117, Loss: 2.1246, Train: 1.0000, Val: 0.7740, Test: 0.8110
Epoch: 118, Loss: 2.3982, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 119, Loss: 2.5812, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 120, Loss: 2.5131, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 121, Loss: 2.5931, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 122, Loss: 2.5271, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 123, Loss: 2.2812, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 124, Loss: 2.8362, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 125, Loss: 3.0094, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 126, Loss: 2.3193, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 127, Loss: 2.2166, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 128, Loss: 2.2251, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 129, Loss: 2.2502, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 130, Loss: 2.6937, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 131, Loss: 2.4269, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 132, Loss: 2.4529, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 133, Loss: 2.6078, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 134, Loss: 2.5969, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 135, Loss: 2.5267, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 136, Loss: 2.2503, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 137, Loss: 2.4750, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 138, Loss: 2.5764, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 139, Loss: 2.5069, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 140, Loss: 2.5033, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 141, Loss: 2.5314, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 142, Loss: 2.3505, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 143, Loss: 2.4855, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 144, Loss: 2.2439, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 145, Loss: 2.3543, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 146, Loss: 2.9823, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 147, Loss: 2.2886, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 148, Loss: 2.2093, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 149, Loss: 2.5903, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 150, Loss: 2.5990, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 151, Loss: 2.4566, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 152, Loss: 2.2435, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 153, Loss: 2.6647, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 154, Loss: 2.7009, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 155, Loss: 2.5231, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 156, Loss: 2.4236, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 157, Loss: 2.4853, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 158, Loss: 1.8627, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 159, Loss: 2.5918, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 160, Loss: 2.4999, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 161, Loss: 2.6537, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 162, Loss: 2.3469, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 163, Loss: 2.0342, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 164, Loss: 2.4870, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 165, Loss: 2.3921, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 166, Loss: 1.9688, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 167, Loss: 2.4877, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 168, Loss: 2.3890, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 169, Loss: 2.4146, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 170, Loss: 2.9068, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 171, Loss: 2.5613, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 172, Loss: 2.2095, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 173, Loss: 2.8320, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 174, Loss: 2.6643, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 175, Loss: 2.5815, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 176, Loss: 2.4850, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 177, Loss: 2.1344, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 178, Loss: 2.4102, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 179, Loss: 2.2710, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 180, Loss: 2.2740, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 181, Loss: 2.3131, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 182, Loss: 2.7550, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 183, Loss: 2.5460, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 184, Loss: 2.1745, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 185, Loss: 2.5135, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 186, Loss: 2.2716, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 187, Loss: 2.4467, Train: 1.0000, Val: 0.7760, Test: 0.8060
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 188, Loss: 2.2320, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 189, Loss: 2.8951, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 190, Loss: 2.2397, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 191, Loss: 2.1377, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 192, Loss: 2.2700, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 193, Loss: 2.1695, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 194, Loss: 2.2779, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 195, Loss: 2.1673, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 196, Loss: 2.8631, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 197, Loss: 2.6833, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 198, Loss: 2.4539, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 199, Loss: 2.4743, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 200, Loss: 2.5631, Train: 1.0000, Val: 0.7780, Test: 0.8020
MAD:  0.6085
Best Test Accuracy: 0.8160, Val Accuracy: 0.7820, Train Accuracy: 1.0000
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (1): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8534, Train: 0.2000, Val: 0.1160, Test: 0.1320
Epoch: 2, Loss: 4.8271, Train: 0.4286, Val: 0.2780, Test: 0.2880
Epoch: 3, Loss: 4.8025, Train: 0.4643, Val: 0.3100, Test: 0.3210
Epoch: 4, Loss: 4.7569, Train: 0.4786, Val: 0.3340, Test: 0.3350
Epoch: 5, Loss: 4.7523, Train: 0.5071, Val: 0.3440, Test: 0.3430
Epoch: 6, Loss: 4.6368, Train: 0.5071, Val: 0.3420, Test: 0.3400
Epoch: 7, Loss: 4.6191, Train: 0.5214, Val: 0.3360, Test: 0.3470
Epoch: 8, Loss: 4.5623, Train: 0.5143, Val: 0.3280, Test: 0.3470
Epoch: 9, Loss: 4.5158, Train: 0.5071, Val: 0.3260, Test: 0.3450
Epoch: 10, Loss: 4.3922, Train: 0.5000, Val: 0.3280, Test: 0.3460
Epoch: 11, Loss: 4.2698, Train: 0.4929, Val: 0.3260, Test: 0.3410
Epoch: 12, Loss: 4.2697, Train: 0.5000, Val: 0.3260, Test: 0.3380
Epoch: 13, Loss: 4.0978, Train: 0.5071, Val: 0.3240, Test: 0.3390
Epoch: 14, Loss: 4.0911, Train: 0.5000, Val: 0.3240, Test: 0.3410
Epoch: 15, Loss: 3.9609, Train: 0.5000, Val: 0.3260, Test: 0.3450
Epoch: 16, Loss: 3.8529, Train: 0.5071, Val: 0.3260, Test: 0.3490
Epoch: 17, Loss: 3.8555, Train: 0.5286, Val: 0.3300, Test: 0.3570
Epoch: 18, Loss: 3.7392, Train: 0.5714, Val: 0.3360, Test: 0.3610
Epoch: 19, Loss: 3.4311, Train: 0.6000, Val: 0.3520, Test: 0.3710
Epoch: 20, Loss: 3.6990, Train: 0.6929, Val: 0.3680, Test: 0.3980
Epoch: 21, Loss: 3.4742, Train: 0.7786, Val: 0.4200, Test: 0.4500
Epoch: 22, Loss: 3.7761, Train: 0.8786, Val: 0.5720, Test: 0.5760
Epoch: 23, Loss: 3.3596, Train: 0.9286, Val: 0.6900, Test: 0.7110
Epoch: 24, Loss: 3.4202, Train: 0.9643, Val: 0.7520, Test: 0.7540
Epoch: 25, Loss: 3.1102, Train: 0.9714, Val: 0.7540, Test: 0.7760
Epoch: 26, Loss: 3.5440, Train: 0.9714, Val: 0.7480, Test: 0.7720
Epoch: 27, Loss: 3.4160, Train: 0.9714, Val: 0.7440, Test: 0.7710
Epoch: 28, Loss: 3.4751, Train: 0.9786, Val: 0.7520, Test: 0.7750
Epoch: 29, Loss: 3.2711, Train: 0.9571, Val: 0.7660, Test: 0.7700
Epoch: 30, Loss: 3.0982, Train: 0.9571, Val: 0.7700, Test: 0.7780
Epoch: 31, Loss: 2.9251, Train: 0.9571, Val: 0.7700, Test: 0.7850
Epoch: 32, Loss: 3.3473, Train: 0.9571, Val: 0.7660, Test: 0.7870
Epoch: 33, Loss: 3.2556, Train: 0.9571, Val: 0.7700, Test: 0.7920
Epoch: 34, Loss: 3.0784, Train: 0.9571, Val: 0.7780, Test: 0.7910
Epoch: 35, Loss: 3.1404, Train: 0.9571, Val: 0.7900, Test: 0.7910
Epoch: 36, Loss: 2.9513, Train: 0.9643, Val: 0.7900, Test: 0.8000
Epoch: 37, Loss: 2.8136, Train: 0.9714, Val: 0.7900, Test: 0.8010
Epoch: 38, Loss: 2.4533, Train: 0.9857, Val: 0.7960, Test: 0.7990
Epoch: 39, Loss: 2.9959, Train: 0.9857, Val: 0.7980, Test: 0.8040
Epoch: 40, Loss: 2.9309, Train: 0.9857, Val: 0.7900, Test: 0.8010
Epoch: 41, Loss: 2.9000, Train: 0.9786, Val: 0.7920, Test: 0.8010
Epoch: 42, Loss: 2.7794, Train: 0.9857, Val: 0.7840, Test: 0.8040
Epoch: 43, Loss: 2.5671, Train: 0.9857, Val: 0.7840, Test: 0.7970
Epoch: 44, Loss: 2.5544, Train: 0.9857, Val: 0.7760, Test: 0.8030
Epoch: 45, Loss: 2.8035, Train: 0.9857, Val: 0.7680, Test: 0.8050
Epoch: 46, Loss: 2.7394, Train: 0.9857, Val: 0.7660, Test: 0.8040
Epoch: 47, Loss: 2.6640, Train: 0.9857, Val: 0.7700, Test: 0.8050
Epoch: 48, Loss: 2.8002, Train: 0.9857, Val: 0.7760, Test: 0.8100
Epoch: 49, Loss: 2.6529, Train: 0.9929, Val: 0.7740, Test: 0.8150
Epoch: 50, Loss: 2.6200, Train: 0.9929, Val: 0.7760, Test: 0.8150
Epoch: 51, Loss: 2.9854, Train: 0.9929, Val: 0.7760, Test: 0.8090
Epoch: 52, Loss: 2.7438, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 53, Loss: 2.5635, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 54, Loss: 2.4531, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 55, Loss: 2.9991, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 56, Loss: 2.6148, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 57, Loss: 3.1045, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 58, Loss: 2.7920, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 59, Loss: 2.9854, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 60, Loss: 2.4481, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 61, Loss: 2.6546, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 62, Loss: 2.5407, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 63, Loss: 2.8683, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 64, Loss: 2.4121, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 65, Loss: 2.5490, Train: 1.0000, Val: 0.7760, Test: 0.8160
Epoch: 66, Loss: 3.1438, Train: 0.9929, Val: 0.7780, Test: 0.8130
Epoch: 67, Loss: 2.3677, Train: 0.9929, Val: 0.7780, Test: 0.8140
Epoch: 68, Loss: 2.5690, Train: 0.9929, Val: 0.7800, Test: 0.8140
Epoch: 69, Loss: 2.5126, Train: 1.0000, Val: 0.7740, Test: 0.8160
Epoch: 70, Loss: 2.8338, Train: 1.0000, Val: 0.7760, Test: 0.8160
Epoch: 71, Loss: 2.4690, Train: 1.0000, Val: 0.7760, Test: 0.8150
Epoch: 72, Loss: 2.8783, Train: 1.0000, Val: 0.7760, Test: 0.8130
Epoch: 73, Loss: 2.6758, Train: 1.0000, Val: 0.7760, Test: 0.8130
Epoch: 74, Loss: 2.5685, Train: 1.0000, Val: 0.7720, Test: 0.8130
Epoch: 75, Loss: 2.5003, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 76, Loss: 2.7807, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 77, Loss: 2.6573, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 78, Loss: 2.3246, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 79, Loss: 2.4964, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 80, Loss: 2.7201, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 81, Loss: 2.3427, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 82, Loss: 2.5902, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 83, Loss: 2.4486, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 84, Loss: 2.2473, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 85, Loss: 2.2205, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 86, Loss: 2.5452, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 87, Loss: 2.3448, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 88, Loss: 2.3598, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 89, Loss: 2.5029, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 90, Loss: 2.9759, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 91, Loss: 2.8463, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 92, Loss: 2.5278, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 93, Loss: 2.4361, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 94, Loss: 2.7827, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 95, Loss: 2.7210, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 96, Loss: 2.5208, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 97, Loss: 2.2604, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 98, Loss: 2.5834, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 99, Loss: 2.5871, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 100, Loss: 2.5607, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 101, Loss: 2.1603, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 102, Loss: 2.5160, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 103, Loss: 2.7884, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 104, Loss: 2.6527, Train: 1.0000, Val: 0.7800, Test: 0.8030
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 105, Loss: 2.5460, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 106, Loss: 2.3725, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 107, Loss: 2.5230, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 108, Loss: 2.6717, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 109, Loss: 2.5099, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 110, Loss: 2.5427, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 111, Loss: 2.5573, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 112, Loss: 2.7252, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 113, Loss: 2.3705, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 114, Loss: 2.3755, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 115, Loss: 2.6153, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 116, Loss: 2.6863, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 117, Loss: 2.5246, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 118, Loss: 2.2645, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 119, Loss: 2.4638, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 120, Loss: 2.4198, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 121, Loss: 2.4000, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 122, Loss: 2.3279, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 123, Loss: 2.5827, Train: 1.0000, Val: 0.7960, Test: 0.8070
Epoch: 124, Loss: 2.2226, Train: 1.0000, Val: 0.7960, Test: 0.8050
Epoch: 125, Loss: 2.8071, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 126, Loss: 2.2648, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 127, Loss: 2.1146, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 128, Loss: 2.6384, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 129, Loss: 2.4639, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 130, Loss: 2.2811, Train: 1.0000, Val: 0.7940, Test: 0.8070
Epoch: 131, Loss: 2.3857, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 132, Loss: 2.1636, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 133, Loss: 2.5143, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 134, Loss: 2.3572, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 135, Loss: 2.1485, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 136, Loss: 2.6009, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 137, Loss: 2.6338, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 138, Loss: 2.2518, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 139, Loss: 2.3728, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 140, Loss: 2.5998, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 141, Loss: 2.3919, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 142, Loss: 2.4575, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 143, Loss: 2.2482, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 144, Loss: 2.5921, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 145, Loss: 2.5580, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 146, Loss: 2.3866, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 147, Loss: 2.6344, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 148, Loss: 2.3037, Train: 1.0000, Val: 0.7880, Test: 0.8050
Epoch: 149, Loss: 2.5623, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 150, Loss: 2.1500, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 151, Loss: 2.2401, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 152, Loss: 2.5888, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 153, Loss: 2.5197, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 154, Loss: 2.5927, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 155, Loss: 2.5656, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 156, Loss: 2.5947, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 157, Loss: 2.3895, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 158, Loss: 2.6921, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 159, Loss: 2.3820, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 160, Loss: 2.2463, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 161, Loss: 2.8357, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 162, Loss: 2.0698, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 163, Loss: 2.5858, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 164, Loss: 2.0358, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 165, Loss: 2.5832, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 166, Loss: 2.7667, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 167, Loss: 2.6559, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 168, Loss: 2.5514, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 169, Loss: 2.6888, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 170, Loss: 2.5973, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 171, Loss: 2.6922, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 172, Loss: 2.4899, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 173, Loss: 2.3526, Train: 1.0000, Val: 0.7880, Test: 0.8050
Epoch: 174, Loss: 2.7616, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 175, Loss: 2.4942, Train: 1.0000, Val: 0.7880, Test: 0.8050
Epoch: 176, Loss: 2.4524, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 177, Loss: 2.3146, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 178, Loss: 2.3149, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 179, Loss: 2.4501, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 180, Loss: 2.3042, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 181, Loss: 2.3188, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 182, Loss: 2.3726, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 183, Loss: 2.5538, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 184, Loss: 2.6263, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 185, Loss: 2.3197, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 186, Loss: 2.3099, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 187, Loss: 2.2931, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 188, Loss: 2.4082, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 189, Loss: 2.8360, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 190, Loss: 2.4150, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 191, Loss: 2.8631, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 192, Loss: 2.3106, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 193, Loss: 2.2053, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 194, Loss: 2.5206, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 195, Loss: 2.3402, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 196, Loss: 2.4559, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 197, Loss: 2.5535, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 198, Loss: 2.4142, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 199, Loss: 2.3353, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 200, Loss: 2.7262, Train: 1.0000, Val: 0.7800, Test: 0.8060
MAD:  0.4522
Best Test Accuracy: 0.8160, Val Accuracy: 0.7760, Train Accuracy: 1.0000
Training completed.
Average Test Accuracy:  0.8173 ± 0.00433704968844026
Average MAD:  0.31472 ± 0.21798161757359266
