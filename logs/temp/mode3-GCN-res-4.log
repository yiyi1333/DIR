Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8598, Train: 0.0714, Val: 0.0520, Test: 0.0620
Epoch: 2, Loss: 4.8476, Train: 0.3143, Val: 0.2800, Test: 0.2990
Epoch: 3, Loss: 4.8334, Train: 0.5071, Val: 0.4120, Test: 0.4210
Epoch: 4, Loss: 4.7875, Train: 0.5500, Val: 0.4520, Test: 0.4860
Epoch: 5, Loss: 4.7848, Train: 0.5571, Val: 0.4680, Test: 0.5070
Epoch: 6, Loss: 4.7225, Train: 0.5571, Val: 0.4760, Test: 0.5150
Epoch: 7, Loss: 4.7340, Train: 0.5571, Val: 0.4840, Test: 0.5220
Epoch: 8, Loss: 4.6647, Train: 0.5571, Val: 0.4960, Test: 0.5350
Epoch: 9, Loss: 4.6852, Train: 0.5857, Val: 0.5040, Test: 0.5440
Epoch: 10, Loss: 4.6585, Train: 0.6286, Val: 0.5240, Test: 0.5550
Epoch: 11, Loss: 4.4962, Train: 0.6429, Val: 0.5280, Test: 0.5620
Epoch: 12, Loss: 4.5946, Train: 0.6500, Val: 0.5260, Test: 0.5710
Epoch: 13, Loss: 4.5130, Train: 0.6500, Val: 0.5240, Test: 0.5690
Epoch: 14, Loss: 4.4077, Train: 0.6714, Val: 0.5340, Test: 0.5700
Epoch: 15, Loss: 4.3704, Train: 0.6786, Val: 0.5360, Test: 0.5730
Epoch: 16, Loss: 4.2306, Train: 0.6929, Val: 0.5440, Test: 0.5790
Epoch: 17, Loss: 4.1179, Train: 0.7357, Val: 0.5520, Test: 0.5910
Epoch: 18, Loss: 4.2081, Train: 0.7429, Val: 0.5660, Test: 0.6280
Epoch: 19, Loss: 3.9532, Train: 0.7643, Val: 0.5880, Test: 0.6510
Epoch: 20, Loss: 4.1037, Train: 0.7929, Val: 0.6100, Test: 0.6770
Epoch: 21, Loss: 4.3859, Train: 0.8071, Val: 0.6320, Test: 0.6860
Epoch: 22, Loss: 4.2206, Train: 0.8714, Val: 0.6440, Test: 0.7010
Epoch: 23, Loss: 4.3145, Train: 0.9286, Val: 0.6860, Test: 0.7250
Epoch: 24, Loss: 3.9009, Train: 0.9500, Val: 0.7040, Test: 0.7430
Epoch: 25, Loss: 4.2190, Train: 0.9571, Val: 0.7260, Test: 0.7660
Epoch: 26, Loss: 4.0356, Train: 0.9500, Val: 0.7260, Test: 0.7650
Epoch: 27, Loss: 4.0305, Train: 0.9643, Val: 0.7400, Test: 0.7560
Epoch: 28, Loss: 4.0247, Train: 0.9571, Val: 0.7260, Test: 0.7400
Epoch: 29, Loss: 3.8750, Train: 0.9571, Val: 0.7180, Test: 0.7360
Epoch: 30, Loss: 3.9094, Train: 0.9571, Val: 0.7160, Test: 0.7430
Epoch: 31, Loss: 4.3123, Train: 0.9571, Val: 0.7240, Test: 0.7550
Epoch: 32, Loss: 3.9722, Train: 0.9643, Val: 0.7320, Test: 0.7700
Epoch: 33, Loss: 4.0610, Train: 0.9714, Val: 0.7460, Test: 0.7750
Epoch: 34, Loss: 3.6340, Train: 0.9714, Val: 0.7480, Test: 0.7870
Epoch: 35, Loss: 4.1725, Train: 0.9786, Val: 0.7580, Test: 0.7910
Epoch: 36, Loss: 3.8695, Train: 0.9857, Val: 0.7720, Test: 0.8020
Epoch: 37, Loss: 4.0332, Train: 0.9786, Val: 0.7820, Test: 0.8040
Epoch: 38, Loss: 3.6994, Train: 0.9786, Val: 0.7940, Test: 0.8090
Epoch: 39, Loss: 3.9827, Train: 0.9786, Val: 0.8000, Test: 0.8130
Epoch: 40, Loss: 3.8649, Train: 0.9786, Val: 0.7960, Test: 0.8170
Epoch: 41, Loss: 3.8317, Train: 0.9786, Val: 0.7980, Test: 0.8180
Epoch: 42, Loss: 4.0560, Train: 0.9786, Val: 0.8040, Test: 0.8180
Epoch: 43, Loss: 3.6017, Train: 0.9786, Val: 0.8040, Test: 0.8170
Epoch: 44, Loss: 3.8586, Train: 0.9786, Val: 0.8040, Test: 0.8140
Epoch: 45, Loss: 3.9575, Train: 0.9786, Val: 0.8040, Test: 0.8160
Epoch: 46, Loss: 3.7364, Train: 0.9857, Val: 0.8060, Test: 0.8160
Epoch: 47, Loss: 3.8843, Train: 0.9857, Val: 0.8040, Test: 0.8160
Epoch: 48, Loss: 3.4107, Train: 0.9857, Val: 0.8040, Test: 0.8200
Epoch: 49, Loss: 3.7067, Train: 0.9857, Val: 0.7980, Test: 0.8200
Epoch: 50, Loss: 4.0321, Train: 0.9929, Val: 0.8020, Test: 0.8190
Epoch: 51, Loss: 3.7043, Train: 0.9857, Val: 0.7980, Test: 0.8200
Epoch: 52, Loss: 4.0117, Train: 0.9857, Val: 0.7900, Test: 0.8190
Epoch: 53, Loss: 3.6053, Train: 0.9857, Val: 0.7840, Test: 0.8150
Epoch: 54, Loss: 3.6963, Train: 0.9857, Val: 0.7760, Test: 0.8140
Epoch: 55, Loss: 3.9405, Train: 0.9857, Val: 0.7780, Test: 0.8140
Epoch: 56, Loss: 3.7975, Train: 0.9857, Val: 0.7780, Test: 0.8140
Epoch: 57, Loss: 3.8460, Train: 0.9857, Val: 0.7760, Test: 0.8160
Epoch: 58, Loss: 3.9265, Train: 0.9857, Val: 0.7820, Test: 0.8170
Epoch: 59, Loss: 3.5931, Train: 0.9857, Val: 0.7860, Test: 0.8190
Epoch: 60, Loss: 3.8142, Train: 0.9857, Val: 0.7960, Test: 0.8190
Epoch: 61, Loss: 3.5004, Train: 0.9857, Val: 0.7980, Test: 0.8190
Epoch: 62, Loss: 3.9546, Train: 0.9857, Val: 0.7980, Test: 0.8170
Epoch: 63, Loss: 3.5124, Train: 0.9857, Val: 0.8000, Test: 0.8180
Epoch: 64, Loss: 3.7386, Train: 0.9857, Val: 0.7960, Test: 0.8160
Epoch: 65, Loss: 3.4612, Train: 0.9929, Val: 0.7960, Test: 0.8170
Epoch: 66, Loss: 3.4765, Train: 0.9929, Val: 0.7940, Test: 0.8160
Epoch: 67, Loss: 3.8097, Train: 0.9929, Val: 0.7920, Test: 0.8110
Epoch: 68, Loss: 3.9332, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 69, Loss: 3.6784, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 70, Loss: 3.7739, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 71, Loss: 3.8750, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 72, Loss: 3.8602, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 73, Loss: 3.6442, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 74, Loss: 3.9372, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 75, Loss: 3.8232, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 76, Loss: 3.7189, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 77, Loss: 3.4976, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 78, Loss: 3.8412, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 79, Loss: 3.5768, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 80, Loss: 3.9293, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 81, Loss: 3.9633, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 82, Loss: 3.7039, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 83, Loss: 3.8803, Train: 1.0000, Val: 0.7640, Test: 0.7980
Epoch: 84, Loss: 3.8539, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 85, Loss: 3.5647, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 86, Loss: 3.6012, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 87, Loss: 3.7805, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 88, Loss: 3.7443, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 89, Loss: 3.7403, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 90, Loss: 3.7733, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 91, Loss: 3.6542, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 92, Loss: 3.7022, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 93, Loss: 3.9997, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 94, Loss: 3.3919, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 95, Loss: 3.5316, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 96, Loss: 3.7975, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 97, Loss: 3.6560, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 98, Loss: 3.3301, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 99, Loss: 3.3193, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 100, Loss: 3.6891, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 101, Loss: 3.4931, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 102, Loss: 3.3560, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 103, Loss: 3.5967, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 104, Loss: 3.3145, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 105, Loss: 3.7731, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 106, Loss: 3.8640, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 107, Loss: 3.4992, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 108, Loss: 3.5908, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 109, Loss: 3.6595, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 110, Loss: 3.5185, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 111, Loss: 3.5676, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 112, Loss: 3.5277, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 113, Loss: 3.8682, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 114, Loss: 3.5960, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 115, Loss: 3.5586, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 116, Loss: 4.0504, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 117, Loss: 3.9358, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 118, Loss: 3.6597, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 119, Loss: 3.7361, Train: 1.0000, Val: 0.7820, Test: 0.8080
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 3.7634, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 121, Loss: 3.7588, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 122, Loss: 3.9058, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 123, Loss: 3.4581, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 124, Loss: 3.8974, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 125, Loss: 3.4934, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 126, Loss: 3.7683, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 127, Loss: 4.0045, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 128, Loss: 3.5146, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 129, Loss: 3.3082, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 130, Loss: 3.4232, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 131, Loss: 3.5543, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 132, Loss: 3.7334, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 133, Loss: 3.5581, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 134, Loss: 3.7916, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 135, Loss: 3.7993, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 136, Loss: 3.5512, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 137, Loss: 3.8940, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 138, Loss: 3.9033, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 139, Loss: 3.6227, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 140, Loss: 3.6171, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 141, Loss: 3.4074, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 142, Loss: 3.9995, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 143, Loss: 3.7268, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 144, Loss: 3.4800, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 145, Loss: 3.8208, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 146, Loss: 3.9997, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 147, Loss: 3.9730, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 148, Loss: 3.9610, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 149, Loss: 3.7856, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 150, Loss: 3.4455, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 151, Loss: 3.6239, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 152, Loss: 3.4865, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 153, Loss: 3.7131, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 154, Loss: 3.4858, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 155, Loss: 3.6185, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 156, Loss: 3.6184, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 157, Loss: 3.6540, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 158, Loss: 3.6172, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 159, Loss: 3.8613, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 160, Loss: 3.9258, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 161, Loss: 3.6512, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 162, Loss: 4.0346, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 163, Loss: 3.8594, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 164, Loss: 3.7866, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 165, Loss: 3.3090, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 166, Loss: 3.8877, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 167, Loss: 3.6554, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 168, Loss: 3.2376, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 169, Loss: 3.5858, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 170, Loss: 3.6847, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 171, Loss: 3.6846, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 172, Loss: 3.4904, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 173, Loss: 3.4469, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 174, Loss: 3.5785, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 175, Loss: 3.7191, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 176, Loss: 3.3760, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 177, Loss: 3.7569, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 178, Loss: 3.7178, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 179, Loss: 3.8997, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 180, Loss: 3.6123, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 181, Loss: 3.8293, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 182, Loss: 3.7159, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 183, Loss: 3.6124, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 184, Loss: 3.6883, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 185, Loss: 3.7232, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 186, Loss: 3.7174, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 187, Loss: 3.2366, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 188, Loss: 3.6963, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 189, Loss: 3.4058, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 190, Loss: 3.5775, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 191, Loss: 3.6609, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 192, Loss: 3.5759, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 193, Loss: 3.5461, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 194, Loss: 3.6826, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 195, Loss: 3.5499, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 196, Loss: 3.5489, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 197, Loss: 3.3056, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 198, Loss: 3.7523, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 199, Loss: 3.7190, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 200, Loss: 3.7143, Train: 1.0000, Val: 0.7740, Test: 0.7970
MAD:  0.3952
Best Test Accuracy: 0.8200, Val Accuracy: 0.8040, Train Accuracy: 0.9857
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8519, Train: 0.1786, Val: 0.1020, Test: 0.1310
Epoch: 2, Loss: 4.8216, Train: 0.2786, Val: 0.1760, Test: 0.1870
Epoch: 3, Loss: 4.8201, Train: 0.3286, Val: 0.1940, Test: 0.1950
Epoch: 4, Loss: 4.7814, Train: 0.3643, Val: 0.2000, Test: 0.2110
Epoch: 5, Loss: 4.7536, Train: 0.3857, Val: 0.2200, Test: 0.2400
Epoch: 6, Loss: 4.7418, Train: 0.3929, Val: 0.2320, Test: 0.2630
Epoch: 7, Loss: 4.7520, Train: 0.4071, Val: 0.2360, Test: 0.2750
Epoch: 8, Loss: 4.6381, Train: 0.4214, Val: 0.2600, Test: 0.2850
Epoch: 9, Loss: 4.6397, Train: 0.4214, Val: 0.2980, Test: 0.3120
Epoch: 10, Loss: 4.6052, Train: 0.4786, Val: 0.3180, Test: 0.3460
Epoch: 11, Loss: 4.4697, Train: 0.5286, Val: 0.3260, Test: 0.3660
Epoch: 12, Loss: 4.5250, Train: 0.5786, Val: 0.3500, Test: 0.3950
Epoch: 13, Loss: 4.4881, Train: 0.6071, Val: 0.3820, Test: 0.4300
Epoch: 14, Loss: 4.2284, Train: 0.6357, Val: 0.4180, Test: 0.4620
Epoch: 15, Loss: 4.5078, Train: 0.7000, Val: 0.4700, Test: 0.5300
Epoch: 16, Loss: 4.2484, Train: 0.7357, Val: 0.5360, Test: 0.5840
Epoch: 17, Loss: 4.1205, Train: 0.7429, Val: 0.5920, Test: 0.6290
Epoch: 18, Loss: 4.3396, Train: 0.7929, Val: 0.6280, Test: 0.6610
Epoch: 19, Loss: 4.1892, Train: 0.8214, Val: 0.6520, Test: 0.6830
Epoch: 20, Loss: 4.0603, Train: 0.8357, Val: 0.6680, Test: 0.6980
Epoch: 21, Loss: 4.1410, Train: 0.8643, Val: 0.6740, Test: 0.7150
Epoch: 22, Loss: 3.9269, Train: 0.9214, Val: 0.7060, Test: 0.7550
Epoch: 23, Loss: 4.0218, Train: 0.9786, Val: 0.7240, Test: 0.7690
Epoch: 24, Loss: 4.0880, Train: 0.9786, Val: 0.7460, Test: 0.7740
Epoch: 25, Loss: 3.8223, Train: 0.9857, Val: 0.7660, Test: 0.7820
Epoch: 26, Loss: 3.8385, Train: 0.9929, Val: 0.7740, Test: 0.7940
Epoch: 27, Loss: 3.8137, Train: 0.9857, Val: 0.7840, Test: 0.7920
Epoch: 28, Loss: 4.0673, Train: 0.9857, Val: 0.7780, Test: 0.7810
Epoch: 29, Loss: 3.7989, Train: 0.9714, Val: 0.7700, Test: 0.7790
Epoch: 30, Loss: 3.6321, Train: 0.9643, Val: 0.7740, Test: 0.7770
Epoch: 31, Loss: 3.8486, Train: 0.9643, Val: 0.7760, Test: 0.7850
Epoch: 32, Loss: 4.0911, Train: 0.9714, Val: 0.7800, Test: 0.7870
Epoch: 33, Loss: 3.7835, Train: 0.9714, Val: 0.7800, Test: 0.7940
Epoch: 34, Loss: 3.8728, Train: 0.9857, Val: 0.7880, Test: 0.7940
Epoch: 35, Loss: 3.6258, Train: 0.9857, Val: 0.7960, Test: 0.7970
Epoch: 36, Loss: 3.8069, Train: 0.9786, Val: 0.7980, Test: 0.8090
Epoch: 37, Loss: 3.9761, Train: 0.9786, Val: 0.7960, Test: 0.8080
Epoch: 38, Loss: 3.8701, Train: 0.9786, Val: 0.8000, Test: 0.8060
Epoch: 39, Loss: 3.7153, Train: 0.9857, Val: 0.7940, Test: 0.8050
Epoch: 40, Loss: 3.9797, Train: 0.9857, Val: 0.7880, Test: 0.8030
Epoch: 41, Loss: 3.9133, Train: 0.9929, Val: 0.7820, Test: 0.8050
Epoch: 42, Loss: 3.3844, Train: 0.9929, Val: 0.7880, Test: 0.8090
Epoch: 43, Loss: 3.6924, Train: 0.9929, Val: 0.7820, Test: 0.8080
Epoch: 44, Loss: 4.0949, Train: 0.9929, Val: 0.7880, Test: 0.8130
Epoch: 45, Loss: 3.5812, Train: 0.9929, Val: 0.7960, Test: 0.8190
Epoch: 46, Loss: 4.1190, Train: 0.9929, Val: 0.7960, Test: 0.8180
Epoch: 47, Loss: 3.5131, Train: 0.9929, Val: 0.7980, Test: 0.8200
Epoch: 48, Loss: 3.9208, Train: 1.0000, Val: 0.7980, Test: 0.8210
Epoch: 49, Loss: 3.5983, Train: 1.0000, Val: 0.8000, Test: 0.8230
Epoch: 50, Loss: 3.3867, Train: 1.0000, Val: 0.8020, Test: 0.8230
Epoch: 51, Loss: 3.4439, Train: 1.0000, Val: 0.8020, Test: 0.8220
Epoch: 52, Loss: 3.7264, Train: 1.0000, Val: 0.7980, Test: 0.8170
Epoch: 53, Loss: 3.4818, Train: 1.0000, Val: 0.8000, Test: 0.8200
Epoch: 54, Loss: 3.6398, Train: 1.0000, Val: 0.7980, Test: 0.8190
Epoch: 55, Loss: 3.9210, Train: 1.0000, Val: 0.8020, Test: 0.8180
Epoch: 56, Loss: 3.5697, Train: 1.0000, Val: 0.8040, Test: 0.8160
Epoch: 57, Loss: 3.6377, Train: 1.0000, Val: 0.8020, Test: 0.8150
Epoch: 58, Loss: 3.9662, Train: 1.0000, Val: 0.8000, Test: 0.8130
Epoch: 59, Loss: 3.6651, Train: 1.0000, Val: 0.7960, Test: 0.8120
Epoch: 60, Loss: 3.5026, Train: 1.0000, Val: 0.7960, Test: 0.8070
Epoch: 61, Loss: 3.9650, Train: 1.0000, Val: 0.7960, Test: 0.8040
Epoch: 62, Loss: 3.6448, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 63, Loss: 3.6351, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 64, Loss: 3.6484, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 65, Loss: 3.9700, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 66, Loss: 3.8382, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 67, Loss: 3.8906, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 68, Loss: 3.8247, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 69, Loss: 3.8816, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 70, Loss: 3.8326, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 71, Loss: 3.6275, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 72, Loss: 3.7558, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 73, Loss: 3.5535, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 74, Loss: 3.3621, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 75, Loss: 3.7462, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 76, Loss: 4.1203, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 77, Loss: 3.9028, Train: 1.0000, Val: 0.7720, Test: 0.8110
Epoch: 78, Loss: 3.9403, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 79, Loss: 3.3464, Train: 1.0000, Val: 0.7800, Test: 0.8120
Epoch: 80, Loss: 3.3932, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 81, Loss: 3.9097, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 82, Loss: 3.4943, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 83, Loss: 3.6479, Train: 1.0000, Val: 0.7820, Test: 0.8160
Epoch: 84, Loss: 3.4962, Train: 1.0000, Val: 0.7800, Test: 0.8150
Epoch: 85, Loss: 3.6418, Train: 1.0000, Val: 0.7820, Test: 0.8180
Epoch: 86, Loss: 3.5470, Train: 1.0000, Val: 0.7820, Test: 0.8170
Epoch: 87, Loss: 3.8356, Train: 1.0000, Val: 0.7880, Test: 0.8170
Epoch: 88, Loss: 3.5938, Train: 1.0000, Val: 0.7880, Test: 0.8180
Epoch: 89, Loss: 3.7026, Train: 1.0000, Val: 0.7880, Test: 0.8210
Epoch: 90, Loss: 3.4994, Train: 1.0000, Val: 0.7880, Test: 0.8170
Epoch: 91, Loss: 3.4278, Train: 1.0000, Val: 0.7840, Test: 0.8160
Epoch: 92, Loss: 3.5108, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 93, Loss: 3.6806, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 94, Loss: 4.1350, Train: 1.0000, Val: 0.7820, Test: 0.8150
Epoch: 95, Loss: 3.9756, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 96, Loss: 3.6396, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 97, Loss: 3.8801, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 98, Loss: 3.6871, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 99, Loss: 3.5601, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 100, Loss: 3.8716, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 101, Loss: 3.4918, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 102, Loss: 3.7970, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 103, Loss: 3.5479, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 104, Loss: 3.5589, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 105, Loss: 3.8504, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 106, Loss: 3.3109, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 107, Loss: 3.7953, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 108, Loss: 3.5072, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 109, Loss: 3.5890, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 110, Loss: 3.6597, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 111, Loss: 3.6697, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 112, Loss: 3.8379, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 113, Loss: 3.7763, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 114, Loss: 3.4126, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 115, Loss: 3.8395, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 116, Loss: 3.5202, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 117, Loss: 3.8262, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 118, Loss: 3.6226, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 119, Loss: 3.6698, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 120, Loss: 3.5659, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 121, Loss: 3.7620, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 122, Loss: 3.7713, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 123, Loss: 3.7274, Train: 1.0000, Val: 0.7920, Test: 0.8160
Epoch: 124, Loss: 3.8952, Train: 1.0000, Val: 0.7920, Test: 0.8150
Epoch: 125, Loss: 3.7577, Train: 1.0000, Val: 0.7920, Test: 0.8140
Epoch: 126, Loss: 3.7956, Train: 1.0000, Val: 0.7920, Test: 0.8170
Epoch: 127, Loss: 3.9335, Train: 1.0000, Val: 0.7880, Test: 0.8140
Epoch: 128, Loss: 3.5539, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 129, Loss: 3.6163, Train: 1.0000, Val: 0.7860, Test: 0.8130
Epoch: 130, Loss: 3.8573, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 131, Loss: 3.6567, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 132, Loss: 3.5460, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 133, Loss: 3.1096, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 134, Loss: 3.7586, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 135, Loss: 3.6530, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 136, Loss: 3.6944, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 137, Loss: 3.5588, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 138, Loss: 3.1841, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 139, Loss: 3.7284, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 140, Loss: 3.6527, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 141, Loss: 3.8253, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 142, Loss: 3.6141, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 143, Loss: 3.7364, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 144, Loss: 3.7930, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 145, Loss: 3.6833, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 146, Loss: 3.7193, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 147, Loss: 3.6568, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 148, Loss: 3.9283, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 149, Loss: 3.5466, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 150, Loss: 3.7189, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 151, Loss: 3.6857, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 152, Loss: 3.7546, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 153, Loss: 3.8962, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 154, Loss: 3.4765, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 155, Loss: 3.8605, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 156, Loss: 3.4813, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 157, Loss: 3.3383, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 158, Loss: 3.7966, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 159, Loss: 3.5806, Train: 1.0000, Val: 0.7780, Test: 0.8010
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 160, Loss: 3.8948, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 161, Loss: 3.6862, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 162, Loss: 4.0339, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 163, Loss: 3.5830, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 164, Loss: 3.5282, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 165, Loss: 3.8632, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 166, Loss: 3.6606, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 167, Loss: 3.7564, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 168, Loss: 3.5825, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 169, Loss: 3.5832, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 170, Loss: 3.5129, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 171, Loss: 3.7271, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 172, Loss: 3.4797, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 173, Loss: 3.9991, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 174, Loss: 3.7539, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 175, Loss: 3.5927, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 176, Loss: 3.6815, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 177, Loss: 3.8304, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 178, Loss: 3.7933, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 179, Loss: 3.6489, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 180, Loss: 3.3450, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 181, Loss: 3.3044, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 182, Loss: 3.6485, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 183, Loss: 3.6210, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 184, Loss: 3.6237, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 185, Loss: 4.1359, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 186, Loss: 3.5146, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 187, Loss: 3.5838, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 188, Loss: 3.6901, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 189, Loss: 3.3453, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 190, Loss: 3.9273, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 191, Loss: 3.6180, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 192, Loss: 3.7199, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 193, Loss: 3.6841, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 194, Loss: 3.8948, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 195, Loss: 3.7197, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 196, Loss: 3.5476, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 197, Loss: 3.7556, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 198, Loss: 3.6547, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 199, Loss: 3.7894, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 200, Loss: 3.5123, Train: 1.0000, Val: 0.7780, Test: 0.8060
MAD:  0.4584
Best Test Accuracy: 0.8230, Val Accuracy: 0.8000, Train Accuracy: 1.0000
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8561, Train: 0.1571, Val: 0.1280, Test: 0.1240
Epoch: 2, Loss: 4.8392, Train: 0.2643, Val: 0.2580, Test: 0.2580
Epoch: 3, Loss: 4.8251, Train: 0.3071, Val: 0.2800, Test: 0.2770
Epoch: 4, Loss: 4.7876, Train: 0.3286, Val: 0.2720, Test: 0.2770
Epoch: 5, Loss: 4.7552, Train: 0.3643, Val: 0.2600, Test: 0.2700
Epoch: 6, Loss: 4.7427, Train: 0.3714, Val: 0.2560, Test: 0.2680
Epoch: 7, Loss: 4.7416, Train: 0.3929, Val: 0.2620, Test: 0.2730
Epoch: 8, Loss: 4.6561, Train: 0.4000, Val: 0.2560, Test: 0.2670
Epoch: 9, Loss: 4.5996, Train: 0.4071, Val: 0.2560, Test: 0.2670
Epoch: 10, Loss: 4.5258, Train: 0.4071, Val: 0.2680, Test: 0.2650
Epoch: 11, Loss: 4.6656, Train: 0.4214, Val: 0.2700, Test: 0.2740
Epoch: 12, Loss: 4.4706, Train: 0.4357, Val: 0.2740, Test: 0.2910
Epoch: 13, Loss: 4.4762, Train: 0.4786, Val: 0.2820, Test: 0.2970
Epoch: 14, Loss: 4.5412, Train: 0.5000, Val: 0.3260, Test: 0.3360
Epoch: 15, Loss: 4.2099, Train: 0.5429, Val: 0.3460, Test: 0.3650
Epoch: 16, Loss: 4.2988, Train: 0.6071, Val: 0.4160, Test: 0.4380
Epoch: 17, Loss: 4.1294, Train: 0.6286, Val: 0.4940, Test: 0.5100
Epoch: 18, Loss: 4.3055, Train: 0.6643, Val: 0.5380, Test: 0.5590
Epoch: 19, Loss: 4.2275, Train: 0.7071, Val: 0.5760, Test: 0.6040
Epoch: 20, Loss: 3.9478, Train: 0.7786, Val: 0.6160, Test: 0.6530
Epoch: 21, Loss: 4.1126, Train: 0.8214, Val: 0.6620, Test: 0.6950
Epoch: 22, Loss: 3.9806, Train: 0.8786, Val: 0.6960, Test: 0.7270
Epoch: 23, Loss: 4.3973, Train: 0.9429, Val: 0.7140, Test: 0.7510
Epoch: 24, Loss: 4.0806, Train: 0.9500, Val: 0.7220, Test: 0.7480
Epoch: 25, Loss: 4.0238, Train: 0.9429, Val: 0.6940, Test: 0.7330
Epoch: 26, Loss: 4.0115, Train: 0.9357, Val: 0.6880, Test: 0.7150
Epoch: 27, Loss: 3.9534, Train: 0.9429, Val: 0.6840, Test: 0.7120
Epoch: 28, Loss: 4.2766, Train: 0.9500, Val: 0.6880, Test: 0.7050
Epoch: 29, Loss: 3.9970, Train: 0.9714, Val: 0.6920, Test: 0.6920
Epoch: 30, Loss: 3.9128, Train: 0.9714, Val: 0.6880, Test: 0.6980
Epoch: 31, Loss: 3.9455, Train: 0.9643, Val: 0.6960, Test: 0.7140
Epoch: 32, Loss: 4.0077, Train: 0.9786, Val: 0.7060, Test: 0.7300
Epoch: 33, Loss: 3.9636, Train: 0.9786, Val: 0.7300, Test: 0.7590
Epoch: 34, Loss: 3.9051, Train: 0.9786, Val: 0.7380, Test: 0.7690
Epoch: 35, Loss: 4.0342, Train: 0.9786, Val: 0.7600, Test: 0.7730
Epoch: 36, Loss: 3.9625, Train: 0.9786, Val: 0.7700, Test: 0.7840
Epoch: 37, Loss: 4.0170, Train: 0.9857, Val: 0.7800, Test: 0.7830
Epoch: 38, Loss: 3.8711, Train: 0.9857, Val: 0.7780, Test: 0.7830
Epoch: 39, Loss: 4.0957, Train: 0.9786, Val: 0.7800, Test: 0.7860
Epoch: 40, Loss: 3.6840, Train: 0.9857, Val: 0.7840, Test: 0.7880
Epoch: 41, Loss: 3.8789, Train: 0.9857, Val: 0.7940, Test: 0.8000
Epoch: 42, Loss: 3.7557, Train: 0.9857, Val: 0.7920, Test: 0.8040
Epoch: 43, Loss: 3.8724, Train: 0.9857, Val: 0.7900, Test: 0.8130
Epoch: 44, Loss: 4.0988, Train: 0.9929, Val: 0.7920, Test: 0.8160
Epoch: 45, Loss: 3.9311, Train: 0.9929, Val: 0.7920, Test: 0.8190
Epoch: 46, Loss: 3.9030, Train: 0.9929, Val: 0.7980, Test: 0.8200
Epoch: 47, Loss: 3.7712, Train: 0.9929, Val: 0.7940, Test: 0.8190
Epoch: 48, Loss: 3.9396, Train: 0.9857, Val: 0.7920, Test: 0.8190
Epoch: 49, Loss: 3.7401, Train: 0.9857, Val: 0.7900, Test: 0.8130
Epoch: 50, Loss: 3.8348, Train: 0.9857, Val: 0.7840, Test: 0.8100
Epoch: 51, Loss: 4.1053, Train: 0.9857, Val: 0.7780, Test: 0.8040
Epoch: 52, Loss: 3.6624, Train: 0.9857, Val: 0.7780, Test: 0.8010
Epoch: 53, Loss: 3.7838, Train: 0.9857, Val: 0.7800, Test: 0.8020
Epoch: 54, Loss: 3.9657, Train: 0.9857, Val: 0.7880, Test: 0.8020
Epoch: 55, Loss: 3.4939, Train: 0.9929, Val: 0.7900, Test: 0.8080
Epoch: 56, Loss: 4.0954, Train: 0.9929, Val: 0.7900, Test: 0.8120
Epoch: 57, Loss: 3.9732, Train: 0.9929, Val: 0.7860, Test: 0.8140
Epoch: 58, Loss: 3.5568, Train: 0.9929, Val: 0.7860, Test: 0.8130
Epoch: 59, Loss: 3.9065, Train: 0.9929, Val: 0.7840, Test: 0.8110
Epoch: 60, Loss: 3.7852, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 61, Loss: 3.5225, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 62, Loss: 3.7244, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 63, Loss: 3.6440, Train: 1.0000, Val: 0.7920, Test: 0.8140
Epoch: 64, Loss: 3.4584, Train: 1.0000, Val: 0.7980, Test: 0.8140
Epoch: 65, Loss: 4.0176, Train: 1.0000, Val: 0.7980, Test: 0.8130
Epoch: 66, Loss: 3.6177, Train: 1.0000, Val: 0.7960, Test: 0.8140
Epoch: 67, Loss: 3.8153, Train: 1.0000, Val: 0.7980, Test: 0.8140
Epoch: 68, Loss: 3.7223, Train: 1.0000, Val: 0.7980, Test: 0.8140
Epoch: 69, Loss: 3.8846, Train: 1.0000, Val: 0.8020, Test: 0.8150
Epoch: 70, Loss: 3.7772, Train: 1.0000, Val: 0.8040, Test: 0.8170
Epoch: 71, Loss: 3.9029, Train: 1.0000, Val: 0.8040, Test: 0.8160
Epoch: 72, Loss: 3.9101, Train: 1.0000, Val: 0.8000, Test: 0.8150
Epoch: 73, Loss: 3.3956, Train: 1.0000, Val: 0.7940, Test: 0.8120
Epoch: 74, Loss: 3.4403, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 75, Loss: 3.5863, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 76, Loss: 3.5833, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 77, Loss: 3.2495, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 78, Loss: 3.6165, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 79, Loss: 3.6742, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 80, Loss: 3.6335, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 81, Loss: 4.0563, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 82, Loss: 3.6750, Train: 1.0000, Val: 0.7960, Test: 0.8130
Epoch: 83, Loss: 3.5795, Train: 1.0000, Val: 0.7920, Test: 0.8150
Epoch: 84, Loss: 3.7741, Train: 1.0000, Val: 0.7900, Test: 0.8160
Epoch: 85, Loss: 3.8008, Train: 1.0000, Val: 0.7920, Test: 0.8120
Epoch: 86, Loss: 3.5129, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 87, Loss: 3.6830, Train: 1.0000, Val: 0.7940, Test: 0.8110
Epoch: 88, Loss: 3.6670, Train: 1.0000, Val: 0.7940, Test: 0.8120
Epoch: 89, Loss: 3.6050, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 90, Loss: 3.5370, Train: 1.0000, Val: 0.7920, Test: 0.8120
Epoch: 91, Loss: 3.5956, Train: 1.0000, Val: 0.7960, Test: 0.8150
Epoch: 92, Loss: 3.4851, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 93, Loss: 3.9054, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 94, Loss: 3.6115, Train: 1.0000, Val: 0.7900, Test: 0.8160
Epoch: 95, Loss: 3.7683, Train: 1.0000, Val: 0.7900, Test: 0.8180
Epoch: 96, Loss: 3.4259, Train: 1.0000, Val: 0.7880, Test: 0.8180
Epoch: 97, Loss: 3.8046, Train: 1.0000, Val: 0.7880, Test: 0.8180
Epoch: 98, Loss: 4.0539, Train: 1.0000, Val: 0.7900, Test: 0.8160
Epoch: 99, Loss: 3.7400, Train: 1.0000, Val: 0.7900, Test: 0.8150
Epoch: 100, Loss: 3.5928, Train: 1.0000, Val: 0.7880, Test: 0.8160
Epoch: 101, Loss: 4.0172, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 102, Loss: 3.6936, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 103, Loss: 3.7379, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 104, Loss: 3.6978, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 105, Loss: 3.6338, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 106, Loss: 3.3570, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 107, Loss: 3.8372, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 108, Loss: 3.5010, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 109, Loss: 3.8268, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 110, Loss: 3.7892, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 111, Loss: 3.5637, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 112, Loss: 3.7597, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 113, Loss: 3.6625, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 114, Loss: 3.7581, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 115, Loss: 3.3521, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 116, Loss: 3.7245, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 117, Loss: 3.4905, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 118, Loss: 3.4794, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 119, Loss: 3.9760, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 120, Loss: 3.6180, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 121, Loss: 3.7638, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 122, Loss: 3.7200, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 123, Loss: 3.7986, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 124, Loss: 3.6358, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 125, Loss: 3.7348, Train: 1.0000, Val: 0.7880, Test: 0.8050
Epoch: 126, Loss: 3.4192, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 127, Loss: 3.8964, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 128, Loss: 3.6677, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 129, Loss: 3.8114, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 130, Loss: 3.8609, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 131, Loss: 3.5800, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 132, Loss: 3.4526, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 133, Loss: 3.6553, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 134, Loss: 3.6578, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 135, Loss: 3.5424, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 136, Loss: 3.8107, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 137, Loss: 3.8231, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 138, Loss: 3.4841, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 139, Loss: 3.4169, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 140, Loss: 3.6564, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 141, Loss: 3.6194, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 142, Loss: 3.7901, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 143, Loss: 3.8971, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 144, Loss: 3.4665, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 145, Loss: 3.6880, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 146, Loss: 3.6865, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 147, Loss: 3.6593, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 148, Loss: 3.4168, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 149, Loss: 3.4201, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 150, Loss: 3.3451, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 151, Loss: 3.9348, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 152, Loss: 3.7320, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 153, Loss: 3.6888, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 154, Loss: 3.8646, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 155, Loss: 3.7311, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 156, Loss: 3.6907, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 157, Loss: 3.8235, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 158, Loss: 3.7244, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 159, Loss: 3.8198, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 160, Loss: 3.3747, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 161, Loss: 3.3808, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 162, Loss: 3.3373, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 163, Loss: 3.5120, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 164, Loss: 3.7611, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 165, Loss: 3.7291, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 166, Loss: 3.6188, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 167, Loss: 3.6504, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 168, Loss: 3.4088, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 169, Loss: 3.7928, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 170, Loss: 3.6909, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 171, Loss: 3.3031, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 172, Loss: 3.7606, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 173, Loss: 3.4828, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 174, Loss: 3.6840, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 175, Loss: 3.5855, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 176, Loss: 3.6849, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 177, Loss: 3.6478, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 178, Loss: 3.7195, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 179, Loss: 3.6507, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 180, Loss: 4.0293, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 181, Loss: 3.6122, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 182, Loss: 3.8213, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 183, Loss: 3.5788, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 184, Loss: 3.6861, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 185, Loss: 3.7908, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 186, Loss: 3.5794, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 187, Loss: 3.7531, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 188, Loss: 3.8895, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 189, Loss: 3.7525, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 190, Loss: 4.1149, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 191, Loss: 3.7968, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 192, Loss: 3.8211, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 193, Loss: 3.6167, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 194, Loss: 3.8308, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 195, Loss: 3.4754, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 196, Loss: 3.8633, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 197, Loss: 3.8508, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 198, Loss: 3.6638, Train: 1.0000, Val: 0.7820, Test: 0.8030
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 199, Loss: 3.6891, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 200, Loss: 3.5523, Train: 1.0000, Val: 0.7840, Test: 0.8030
MAD:  0.3496
Best Test Accuracy: 0.8200, Val Accuracy: 0.7980, Train Accuracy: 0.9929
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8505, Train: 0.1500, Val: 0.1220, Test: 0.1100
Epoch: 2, Loss: 4.8392, Train: 0.3929, Val: 0.2480, Test: 0.2500
Epoch: 3, Loss: 4.8077, Train: 0.4214, Val: 0.2800, Test: 0.2800
Epoch: 4, Loss: 4.7939, Train: 0.4500, Val: 0.2820, Test: 0.2890
Epoch: 5, Loss: 4.7606, Train: 0.4571, Val: 0.2720, Test: 0.2820
Epoch: 6, Loss: 4.6662, Train: 0.4643, Val: 0.2920, Test: 0.2890
Epoch: 7, Loss: 4.6298, Train: 0.4857, Val: 0.2980, Test: 0.2960
Epoch: 8, Loss: 4.5669, Train: 0.4929, Val: 0.3080, Test: 0.3120
Epoch: 9, Loss: 4.5608, Train: 0.5000, Val: 0.3160, Test: 0.3170
Epoch: 10, Loss: 4.5966, Train: 0.5071, Val: 0.3260, Test: 0.3260
Epoch: 11, Loss: 4.4514, Train: 0.5143, Val: 0.3400, Test: 0.3360
Epoch: 12, Loss: 4.5239, Train: 0.5429, Val: 0.3540, Test: 0.3550
Epoch: 13, Loss: 4.2918, Train: 0.5643, Val: 0.3680, Test: 0.3670
Epoch: 14, Loss: 4.5287, Train: 0.5857, Val: 0.3880, Test: 0.3940
Epoch: 15, Loss: 4.0069, Train: 0.6000, Val: 0.4080, Test: 0.4190
Epoch: 16, Loss: 4.2407, Train: 0.6214, Val: 0.4420, Test: 0.4460
Epoch: 17, Loss: 4.3752, Train: 0.6857, Val: 0.4620, Test: 0.4790
Epoch: 18, Loss: 4.1601, Train: 0.7000, Val: 0.4920, Test: 0.5010
Epoch: 19, Loss: 4.1314, Train: 0.7500, Val: 0.5140, Test: 0.5160
Epoch: 20, Loss: 4.0437, Train: 0.8143, Val: 0.5500, Test: 0.5510
Epoch: 21, Loss: 4.3192, Train: 0.8429, Val: 0.5780, Test: 0.5760
Epoch: 22, Loss: 4.2011, Train: 0.9000, Val: 0.6160, Test: 0.6210
Epoch: 23, Loss: 3.9558, Train: 0.9286, Val: 0.6800, Test: 0.6820
Epoch: 24, Loss: 4.3710, Train: 0.9286, Val: 0.7200, Test: 0.7230
Epoch: 25, Loss: 4.1579, Train: 0.9429, Val: 0.7360, Test: 0.7450
Epoch: 26, Loss: 3.5981, Train: 0.9571, Val: 0.7500, Test: 0.7510
Epoch: 27, Loss: 4.0714, Train: 0.9571, Val: 0.7660, Test: 0.7730
Epoch: 28, Loss: 3.9672, Train: 0.9643, Val: 0.7760, Test: 0.7810
Epoch: 29, Loss: 3.6892, Train: 0.9714, Val: 0.7820, Test: 0.7830
Epoch: 30, Loss: 4.0332, Train: 0.9714, Val: 0.7800, Test: 0.7860
Epoch: 31, Loss: 3.9807, Train: 0.9714, Val: 0.7760, Test: 0.7790
Epoch: 32, Loss: 4.0373, Train: 0.9714, Val: 0.7720, Test: 0.7710
Epoch: 33, Loss: 3.8897, Train: 0.9714, Val: 0.7680, Test: 0.7720
Epoch: 34, Loss: 3.9731, Train: 0.9714, Val: 0.7720, Test: 0.7760
Epoch: 35, Loss: 4.0149, Train: 0.9714, Val: 0.7700, Test: 0.7800
Epoch: 36, Loss: 3.8567, Train: 0.9857, Val: 0.7780, Test: 0.7770
Epoch: 37, Loss: 3.9397, Train: 0.9857, Val: 0.7680, Test: 0.7720
Epoch: 38, Loss: 4.0785, Train: 0.9857, Val: 0.7620, Test: 0.7660
Epoch: 39, Loss: 4.0728, Train: 0.9857, Val: 0.7580, Test: 0.7680
Epoch: 40, Loss: 3.8470, Train: 0.9929, Val: 0.7520, Test: 0.7620
Epoch: 41, Loss: 3.8845, Train: 0.9929, Val: 0.7440, Test: 0.7640
Epoch: 42, Loss: 3.8765, Train: 0.9929, Val: 0.7480, Test: 0.7670
Epoch: 43, Loss: 3.7443, Train: 0.9929, Val: 0.7520, Test: 0.7690
Epoch: 44, Loss: 3.5979, Train: 0.9929, Val: 0.7500, Test: 0.7720
Epoch: 45, Loss: 3.9818, Train: 0.9857, Val: 0.7620, Test: 0.7750
Epoch: 46, Loss: 3.9277, Train: 0.9857, Val: 0.7680, Test: 0.7790
Epoch: 47, Loss: 3.7029, Train: 0.9929, Val: 0.7700, Test: 0.7820
Epoch: 48, Loss: 3.7674, Train: 0.9929, Val: 0.7760, Test: 0.7820
Epoch: 49, Loss: 3.8174, Train: 0.9929, Val: 0.7740, Test: 0.7820
Epoch: 50, Loss: 3.6023, Train: 1.0000, Val: 0.7780, Test: 0.7850
Epoch: 51, Loss: 3.7722, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 52, Loss: 3.5745, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 53, Loss: 3.8159, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 54, Loss: 3.7365, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 55, Loss: 3.8361, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 56, Loss: 3.7374, Train: 0.9929, Val: 0.7760, Test: 0.7980
Epoch: 57, Loss: 3.4375, Train: 0.9929, Val: 0.7740, Test: 0.7980
Epoch: 58, Loss: 3.6396, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 59, Loss: 3.9417, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 60, Loss: 3.6597, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 61, Loss: 3.6196, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 62, Loss: 3.8067, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 63, Loss: 3.9197, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 64, Loss: 3.5905, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 65, Loss: 3.4580, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 66, Loss: 3.7909, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 67, Loss: 3.7924, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 68, Loss: 3.8993, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 69, Loss: 3.9427, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 70, Loss: 3.4556, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 71, Loss: 3.6801, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 72, Loss: 3.7387, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 73, Loss: 3.4116, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 74, Loss: 4.1524, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 75, Loss: 3.5558, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 76, Loss: 3.6119, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 77, Loss: 3.6569, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 78, Loss: 3.5464, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 79, Loss: 3.7883, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 80, Loss: 3.3906, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 81, Loss: 3.4367, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 82, Loss: 3.7686, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 83, Loss: 3.6737, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 84, Loss: 3.5032, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 85, Loss: 3.6993, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 86, Loss: 3.7203, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 87, Loss: 3.4916, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 88, Loss: 3.7081, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 89, Loss: 3.7438, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 90, Loss: 3.5203, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 91, Loss: 3.7062, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 92, Loss: 3.6318, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 93, Loss: 3.7689, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 94, Loss: 3.7393, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 95, Loss: 3.6505, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 96, Loss: 3.9654, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 97, Loss: 3.6352, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 98, Loss: 3.7267, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 99, Loss: 3.7746, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 100, Loss: 3.4627, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 101, Loss: 3.7996, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 102, Loss: 3.9026, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 103, Loss: 3.7087, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 104, Loss: 3.6238, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 105, Loss: 3.5932, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 106, Loss: 3.6554, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 107, Loss: 3.5551, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 108, Loss: 3.6938, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 109, Loss: 3.6904, Train: 1.0000, Val: 0.7720, Test: 0.7830
Epoch: 110, Loss: 3.6607, Train: 1.0000, Val: 0.7720, Test: 0.7820
Epoch: 111, Loss: 3.5188, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 112, Loss: 3.8416, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 113, Loss: 3.5318, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 114, Loss: 3.5181, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 115, Loss: 3.5549, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 116, Loss: 3.2212, Train: 1.0000, Val: 0.7700, Test: 0.7950
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 117, Loss: 3.7275, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 118, Loss: 3.6947, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 119, Loss: 3.9293, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 120, Loss: 3.7303, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 121, Loss: 3.5506, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 122, Loss: 3.4237, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 123, Loss: 3.7656, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 124, Loss: 3.8944, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 125, Loss: 3.4435, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 126, Loss: 3.6923, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 127, Loss: 3.5244, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 128, Loss: 3.7635, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 129, Loss: 3.6673, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 130, Loss: 3.5633, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 131, Loss: 3.6544, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 132, Loss: 3.7878, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 133, Loss: 3.3498, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 134, Loss: 3.6548, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 135, Loss: 3.7312, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 136, Loss: 3.6258, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 137, Loss: 3.3123, Train: 1.0000, Val: 0.7620, Test: 0.7990
Epoch: 138, Loss: 4.0329, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 139, Loss: 3.6918, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 140, Loss: 3.8928, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 141, Loss: 3.7626, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 142, Loss: 3.6260, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 143, Loss: 4.1029, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 144, Loss: 3.7923, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 145, Loss: 3.4155, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 146, Loss: 3.6164, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 147, Loss: 3.8577, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 148, Loss: 3.8229, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 149, Loss: 3.4809, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 150, Loss: 3.5438, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 151, Loss: 3.6843, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 152, Loss: 3.6679, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 153, Loss: 3.5218, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 154, Loss: 3.5489, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 155, Loss: 3.5906, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 156, Loss: 3.5511, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 157, Loss: 3.7172, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 158, Loss: 3.6164, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 159, Loss: 4.0688, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 160, Loss: 3.7172, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 161, Loss: 3.0691, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 162, Loss: 3.9290, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 163, Loss: 3.8224, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 164, Loss: 3.5144, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 165, Loss: 3.8261, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 166, Loss: 3.5545, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 167, Loss: 3.5229, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 168, Loss: 3.9237, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 169, Loss: 3.6101, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 170, Loss: 3.4128, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 171, Loss: 3.8209, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 172, Loss: 3.3812, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 173, Loss: 3.4922, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 174, Loss: 3.7180, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 175, Loss: 3.8593, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 176, Loss: 3.9009, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 177, Loss: 3.4439, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 178, Loss: 3.8564, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 179, Loss: 3.5147, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 180, Loss: 3.6513, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 181, Loss: 3.8549, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 182, Loss: 3.9617, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 183, Loss: 3.8217, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 184, Loss: 3.4416, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 185, Loss: 4.0622, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 186, Loss: 3.6251, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 187, Loss: 3.4787, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 188, Loss: 3.8554, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 189, Loss: 3.5962, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 190, Loss: 3.9943, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 191, Loss: 3.7936, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 192, Loss: 3.6512, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 193, Loss: 3.5401, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 194, Loss: 3.8568, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 195, Loss: 3.8212, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 196, Loss: 3.5093, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 197, Loss: 3.7525, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 198, Loss: 3.7505, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 199, Loss: 3.5426, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 200, Loss: 3.5106, Train: 1.0000, Val: 0.7780, Test: 0.8000
MAD:  0.5545
Best Test Accuracy: 0.8090, Val Accuracy: 0.7740, Train Accuracy: 1.0000
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8566, Train: 0.1500, Val: 0.1300, Test: 0.1230
Epoch: 2, Loss: 4.8239, Train: 0.2643, Val: 0.1620, Test: 0.1630
Epoch: 3, Loss: 4.8079, Train: 0.2714, Val: 0.1800, Test: 0.1730
Epoch: 4, Loss: 4.7779, Train: 0.3000, Val: 0.1860, Test: 0.1890
Epoch: 5, Loss: 4.7370, Train: 0.3214, Val: 0.1940, Test: 0.2060
Epoch: 6, Loss: 4.6823, Train: 0.3571, Val: 0.2180, Test: 0.2170
Epoch: 7, Loss: 4.5988, Train: 0.3643, Val: 0.2200, Test: 0.2240
Epoch: 8, Loss: 4.5742, Train: 0.3857, Val: 0.2280, Test: 0.2270
Epoch: 9, Loss: 4.5007, Train: 0.3929, Val: 0.2340, Test: 0.2310
Epoch: 10, Loss: 4.5051, Train: 0.4214, Val: 0.2640, Test: 0.2440
Epoch: 11, Loss: 4.5440, Train: 0.4500, Val: 0.2840, Test: 0.2720
Epoch: 12, Loss: 4.3392, Train: 0.5214, Val: 0.3200, Test: 0.3260
Epoch: 13, Loss: 4.2197, Train: 0.5571, Val: 0.3640, Test: 0.3750
Epoch: 14, Loss: 4.2465, Train: 0.6071, Val: 0.4340, Test: 0.4400
Epoch: 15, Loss: 4.2453, Train: 0.6571, Val: 0.4980, Test: 0.5170
Epoch: 16, Loss: 4.4145, Train: 0.7000, Val: 0.6000, Test: 0.6020
Epoch: 17, Loss: 4.1807, Train: 0.7929, Val: 0.6820, Test: 0.6840
Epoch: 18, Loss: 4.3292, Train: 0.9000, Val: 0.7400, Test: 0.7590
Epoch: 19, Loss: 4.1158, Train: 0.9357, Val: 0.7720, Test: 0.7830
Epoch: 20, Loss: 4.3400, Train: 0.9643, Val: 0.7720, Test: 0.7970
Epoch: 21, Loss: 4.3447, Train: 0.9571, Val: 0.7720, Test: 0.8020
Epoch: 22, Loss: 4.0803, Train: 0.9643, Val: 0.7560, Test: 0.7930
Epoch: 23, Loss: 4.0642, Train: 0.9571, Val: 0.7560, Test: 0.7730
Epoch: 24, Loss: 4.0215, Train: 0.9500, Val: 0.7600, Test: 0.7590
Epoch: 25, Loss: 4.1048, Train: 0.9429, Val: 0.7560, Test: 0.7500
Epoch: 26, Loss: 3.9853, Train: 0.9429, Val: 0.7440, Test: 0.7430
Epoch: 27, Loss: 4.2426, Train: 0.9571, Val: 0.7560, Test: 0.7490
Epoch: 28, Loss: 3.8554, Train: 0.9571, Val: 0.7660, Test: 0.7670
Epoch: 29, Loss: 3.7008, Train: 0.9571, Val: 0.7640, Test: 0.7860
Epoch: 30, Loss: 3.8972, Train: 0.9643, Val: 0.7740, Test: 0.7940
Epoch: 31, Loss: 4.1306, Train: 0.9571, Val: 0.7760, Test: 0.8080
Epoch: 32, Loss: 4.0575, Train: 0.9643, Val: 0.7840, Test: 0.8130
Epoch: 33, Loss: 3.8175, Train: 0.9786, Val: 0.7940, Test: 0.8160
Epoch: 34, Loss: 3.9827, Train: 0.9786, Val: 0.8020, Test: 0.8200
Epoch: 35, Loss: 3.8159, Train: 0.9786, Val: 0.8020, Test: 0.8230
Epoch: 36, Loss: 3.9038, Train: 0.9643, Val: 0.8100, Test: 0.8260
Epoch: 37, Loss: 3.9162, Train: 0.9643, Val: 0.8120, Test: 0.8260
Epoch: 38, Loss: 3.8790, Train: 0.9643, Val: 0.8100, Test: 0.8270
Epoch: 39, Loss: 3.6648, Train: 0.9714, Val: 0.8080, Test: 0.8280
Epoch: 40, Loss: 3.5628, Train: 0.9714, Val: 0.8100, Test: 0.8320
Epoch: 41, Loss: 3.9077, Train: 0.9857, Val: 0.8020, Test: 0.8270
Epoch: 42, Loss: 3.9651, Train: 0.9857, Val: 0.7940, Test: 0.8230
Epoch: 43, Loss: 4.0244, Train: 0.9857, Val: 0.7900, Test: 0.8190
Epoch: 44, Loss: 4.0252, Train: 0.9857, Val: 0.7820, Test: 0.8150
Epoch: 45, Loss: 3.9511, Train: 0.9857, Val: 0.7800, Test: 0.8120
Epoch: 46, Loss: 3.8116, Train: 0.9857, Val: 0.7820, Test: 0.8080
Epoch: 47, Loss: 3.9571, Train: 0.9857, Val: 0.7860, Test: 0.8090
Epoch: 48, Loss: 3.8244, Train: 0.9929, Val: 0.7860, Test: 0.8090
Epoch: 49, Loss: 3.8599, Train: 0.9929, Val: 0.7900, Test: 0.7990
Epoch: 50, Loss: 3.6251, Train: 0.9929, Val: 0.7880, Test: 0.7930
Epoch: 51, Loss: 3.8770, Train: 0.9929, Val: 0.7900, Test: 0.7960
Epoch: 52, Loss: 3.7798, Train: 0.9929, Val: 0.7940, Test: 0.7950
Epoch: 53, Loss: 3.8022, Train: 0.9929, Val: 0.7900, Test: 0.8000
Epoch: 54, Loss: 3.7152, Train: 0.9929, Val: 0.7940, Test: 0.8050
Epoch: 55, Loss: 3.5045, Train: 0.9929, Val: 0.7940, Test: 0.8060
Epoch: 56, Loss: 3.8974, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 57, Loss: 3.7413, Train: 0.9929, Val: 0.7980, Test: 0.8060
Epoch: 58, Loss: 3.9557, Train: 0.9929, Val: 0.8000, Test: 0.8070
Epoch: 59, Loss: 3.5189, Train: 0.9929, Val: 0.8000, Test: 0.8110
Epoch: 60, Loss: 3.7401, Train: 0.9929, Val: 0.8040, Test: 0.8130
Epoch: 61, Loss: 3.8453, Train: 0.9929, Val: 0.8080, Test: 0.8130
Epoch: 62, Loss: 3.5075, Train: 0.9929, Val: 0.8120, Test: 0.8110
Epoch: 63, Loss: 3.6296, Train: 1.0000, Val: 0.8120, Test: 0.8110
Epoch: 64, Loss: 3.9835, Train: 1.0000, Val: 0.8020, Test: 0.8130
Epoch: 65, Loss: 3.5042, Train: 1.0000, Val: 0.8020, Test: 0.8180
Epoch: 66, Loss: 3.9274, Train: 1.0000, Val: 0.7960, Test: 0.8170
Epoch: 67, Loss: 3.6459, Train: 1.0000, Val: 0.7920, Test: 0.8160
Epoch: 68, Loss: 3.6464, Train: 1.0000, Val: 0.7860, Test: 0.8130
Epoch: 69, Loss: 3.6009, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 70, Loss: 3.6118, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 71, Loss: 3.6123, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 72, Loss: 3.8067, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 73, Loss: 3.8826, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 74, Loss: 3.5622, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 75, Loss: 3.7825, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 76, Loss: 3.0234, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 77, Loss: 4.0037, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 78, Loss: 3.6576, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 79, Loss: 3.8597, Train: 1.0000, Val: 0.7920, Test: 0.7960
Epoch: 80, Loss: 3.6103, Train: 1.0000, Val: 0.7960, Test: 0.8010
Epoch: 81, Loss: 3.7609, Train: 1.0000, Val: 0.7980, Test: 0.8020
Epoch: 82, Loss: 3.6411, Train: 1.0000, Val: 0.7940, Test: 0.8030
Epoch: 83, Loss: 3.7169, Train: 1.0000, Val: 0.7940, Test: 0.8020
Epoch: 84, Loss: 3.5730, Train: 1.0000, Val: 0.7920, Test: 0.8010
Epoch: 85, Loss: 3.6772, Train: 1.0000, Val: 0.7920, Test: 0.7990
Epoch: 86, Loss: 3.4693, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 87, Loss: 3.5301, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 88, Loss: 3.6387, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 89, Loss: 3.5851, Train: 1.0000, Val: 0.7940, Test: 0.8030
Epoch: 90, Loss: 3.6900, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 91, Loss: 3.6091, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 92, Loss: 3.8316, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 93, Loss: 3.5077, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 94, Loss: 3.8605, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 95, Loss: 3.6674, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 96, Loss: 3.7618, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 97, Loss: 3.6633, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 98, Loss: 4.0806, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 99, Loss: 3.6671, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 100, Loss: 3.4498, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 101, Loss: 3.5867, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 102, Loss: 3.6893, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 103, Loss: 3.8156, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 104, Loss: 3.6220, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 105, Loss: 3.6202, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 106, Loss: 3.6654, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 107, Loss: 3.5911, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 108, Loss: 3.8352, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 109, Loss: 4.0356, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 110, Loss: 3.3939, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 111, Loss: 3.6301, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 112, Loss: 3.7898, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 113, Loss: 3.7744, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 114, Loss: 3.6891, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 115, Loss: 3.7685, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 116, Loss: 3.5817, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 117, Loss: 3.6004, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 118, Loss: 3.7919, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 119, Loss: 3.9330, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 120, Loss: 3.7223, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 121, Loss: 3.7270, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 122, Loss: 3.3791, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 123, Loss: 3.3802, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 124, Loss: 3.7218, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 125, Loss: 3.7656, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 126, Loss: 3.6883, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 127, Loss: 3.5950, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 128, Loss: 3.7944, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 129, Loss: 3.6487, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 130, Loss: 3.4509, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 131, Loss: 3.4441, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 132, Loss: 3.6797, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 133, Loss: 3.6933, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 134, Loss: 3.7887, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 135, Loss: 3.7238, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 136, Loss: 3.6928, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 137, Loss: 3.5518, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 138, Loss: 3.4494, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 139, Loss: 3.5474, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 140, Loss: 3.5489, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 141, Loss: 3.9000, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 142, Loss: 3.3387, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 143, Loss: 3.6520, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 144, Loss: 3.5797, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 145, Loss: 3.5160, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 146, Loss: 3.7558, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 147, Loss: 3.5166, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 148, Loss: 3.6989, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 149, Loss: 3.6209, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 150, Loss: 3.6915, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 151, Loss: 3.7195, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 152, Loss: 3.8339, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 153, Loss: 3.6567, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 154, Loss: 3.3509, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 155, Loss: 3.5112, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 156, Loss: 3.7863, Train: 1.0000, Val: 0.7880, Test: 0.8070
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 157, Loss: 3.5792, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 158, Loss: 3.5788, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 159, Loss: 3.7561, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 160, Loss: 3.9960, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 161, Loss: 3.6172, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 162, Loss: 3.5503, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 163, Loss: 3.4499, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 164, Loss: 3.7498, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 165, Loss: 3.6888, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 166, Loss: 3.7269, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 167, Loss: 3.5866, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 168, Loss: 3.6843, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 169, Loss: 3.8924, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 170, Loss: 3.6827, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 171, Loss: 3.4819, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 172, Loss: 3.7208, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 173, Loss: 3.3151, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 174, Loss: 3.7930, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 175, Loss: 3.5861, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 176, Loss: 3.7240, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 177, Loss: 3.9929, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 178, Loss: 3.6144, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 179, Loss: 3.6151, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 180, Loss: 3.3064, Train: 1.0000, Val: 0.7760, Test: 0.8130
Epoch: 181, Loss: 3.8190, Train: 1.0000, Val: 0.7760, Test: 0.8130
Epoch: 182, Loss: 3.9601, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 183, Loss: 3.7925, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 184, Loss: 3.6140, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 185, Loss: 3.8578, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 186, Loss: 3.5790, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 187, Loss: 3.4130, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 188, Loss: 3.7517, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 189, Loss: 3.6473, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 190, Loss: 3.7230, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 191, Loss: 3.6586, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 192, Loss: 3.6113, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 193, Loss: 3.3166, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 194, Loss: 3.8064, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 195, Loss: 3.7500, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 196, Loss: 3.8580, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 197, Loss: 3.4054, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 198, Loss: 3.7210, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 199, Loss: 4.0332, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 200, Loss: 3.5850, Train: 1.0000, Val: 0.7760, Test: 0.8070
MAD:  0.2577
Best Test Accuracy: 0.8320, Val Accuracy: 0.8100, Train Accuracy: 0.9714
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8536, Train: 0.2143, Val: 0.0940, Test: 0.0960
Epoch: 2, Loss: 4.8365, Train: 0.2786, Val: 0.1560, Test: 0.1610
Epoch: 3, Loss: 4.8319, Train: 0.3000, Val: 0.1900, Test: 0.1810
Epoch: 4, Loss: 4.7786, Train: 0.3214, Val: 0.2000, Test: 0.1970
Epoch: 5, Loss: 4.7519, Train: 0.3214, Val: 0.2020, Test: 0.2080
Epoch: 6, Loss: 4.6638, Train: 0.3429, Val: 0.2080, Test: 0.2190
Epoch: 7, Loss: 4.7071, Train: 0.3857, Val: 0.2080, Test: 0.2290
Epoch: 8, Loss: 4.6863, Train: 0.3929, Val: 0.2220, Test: 0.2370
Epoch: 9, Loss: 4.5950, Train: 0.3929, Val: 0.2300, Test: 0.2380
Epoch: 10, Loss: 4.5799, Train: 0.4071, Val: 0.2380, Test: 0.2450
Epoch: 11, Loss: 4.5980, Train: 0.4286, Val: 0.2400, Test: 0.2570
Epoch: 12, Loss: 4.6236, Train: 0.4357, Val: 0.2520, Test: 0.2600
Epoch: 13, Loss: 4.4805, Train: 0.4357, Val: 0.2580, Test: 0.2690
Epoch: 14, Loss: 4.4795, Train: 0.4357, Val: 0.2680, Test: 0.2810
Epoch: 15, Loss: 4.2688, Train: 0.4500, Val: 0.2760, Test: 0.2870
Epoch: 16, Loss: 4.3309, Train: 0.4786, Val: 0.2940, Test: 0.3010
Epoch: 17, Loss: 4.2013, Train: 0.5214, Val: 0.3380, Test: 0.3320
Epoch: 18, Loss: 4.1132, Train: 0.6643, Val: 0.4380, Test: 0.4110
Epoch: 19, Loss: 4.3305, Train: 0.7786, Val: 0.5640, Test: 0.5510
Epoch: 20, Loss: 4.3807, Train: 0.8571, Val: 0.7020, Test: 0.6780
Epoch: 21, Loss: 4.0513, Train: 0.9071, Val: 0.7680, Test: 0.7750
Epoch: 22, Loss: 4.2134, Train: 0.9286, Val: 0.7860, Test: 0.7990
Epoch: 23, Loss: 4.1185, Train: 0.9214, Val: 0.7820, Test: 0.8060
Epoch: 24, Loss: 4.1649, Train: 0.9071, Val: 0.7740, Test: 0.7890
Epoch: 25, Loss: 4.2280, Train: 0.8929, Val: 0.7840, Test: 0.7850
Epoch: 26, Loss: 4.1279, Train: 0.9071, Val: 0.7800, Test: 0.7820
Epoch: 27, Loss: 4.1925, Train: 0.9071, Val: 0.7780, Test: 0.7800
Epoch: 28, Loss: 4.0881, Train: 0.9286, Val: 0.7740, Test: 0.7670
Epoch: 29, Loss: 3.8852, Train: 0.9286, Val: 0.7740, Test: 0.7760
Epoch: 30, Loss: 4.1395, Train: 0.9429, Val: 0.7700, Test: 0.7750
Epoch: 31, Loss: 3.9224, Train: 0.9571, Val: 0.7720, Test: 0.7820
Epoch: 32, Loss: 4.1180, Train: 0.9500, Val: 0.7740, Test: 0.7870
Epoch: 33, Loss: 3.9105, Train: 0.9429, Val: 0.7720, Test: 0.7750
Epoch: 34, Loss: 4.0134, Train: 0.9429, Val: 0.7820, Test: 0.7750
Epoch: 35, Loss: 3.7745, Train: 0.9500, Val: 0.7800, Test: 0.7770
Epoch: 36, Loss: 4.0462, Train: 0.9500, Val: 0.7680, Test: 0.7710
Epoch: 37, Loss: 4.1512, Train: 0.9571, Val: 0.7700, Test: 0.7710
Epoch: 38, Loss: 3.9334, Train: 0.9643, Val: 0.7760, Test: 0.7770
Epoch: 39, Loss: 3.9051, Train: 0.9714, Val: 0.7760, Test: 0.7810
Epoch: 40, Loss: 3.8299, Train: 0.9786, Val: 0.7800, Test: 0.7840
Epoch: 41, Loss: 3.6645, Train: 0.9857, Val: 0.7820, Test: 0.7870
Epoch: 42, Loss: 3.9703, Train: 0.9857, Val: 0.7800, Test: 0.7900
Epoch: 43, Loss: 3.8447, Train: 0.9929, Val: 0.7860, Test: 0.7920
Epoch: 44, Loss: 3.6583, Train: 0.9929, Val: 0.7920, Test: 0.7920
Epoch: 45, Loss: 3.8248, Train: 0.9857, Val: 0.7920, Test: 0.7990
Epoch: 46, Loss: 3.9369, Train: 0.9857, Val: 0.7860, Test: 0.7960
Epoch: 47, Loss: 3.7722, Train: 0.9857, Val: 0.7900, Test: 0.7960
Epoch: 48, Loss: 3.8989, Train: 0.9857, Val: 0.7820, Test: 0.7960
Epoch: 49, Loss: 4.3343, Train: 0.9857, Val: 0.7840, Test: 0.7940
Epoch: 50, Loss: 3.6983, Train: 0.9857, Val: 0.7860, Test: 0.7950
Epoch: 51, Loss: 3.8300, Train: 0.9857, Val: 0.7840, Test: 0.7960
Epoch: 52, Loss: 3.6426, Train: 0.9857, Val: 0.7880, Test: 0.7980
Epoch: 53, Loss: 4.0125, Train: 0.9929, Val: 0.7880, Test: 0.8050
Epoch: 54, Loss: 3.9848, Train: 0.9929, Val: 0.7900, Test: 0.8140
Epoch: 55, Loss: 3.6739, Train: 0.9929, Val: 0.7880, Test: 0.8190
Epoch: 56, Loss: 3.6840, Train: 0.9929, Val: 0.7900, Test: 0.8190
Epoch: 57, Loss: 3.3670, Train: 0.9929, Val: 0.7900, Test: 0.8210
Epoch: 58, Loss: 3.9414, Train: 0.9929, Val: 0.8000, Test: 0.8180
Epoch: 59, Loss: 3.5366, Train: 0.9929, Val: 0.7960, Test: 0.8140
Epoch: 60, Loss: 3.7574, Train: 0.9857, Val: 0.7900, Test: 0.8110
Epoch: 61, Loss: 3.4774, Train: 0.9857, Val: 0.7920, Test: 0.8110
Epoch: 62, Loss: 3.7590, Train: 0.9929, Val: 0.7920, Test: 0.8070
Epoch: 63, Loss: 3.5665, Train: 0.9929, Val: 0.7920, Test: 0.8070
Epoch: 64, Loss: 3.7926, Train: 0.9929, Val: 0.7900, Test: 0.8050
Epoch: 65, Loss: 3.6973, Train: 0.9929, Val: 0.7900, Test: 0.8020
Epoch: 66, Loss: 3.6031, Train: 0.9929, Val: 0.7920, Test: 0.8050
Epoch: 67, Loss: 3.7837, Train: 0.9929, Val: 0.7880, Test: 0.8030
Epoch: 68, Loss: 3.8690, Train: 0.9929, Val: 0.7940, Test: 0.8050
Epoch: 69, Loss: 3.8213, Train: 0.9929, Val: 0.7900, Test: 0.8040
Epoch: 70, Loss: 3.7597, Train: 0.9929, Val: 0.7940, Test: 0.8020
Epoch: 71, Loss: 3.6070, Train: 0.9929, Val: 0.7960, Test: 0.8030
Epoch: 72, Loss: 3.5251, Train: 0.9929, Val: 0.7920, Test: 0.8030
Epoch: 73, Loss: 3.7525, Train: 0.9929, Val: 0.7980, Test: 0.8030
Epoch: 74, Loss: 3.8994, Train: 0.9929, Val: 0.8020, Test: 0.8030
Epoch: 75, Loss: 3.5741, Train: 1.0000, Val: 0.8000, Test: 0.8060
Epoch: 76, Loss: 3.4130, Train: 1.0000, Val: 0.8000, Test: 0.8060
Epoch: 77, Loss: 3.5876, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 78, Loss: 3.6222, Train: 0.9929, Val: 0.7880, Test: 0.8020
Epoch: 79, Loss: 3.6725, Train: 0.9929, Val: 0.7880, Test: 0.8030
Epoch: 80, Loss: 3.7196, Train: 0.9929, Val: 0.7880, Test: 0.8020
Epoch: 81, Loss: 4.0897, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 82, Loss: 4.0982, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 83, Loss: 3.6706, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 84, Loss: 3.6915, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 85, Loss: 3.7485, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 86, Loss: 3.5114, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 87, Loss: 3.6363, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 88, Loss: 3.4267, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 89, Loss: 3.6188, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 90, Loss: 3.6476, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 91, Loss: 3.5979, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 92, Loss: 3.6495, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 93, Loss: 3.6924, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 94, Loss: 3.6804, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 95, Loss: 3.7048, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 96, Loss: 3.5265, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 97, Loss: 3.8462, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 98, Loss: 3.6229, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 99, Loss: 3.8348, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 100, Loss: 3.6324, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 101, Loss: 3.9243, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 102, Loss: 3.5423, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 103, Loss: 3.7292, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 104, Loss: 3.7086, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 105, Loss: 3.7389, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 106, Loss: 3.7932, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 107, Loss: 3.7355, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 108, Loss: 3.8750, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 109, Loss: 3.9419, Train: 1.0000, Val: 0.7880, Test: 0.7950
Epoch: 110, Loss: 3.5624, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 111, Loss: 3.8353, Train: 1.0000, Val: 0.7940, Test: 0.8000
Epoch: 112, Loss: 3.7616, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 113, Loss: 3.5348, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 114, Loss: 3.6669, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 115, Loss: 3.9069, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 116, Loss: 3.4211, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 117, Loss: 3.2370, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 118, Loss: 3.6430, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 119, Loss: 3.7102, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 120, Loss: 3.5187, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 121, Loss: 3.6418, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 122, Loss: 3.8912, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 123, Loss: 3.5241, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 124, Loss: 3.8445, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 125, Loss: 3.1815, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 126, Loss: 3.4645, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 127, Loss: 3.7240, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 128, Loss: 3.4847, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 129, Loss: 3.8644, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 130, Loss: 3.6316, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 131, Loss: 3.5955, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 132, Loss: 3.7610, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 133, Loss: 3.7990, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 134, Loss: 3.6884, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 135, Loss: 3.5864, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 136, Loss: 3.6314, Train: 1.0000, Val: 0.7880, Test: 0.7940
Epoch: 137, Loss: 3.6223, Train: 1.0000, Val: 0.7900, Test: 0.7930
Epoch: 138, Loss: 3.6530, Train: 1.0000, Val: 0.7860, Test: 0.7910
Epoch: 139, Loss: 3.7755, Train: 1.0000, Val: 0.7880, Test: 0.7920
Epoch: 140, Loss: 3.5560, Train: 1.0000, Val: 0.7880, Test: 0.7920
Epoch: 141, Loss: 3.8589, Train: 1.0000, Val: 0.7880, Test: 0.7920
Epoch: 142, Loss: 3.7285, Train: 1.0000, Val: 0.7860, Test: 0.7900
Epoch: 143, Loss: 3.5471, Train: 1.0000, Val: 0.7840, Test: 0.7910
Epoch: 144, Loss: 3.4103, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 145, Loss: 3.9038, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 146, Loss: 3.5844, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 147, Loss: 3.6529, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 148, Loss: 3.6900, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 149, Loss: 3.5494, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 150, Loss: 3.7272, Train: 1.0000, Val: 0.7580, Test: 0.7880
Epoch: 151, Loss: 3.6174, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 152, Loss: 3.3045, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 153, Loss: 3.6869, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 154, Loss: 3.6887, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 155, Loss: 3.5815, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 156, Loss: 3.4091, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 157, Loss: 3.1701, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 158, Loss: 3.7862, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 159, Loss: 3.5100, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 160, Loss: 3.6518, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 161, Loss: 3.4086, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 162, Loss: 3.5782, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 163, Loss: 3.8237, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 164, Loss: 3.8255, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 165, Loss: 3.8948, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 166, Loss: 3.5804, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 167, Loss: 3.6983, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 168, Loss: 3.6188, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 169, Loss: 3.7890, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 170, Loss: 3.4299, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 171, Loss: 3.9291, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 172, Loss: 3.8286, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 173, Loss: 3.3699, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 174, Loss: 3.4736, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 175, Loss: 3.8608, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 176, Loss: 3.1814, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 177, Loss: 3.5785, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 178, Loss: 3.8926, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 179, Loss: 3.6848, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 180, Loss: 3.4741, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 181, Loss: 3.6504, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 182, Loss: 3.4439, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 183, Loss: 3.5467, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 184, Loss: 3.5852, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 185, Loss: 3.7480, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 186, Loss: 3.6833, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 187, Loss: 3.4101, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 188, Loss: 3.8543, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 189, Loss: 3.3081, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 190, Loss: 3.5093, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 191, Loss: 3.7254, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 192, Loss: 3.6479, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 193, Loss: 3.5815, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 194, Loss: 3.5478, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 195, Loss: 3.5464, Train: 1.0000, Val: 0.7780, Test: 0.8000
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 196, Loss: 3.4749, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 197, Loss: 3.5465, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 198, Loss: 3.8566, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 199, Loss: 3.5120, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 200, Loss: 3.7234, Train: 1.0000, Val: 0.7780, Test: 0.8020
MAD:  0.5102
Best Test Accuracy: 0.8210, Val Accuracy: 0.7900, Train Accuracy: 0.9929
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8447, Train: 0.1714, Val: 0.0860, Test: 0.0950
Epoch: 2, Loss: 4.8245, Train: 0.2357, Val: 0.1100, Test: 0.1200
Epoch: 3, Loss: 4.8096, Train: 0.3143, Val: 0.1520, Test: 0.1640
Epoch: 4, Loss: 4.7447, Train: 0.4357, Val: 0.1960, Test: 0.2240
Epoch: 5, Loss: 4.7774, Train: 0.5357, Val: 0.2660, Test: 0.3070
Epoch: 6, Loss: 4.7096, Train: 0.6286, Val: 0.3640, Test: 0.4090
Epoch: 7, Loss: 4.6503, Train: 0.7214, Val: 0.4620, Test: 0.4900
Epoch: 8, Loss: 4.6421, Train: 0.7500, Val: 0.5180, Test: 0.5430
Epoch: 9, Loss: 4.5849, Train: 0.7857, Val: 0.5500, Test: 0.5760
Epoch: 10, Loss: 4.5791, Train: 0.8000, Val: 0.5740, Test: 0.6010
Epoch: 11, Loss: 4.5546, Train: 0.7786, Val: 0.5900, Test: 0.6230
Epoch: 12, Loss: 4.4181, Train: 0.7857, Val: 0.5960, Test: 0.6250
Epoch: 13, Loss: 4.3915, Train: 0.7929, Val: 0.5980, Test: 0.6290
Epoch: 14, Loss: 4.1880, Train: 0.8000, Val: 0.6000, Test: 0.6280
Epoch: 15, Loss: 4.3947, Train: 0.8214, Val: 0.5760, Test: 0.6240
Epoch: 16, Loss: 4.4172, Train: 0.8143, Val: 0.5700, Test: 0.6120
Epoch: 17, Loss: 4.2084, Train: 0.8214, Val: 0.5760, Test: 0.5970
Epoch: 18, Loss: 4.1467, Train: 0.8214, Val: 0.5600, Test: 0.5820
Epoch: 19, Loss: 4.0320, Train: 0.8214, Val: 0.5340, Test: 0.5570
Epoch: 20, Loss: 3.9728, Train: 0.8571, Val: 0.5460, Test: 0.5620
Epoch: 21, Loss: 4.2699, Train: 0.8857, Val: 0.6080, Test: 0.6170
Epoch: 22, Loss: 4.1099, Train: 0.9071, Val: 0.6660, Test: 0.6450
Epoch: 23, Loss: 4.2558, Train: 0.9357, Val: 0.6900, Test: 0.6650
Epoch: 24, Loss: 4.0133, Train: 0.9357, Val: 0.6880, Test: 0.6820
Epoch: 25, Loss: 3.9322, Train: 0.9357, Val: 0.6820, Test: 0.6910
Epoch: 26, Loss: 4.2175, Train: 0.9357, Val: 0.6700, Test: 0.6840
Epoch: 27, Loss: 4.1913, Train: 0.9357, Val: 0.6820, Test: 0.6900
Epoch: 28, Loss: 4.1667, Train: 0.9429, Val: 0.7040, Test: 0.7090
Epoch: 29, Loss: 4.1595, Train: 0.9500, Val: 0.7200, Test: 0.7350
Epoch: 30, Loss: 4.1723, Train: 0.9643, Val: 0.7400, Test: 0.7580
Epoch: 31, Loss: 3.8639, Train: 0.9643, Val: 0.7720, Test: 0.7750
Epoch: 32, Loss: 4.1713, Train: 0.9643, Val: 0.7760, Test: 0.7910
Epoch: 33, Loss: 3.7984, Train: 0.9643, Val: 0.7880, Test: 0.8020
Epoch: 34, Loss: 4.0187, Train: 0.9643, Val: 0.7940, Test: 0.8110
Epoch: 35, Loss: 3.9479, Train: 0.9714, Val: 0.8040, Test: 0.8090
Epoch: 36, Loss: 3.9113, Train: 0.9786, Val: 0.8000, Test: 0.8090
Epoch: 37, Loss: 3.9246, Train: 0.9786, Val: 0.8060, Test: 0.8130
Epoch: 38, Loss: 3.7918, Train: 0.9857, Val: 0.8100, Test: 0.8230
Epoch: 39, Loss: 3.8488, Train: 0.9857, Val: 0.8040, Test: 0.8180
Epoch: 40, Loss: 3.8901, Train: 0.9786, Val: 0.8020, Test: 0.8190
Epoch: 41, Loss: 3.7550, Train: 0.9786, Val: 0.8100, Test: 0.8140
Epoch: 42, Loss: 3.8159, Train: 0.9857, Val: 0.8080, Test: 0.8110
Epoch: 43, Loss: 4.0866, Train: 0.9857, Val: 0.8080, Test: 0.8110
Epoch: 44, Loss: 3.9987, Train: 0.9857, Val: 0.8080, Test: 0.8070
Epoch: 45, Loss: 3.6924, Train: 0.9857, Val: 0.8000, Test: 0.8030
Epoch: 46, Loss: 3.6891, Train: 0.9857, Val: 0.7980, Test: 0.7970
Epoch: 47, Loss: 3.8680, Train: 0.9857, Val: 0.7880, Test: 0.7960
Epoch: 48, Loss: 4.0535, Train: 0.9857, Val: 0.7820, Test: 0.7940
Epoch: 49, Loss: 4.0594, Train: 0.9857, Val: 0.7800, Test: 0.7870
Epoch: 50, Loss: 3.6614, Train: 0.9857, Val: 0.7800, Test: 0.7860
Epoch: 51, Loss: 4.1062, Train: 0.9857, Val: 0.7720, Test: 0.7880
Epoch: 52, Loss: 3.8316, Train: 0.9857, Val: 0.7740, Test: 0.7900
Epoch: 53, Loss: 3.6475, Train: 0.9857, Val: 0.7720, Test: 0.7900
Epoch: 54, Loss: 3.6161, Train: 0.9857, Val: 0.7700, Test: 0.7970
Epoch: 55, Loss: 3.7649, Train: 0.9857, Val: 0.7720, Test: 0.7970
Epoch: 56, Loss: 3.7090, Train: 0.9857, Val: 0.7740, Test: 0.8030
Epoch: 57, Loss: 3.6230, Train: 0.9857, Val: 0.7780, Test: 0.8000
Epoch: 58, Loss: 3.7311, Train: 0.9857, Val: 0.7760, Test: 0.7980
Epoch: 59, Loss: 3.5566, Train: 0.9857, Val: 0.7800, Test: 0.8030
Epoch: 60, Loss: 3.3398, Train: 0.9929, Val: 0.7860, Test: 0.8030
Epoch: 61, Loss: 3.8065, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 62, Loss: 3.4852, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 63, Loss: 3.7320, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 64, Loss: 3.7014, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 65, Loss: 3.6026, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 66, Loss: 3.5175, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 67, Loss: 3.5614, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 68, Loss: 3.8403, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 69, Loss: 3.5597, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 70, Loss: 3.7182, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 71, Loss: 3.6132, Train: 1.0000, Val: 0.7960, Test: 0.8080
Epoch: 72, Loss: 3.3502, Train: 1.0000, Val: 0.7960, Test: 0.8090
Epoch: 73, Loss: 3.7282, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 74, Loss: 3.4189, Train: 1.0000, Val: 0.7940, Test: 0.8070
Epoch: 75, Loss: 3.4216, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 76, Loss: 3.4425, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 77, Loss: 3.8072, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 78, Loss: 3.7811, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 79, Loss: 3.7955, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 80, Loss: 3.7830, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 81, Loss: 3.7482, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 82, Loss: 3.5324, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 83, Loss: 3.6561, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 84, Loss: 3.8260, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 85, Loss: 3.3818, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 86, Loss: 3.6091, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 87, Loss: 3.7445, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 88, Loss: 3.5480, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 89, Loss: 3.8411, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 90, Loss: 3.8743, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 91, Loss: 3.8746, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 92, Loss: 3.3363, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 93, Loss: 3.9065, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 94, Loss: 3.8142, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 95, Loss: 3.6634, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 96, Loss: 3.7268, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 97, Loss: 3.4536, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 98, Loss: 3.9409, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 99, Loss: 3.5317, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 100, Loss: 3.7486, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 101, Loss: 3.5645, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 102, Loss: 3.3614, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 103, Loss: 3.6283, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 104, Loss: 3.5799, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 105, Loss: 3.9318, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 106, Loss: 3.7360, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 107, Loss: 3.7694, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 108, Loss: 3.6449, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 109, Loss: 4.0465, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 110, Loss: 3.8284, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 111, Loss: 3.3104, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 112, Loss: 3.6550, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 113, Loss: 3.7526, Train: 1.0000, Val: 0.7840, Test: 0.8040
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 114, Loss: 3.4532, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 115, Loss: 4.0733, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 116, Loss: 3.9317, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 117, Loss: 3.8157, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 118, Loss: 3.8396, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 119, Loss: 3.6628, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 120, Loss: 3.7904, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 121, Loss: 3.5785, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 122, Loss: 3.3223, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 123, Loss: 3.6871, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 124, Loss: 3.5176, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 125, Loss: 3.7253, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 126, Loss: 3.1443, Train: 1.0000, Val: 0.7880, Test: 0.8150
Epoch: 127, Loss: 3.5986, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 128, Loss: 3.7075, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 129, Loss: 3.6278, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 130, Loss: 3.5475, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 131, Loss: 3.8636, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 132, Loss: 3.4919, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 133, Loss: 3.6235, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 134, Loss: 3.3795, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 135, Loss: 3.9316, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 136, Loss: 3.6935, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 137, Loss: 3.7581, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 138, Loss: 3.7671, Train: 1.0000, Val: 0.7960, Test: 0.8100
Epoch: 139, Loss: 3.6223, Train: 1.0000, Val: 0.7980, Test: 0.8120
Epoch: 140, Loss: 3.2736, Train: 1.0000, Val: 0.7980, Test: 0.8120
Epoch: 141, Loss: 3.5129, Train: 1.0000, Val: 0.7960, Test: 0.8120
Epoch: 142, Loss: 3.6918, Train: 1.0000, Val: 0.7940, Test: 0.8110
Epoch: 143, Loss: 3.5873, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 144, Loss: 3.6850, Train: 1.0000, Val: 0.7920, Test: 0.8070
Epoch: 145, Loss: 3.9275, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 146, Loss: 3.5566, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 147, Loss: 3.4435, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 148, Loss: 3.8256, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 149, Loss: 3.9369, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 150, Loss: 3.6234, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 151, Loss: 3.5810, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 152, Loss: 3.7237, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 153, Loss: 3.5126, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 154, Loss: 3.4934, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 155, Loss: 3.5646, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 156, Loss: 3.6902, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 157, Loss: 3.7170, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 158, Loss: 3.5471, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 159, Loss: 3.4913, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 160, Loss: 3.6619, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 161, Loss: 3.5472, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 162, Loss: 3.7912, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 163, Loss: 3.6497, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 164, Loss: 3.3729, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 165, Loss: 3.5434, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 166, Loss: 3.4412, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 167, Loss: 3.6853, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 168, Loss: 3.8319, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 169, Loss: 3.8009, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 170, Loss: 3.7557, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 171, Loss: 3.9260, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 172, Loss: 3.4797, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 173, Loss: 3.6879, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 174, Loss: 3.4852, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 175, Loss: 3.7208, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 176, Loss: 3.5089, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 177, Loss: 3.6199, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 178, Loss: 3.2695, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 179, Loss: 3.6168, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 180, Loss: 3.5810, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 181, Loss: 3.8597, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 182, Loss: 3.9659, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 183, Loss: 3.8235, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 184, Loss: 3.7882, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 185, Loss: 3.4858, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 186, Loss: 3.7607, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 187, Loss: 3.3814, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 188, Loss: 3.5115, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 189, Loss: 3.8217, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 190, Loss: 3.6877, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 191, Loss: 3.8571, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 192, Loss: 3.5443, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 193, Loss: 3.6486, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 194, Loss: 3.5774, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 195, Loss: 3.6848, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 196, Loss: 3.7929, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 197, Loss: 3.6195, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 198, Loss: 3.7566, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 199, Loss: 3.9679, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 200, Loss: 3.6820, Train: 1.0000, Val: 0.7780, Test: 0.8060
MAD:  0.2869
Best Test Accuracy: 0.8230, Val Accuracy: 0.8100, Train Accuracy: 0.9857
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8496, Train: 0.1357, Val: 0.1700, Test: 0.1940
Epoch: 2, Loss: 4.8348, Train: 0.2500, Val: 0.3000, Test: 0.3010
Epoch: 3, Loss: 4.8237, Train: 0.2857, Val: 0.3360, Test: 0.3440
Epoch: 4, Loss: 4.8033, Train: 0.2929, Val: 0.3400, Test: 0.3560
Epoch: 5, Loss: 4.7437, Train: 0.3071, Val: 0.3400, Test: 0.3610
Epoch: 6, Loss: 4.7384, Train: 0.3214, Val: 0.3580, Test: 0.3870
Epoch: 7, Loss: 4.7023, Train: 0.3786, Val: 0.3760, Test: 0.4010
Epoch: 8, Loss: 4.5880, Train: 0.3786, Val: 0.3680, Test: 0.4140
Epoch: 9, Loss: 4.5189, Train: 0.4000, Val: 0.3580, Test: 0.4120
Epoch: 10, Loss: 4.6145, Train: 0.4143, Val: 0.3460, Test: 0.4000
Epoch: 11, Loss: 4.5268, Train: 0.4071, Val: 0.3360, Test: 0.3970
Epoch: 12, Loss: 4.5447, Train: 0.4357, Val: 0.3420, Test: 0.3970
Epoch: 13, Loss: 4.3917, Train: 0.4357, Val: 0.3460, Test: 0.4010
Epoch: 14, Loss: 4.3933, Train: 0.4714, Val: 0.3560, Test: 0.4060
Epoch: 15, Loss: 4.2671, Train: 0.5429, Val: 0.3840, Test: 0.4280
Epoch: 16, Loss: 4.2360, Train: 0.5714, Val: 0.4140, Test: 0.4540
Epoch: 17, Loss: 4.3017, Train: 0.6429, Val: 0.4360, Test: 0.4930
Epoch: 18, Loss: 4.4414, Train: 0.6714, Val: 0.4840, Test: 0.5310
Epoch: 19, Loss: 4.3349, Train: 0.7357, Val: 0.5280, Test: 0.5910
Epoch: 20, Loss: 4.2108, Train: 0.8357, Val: 0.5840, Test: 0.6520
Epoch: 21, Loss: 4.0932, Train: 0.9143, Val: 0.6200, Test: 0.7000
Epoch: 22, Loss: 4.0480, Train: 0.9357, Val: 0.6680, Test: 0.7300
Epoch: 23, Loss: 3.9465, Train: 0.9643, Val: 0.6960, Test: 0.7610
Epoch: 24, Loss: 4.2291, Train: 0.9714, Val: 0.7160, Test: 0.7590
Epoch: 25, Loss: 4.2542, Train: 0.9714, Val: 0.7380, Test: 0.7680
Epoch: 26, Loss: 4.0566, Train: 0.9643, Val: 0.7400, Test: 0.7710
Epoch: 27, Loss: 3.9046, Train: 0.9643, Val: 0.7440, Test: 0.7700
Epoch: 28, Loss: 4.1735, Train: 0.9714, Val: 0.7420, Test: 0.7670
Epoch: 29, Loss: 4.1811, Train: 0.9786, Val: 0.7440, Test: 0.7670
Epoch: 30, Loss: 3.9155, Train: 0.9714, Val: 0.7420, Test: 0.7740
Epoch: 31, Loss: 4.0176, Train: 0.9714, Val: 0.7360, Test: 0.7770
Epoch: 32, Loss: 3.9450, Train: 0.9714, Val: 0.7460, Test: 0.7760
Epoch: 33, Loss: 3.9812, Train: 0.9714, Val: 0.7600, Test: 0.7860
Epoch: 34, Loss: 3.8613, Train: 0.9714, Val: 0.7560, Test: 0.7900
Epoch: 35, Loss: 4.0463, Train: 0.9714, Val: 0.7620, Test: 0.7940
Epoch: 36, Loss: 3.6973, Train: 0.9714, Val: 0.7660, Test: 0.8050
Epoch: 37, Loss: 3.7440, Train: 0.9714, Val: 0.7620, Test: 0.8030
Epoch: 38, Loss: 3.8701, Train: 0.9714, Val: 0.7620, Test: 0.8050
Epoch: 39, Loss: 4.1164, Train: 0.9786, Val: 0.7620, Test: 0.8060
Epoch: 40, Loss: 3.8919, Train: 0.9786, Val: 0.7620, Test: 0.8080
Epoch: 41, Loss: 3.7640, Train: 0.9786, Val: 0.7640, Test: 0.8100
Epoch: 42, Loss: 3.8724, Train: 0.9786, Val: 0.7740, Test: 0.8060
Epoch: 43, Loss: 3.7676, Train: 0.9786, Val: 0.7820, Test: 0.8070
Epoch: 44, Loss: 3.8183, Train: 0.9786, Val: 0.7800, Test: 0.8040
Epoch: 45, Loss: 3.8254, Train: 0.9786, Val: 0.7800, Test: 0.7980
Epoch: 46, Loss: 3.7762, Train: 0.9786, Val: 0.7820, Test: 0.7990
Epoch: 47, Loss: 3.8370, Train: 0.9857, Val: 0.7800, Test: 0.7950
Epoch: 48, Loss: 3.9824, Train: 0.9857, Val: 0.7800, Test: 0.8000
Epoch: 49, Loss: 3.5754, Train: 0.9857, Val: 0.7820, Test: 0.8030
Epoch: 50, Loss: 3.7437, Train: 0.9857, Val: 0.7720, Test: 0.8020
Epoch: 51, Loss: 3.7117, Train: 0.9857, Val: 0.7720, Test: 0.7990
Epoch: 52, Loss: 3.8619, Train: 0.9857, Val: 0.7760, Test: 0.8010
Epoch: 53, Loss: 3.7102, Train: 0.9857, Val: 0.7760, Test: 0.7980
Epoch: 54, Loss: 3.9097, Train: 0.9857, Val: 0.7800, Test: 0.7990
Epoch: 55, Loss: 3.8241, Train: 0.9857, Val: 0.7780, Test: 0.8020
Epoch: 56, Loss: 3.7780, Train: 0.9857, Val: 0.7800, Test: 0.7990
Epoch: 57, Loss: 3.7955, Train: 0.9857, Val: 0.7760, Test: 0.7980
Epoch: 58, Loss: 3.5326, Train: 0.9857, Val: 0.7720, Test: 0.7980
Epoch: 59, Loss: 3.6595, Train: 0.9857, Val: 0.7720, Test: 0.7950
Epoch: 60, Loss: 3.6450, Train: 0.9929, Val: 0.7720, Test: 0.7910
Epoch: 61, Loss: 3.7662, Train: 0.9929, Val: 0.7760, Test: 0.7930
Epoch: 62, Loss: 3.9578, Train: 0.9929, Val: 0.7740, Test: 0.7980
Epoch: 63, Loss: 3.9380, Train: 0.9929, Val: 0.7740, Test: 0.7990
Epoch: 64, Loss: 3.7791, Train: 0.9929, Val: 0.7720, Test: 0.7990
Epoch: 65, Loss: 3.7284, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 66, Loss: 3.8106, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 67, Loss: 3.7471, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 68, Loss: 3.6274, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 69, Loss: 3.7184, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 70, Loss: 3.5592, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 71, Loss: 3.8485, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 72, Loss: 3.8498, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 73, Loss: 3.4830, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 74, Loss: 3.5735, Train: 1.0000, Val: 0.7960, Test: 0.8140
Epoch: 75, Loss: 3.5049, Train: 1.0000, Val: 0.8000, Test: 0.8150
Epoch: 76, Loss: 3.7793, Train: 1.0000, Val: 0.8000, Test: 0.8150
Epoch: 77, Loss: 3.6874, Train: 1.0000, Val: 0.7980, Test: 0.8140
Epoch: 78, Loss: 3.7756, Train: 1.0000, Val: 0.7980, Test: 0.8160
Epoch: 79, Loss: 3.4813, Train: 1.0000, Val: 0.7980, Test: 0.8170
Epoch: 80, Loss: 3.6485, Train: 1.0000, Val: 0.7980, Test: 0.8170
Epoch: 81, Loss: 3.8101, Train: 1.0000, Val: 0.7980, Test: 0.8140
Epoch: 82, Loss: 3.7407, Train: 1.0000, Val: 0.7980, Test: 0.8150
Epoch: 83, Loss: 3.9955, Train: 1.0000, Val: 0.7980, Test: 0.8180
Epoch: 84, Loss: 3.6758, Train: 1.0000, Val: 0.7980, Test: 0.8160
Epoch: 85, Loss: 3.8554, Train: 1.0000, Val: 0.7980, Test: 0.8190
Epoch: 86, Loss: 3.4345, Train: 1.0000, Val: 0.7940, Test: 0.8150
Epoch: 87, Loss: 3.8279, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 88, Loss: 4.1019, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 89, Loss: 3.5332, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 90, Loss: 3.6393, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 91, Loss: 3.5407, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 92, Loss: 3.5685, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 93, Loss: 3.8836, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 94, Loss: 3.2137, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 95, Loss: 3.6702, Train: 1.0000, Val: 0.7720, Test: 0.7840
Epoch: 96, Loss: 3.8092, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 97, Loss: 3.8256, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 98, Loss: 3.7526, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 99, Loss: 3.8468, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 100, Loss: 3.4778, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 101, Loss: 3.6658, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 102, Loss: 3.5119, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 103, Loss: 3.6923, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 104, Loss: 3.6661, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 105, Loss: 3.6681, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 106, Loss: 3.6267, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 107, Loss: 3.5726, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 108, Loss: 3.5339, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 109, Loss: 4.0104, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 110, Loss: 3.8713, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 111, Loss: 3.7685, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 112, Loss: 3.4853, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 113, Loss: 3.6037, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 114, Loss: 3.6633, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 115, Loss: 3.8626, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 116, Loss: 3.3785, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 117, Loss: 3.8675, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 118, Loss: 3.8401, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 119, Loss: 3.5547, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 120, Loss: 3.6234, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 121, Loss: 3.6301, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 122, Loss: 3.6946, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 123, Loss: 3.7889, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 124, Loss: 3.6489, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 125, Loss: 3.4149, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 126, Loss: 3.5841, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 127, Loss: 3.4969, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 128, Loss: 3.9678, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 129, Loss: 3.8895, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 130, Loss: 3.6153, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 131, Loss: 3.3834, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 132, Loss: 3.5976, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 133, Loss: 3.6918, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 134, Loss: 4.2822, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 135, Loss: 3.4825, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 136, Loss: 3.5895, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 137, Loss: 3.5492, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 138, Loss: 3.7218, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 139, Loss: 3.5153, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 140, Loss: 3.6873, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 141, Loss: 3.7279, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 142, Loss: 3.8363, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 143, Loss: 3.4576, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 144, Loss: 3.6337, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 145, Loss: 3.3782, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 146, Loss: 3.6577, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 147, Loss: 3.6202, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 148, Loss: 3.4170, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 149, Loss: 3.6542, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 150, Loss: 3.4843, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 151, Loss: 3.7564, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 152, Loss: 3.8239, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 153, Loss: 3.5173, Train: 1.0000, Val: 0.7780, Test: 0.8000
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 3.5847, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 155, Loss: 3.7559, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 156, Loss: 3.7624, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 157, Loss: 3.3741, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 158, Loss: 3.4175, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 159, Loss: 3.6893, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 160, Loss: 3.9360, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 161, Loss: 3.7910, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 162, Loss: 3.4104, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 163, Loss: 3.5601, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 164, Loss: 3.6128, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 165, Loss: 3.6874, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 166, Loss: 3.4790, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 167, Loss: 3.6471, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 168, Loss: 3.7260, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 169, Loss: 3.7560, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 170, Loss: 3.5454, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 171, Loss: 3.8674, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 172, Loss: 3.5799, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 173, Loss: 3.4098, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 174, Loss: 3.8581, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 175, Loss: 3.6445, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 176, Loss: 3.7846, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 177, Loss: 3.6148, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 178, Loss: 3.4469, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 179, Loss: 3.9933, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 180, Loss: 3.4851, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 181, Loss: 3.8672, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 182, Loss: 3.9586, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 183, Loss: 3.7896, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 184, Loss: 3.6470, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 185, Loss: 3.8955, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 186, Loss: 3.8218, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 187, Loss: 3.8229, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 188, Loss: 3.8919, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 189, Loss: 3.8604, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 190, Loss: 3.7626, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 191, Loss: 3.7190, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 192, Loss: 3.4519, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 193, Loss: 3.3511, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 194, Loss: 3.3490, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 195, Loss: 3.6518, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 196, Loss: 3.1715, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 197, Loss: 3.5419, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 198, Loss: 3.6825, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 199, Loss: 3.7827, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 200, Loss: 3.5539, Train: 1.0000, Val: 0.7680, Test: 0.7940
MAD:  0.6874
Best Test Accuracy: 0.8190, Val Accuracy: 0.7980, Train Accuracy: 1.0000
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8621, Train: 0.1000, Val: 0.0460, Test: 0.0560
Epoch: 2, Loss: 4.8439, Train: 0.2286, Val: 0.2020, Test: 0.2110
Epoch: 3, Loss: 4.8290, Train: 0.2000, Val: 0.1880, Test: 0.1950
Epoch: 4, Loss: 4.8033, Train: 0.2000, Val: 0.1840, Test: 0.1760
Epoch: 5, Loss: 4.7789, Train: 0.2000, Val: 0.1700, Test: 0.1740
Epoch: 6, Loss: 4.7521, Train: 0.1929, Val: 0.1640, Test: 0.1740
Epoch: 7, Loss: 4.7244, Train: 0.2000, Val: 0.1560, Test: 0.1570
Epoch: 8, Loss: 4.6710, Train: 0.2071, Val: 0.1540, Test: 0.1570
Epoch: 9, Loss: 4.6464, Train: 0.2214, Val: 0.1540, Test: 0.1590
Epoch: 10, Loss: 4.6378, Train: 0.2429, Val: 0.1660, Test: 0.1790
Epoch: 11, Loss: 4.5776, Train: 0.3000, Val: 0.1980, Test: 0.1990
Epoch: 12, Loss: 4.6230, Train: 0.3429, Val: 0.2300, Test: 0.2350
Epoch: 13, Loss: 4.4560, Train: 0.3786, Val: 0.2760, Test: 0.2820
Epoch: 14, Loss: 4.6376, Train: 0.4071, Val: 0.3100, Test: 0.3390
Epoch: 15, Loss: 4.4479, Train: 0.4214, Val: 0.3520, Test: 0.3870
Epoch: 16, Loss: 4.5846, Train: 0.4500, Val: 0.4140, Test: 0.4440
Epoch: 17, Loss: 4.4700, Train: 0.4857, Val: 0.4420, Test: 0.4880
Epoch: 18, Loss: 4.3417, Train: 0.5143, Val: 0.4640, Test: 0.5050
Epoch: 19, Loss: 4.3711, Train: 0.6143, Val: 0.5020, Test: 0.5360
Epoch: 20, Loss: 4.2851, Train: 0.7357, Val: 0.5660, Test: 0.5930
Epoch: 21, Loss: 4.3633, Train: 0.8000, Val: 0.6480, Test: 0.6560
Epoch: 22, Loss: 4.3338, Train: 0.8571, Val: 0.7160, Test: 0.7240
Epoch: 23, Loss: 4.2233, Train: 0.9143, Val: 0.7620, Test: 0.7850
Epoch: 24, Loss: 4.0191, Train: 0.9357, Val: 0.7640, Test: 0.8110
Epoch: 25, Loss: 4.2216, Train: 0.9357, Val: 0.7420, Test: 0.7860
Epoch: 26, Loss: 3.9912, Train: 0.9500, Val: 0.7180, Test: 0.7510
Epoch: 27, Loss: 4.3205, Train: 0.9500, Val: 0.7100, Test: 0.7360
Epoch: 28, Loss: 4.0250, Train: 0.9571, Val: 0.7240, Test: 0.7570
Epoch: 29, Loss: 4.1175, Train: 0.9500, Val: 0.7380, Test: 0.7650
Epoch: 30, Loss: 4.0668, Train: 0.9571, Val: 0.7420, Test: 0.7800
Epoch: 31, Loss: 3.9740, Train: 0.9571, Val: 0.7500, Test: 0.7940
Epoch: 32, Loss: 3.7906, Train: 0.9643, Val: 0.7580, Test: 0.8050
Epoch: 33, Loss: 3.8841, Train: 0.9643, Val: 0.7640, Test: 0.8070
Epoch: 34, Loss: 3.8838, Train: 0.9643, Val: 0.7600, Test: 0.8070
Epoch: 35, Loss: 3.8665, Train: 0.9714, Val: 0.7620, Test: 0.8010
Epoch: 36, Loss: 4.0099, Train: 0.9714, Val: 0.7620, Test: 0.8000
Epoch: 37, Loss: 4.1379, Train: 0.9857, Val: 0.7720, Test: 0.8010
Epoch: 38, Loss: 4.0630, Train: 0.9857, Val: 0.7760, Test: 0.8050
Epoch: 39, Loss: 3.8950, Train: 0.9857, Val: 0.7880, Test: 0.8090
Epoch: 40, Loss: 3.8845, Train: 0.9857, Val: 0.7880, Test: 0.8140
Epoch: 41, Loss: 4.1141, Train: 0.9857, Val: 0.7940, Test: 0.8140
Epoch: 42, Loss: 3.8936, Train: 0.9857, Val: 0.7960, Test: 0.8160
Epoch: 43, Loss: 3.8181, Train: 0.9786, Val: 0.7940, Test: 0.8190
Epoch: 44, Loss: 4.0122, Train: 0.9857, Val: 0.7960, Test: 0.8210
Epoch: 45, Loss: 3.6938, Train: 0.9857, Val: 0.8000, Test: 0.8260
Epoch: 46, Loss: 3.8397, Train: 0.9857, Val: 0.7940, Test: 0.8220
Epoch: 47, Loss: 3.7824, Train: 0.9929, Val: 0.7920, Test: 0.8190
Epoch: 48, Loss: 3.9923, Train: 0.9857, Val: 0.7800, Test: 0.8150
Epoch: 49, Loss: 3.9103, Train: 0.9857, Val: 0.7760, Test: 0.8070
Epoch: 50, Loss: 3.8494, Train: 0.9857, Val: 0.7720, Test: 0.8040
Epoch: 51, Loss: 3.7993, Train: 0.9857, Val: 0.7720, Test: 0.8040
Epoch: 52, Loss: 3.4498, Train: 0.9857, Val: 0.7720, Test: 0.8070
Epoch: 53, Loss: 4.1249, Train: 0.9857, Val: 0.7740, Test: 0.8030
Epoch: 54, Loss: 3.9689, Train: 0.9929, Val: 0.7660, Test: 0.7990
Epoch: 55, Loss: 3.7610, Train: 0.9929, Val: 0.7700, Test: 0.8010
Epoch: 56, Loss: 3.7092, Train: 0.9929, Val: 0.7660, Test: 0.7980
Epoch: 57, Loss: 3.7569, Train: 0.9929, Val: 0.7620, Test: 0.7990
Epoch: 58, Loss: 3.8329, Train: 1.0000, Val: 0.7640, Test: 0.7980
Epoch: 59, Loss: 3.8332, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 60, Loss: 3.8254, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 61, Loss: 3.5660, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 62, Loss: 3.7041, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 63, Loss: 3.6330, Train: 0.9929, Val: 0.7900, Test: 0.8130
Epoch: 64, Loss: 3.8067, Train: 0.9929, Val: 0.7920, Test: 0.8150
Epoch: 65, Loss: 3.5391, Train: 0.9929, Val: 0.7940, Test: 0.8150
Epoch: 66, Loss: 3.5836, Train: 0.9929, Val: 0.7940, Test: 0.8160
Epoch: 67, Loss: 3.9162, Train: 0.9929, Val: 0.7960, Test: 0.8160
Epoch: 68, Loss: 3.6455, Train: 1.0000, Val: 0.7980, Test: 0.8150
Epoch: 69, Loss: 3.8095, Train: 1.0000, Val: 0.7940, Test: 0.8120
Epoch: 70, Loss: 3.7670, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 71, Loss: 3.8033, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 72, Loss: 3.8370, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 73, Loss: 3.7438, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 74, Loss: 3.6480, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 75, Loss: 3.6772, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 76, Loss: 3.5293, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 77, Loss: 3.9038, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 78, Loss: 3.6313, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 79, Loss: 3.6471, Train: 1.0000, Val: 0.7580, Test: 0.7980
Epoch: 80, Loss: 3.7865, Train: 1.0000, Val: 0.7620, Test: 0.8000
Epoch: 81, Loss: 4.0737, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 82, Loss: 3.7724, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 83, Loss: 3.6465, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 84, Loss: 3.6759, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 85, Loss: 3.6475, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 86, Loss: 3.4684, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 87, Loss: 3.6994, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 88, Loss: 3.5554, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 89, Loss: 3.8026, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 90, Loss: 3.4601, Train: 1.0000, Val: 0.7880, Test: 0.8150
Epoch: 91, Loss: 3.8343, Train: 1.0000, Val: 0.7880, Test: 0.8160
Epoch: 92, Loss: 3.4099, Train: 1.0000, Val: 0.7880, Test: 0.8160
Epoch: 93, Loss: 3.8384, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 94, Loss: 3.8625, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 95, Loss: 3.9059, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 96, Loss: 3.5362, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 97, Loss: 3.4545, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 98, Loss: 3.8020, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 99, Loss: 3.7126, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 100, Loss: 3.6976, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 101, Loss: 3.6743, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 102, Loss: 3.5936, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 103, Loss: 3.8133, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 104, Loss: 3.7748, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 105, Loss: 3.5653, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 106, Loss: 3.6922, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 107, Loss: 3.6270, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 108, Loss: 3.6282, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 109, Loss: 3.3885, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 110, Loss: 4.0692, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 111, Loss: 3.6058, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 112, Loss: 3.6959, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 113, Loss: 3.9346, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 114, Loss: 3.6540, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 115, Loss: 3.5936, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 116, Loss: 3.7060, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 117, Loss: 3.5497, Train: 1.0000, Val: 0.7720, Test: 0.8110
Epoch: 118, Loss: 3.4783, Train: 1.0000, Val: 0.7720, Test: 0.8110
Epoch: 119, Loss: 3.4615, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 120, Loss: 3.5552, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 121, Loss: 3.6625, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 122, Loss: 3.4871, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 123, Loss: 3.5944, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 124, Loss: 3.5326, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 125, Loss: 3.3905, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 126, Loss: 3.6923, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 127, Loss: 3.4468, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 128, Loss: 3.6969, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 129, Loss: 3.4299, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 130, Loss: 3.8626, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 131, Loss: 3.5798, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 132, Loss: 3.4207, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 133, Loss: 3.4101, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 134, Loss: 3.6183, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 135, Loss: 3.6890, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 136, Loss: 3.1740, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 137, Loss: 3.6905, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 138, Loss: 3.4131, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 139, Loss: 3.7966, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 140, Loss: 3.6939, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 141, Loss: 3.6932, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 142, Loss: 3.9288, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 143, Loss: 3.7597, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 144, Loss: 3.6894, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 145, Loss: 3.6509, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 146, Loss: 3.5870, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 147, Loss: 3.9632, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 148, Loss: 3.9250, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 149, Loss: 3.5845, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 150, Loss: 3.5631, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 151, Loss: 3.7186, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 152, Loss: 3.9267, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 153, Loss: 3.4505, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 154, Loss: 3.5171, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 155, Loss: 3.5886, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 156, Loss: 3.7934, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 157, Loss: 3.6894, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 158, Loss: 3.5575, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 159, Loss: 3.5841, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 160, Loss: 3.8583, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 161, Loss: 3.5846, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 162, Loss: 3.7191, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 163, Loss: 3.8968, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 164, Loss: 3.6866, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 165, Loss: 3.6258, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 166, Loss: 3.6239, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 167, Loss: 3.6861, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 168, Loss: 3.7254, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 169, Loss: 3.6472, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 170, Loss: 3.7536, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 171, Loss: 3.4380, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 172, Loss: 3.6512, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 173, Loss: 3.6831, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 174, Loss: 3.2996, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 175, Loss: 3.5419, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 176, Loss: 3.5535, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 177, Loss: 3.6173, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 178, Loss: 3.4047, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 179, Loss: 3.4123, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 180, Loss: 3.4522, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 181, Loss: 3.8570, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 182, Loss: 3.6128, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 183, Loss: 3.4739, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 184, Loss: 3.3734, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 185, Loss: 3.5847, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 186, Loss: 3.6175, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 187, Loss: 3.9328, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 188, Loss: 3.4749, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 189, Loss: 3.6467, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 190, Loss: 3.2731, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 191, Loss: 3.7206, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 192, Loss: 3.8597, Train: 1.0000, Val: 0.7780, Test: 0.8110
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 3.4780, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 194, Loss: 3.4748, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 195, Loss: 3.7828, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 196, Loss: 3.5828, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 197, Loss: 3.7852, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 198, Loss: 3.5865, Train: 1.0000, Val: 0.7840, Test: 0.8160
Epoch: 199, Loss: 3.2798, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 200, Loss: 3.3357, Train: 1.0000, Val: 0.7820, Test: 0.8120
MAD:  0.4175
Best Test Accuracy: 0.8260, Val Accuracy: 0.8000, Train Accuracy: 0.9857
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8542, Train: 0.1214, Val: 0.0760, Test: 0.0780
Epoch: 2, Loss: 4.8357, Train: 0.2286, Val: 0.0900, Test: 0.1120
Epoch: 3, Loss: 4.8301, Train: 0.2929, Val: 0.1500, Test: 0.1640
Epoch: 4, Loss: 4.8138, Train: 0.3857, Val: 0.2320, Test: 0.2540
Epoch: 5, Loss: 4.7642, Train: 0.4643, Val: 0.2860, Test: 0.2990
Epoch: 6, Loss: 4.7017, Train: 0.4786, Val: 0.3020, Test: 0.3240
Epoch: 7, Loss: 4.6992, Train: 0.4929, Val: 0.3180, Test: 0.3340
Epoch: 8, Loss: 4.5963, Train: 0.4929, Val: 0.3100, Test: 0.3340
Epoch: 9, Loss: 4.5718, Train: 0.4857, Val: 0.3120, Test: 0.3270
Epoch: 10, Loss: 4.5490, Train: 0.4929, Val: 0.3100, Test: 0.3280
Epoch: 11, Loss: 4.4098, Train: 0.4857, Val: 0.3020, Test: 0.3260
Epoch: 12, Loss: 4.4380, Train: 0.4857, Val: 0.3080, Test: 0.3270
Epoch: 13, Loss: 4.4715, Train: 0.5000, Val: 0.3060, Test: 0.3260
Epoch: 14, Loss: 4.1668, Train: 0.5143, Val: 0.3100, Test: 0.3330
Epoch: 15, Loss: 4.3061, Train: 0.5714, Val: 0.3300, Test: 0.3500
Epoch: 16, Loss: 4.2636, Train: 0.6357, Val: 0.3560, Test: 0.3680
Epoch: 17, Loss: 4.3619, Train: 0.7286, Val: 0.4260, Test: 0.4270
Epoch: 18, Loss: 4.3446, Train: 0.8214, Val: 0.5400, Test: 0.5460
Epoch: 19, Loss: 4.1648, Train: 0.8786, Val: 0.6660, Test: 0.6770
Epoch: 20, Loss: 4.1966, Train: 0.9286, Val: 0.7380, Test: 0.7430
Epoch: 21, Loss: 4.3148, Train: 0.9643, Val: 0.7780, Test: 0.7960
Epoch: 22, Loss: 4.0862, Train: 0.9643, Val: 0.7800, Test: 0.8070
Epoch: 23, Loss: 3.8882, Train: 0.9714, Val: 0.7720, Test: 0.8140
Epoch: 24, Loss: 4.1592, Train: 0.9643, Val: 0.7660, Test: 0.8140
Epoch: 25, Loss: 4.2493, Train: 0.9714, Val: 0.7640, Test: 0.8050
Epoch: 26, Loss: 3.9817, Train: 0.9714, Val: 0.7700, Test: 0.7990
Epoch: 27, Loss: 4.0001, Train: 0.9714, Val: 0.7700, Test: 0.7940
Epoch: 28, Loss: 3.7638, Train: 0.9714, Val: 0.7640, Test: 0.7900
Epoch: 29, Loss: 4.2133, Train: 0.9714, Val: 0.7700, Test: 0.7910
Epoch: 30, Loss: 4.0079, Train: 0.9714, Val: 0.7740, Test: 0.7810
Epoch: 31, Loss: 4.0360, Train: 0.9714, Val: 0.7760, Test: 0.7790
Epoch: 32, Loss: 4.1602, Train: 0.9714, Val: 0.7760, Test: 0.7850
Epoch: 33, Loss: 3.8991, Train: 0.9714, Val: 0.7740, Test: 0.7840
Epoch: 34, Loss: 4.1195, Train: 0.9786, Val: 0.7720, Test: 0.7820
Epoch: 35, Loss: 4.0278, Train: 0.9786, Val: 0.7760, Test: 0.7830
Epoch: 36, Loss: 3.8080, Train: 0.9857, Val: 0.7680, Test: 0.7880
Epoch: 37, Loss: 3.7531, Train: 0.9857, Val: 0.7720, Test: 0.7920
Epoch: 38, Loss: 4.0382, Train: 0.9857, Val: 0.7760, Test: 0.7920
Epoch: 39, Loss: 3.9019, Train: 0.9786, Val: 0.7880, Test: 0.7920
Epoch: 40, Loss: 3.4981, Train: 0.9857, Val: 0.7800, Test: 0.7920
Epoch: 41, Loss: 4.2135, Train: 0.9857, Val: 0.7760, Test: 0.7960
Epoch: 42, Loss: 4.1373, Train: 0.9857, Val: 0.7780, Test: 0.8000
Epoch: 43, Loss: 4.2351, Train: 0.9929, Val: 0.7780, Test: 0.8000
Epoch: 44, Loss: 3.6940, Train: 0.9929, Val: 0.7780, Test: 0.7990
Epoch: 45, Loss: 3.6848, Train: 0.9929, Val: 0.7720, Test: 0.7970
Epoch: 46, Loss: 3.9615, Train: 0.9929, Val: 0.7760, Test: 0.8060
Epoch: 47, Loss: 3.8883, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 48, Loss: 3.6288, Train: 0.9929, Val: 0.7800, Test: 0.8170
Epoch: 49, Loss: 3.5438, Train: 0.9929, Val: 0.7780, Test: 0.8180
Epoch: 50, Loss: 3.7837, Train: 0.9929, Val: 0.7780, Test: 0.8180
Epoch: 51, Loss: 3.8819, Train: 0.9929, Val: 0.7760, Test: 0.8120
Epoch: 52, Loss: 3.5648, Train: 0.9929, Val: 0.7740, Test: 0.8130
Epoch: 53, Loss: 3.9555, Train: 0.9929, Val: 0.7760, Test: 0.8100
Epoch: 54, Loss: 3.9290, Train: 0.9929, Val: 0.7760, Test: 0.8110
Epoch: 55, Loss: 3.8593, Train: 0.9929, Val: 0.7760, Test: 0.8120
Epoch: 56, Loss: 3.5508, Train: 0.9929, Val: 0.7800, Test: 0.8110
Epoch: 57, Loss: 3.9448, Train: 0.9929, Val: 0.7800, Test: 0.8070
Epoch: 58, Loss: 3.7161, Train: 0.9929, Val: 0.7820, Test: 0.8070
Epoch: 59, Loss: 3.7224, Train: 0.9929, Val: 0.7820, Test: 0.8060
Epoch: 60, Loss: 3.5758, Train: 0.9929, Val: 0.7840, Test: 0.8090
Epoch: 61, Loss: 3.3429, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 62, Loss: 3.8333, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 63, Loss: 3.7070, Train: 1.0000, Val: 0.7900, Test: 0.8050
Epoch: 64, Loss: 3.2928, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 65, Loss: 3.6976, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 66, Loss: 3.5099, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 67, Loss: 3.3905, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 68, Loss: 3.9804, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 69, Loss: 3.5943, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 70, Loss: 3.7599, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 71, Loss: 3.7278, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 72, Loss: 3.5500, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 73, Loss: 3.5817, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 74, Loss: 3.8435, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 75, Loss: 3.6527, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 76, Loss: 3.6470, Train: 1.0000, Val: 0.7900, Test: 0.8140
Epoch: 77, Loss: 3.9840, Train: 1.0000, Val: 0.7880, Test: 0.8140
Epoch: 78, Loss: 3.7008, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 79, Loss: 3.7840, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 80, Loss: 3.8106, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 81, Loss: 3.7452, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 82, Loss: 3.6589, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 83, Loss: 3.6857, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 84, Loss: 3.7933, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 85, Loss: 3.5947, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 86, Loss: 3.9156, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 87, Loss: 3.8733, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 88, Loss: 3.5061, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 89, Loss: 3.7643, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 90, Loss: 3.5560, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 91, Loss: 3.5698, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 92, Loss: 3.5402, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 93, Loss: 3.6693, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 94, Loss: 3.7416, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 95, Loss: 3.5895, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 96, Loss: 3.6903, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 97, Loss: 3.8418, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 98, Loss: 3.9736, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 99, Loss: 3.6296, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 100, Loss: 3.5613, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 101, Loss: 3.5292, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 102, Loss: 3.7443, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 103, Loss: 3.6603, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 104, Loss: 3.8366, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 105, Loss: 3.8354, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 106, Loss: 3.3908, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 107, Loss: 4.0759, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 108, Loss: 3.8326, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 109, Loss: 3.7288, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 110, Loss: 3.6562, Train: 1.0000, Val: 0.7820, Test: 0.8080
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 111, Loss: 3.8148, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 112, Loss: 3.8993, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 113, Loss: 3.6536, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 114, Loss: 3.6905, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 115, Loss: 3.5938, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 116, Loss: 3.5508, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 117, Loss: 3.6461, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 118, Loss: 3.5214, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 119, Loss: 3.6956, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 120, Loss: 3.5970, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 121, Loss: 3.8445, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 122, Loss: 3.6537, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 123, Loss: 3.2530, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 124, Loss: 3.6570, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 125, Loss: 3.4881, Train: 1.0000, Val: 0.7840, Test: 0.8120
Epoch: 126, Loss: 3.8918, Train: 1.0000, Val: 0.7840, Test: 0.8120
Epoch: 127, Loss: 3.7357, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 128, Loss: 3.6126, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 129, Loss: 3.6640, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 130, Loss: 3.6894, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 131, Loss: 3.5917, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 132, Loss: 3.6652, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 133, Loss: 3.3855, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 134, Loss: 3.3843, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 135, Loss: 3.6218, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 136, Loss: 3.5972, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 137, Loss: 3.7973, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 138, Loss: 3.7298, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 139, Loss: 3.5551, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 140, Loss: 3.6591, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 141, Loss: 3.7598, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 142, Loss: 3.6498, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 143, Loss: 3.4824, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 144, Loss: 3.5121, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 145, Loss: 3.5221, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 146, Loss: 3.4167, Train: 1.0000, Val: 0.7960, Test: 0.8090
Epoch: 147, Loss: 3.6568, Train: 1.0000, Val: 0.7960, Test: 0.8120
Epoch: 148, Loss: 3.5850, Train: 1.0000, Val: 0.7940, Test: 0.8120
Epoch: 149, Loss: 4.0294, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 150, Loss: 3.8230, Train: 1.0000, Val: 0.7960, Test: 0.8100
Epoch: 151, Loss: 3.5526, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 152, Loss: 3.5820, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 153, Loss: 3.8299, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 154, Loss: 3.8866, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 155, Loss: 3.8281, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 156, Loss: 3.8951, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 157, Loss: 3.6857, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 158, Loss: 3.5885, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 159, Loss: 3.5852, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 160, Loss: 3.4405, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 161, Loss: 3.4869, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 162, Loss: 3.7242, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 163, Loss: 3.4122, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 164, Loss: 3.7828, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 165, Loss: 3.4744, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 166, Loss: 3.8268, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 167, Loss: 3.7232, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 168, Loss: 3.5829, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 169, Loss: 3.8239, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 170, Loss: 3.6496, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 171, Loss: 3.4125, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 172, Loss: 3.7973, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 173, Loss: 3.5547, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 174, Loss: 3.6916, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 175, Loss: 3.7645, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 176, Loss: 3.7550, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 177, Loss: 3.8359, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 178, Loss: 3.4810, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 179, Loss: 3.5175, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 180, Loss: 3.8565, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 181, Loss: 3.8253, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 182, Loss: 3.7162, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 183, Loss: 3.7591, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 184, Loss: 3.7563, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 185, Loss: 3.8209, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 186, Loss: 3.8911, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 187, Loss: 3.5821, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 188, Loss: 3.8223, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 189, Loss: 3.7867, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 190, Loss: 3.9980, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 191, Loss: 3.4948, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 192, Loss: 3.5497, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 193, Loss: 3.4415, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 194, Loss: 3.5431, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 195, Loss: 3.5217, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 196, Loss: 3.1747, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 197, Loss: 3.6163, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 198, Loss: 3.6863, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 199, Loss: 3.8539, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 200, Loss: 3.6854, Train: 1.0000, Val: 0.7880, Test: 0.8000
MAD:  0.4029
Best Test Accuracy: 0.8180, Val Accuracy: 0.7780, Train Accuracy: 0.9929
Training completed.
Average Test Accuracy:  0.8211 ± 0.00559374650837878
Average MAD:  0.43202999999999997 ± 0.1215249608105265
