Seed:  0
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 8.1138, Train: 0.1429, Val: 0.0700, Test: 0.0750
Epoch: 2, Loss: 5.7110, Train: 0.1714, Val: 0.1760, Test: 0.1450
Epoch: 3, Loss: 4.6933, Train: 0.1929, Val: 0.1780, Test: 0.1420
Epoch: 4, Loss: 3.9477, Train: 0.2071, Val: 0.1580, Test: 0.1270
Epoch: 5, Loss: 3.5202, Train: 0.1357, Val: 0.1160, Test: 0.0950
Epoch: 6, Loss: 3.1362, Train: 0.1500, Val: 0.1120, Test: 0.0920
Epoch: 7, Loss: 2.8151, Train: 0.1357, Val: 0.0880, Test: 0.0930
Epoch: 8, Loss: 2.7132, Train: 0.1357, Val: 0.0900, Test: 0.0890
Epoch: 9, Loss: 2.9844, Train: 0.1214, Val: 0.1180, Test: 0.1250
Epoch: 10, Loss: 2.7120, Train: 0.1500, Val: 0.1440, Test: 0.1420
Epoch: 11, Loss: 2.7820, Train: 0.1357, Val: 0.1540, Test: 0.1420
Epoch: 12, Loss: 2.2023, Train: 0.1571, Val: 0.1540, Test: 0.1420
Epoch: 13, Loss: 2.1696, Train: 0.1500, Val: 0.1540, Test: 0.1430
Epoch: 14, Loss: 2.3617, Train: 0.1429, Val: 0.1560, Test: 0.1430
Epoch: 15, Loss: 2.2041, Train: 0.1500, Val: 0.1560, Test: 0.1440
Epoch: 16, Loss: 2.1037, Train: 0.1500, Val: 0.1560, Test: 0.1440
Epoch: 17, Loss: 2.0988, Train: 0.1500, Val: 0.1560, Test: 0.1440
Epoch: 18, Loss: 2.1445, Train: 0.1500, Val: 0.1560, Test: 0.1430
Epoch: 19, Loss: 2.1453, Train: 0.1643, Val: 0.1560, Test: 0.1450
Epoch: 20, Loss: 2.0884, Train: 0.1714, Val: 0.1640, Test: 0.1450
Epoch: 21, Loss: 2.0759, Train: 0.1786, Val: 0.1640, Test: 0.1480
Epoch: 22, Loss: 1.9726, Train: 0.1786, Val: 0.1700, Test: 0.1470
Epoch: 23, Loss: 2.3366, Train: 0.1786, Val: 0.1660, Test: 0.1460
Epoch: 24, Loss: 1.9995, Train: 0.1786, Val: 0.1720, Test: 0.1440
Epoch: 25, Loss: 2.0985, Train: 0.1786, Val: 0.1700, Test: 0.1420
Epoch: 26, Loss: 2.1488, Train: 0.2071, Val: 0.1700, Test: 0.1450
Epoch: 27, Loss: 2.1355, Train: 0.2214, Val: 0.1760, Test: 0.1510
Epoch: 28, Loss: 2.0886, Train: 0.2286, Val: 0.1780, Test: 0.1570
Epoch: 29, Loss: 2.0014, Train: 0.2357, Val: 0.1820, Test: 0.1620
Epoch: 30, Loss: 1.9992, Train: 0.2714, Val: 0.1860, Test: 0.1640
Epoch: 31, Loss: 2.0813, Train: 0.2571, Val: 0.1960, Test: 0.1750
Epoch: 32, Loss: 2.0038, Train: 0.2429, Val: 0.2000, Test: 0.1870
Epoch: 33, Loss: 2.0578, Train: 0.2571, Val: 0.2100, Test: 0.1970
Epoch: 34, Loss: 2.0444, Train: 0.2643, Val: 0.2060, Test: 0.2060
Epoch: 35, Loss: 2.0652, Train: 0.2643, Val: 0.2100, Test: 0.2130
Epoch: 36, Loss: 1.9622, Train: 0.2571, Val: 0.2140, Test: 0.2160
Epoch: 37, Loss: 1.9187, Train: 0.2500, Val: 0.2300, Test: 0.2230
Epoch: 38, Loss: 1.9139, Train: 0.2286, Val: 0.2500, Test: 0.2320
Epoch: 39, Loss: 1.9376, Train: 0.2286, Val: 0.2620, Test: 0.2370
Epoch: 40, Loss: 1.9814, Train: 0.2357, Val: 0.2760, Test: 0.2480
Epoch: 41, Loss: 1.9191, Train: 0.2500, Val: 0.2720, Test: 0.2490
Epoch: 42, Loss: 1.9234, Train: 0.2143, Val: 0.2780, Test: 0.2570
Epoch: 43, Loss: 1.9029, Train: 0.2357, Val: 0.2780, Test: 0.2650
Epoch: 44, Loss: 1.9095, Train: 0.2357, Val: 0.2580, Test: 0.2640
Epoch: 45, Loss: 2.0400, Train: 0.2500, Val: 0.2740, Test: 0.2590
Epoch: 46, Loss: 1.8970, Train: 0.2571, Val: 0.2760, Test: 0.2720
Epoch: 47, Loss: 2.1592, Train: 0.2500, Val: 0.2520, Test: 0.2470
Epoch: 48, Loss: 1.9232, Train: 0.2500, Val: 0.2220, Test: 0.2280
Epoch: 49, Loss: 1.8840, Train: 0.2357, Val: 0.2060, Test: 0.2140
Epoch: 50, Loss: 1.9028, Train: 0.2500, Val: 0.1820, Test: 0.1960
Epoch: 51, Loss: 2.0341, Train: 0.2500, Val: 0.1720, Test: 0.1900
Epoch: 52, Loss: 1.9059, Train: 0.2357, Val: 0.1660, Test: 0.1880
Epoch: 53, Loss: 2.0033, Train: 0.2357, Val: 0.1600, Test: 0.1860
Epoch: 54, Loss: 1.8965, Train: 0.2214, Val: 0.1620, Test: 0.1870
Epoch: 55, Loss: 1.9509, Train: 0.2286, Val: 0.1600, Test: 0.1830
Epoch: 56, Loss: 2.0085, Train: 0.2286, Val: 0.1580, Test: 0.1780
Epoch: 57, Loss: 1.8891, Train: 0.2214, Val: 0.1580, Test: 0.1760
Epoch: 58, Loss: 1.8967, Train: 0.2143, Val: 0.1560, Test: 0.1710
Epoch: 59, Loss: 1.9263, Train: 0.2143, Val: 0.1540, Test: 0.1650
Epoch: 60, Loss: 2.0413, Train: 0.2143, Val: 0.1480, Test: 0.1620
Epoch: 61, Loss: 1.8823, Train: 0.2000, Val: 0.1440, Test: 0.1580
Epoch: 62, Loss: 1.9481, Train: 0.2000, Val: 0.1380, Test: 0.1530
Epoch: 63, Loss: 1.9328, Train: 0.2071, Val: 0.1400, Test: 0.1530
Epoch: 64, Loss: 1.8843, Train: 0.2071, Val: 0.1380, Test: 0.1550
Epoch: 65, Loss: 2.2832, Train: 0.2143, Val: 0.1360, Test: 0.1500
Epoch: 66, Loss: 1.8821, Train: 0.2143, Val: 0.1300, Test: 0.1440
Epoch: 67, Loss: 1.9143, Train: 0.2214, Val: 0.1260, Test: 0.1450
Epoch: 68, Loss: 1.8285, Train: 0.2214, Val: 0.1220, Test: 0.1470
Epoch: 69, Loss: 1.8250, Train: 0.2286, Val: 0.1220, Test: 0.1460
Epoch: 70, Loss: 1.8449, Train: 0.2357, Val: 0.1240, Test: 0.1470
Epoch: 71, Loss: 1.8203, Train: 0.2357, Val: 0.1260, Test: 0.1490
Epoch: 72, Loss: 1.8637, Train: 0.2357, Val: 0.1260, Test: 0.1470
Epoch: 73, Loss: 1.8898, Train: 0.2429, Val: 0.1280, Test: 0.1480
Epoch: 74, Loss: 1.8634, Train: 0.2429, Val: 0.1280, Test: 0.1460
Epoch: 75, Loss: 1.9507, Train: 0.2429, Val: 0.1280, Test: 0.1460
Epoch: 76, Loss: 1.8085, Train: 0.2429, Val: 0.1300, Test: 0.1450
Epoch: 77, Loss: 1.8540, Train: 0.2429, Val: 0.1300, Test: 0.1480
Epoch: 78, Loss: 1.9365, Train: 0.2500, Val: 0.1280, Test: 0.1490
Epoch: 79, Loss: 1.8373, Train: 0.2500, Val: 0.1280, Test: 0.1510
Epoch: 80, Loss: 1.8091, Train: 0.2571, Val: 0.1320, Test: 0.1510
Epoch: 81, Loss: 1.8303, Train: 0.2643, Val: 0.1320, Test: 0.1520
Epoch: 82, Loss: 1.7968, Train: 0.2643, Val: 0.1320, Test: 0.1520
Epoch: 83, Loss: 1.9130, Train: 0.2571, Val: 0.1320, Test: 0.1510
Epoch: 84, Loss: 1.8255, Train: 0.2571, Val: 0.1320, Test: 0.1510
Epoch: 85, Loss: 1.7548, Train: 0.2571, Val: 0.1300, Test: 0.1510
Epoch: 86, Loss: 1.7970, Train: 0.2571, Val: 0.1280, Test: 0.1520
Epoch: 87, Loss: 1.7948, Train: 0.2571, Val: 0.1300, Test: 0.1510
Epoch: 88, Loss: 1.7734, Train: 0.2500, Val: 0.1320, Test: 0.1520
Epoch: 89, Loss: 1.7821, Train: 0.2500, Val: 0.1300, Test: 0.1520
Epoch: 90, Loss: 1.8079, Train: 0.2429, Val: 0.1280, Test: 0.1510
Epoch: 91, Loss: 1.7595, Train: 0.2429, Val: 0.1320, Test: 0.1510
Epoch: 92, Loss: 1.7367, Train: 0.2429, Val: 0.1340, Test: 0.1520
Epoch: 93, Loss: 1.7738, Train: 0.2429, Val: 0.1360, Test: 0.1530
Epoch: 94, Loss: 1.7256, Train: 0.2500, Val: 0.1400, Test: 0.1540
Epoch: 95, Loss: 1.7393, Train: 0.2500, Val: 0.1460, Test: 0.1550
Epoch: 96, Loss: 1.7087, Train: 0.2571, Val: 0.1440, Test: 0.1560
Epoch: 97, Loss: 1.7315, Train: 0.2571, Val: 0.1480, Test: 0.1570
Epoch: 98, Loss: 1.7396, Train: 0.2643, Val: 0.1580, Test: 0.1600
Epoch: 99, Loss: 1.7271, Train: 0.2714, Val: 0.1600, Test: 0.1630
Epoch: 100, Loss: 1.6955, Train: 0.2857, Val: 0.1620, Test: 0.1760
Epoch: 101, Loss: 1.7272, Train: 0.2786, Val: 0.1680, Test: 0.1770
Epoch: 102, Loss: 1.7339, Train: 0.3071, Val: 0.1780, Test: 0.1880
Epoch: 103, Loss: 1.7283, Train: 0.3214, Val: 0.1840, Test: 0.1960
Epoch: 104, Loss: 1.6761, Train: 0.3643, Val: 0.2060, Test: 0.2290
Epoch: 105, Loss: 1.6523, Train: 0.3929, Val: 0.2280, Test: 0.2640
Epoch: 106, Loss: 1.6576, Train: 0.3929, Val: 0.2520, Test: 0.2890
Epoch: 107, Loss: 1.6791, Train: 0.3857, Val: 0.2660, Test: 0.3140
Epoch: 108, Loss: 1.6410, Train: 0.3786, Val: 0.2860, Test: 0.3230
Epoch: 109, Loss: 1.6493, Train: 0.3643, Val: 0.3000, Test: 0.3290
Epoch: 110, Loss: 1.6756, Train: 0.3643, Val: 0.3100, Test: 0.3430
Epoch: 111, Loss: 1.6412, Train: 0.3643, Val: 0.3120, Test: 0.3490
Epoch: 112, Loss: 1.7246, Train: 0.3643, Val: 0.3160, Test: 0.3490
Epoch: 113, Loss: 1.6476, Train: 0.3643, Val: 0.3220, Test: 0.3560
Epoch: 114, Loss: 1.6408, Train: 0.3500, Val: 0.3260, Test: 0.3560
Epoch: 115, Loss: 1.6437, Train: 0.3500, Val: 0.3360, Test: 0.3630
Epoch: 116, Loss: 1.6291, Train: 0.3500, Val: 0.3360, Test: 0.3640
Epoch: 117, Loss: 1.6246, Train: 0.3357, Val: 0.3360, Test: 0.3650
Epoch: 118, Loss: 1.6485, Train: 0.3286, Val: 0.3380, Test: 0.3610
Epoch: 119, Loss: 1.6325, Train: 0.3286, Val: 0.3340, Test: 0.3620
Epoch: 120, Loss: 1.5915, Train: 0.3286, Val: 0.3380, Test: 0.3620
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 121, Loss: 1.6039, Train: 0.3286, Val: 0.3380, Test: 0.3640
Epoch: 122, Loss: 1.6233, Train: 0.3214, Val: 0.3360, Test: 0.3660
Epoch: 123, Loss: 1.6277, Train: 0.3214, Val: 0.3320, Test: 0.3650
Epoch: 124, Loss: 1.6058, Train: 0.3214, Val: 0.3300, Test: 0.3650
Epoch: 125, Loss: 1.6283, Train: 0.3286, Val: 0.3300, Test: 0.3650
Epoch: 126, Loss: 1.6086, Train: 0.3214, Val: 0.3300, Test: 0.3640
Epoch: 127, Loss: 1.6937, Train: 0.3071, Val: 0.3300, Test: 0.3620
Epoch: 128, Loss: 1.6158, Train: 0.3071, Val: 0.3300, Test: 0.3630
Epoch: 129, Loss: 1.5981, Train: 0.3071, Val: 0.3300, Test: 0.3630
Epoch: 130, Loss: 1.6132, Train: 0.3071, Val: 0.3300, Test: 0.3640
Epoch: 131, Loss: 1.5934, Train: 0.3071, Val: 0.3380, Test: 0.3680
Epoch: 132, Loss: 1.6299, Train: 0.3071, Val: 0.3380, Test: 0.3700
Epoch: 133, Loss: 1.5681, Train: 0.3071, Val: 0.3380, Test: 0.3680
Epoch: 134, Loss: 1.5722, Train: 0.3071, Val: 0.3380, Test: 0.3680
Epoch: 135, Loss: 1.6615, Train: 0.3071, Val: 0.3400, Test: 0.3670
Epoch: 136, Loss: 1.5537, Train: 0.3071, Val: 0.3420, Test: 0.3680
Epoch: 137, Loss: 1.6146, Train: 0.3143, Val: 0.3460, Test: 0.3700
Epoch: 138, Loss: 1.5762, Train: 0.3357, Val: 0.3500, Test: 0.3740
Epoch: 139, Loss: 1.5546, Train: 0.3357, Val: 0.3540, Test: 0.3790
Epoch: 140, Loss: 1.5315, Train: 0.3357, Val: 0.3560, Test: 0.3790
Epoch: 141, Loss: 1.5536, Train: 0.3500, Val: 0.3660, Test: 0.3800
Epoch: 142, Loss: 1.5886, Train: 0.3714, Val: 0.3720, Test: 0.3850
Epoch: 143, Loss: 1.5803, Train: 0.3714, Val: 0.3700, Test: 0.3860
Epoch: 144, Loss: 1.5796, Train: 0.3857, Val: 0.3700, Test: 0.3870
Epoch: 145, Loss: 1.5694, Train: 0.3857, Val: 0.3780, Test: 0.3940
Epoch: 146, Loss: 1.5269, Train: 0.3929, Val: 0.3720, Test: 0.3950
Epoch: 147, Loss: 1.5474, Train: 0.3929, Val: 0.3780, Test: 0.3990
Epoch: 148, Loss: 1.4953, Train: 0.4071, Val: 0.3820, Test: 0.4010
Epoch: 149, Loss: 1.5736, Train: 0.4071, Val: 0.3740, Test: 0.3990
Epoch: 150, Loss: 1.5674, Train: 0.4000, Val: 0.3820, Test: 0.3970
Epoch: 151, Loss: 1.5192, Train: 0.4000, Val: 0.3800, Test: 0.3980
Epoch: 152, Loss: 1.5561, Train: 0.3786, Val: 0.3800, Test: 0.3950
Epoch: 153, Loss: 1.5953, Train: 0.3714, Val: 0.3780, Test: 0.3950
Epoch: 154, Loss: 1.5325, Train: 0.3714, Val: 0.3660, Test: 0.3920
Epoch: 155, Loss: 1.4750, Train: 0.3714, Val: 0.3680, Test: 0.3870
Epoch: 156, Loss: 1.4839, Train: 0.3714, Val: 0.3680, Test: 0.3870
Epoch: 157, Loss: 1.5111, Train: 0.3714, Val: 0.3600, Test: 0.3860
Epoch: 158, Loss: 1.5331, Train: 0.3643, Val: 0.3620, Test: 0.3840
Epoch: 159, Loss: 1.5939, Train: 0.3643, Val: 0.3620, Test: 0.3840
Epoch: 160, Loss: 1.4900, Train: 0.3643, Val: 0.3600, Test: 0.3850
Epoch: 161, Loss: 1.4514, Train: 0.3643, Val: 0.3660, Test: 0.3870
Epoch: 162, Loss: 1.5293, Train: 0.3643, Val: 0.3680, Test: 0.3890
Epoch: 163, Loss: 1.4494, Train: 0.3714, Val: 0.3720, Test: 0.3990
Epoch: 164, Loss: 1.4635, Train: 0.3857, Val: 0.3820, Test: 0.3990
Epoch: 165, Loss: 1.4461, Train: 0.3929, Val: 0.3840, Test: 0.4020
Epoch: 166, Loss: 1.5147, Train: 0.4000, Val: 0.3880, Test: 0.4040
Epoch: 167, Loss: 1.4456, Train: 0.4143, Val: 0.3820, Test: 0.4020
Epoch: 168, Loss: 1.4183, Train: 0.4143, Val: 0.3840, Test: 0.4040
Epoch: 169, Loss: 1.4340, Train: 0.4000, Val: 0.3820, Test: 0.4060
Epoch: 170, Loss: 1.3988, Train: 0.4000, Val: 0.3880, Test: 0.4060
Epoch: 171, Loss: 1.4367, Train: 0.4000, Val: 0.3900, Test: 0.4090
Epoch: 172, Loss: 1.3811, Train: 0.3857, Val: 0.3840, Test: 0.4090
Epoch: 173, Loss: 1.4386, Train: 0.3857, Val: 0.3820, Test: 0.4030
Epoch: 174, Loss: 1.4048, Train: 0.3929, Val: 0.3800, Test: 0.4030
Epoch: 175, Loss: 1.4187, Train: 0.3929, Val: 0.3800, Test: 0.4030
Epoch: 176, Loss: 1.4319, Train: 0.3929, Val: 0.3840, Test: 0.4040
Epoch: 177, Loss: 1.4397, Train: 0.3929, Val: 0.3900, Test: 0.4090
Epoch: 178, Loss: 1.3751, Train: 0.3929, Val: 0.3880, Test: 0.4090
Epoch: 179, Loss: 1.3856, Train: 0.4000, Val: 0.3960, Test: 0.4080
Epoch: 180, Loss: 1.3725, Train: 0.4000, Val: 0.3960, Test: 0.4090
Epoch: 181, Loss: 1.3900, Train: 0.4000, Val: 0.3960, Test: 0.4120
Epoch: 182, Loss: 1.3422, Train: 0.4071, Val: 0.3980, Test: 0.4150
Epoch: 183, Loss: 1.4969, Train: 0.4071, Val: 0.3980, Test: 0.4130
Epoch: 184, Loss: 1.5165, Train: 0.4071, Val: 0.3940, Test: 0.4120
Epoch: 185, Loss: 1.3391, Train: 0.4000, Val: 0.3880, Test: 0.4100
Epoch: 186, Loss: 1.4355, Train: 0.4000, Val: 0.3880, Test: 0.4030
Epoch: 187, Loss: 1.3711, Train: 0.4000, Val: 0.3760, Test: 0.4010
Epoch: 188, Loss: 1.3156, Train: 0.4000, Val: 0.3680, Test: 0.3970
Epoch: 189, Loss: 1.3888, Train: 0.4000, Val: 0.3620, Test: 0.3980
Epoch: 190, Loss: 1.3604, Train: 0.3857, Val: 0.3600, Test: 0.3960
Epoch: 191, Loss: 1.3674, Train: 0.3786, Val: 0.3560, Test: 0.3950
Epoch: 192, Loss: 1.3386, Train: 0.3857, Val: 0.3600, Test: 0.3910
Epoch: 193, Loss: 1.3324, Train: 0.3929, Val: 0.3640, Test: 0.3900
Epoch: 194, Loss: 1.2866, Train: 0.4143, Val: 0.3640, Test: 0.4010
Epoch: 195, Loss: 1.3104, Train: 0.4214, Val: 0.3800, Test: 0.4000
Epoch: 196, Loss: 1.3646, Train: 0.4214, Val: 0.3920, Test: 0.4140
Epoch: 197, Loss: 1.3365, Train: 0.4357, Val: 0.3960, Test: 0.4200
Epoch: 198, Loss: 1.2579, Train: 0.4500, Val: 0.4080, Test: 0.4290
Epoch: 199, Loss: 1.2669, Train: 0.4429, Val: 0.4080, Test: 0.4300
Epoch: 200, Loss: 1.2474, Train: 0.4500, Val: 0.4080, Test: 0.4310
MAD:  0.5233
Best Test Accuracy: 0.4310, Val Accuracy: 0.4080, Train Accuracy: 0.4500
Training completed.
Seed:  1
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 7.2734, Train: 0.0643, Val: 0.1220, Test: 0.1070
Epoch: 2, Loss: 4.8405, Train: 0.1643, Val: 0.2300, Test: 0.2190
Epoch: 3, Loss: 4.6034, Train: 0.1714, Val: 0.2440, Test: 0.2200
Epoch: 4, Loss: 3.5929, Train: 0.1929, Val: 0.2200, Test: 0.1930
Epoch: 5, Loss: 3.6226, Train: 0.1643, Val: 0.1920, Test: 0.1730
Epoch: 6, Loss: 2.9445, Train: 0.1214, Val: 0.1780, Test: 0.1540
Epoch: 7, Loss: 3.1803, Train: 0.1286, Val: 0.1620, Test: 0.1440
Epoch: 8, Loss: 3.0515, Train: 0.1286, Val: 0.1200, Test: 0.1190
Epoch: 9, Loss: 2.7925, Train: 0.1214, Val: 0.0960, Test: 0.1020
Epoch: 10, Loss: 2.7204, Train: 0.1286, Val: 0.0880, Test: 0.0880
Epoch: 11, Loss: 2.4433, Train: 0.1429, Val: 0.0980, Test: 0.0910
Epoch: 12, Loss: 2.4063, Train: 0.1500, Val: 0.1020, Test: 0.0990
Epoch: 13, Loss: 2.3872, Train: 0.1643, Val: 0.1040, Test: 0.1100
Epoch: 14, Loss: 2.2736, Train: 0.1857, Val: 0.1220, Test: 0.1270
Epoch: 15, Loss: 2.3019, Train: 0.1857, Val: 0.1380, Test: 0.1440
Epoch: 16, Loss: 2.1770, Train: 0.2000, Val: 0.1480, Test: 0.1390
Epoch: 17, Loss: 2.0712, Train: 0.2071, Val: 0.1340, Test: 0.1460
Epoch: 18, Loss: 2.2265, Train: 0.2143, Val: 0.1360, Test: 0.1420
Epoch: 19, Loss: 2.2843, Train: 0.2143, Val: 0.1280, Test: 0.1450
Epoch: 20, Loss: 2.2837, Train: 0.2000, Val: 0.1300, Test: 0.1440
Epoch: 21, Loss: 1.9819, Train: 0.1929, Val: 0.1300, Test: 0.1430
Epoch: 22, Loss: 2.1330, Train: 0.1929, Val: 0.1260, Test: 0.1430
Epoch: 23, Loss: 2.0533, Train: 0.1714, Val: 0.1280, Test: 0.1400
Epoch: 24, Loss: 2.1220, Train: 0.1786, Val: 0.1360, Test: 0.1420
Epoch: 25, Loss: 2.1135, Train: 0.1786, Val: 0.1400, Test: 0.1500
Epoch: 26, Loss: 2.1072, Train: 0.1714, Val: 0.1380, Test: 0.1540
Epoch: 27, Loss: 1.9705, Train: 0.1714, Val: 0.1380, Test: 0.1540
Epoch: 28, Loss: 1.9997, Train: 0.1786, Val: 0.1380, Test: 0.1480
Epoch: 29, Loss: 2.0378, Train: 0.1786, Val: 0.1360, Test: 0.1450
Epoch: 30, Loss: 2.0125, Train: 0.1714, Val: 0.1340, Test: 0.1420
Epoch: 31, Loss: 1.9693, Train: 0.1571, Val: 0.1280, Test: 0.1460
Epoch: 32, Loss: 1.9658, Train: 0.1571, Val: 0.1200, Test: 0.1430
Epoch: 33, Loss: 2.0074, Train: 0.1571, Val: 0.1120, Test: 0.1320
Epoch: 34, Loss: 2.1329, Train: 0.1571, Val: 0.1120, Test: 0.1300
Epoch: 35, Loss: 2.0317, Train: 0.1571, Val: 0.1080, Test: 0.1180
Epoch: 36, Loss: 1.9386, Train: 0.1571, Val: 0.0980, Test: 0.1140
Epoch: 37, Loss: 2.0060, Train: 0.1571, Val: 0.0960, Test: 0.1090
Epoch: 38, Loss: 1.9470, Train: 0.1571, Val: 0.0920, Test: 0.1070
Epoch: 39, Loss: 1.9691, Train: 0.1500, Val: 0.0920, Test: 0.1070
Epoch: 40, Loss: 1.9438, Train: 0.1500, Val: 0.0900, Test: 0.1020
Epoch: 41, Loss: 1.9642, Train: 0.1500, Val: 0.0880, Test: 0.0980
Epoch: 42, Loss: 2.0530, Train: 0.1429, Val: 0.0880, Test: 0.0940
Epoch: 43, Loss: 2.0188, Train: 0.1429, Val: 0.0860, Test: 0.0930
Epoch: 44, Loss: 2.0367, Train: 0.1429, Val: 0.0820, Test: 0.0930
Epoch: 45, Loss: 1.9816, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 46, Loss: 1.9304, Train: 0.1429, Val: 0.0760, Test: 0.0910
Epoch: 47, Loss: 1.9931, Train: 0.1429, Val: 0.0740, Test: 0.0910
Epoch: 48, Loss: 1.8780, Train: 0.1429, Val: 0.0760, Test: 0.0910
Epoch: 49, Loss: 1.9814, Train: 0.1429, Val: 0.0760, Test: 0.0920
Epoch: 50, Loss: 2.0783, Train: 0.1429, Val: 0.0740, Test: 0.0920
Epoch: 51, Loss: 1.9928, Train: 0.1643, Val: 0.0740, Test: 0.0910
Epoch: 52, Loss: 1.9316, Train: 0.1714, Val: 0.0740, Test: 0.0920
Epoch: 53, Loss: 1.8793, Train: 0.1786, Val: 0.0740, Test: 0.0920
Epoch: 54, Loss: 1.9012, Train: 0.1786, Val: 0.0740, Test: 0.0930
Epoch: 55, Loss: 1.9639, Train: 0.1786, Val: 0.0760, Test: 0.0940
Epoch: 56, Loss: 1.9216, Train: 0.1786, Val: 0.0760, Test: 0.0940
Epoch: 57, Loss: 1.9541, Train: 0.1786, Val: 0.0740, Test: 0.0930
Epoch: 58, Loss: 1.9034, Train: 0.1786, Val: 0.0740, Test: 0.0930
Epoch: 59, Loss: 1.8771, Train: 0.1786, Val: 0.0740, Test: 0.0940
Epoch: 60, Loss: 1.8842, Train: 0.1786, Val: 0.0760, Test: 0.0950
Epoch: 61, Loss: 1.8665, Train: 0.1786, Val: 0.0760, Test: 0.0950
Epoch: 62, Loss: 1.8756, Train: 0.1786, Val: 0.0780, Test: 0.0980
Epoch: 63, Loss: 1.8990, Train: 0.1786, Val: 0.0780, Test: 0.1000
Epoch: 64, Loss: 1.8976, Train: 0.1786, Val: 0.0800, Test: 0.1010
Epoch: 65, Loss: 1.8794, Train: 0.1786, Val: 0.0780, Test: 0.1000
Epoch: 66, Loss: 1.8390, Train: 0.1857, Val: 0.0800, Test: 0.1000
Epoch: 67, Loss: 1.9667, Train: 0.1857, Val: 0.0800, Test: 0.1000
Epoch: 68, Loss: 1.9443, Train: 0.2071, Val: 0.0820, Test: 0.1030
Epoch: 69, Loss: 1.9347, Train: 0.2143, Val: 0.0820, Test: 0.1030
Epoch: 70, Loss: 2.0293, Train: 0.2143, Val: 0.0820, Test: 0.1040
Epoch: 71, Loss: 1.8744, Train: 0.2143, Val: 0.0820, Test: 0.1040
Epoch: 72, Loss: 1.8517, Train: 0.2214, Val: 0.0840, Test: 0.1040
Epoch: 73, Loss: 1.8735, Train: 0.2214, Val: 0.0840, Test: 0.1040
Epoch: 74, Loss: 2.1205, Train: 0.2286, Val: 0.0840, Test: 0.1040
Epoch: 75, Loss: 1.8634, Train: 0.2357, Val: 0.0860, Test: 0.1070
Epoch: 76, Loss: 1.9215, Train: 0.2500, Val: 0.0880, Test: 0.1070
Epoch: 77, Loss: 1.8317, Train: 0.2500, Val: 0.0880, Test: 0.1080
Epoch: 78, Loss: 1.8266, Train: 0.2500, Val: 0.0900, Test: 0.1100
Epoch: 79, Loss: 1.7987, Train: 0.2500, Val: 0.0920, Test: 0.1100
Epoch: 80, Loss: 1.9035, Train: 0.2500, Val: 0.0920, Test: 0.1110
Epoch: 81, Loss: 1.9732, Train: 0.2500, Val: 0.0920, Test: 0.1120
Epoch: 82, Loss: 1.8261, Train: 0.2500, Val: 0.0940, Test: 0.1130
Epoch: 83, Loss: 1.9214, Train: 0.2500, Val: 0.0940, Test: 0.1150
Epoch: 84, Loss: 1.7995, Train: 0.2643, Val: 0.0980, Test: 0.1160
Epoch: 85, Loss: 1.8522, Train: 0.2643, Val: 0.0980, Test: 0.1170
Epoch: 86, Loss: 1.8274, Train: 0.2643, Val: 0.1020, Test: 0.1190
Epoch: 87, Loss: 1.7897, Train: 0.2643, Val: 0.1000, Test: 0.1210
Epoch: 88, Loss: 1.7723, Train: 0.2643, Val: 0.1020, Test: 0.1220
Epoch: 89, Loss: 1.8488, Train: 0.2714, Val: 0.1040, Test: 0.1250
Epoch: 90, Loss: 1.8476, Train: 0.2714, Val: 0.1040, Test: 0.1280
Epoch: 91, Loss: 1.7783, Train: 0.2714, Val: 0.1020, Test: 0.1300
Epoch: 92, Loss: 1.7465, Train: 0.2714, Val: 0.1040, Test: 0.1320
Epoch: 93, Loss: 1.7273, Train: 0.2714, Val: 0.1080, Test: 0.1340
Epoch: 94, Loss: 1.7098, Train: 0.2714, Val: 0.1080, Test: 0.1380
Epoch: 95, Loss: 1.7254, Train: 0.2714, Val: 0.1100, Test: 0.1400
Epoch: 96, Loss: 1.7946, Train: 0.2929, Val: 0.1100, Test: 0.1430
Epoch: 97, Loss: 1.6981, Train: 0.2929, Val: 0.1180, Test: 0.1480
Epoch: 98, Loss: 1.7538, Train: 0.3000, Val: 0.1240, Test: 0.1540
Epoch: 99, Loss: 1.6625, Train: 0.3143, Val: 0.1320, Test: 0.1590
Epoch: 100, Loss: 1.7192, Train: 0.3214, Val: 0.1420, Test: 0.1620
Epoch: 101, Loss: 1.7095, Train: 0.3214, Val: 0.1420, Test: 0.1640
Epoch: 102, Loss: 1.7851, Train: 0.3286, Val: 0.1420, Test: 0.1650
Epoch: 103, Loss: 1.7365, Train: 0.3286, Val: 0.1440, Test: 0.1670
Epoch: 104, Loss: 1.9042, Train: 0.3286, Val: 0.1440, Test: 0.1670
Epoch: 105, Loss: 1.8364, Train: 0.3286, Val: 0.1460, Test: 0.1690
Epoch: 106, Loss: 1.7179, Train: 0.3500, Val: 0.1480, Test: 0.1700
Epoch: 107, Loss: 1.6602, Train: 0.3500, Val: 0.1500, Test: 0.1710
Epoch: 108, Loss: 1.6762, Train: 0.3500, Val: 0.1480, Test: 0.1710
Epoch: 109, Loss: 1.6333, Train: 0.3500, Val: 0.1480, Test: 0.1700
Epoch: 110, Loss: 1.7093, Train: 0.3500, Val: 0.1500, Test: 0.1740
Epoch: 111, Loss: 1.6186, Train: 0.3500, Val: 0.1560, Test: 0.1770
Epoch: 112, Loss: 1.8230, Train: 0.3500, Val: 0.1580, Test: 0.1780
Epoch: 113, Loss: 1.6587, Train: 0.3500, Val: 0.1640, Test: 0.1870
Epoch: 114, Loss: 1.6549, Train: 0.3500, Val: 0.1600, Test: 0.1880
Epoch: 115, Loss: 1.6625, Train: 0.3500, Val: 0.1600, Test: 0.1920
Epoch: 116, Loss: 1.6973, Train: 0.3429, Val: 0.1600, Test: 0.1940
Epoch: 117, Loss: 1.5406, Train: 0.3429, Val: 0.1620, Test: 0.1960
Epoch: 118, Loss: 1.5710, Train: 0.3429, Val: 0.1620, Test: 0.1980
Epoch: 119, Loss: 1.6317, Train: 0.3429, Val: 0.1640, Test: 0.2000
Epoch: 120, Loss: 1.5625, Train: 0.3429, Val: 0.1680, Test: 0.2010
Epoch: 121, Loss: 1.5553, Train: 0.3500, Val: 0.1700, Test: 0.1990
Epoch: 122, Loss: 1.5592, Train: 0.3571, Val: 0.1680, Test: 0.1960
Epoch: 123, Loss: 1.6392, Train: 0.3643, Val: 0.1700, Test: 0.1980
Epoch: 124, Loss: 1.5505, Train: 0.3643, Val: 0.1720, Test: 0.1990
Epoch: 125, Loss: 1.5598, Train: 0.3643, Val: 0.1680, Test: 0.1960
Epoch: 126, Loss: 1.6689, Train: 0.3786, Val: 0.1720, Test: 0.1960
Epoch: 127, Loss: 1.5197, Train: 0.3786, Val: 0.1800, Test: 0.1990
Epoch: 128, Loss: 1.5247, Train: 0.3786, Val: 0.1800, Test: 0.2000
Epoch: 129, Loss: 1.6432, Train: 0.3786, Val: 0.1820, Test: 0.2000
Epoch: 130, Loss: 1.5058, Train: 0.3786, Val: 0.1840, Test: 0.2010
Epoch: 131, Loss: 1.5225, Train: 0.3786, Val: 0.1840, Test: 0.2030
Epoch: 132, Loss: 1.4708, Train: 0.3857, Val: 0.1840, Test: 0.2050
Epoch: 133, Loss: 1.4671, Train: 0.3857, Val: 0.1840, Test: 0.2040
Epoch: 134, Loss: 1.5823, Train: 0.3857, Val: 0.1860, Test: 0.2090
Epoch: 135, Loss: 1.4192, Train: 0.3857, Val: 0.1880, Test: 0.2080
Epoch: 136, Loss: 1.4138, Train: 0.3929, Val: 0.1920, Test: 0.2110
Epoch: 137, Loss: 1.4379, Train: 0.3929, Val: 0.1940, Test: 0.2140
Epoch: 138, Loss: 1.4472, Train: 0.4000, Val: 0.1960, Test: 0.2150
Epoch: 139, Loss: 1.4927, Train: 0.4071, Val: 0.1980, Test: 0.2200
Epoch: 140, Loss: 1.4371, Train: 0.4071, Val: 0.1980, Test: 0.2190
Epoch: 141, Loss: 1.4368, Train: 0.4071, Val: 0.2000, Test: 0.2230
Epoch: 142, Loss: 1.4539, Train: 0.4000, Val: 0.2080, Test: 0.2290
Epoch: 143, Loss: 1.5010, Train: 0.4000, Val: 0.2080, Test: 0.2300
Epoch: 144, Loss: 1.3920, Train: 0.4000, Val: 0.2080, Test: 0.2250
Epoch: 145, Loss: 1.4084, Train: 0.4000, Val: 0.2080, Test: 0.2250
Epoch: 146, Loss: 1.4579, Train: 0.4000, Val: 0.2080, Test: 0.2230
Epoch: 147, Loss: 1.3991, Train: 0.4000, Val: 0.2120, Test: 0.2240
Epoch: 148, Loss: 1.3032, Train: 0.4000, Val: 0.2080, Test: 0.2240
Epoch: 149, Loss: 1.3700, Train: 0.4000, Val: 0.2120, Test: 0.2290
Epoch: 150, Loss: 1.3694, Train: 0.4071, Val: 0.2120, Test: 0.2320
Epoch: 151, Loss: 1.6096, Train: 0.4143, Val: 0.2180, Test: 0.2330
Epoch: 152, Loss: 1.3371, Train: 0.4214, Val: 0.2260, Test: 0.2390
Epoch: 153, Loss: 1.4136, Train: 0.4071, Val: 0.2320, Test: 0.2340
Epoch: 154, Loss: 1.3220, Train: 0.4071, Val: 0.2400, Test: 0.2340
Epoch: 155, Loss: 1.3164, Train: 0.4143, Val: 0.2260, Test: 0.2340
Epoch: 156, Loss: 1.3032, Train: 0.4214, Val: 0.2240, Test: 0.2340
Epoch: 157, Loss: 1.2634, Train: 0.4143, Val: 0.2240, Test: 0.2310
Epoch: 158, Loss: 1.2292, Train: 0.4214, Val: 0.2200, Test: 0.2330
Epoch: 159, Loss: 1.2528, Train: 0.4214, Val: 0.2200, Test: 0.2330
Epoch: 160, Loss: 1.2221, Train: 0.4214, Val: 0.2280, Test: 0.2360
Epoch: 161, Loss: 1.2469, Train: 0.4286, Val: 0.2340, Test: 0.2430
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 162, Loss: 1.2035, Train: 0.4429, Val: 0.2480, Test: 0.2600
Epoch: 163, Loss: 1.1997, Train: 0.4571, Val: 0.2700, Test: 0.2770
Epoch: 164, Loss: 1.2591, Train: 0.4786, Val: 0.2780, Test: 0.3010
Epoch: 165, Loss: 1.3296, Train: 0.5000, Val: 0.2980, Test: 0.3170
Epoch: 166, Loss: 1.1801, Train: 0.5214, Val: 0.3080, Test: 0.3240
Epoch: 167, Loss: 1.4267, Train: 0.5214, Val: 0.3120, Test: 0.3240
Epoch: 168, Loss: 1.3055, Train: 0.5357, Val: 0.3100, Test: 0.3250
Epoch: 169, Loss: 1.1696, Train: 0.5357, Val: 0.3180, Test: 0.3270
Epoch: 170, Loss: 1.2134, Train: 0.5357, Val: 0.3160, Test: 0.3270
Epoch: 171, Loss: 1.1091, Train: 0.5357, Val: 0.3060, Test: 0.3240
Epoch: 172, Loss: 1.1663, Train: 0.5357, Val: 0.3100, Test: 0.3240
Epoch: 173, Loss: 1.1104, Train: 0.5500, Val: 0.3140, Test: 0.3270
Epoch: 174, Loss: 1.2971, Train: 0.5714, Val: 0.3280, Test: 0.3270
Epoch: 175, Loss: 1.2166, Train: 0.5786, Val: 0.3320, Test: 0.3380
Epoch: 176, Loss: 1.0327, Train: 0.5571, Val: 0.3460, Test: 0.3380
Epoch: 177, Loss: 1.0552, Train: 0.5571, Val: 0.3460, Test: 0.3360
Epoch: 178, Loss: 1.1141, Train: 0.5571, Val: 0.3420, Test: 0.3350
Epoch: 179, Loss: 1.0308, Train: 0.5714, Val: 0.3400, Test: 0.3340
Epoch: 180, Loss: 1.1344, Train: 0.5786, Val: 0.3480, Test: 0.3330
Epoch: 181, Loss: 1.0782, Train: 0.5714, Val: 0.3560, Test: 0.3340
Epoch: 182, Loss: 1.0903, Train: 0.5714, Val: 0.3580, Test: 0.3340
Epoch: 183, Loss: 0.9866, Train: 0.5643, Val: 0.3560, Test: 0.3380
Epoch: 184, Loss: 1.1880, Train: 0.5786, Val: 0.3560, Test: 0.3390
Epoch: 185, Loss: 1.0148, Train: 0.5571, Val: 0.3460, Test: 0.3370
Epoch: 186, Loss: 1.0563, Train: 0.5571, Val: 0.3460, Test: 0.3370
Epoch: 187, Loss: 1.0466, Train: 0.5500, Val: 0.3480, Test: 0.3400
Epoch: 188, Loss: 1.0985, Train: 0.5500, Val: 0.3500, Test: 0.3410
Epoch: 189, Loss: 1.0442, Train: 0.5500, Val: 0.3560, Test: 0.3420
Epoch: 190, Loss: 1.0804, Train: 0.5500, Val: 0.3560, Test: 0.3430
Epoch: 191, Loss: 0.9667, Train: 0.5500, Val: 0.3580, Test: 0.3380
Epoch: 192, Loss: 0.9777, Train: 0.5500, Val: 0.3580, Test: 0.3430
Epoch: 193, Loss: 0.9242, Train: 0.5571, Val: 0.3660, Test: 0.3500
Epoch: 194, Loss: 0.9172, Train: 0.5571, Val: 0.3680, Test: 0.3530
Epoch: 195, Loss: 1.0121, Train: 0.5786, Val: 0.3720, Test: 0.3550
Epoch: 196, Loss: 0.9026, Train: 0.5857, Val: 0.3760, Test: 0.3600
Epoch: 197, Loss: 0.9788, Train: 0.5857, Val: 0.3720, Test: 0.3590
Epoch: 198, Loss: 0.8966, Train: 0.5714, Val: 0.3700, Test: 0.3540
Epoch: 199, Loss: 0.9877, Train: 0.5643, Val: 0.3600, Test: 0.3500
Epoch: 200, Loss: 0.9547, Train: 0.5571, Val: 0.3540, Test: 0.3400
MAD:  0.6528
Best Test Accuracy: 0.3600, Val Accuracy: 0.3760, Train Accuracy: 0.5857
Training completed.
Seed:  2
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 6.6219, Train: 0.2143, Val: 0.2140, Test: 0.1900
Epoch: 2, Loss: 4.4355, Train: 0.1357, Val: 0.0980, Test: 0.0940
Epoch: 3, Loss: 4.4065, Train: 0.1357, Val: 0.1180, Test: 0.0960
Epoch: 4, Loss: 3.0642, Train: 0.1786, Val: 0.1480, Test: 0.1140
Epoch: 5, Loss: 3.8144, Train: 0.1357, Val: 0.1660, Test: 0.1470
Epoch: 6, Loss: 3.0703, Train: 0.1357, Val: 0.1620, Test: 0.1480
Epoch: 7, Loss: 2.7989, Train: 0.1429, Val: 0.1620, Test: 0.1490
Epoch: 8, Loss: 2.6471, Train: 0.1429, Val: 0.1620, Test: 0.1490
Epoch: 9, Loss: 2.6682, Train: 0.1429, Val: 0.1620, Test: 0.1490
Epoch: 10, Loss: 2.4095, Train: 0.1429, Val: 0.1620, Test: 0.1490
Epoch: 11, Loss: 2.4757, Train: 0.1429, Val: 0.1620, Test: 0.1490
Epoch: 12, Loss: 2.1254, Train: 0.1429, Val: 0.1620, Test: 0.1490
Epoch: 13, Loss: 2.1869, Train: 0.1429, Val: 0.1600, Test: 0.1480
Epoch: 14, Loss: 2.3994, Train: 0.1500, Val: 0.1600, Test: 0.1480
Epoch: 15, Loss: 2.2102, Train: 0.1786, Val: 0.1620, Test: 0.1510
Epoch: 16, Loss: 2.3285, Train: 0.2000, Val: 0.1560, Test: 0.1540
Epoch: 17, Loss: 2.3103, Train: 0.2000, Val: 0.1540, Test: 0.1540
Epoch: 18, Loss: 2.1150, Train: 0.2000, Val: 0.1560, Test: 0.1600
Epoch: 19, Loss: 2.3016, Train: 0.2357, Val: 0.1720, Test: 0.1690
Epoch: 20, Loss: 2.2058, Train: 0.2571, Val: 0.1620, Test: 0.1760
Epoch: 21, Loss: 1.9565, Train: 0.3071, Val: 0.1540, Test: 0.1730
Epoch: 22, Loss: 2.1584, Train: 0.3000, Val: 0.1420, Test: 0.1590
Epoch: 23, Loss: 1.9876, Train: 0.2714, Val: 0.1160, Test: 0.1460
Epoch: 24, Loss: 2.0652, Train: 0.2571, Val: 0.1080, Test: 0.1280
Epoch: 25, Loss: 2.0441, Train: 0.2286, Val: 0.0980, Test: 0.1150
Epoch: 26, Loss: 2.1553, Train: 0.2143, Val: 0.0920, Test: 0.1080
Epoch: 27, Loss: 2.0660, Train: 0.2143, Val: 0.0860, Test: 0.1070
Epoch: 28, Loss: 2.0158, Train: 0.2000, Val: 0.0800, Test: 0.1010
Epoch: 29, Loss: 2.2613, Train: 0.2000, Val: 0.0760, Test: 0.0980
Epoch: 30, Loss: 1.9797, Train: 0.2000, Val: 0.0760, Test: 0.0970
Epoch: 31, Loss: 2.0587, Train: 0.1929, Val: 0.0740, Test: 0.0990
Epoch: 32, Loss: 2.0087, Train: 0.1857, Val: 0.0740, Test: 0.0960
Epoch: 33, Loss: 2.0476, Train: 0.1929, Val: 0.0740, Test: 0.0970
Epoch: 34, Loss: 1.9943, Train: 0.1929, Val: 0.0740, Test: 0.0970
Epoch: 35, Loss: 2.0391, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 36, Loss: 2.0678, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 37, Loss: 2.0052, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 38, Loss: 2.0259, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 39, Loss: 1.9150, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 40, Loss: 2.0616, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 41, Loss: 1.9655, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 42, Loss: 1.9609, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 43, Loss: 1.9589, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 44, Loss: 1.9757, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 45, Loss: 2.0179, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 46, Loss: 1.9724, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 47, Loss: 1.9449, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 48, Loss: 1.9085, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 49, Loss: 1.9462, Train: 0.1929, Val: 0.0720, Test: 0.0970
Epoch: 50, Loss: 2.0223, Train: 0.1929, Val: 0.0720, Test: 0.0970
Epoch: 51, Loss: 1.9414, Train: 0.1929, Val: 0.0720, Test: 0.0970
Epoch: 52, Loss: 1.9923, Train: 0.1929, Val: 0.0720, Test: 0.0990
Epoch: 53, Loss: 1.9227, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 54, Loss: 1.9744, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 55, Loss: 2.0162, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 56, Loss: 1.9194, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 57, Loss: 1.9927, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 58, Loss: 1.9773, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 59, Loss: 1.9105, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 60, Loss: 1.9279, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 61, Loss: 1.8904, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 62, Loss: 1.9288, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 63, Loss: 1.8813, Train: 0.2000, Val: 0.0740, Test: 0.1010
Epoch: 64, Loss: 1.9252, Train: 0.2000, Val: 0.0740, Test: 0.1010
Epoch: 65, Loss: 1.8591, Train: 0.2000, Val: 0.0740, Test: 0.1010
Epoch: 66, Loss: 1.8327, Train: 0.2000, Val: 0.0740, Test: 0.1010
Epoch: 67, Loss: 1.8286, Train: 0.2000, Val: 0.0740, Test: 0.1010
Epoch: 68, Loss: 1.8937, Train: 0.2000, Val: 0.0740, Test: 0.1030
Epoch: 69, Loss: 2.0461, Train: 0.2071, Val: 0.0740, Test: 0.1040
Epoch: 70, Loss: 1.8758, Train: 0.2071, Val: 0.0740, Test: 0.1040
Epoch: 71, Loss: 1.8147, Train: 0.2071, Val: 0.0760, Test: 0.1040
Epoch: 72, Loss: 1.9679, Train: 0.2071, Val: 0.0780, Test: 0.1040
Epoch: 73, Loss: 1.8203, Train: 0.2071, Val: 0.0780, Test: 0.1060
Epoch: 74, Loss: 1.7978, Train: 0.2071, Val: 0.0780, Test: 0.1070
Epoch: 75, Loss: 1.8335, Train: 0.2071, Val: 0.0800, Test: 0.1090
Epoch: 76, Loss: 1.7863, Train: 0.2071, Val: 0.0820, Test: 0.1110
Epoch: 77, Loss: 1.8149, Train: 0.2143, Val: 0.0820, Test: 0.1120
Epoch: 78, Loss: 1.8621, Train: 0.2214, Val: 0.0820, Test: 0.1130
Epoch: 79, Loss: 1.8756, Train: 0.2214, Val: 0.0820, Test: 0.1130
Epoch: 80, Loss: 1.7957, Train: 0.2286, Val: 0.0840, Test: 0.1130
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 81, Loss: 2.0026, Train: 0.2286, Val: 0.0840, Test: 0.1150
Epoch: 82, Loss: 1.7900, Train: 0.2286, Val: 0.0840, Test: 0.1150
Epoch: 83, Loss: 1.8680, Train: 0.2429, Val: 0.0840, Test: 0.1150
Epoch: 84, Loss: 1.7407, Train: 0.2429, Val: 0.0840, Test: 0.1160
Epoch: 85, Loss: 1.8008, Train: 0.2500, Val: 0.0840, Test: 0.1160
Epoch: 86, Loss: 1.7884, Train: 0.2500, Val: 0.0860, Test: 0.1170
Epoch: 87, Loss: 1.7200, Train: 0.2571, Val: 0.0880, Test: 0.1200
Epoch: 88, Loss: 1.8333, Train: 0.2571, Val: 0.0900, Test: 0.1220
Epoch: 89, Loss: 1.7333, Train: 0.2571, Val: 0.0900, Test: 0.1220
Epoch: 90, Loss: 1.7752, Train: 0.2643, Val: 0.0940, Test: 0.1240
Epoch: 91, Loss: 1.7873, Train: 0.2643, Val: 0.0980, Test: 0.1240
Epoch: 92, Loss: 1.7154, Train: 0.2643, Val: 0.0980, Test: 0.1250
Epoch: 93, Loss: 1.7501, Train: 0.2714, Val: 0.1040, Test: 0.1240
Epoch: 94, Loss: 1.8025, Train: 0.2714, Val: 0.1040, Test: 0.1240
Epoch: 95, Loss: 1.7527, Train: 0.2786, Val: 0.1020, Test: 0.1240
Epoch: 96, Loss: 1.8053, Train: 0.2786, Val: 0.1040, Test: 0.1230
Epoch: 97, Loss: 1.7947, Train: 0.2714, Val: 0.1000, Test: 0.1240
Epoch: 98, Loss: 1.7069, Train: 0.2714, Val: 0.0980, Test: 0.1240
Epoch: 99, Loss: 1.7056, Train: 0.2714, Val: 0.0980, Test: 0.1250
Epoch: 100, Loss: 1.8068, Train: 0.2714, Val: 0.1000, Test: 0.1250
Epoch: 101, Loss: 1.7683, Train: 0.2714, Val: 0.1040, Test: 0.1250
Epoch: 102, Loss: 1.6640, Train: 0.2714, Val: 0.1060, Test: 0.1250
Epoch: 103, Loss: 1.6807, Train: 0.2714, Val: 0.1060, Test: 0.1270
Epoch: 104, Loss: 1.6830, Train: 0.2714, Val: 0.1080, Test: 0.1270
Epoch: 105, Loss: 1.7525, Train: 0.2714, Val: 0.1040, Test: 0.1250
Epoch: 106, Loss: 1.7461, Train: 0.2714, Val: 0.1040, Test: 0.1250
Epoch: 107, Loss: 1.7584, Train: 0.2786, Val: 0.1040, Test: 0.1270
Epoch: 108, Loss: 1.6761, Train: 0.2786, Val: 0.1060, Test: 0.1280
Epoch: 109, Loss: 1.6479, Train: 0.2786, Val: 0.1100, Test: 0.1320
Epoch: 110, Loss: 1.7284, Train: 0.2786, Val: 0.1100, Test: 0.1340
Epoch: 111, Loss: 1.6369, Train: 0.2786, Val: 0.1100, Test: 0.1340
Epoch: 112, Loss: 1.6280, Train: 0.2786, Val: 0.1100, Test: 0.1360
Epoch: 113, Loss: 1.6828, Train: 0.2786, Val: 0.1100, Test: 0.1350
Epoch: 114, Loss: 1.6355, Train: 0.2714, Val: 0.1100, Test: 0.1350
Epoch: 115, Loss: 1.6796, Train: 0.2714, Val: 0.1080, Test: 0.1350
Epoch: 116, Loss: 1.6980, Train: 0.2714, Val: 0.1080, Test: 0.1350
Epoch: 117, Loss: 1.6512, Train: 0.2714, Val: 0.1080, Test: 0.1350
Epoch: 118, Loss: 1.6106, Train: 0.2714, Val: 0.1100, Test: 0.1350
Epoch: 119, Loss: 1.6999, Train: 0.2714, Val: 0.1100, Test: 0.1340
Epoch: 120, Loss: 1.6339, Train: 0.2714, Val: 0.1100, Test: 0.1350
Epoch: 121, Loss: 1.6179, Train: 0.2714, Val: 0.1140, Test: 0.1360
Epoch: 122, Loss: 1.6384, Train: 0.2714, Val: 0.1140, Test: 0.1360
Epoch: 123, Loss: 1.6750, Train: 0.2714, Val: 0.1160, Test: 0.1380
Epoch: 124, Loss: 1.7217, Train: 0.2714, Val: 0.1160, Test: 0.1380
Epoch: 125, Loss: 1.6044, Train: 0.2714, Val: 0.1160, Test: 0.1400
Epoch: 126, Loss: 1.6074, Train: 0.2643, Val: 0.1160, Test: 0.1390
Epoch: 127, Loss: 1.6653, Train: 0.2643, Val: 0.1180, Test: 0.1410
Epoch: 128, Loss: 1.5960, Train: 0.2643, Val: 0.1180, Test: 0.1430
Epoch: 129, Loss: 1.6337, Train: 0.2643, Val: 0.1220, Test: 0.1440
Epoch: 130, Loss: 1.5915, Train: 0.2714, Val: 0.1240, Test: 0.1510
Epoch: 131, Loss: 1.5934, Train: 0.2786, Val: 0.1260, Test: 0.1540
Epoch: 132, Loss: 1.5719, Train: 0.2786, Val: 0.1300, Test: 0.1540
Epoch: 133, Loss: 1.5793, Train: 0.2857, Val: 0.1380, Test: 0.1560
Epoch: 134, Loss: 1.5728, Train: 0.3000, Val: 0.1440, Test: 0.1610
Epoch: 135, Loss: 1.6309, Train: 0.3071, Val: 0.1520, Test: 0.1730
Epoch: 136, Loss: 1.5638, Train: 0.3214, Val: 0.1640, Test: 0.1810
Epoch: 137, Loss: 1.5471, Train: 0.3214, Val: 0.1700, Test: 0.1850
Epoch: 138, Loss: 1.5476, Train: 0.3286, Val: 0.1700, Test: 0.1870
Epoch: 139, Loss: 1.7172, Train: 0.3357, Val: 0.1820, Test: 0.1890
Epoch: 140, Loss: 1.5493, Train: 0.3357, Val: 0.1820, Test: 0.1930
Epoch: 141, Loss: 1.5558, Train: 0.3286, Val: 0.1840, Test: 0.1960
Epoch: 142, Loss: 1.5712, Train: 0.3286, Val: 0.1840, Test: 0.1960
Epoch: 143, Loss: 1.5566, Train: 0.3286, Val: 0.1840, Test: 0.1970
Epoch: 144, Loss: 1.7292, Train: 0.3214, Val: 0.1780, Test: 0.1940
Epoch: 145, Loss: 1.5094, Train: 0.3143, Val: 0.1720, Test: 0.1850
Epoch: 146, Loss: 1.5367, Train: 0.3143, Val: 0.1680, Test: 0.1820
Epoch: 147, Loss: 1.5776, Train: 0.3143, Val: 0.1740, Test: 0.1870
Epoch: 148, Loss: 1.5304, Train: 0.3214, Val: 0.1760, Test: 0.1900
Epoch: 149, Loss: 1.5063, Train: 0.3214, Val: 0.1800, Test: 0.1940
Epoch: 150, Loss: 1.5038, Train: 0.3429, Val: 0.1900, Test: 0.2060
Epoch: 151, Loss: 1.4638, Train: 0.3500, Val: 0.2040, Test: 0.2180
Epoch: 152, Loss: 1.5279, Train: 0.3857, Val: 0.2100, Test: 0.2360
Epoch: 153, Loss: 1.5411, Train: 0.4143, Val: 0.2340, Test: 0.2650
Epoch: 154, Loss: 1.4624, Train: 0.4786, Val: 0.2440, Test: 0.2710
Epoch: 155, Loss: 1.5179, Train: 0.4929, Val: 0.2520, Test: 0.2760
Epoch: 156, Loss: 1.5429, Train: 0.5000, Val: 0.2600, Test: 0.2960
Epoch: 157, Loss: 1.4361, Train: 0.5071, Val: 0.2620, Test: 0.2970
Epoch: 158, Loss: 1.5894, Train: 0.4786, Val: 0.2700, Test: 0.3020
Epoch: 159, Loss: 1.4551, Train: 0.4714, Val: 0.2780, Test: 0.3120
Epoch: 160, Loss: 1.4762, Train: 0.4643, Val: 0.2760, Test: 0.3120
Epoch: 161, Loss: 1.4264, Train: 0.4571, Val: 0.2780, Test: 0.3060
Epoch: 162, Loss: 1.4740, Train: 0.4500, Val: 0.2840, Test: 0.3000
Epoch: 163, Loss: 1.4281, Train: 0.4500, Val: 0.2780, Test: 0.3030
Epoch: 164, Loss: 1.4506, Train: 0.4500, Val: 0.2820, Test: 0.3040
Epoch: 165, Loss: 1.4136, Train: 0.4429, Val: 0.2900, Test: 0.3110
Epoch: 166, Loss: 1.4066, Train: 0.4429, Val: 0.2940, Test: 0.3160
Epoch: 167, Loss: 1.4644, Train: 0.4429, Val: 0.2840, Test: 0.3100
Epoch: 168, Loss: 1.5892, Train: 0.4429, Val: 0.2700, Test: 0.3050
Epoch: 169, Loss: 1.3728, Train: 0.4643, Val: 0.2600, Test: 0.3010
Epoch: 170, Loss: 1.4868, Train: 0.4571, Val: 0.2480, Test: 0.2870
Epoch: 171, Loss: 1.3848, Train: 0.4571, Val: 0.2300, Test: 0.2790
Epoch: 172, Loss: 1.3734, Train: 0.4714, Val: 0.2260, Test: 0.2770
Epoch: 173, Loss: 1.4384, Train: 0.4643, Val: 0.2260, Test: 0.2720
Epoch: 174, Loss: 1.3347, Train: 0.4500, Val: 0.2240, Test: 0.2720
Epoch: 175, Loss: 1.3590, Train: 0.4429, Val: 0.2260, Test: 0.2730
Epoch: 176, Loss: 1.3202, Train: 0.4500, Val: 0.2380, Test: 0.2770
Epoch: 177, Loss: 1.3795, Train: 0.4643, Val: 0.2480, Test: 0.2750
Epoch: 178, Loss: 1.3036, Train: 0.4714, Val: 0.2660, Test: 0.2900
Epoch: 179, Loss: 1.3721, Train: 0.5071, Val: 0.2620, Test: 0.2910
Epoch: 180, Loss: 1.2885, Train: 0.4929, Val: 0.2520, Test: 0.2820
Epoch: 181, Loss: 1.3391, Train: 0.5143, Val: 0.2520, Test: 0.2790
Epoch: 182, Loss: 1.3079, Train: 0.4786, Val: 0.2480, Test: 0.2790
Epoch: 183, Loss: 1.3665, Train: 0.4643, Val: 0.2540, Test: 0.2790
Epoch: 184, Loss: 1.3562, Train: 0.4357, Val: 0.2420, Test: 0.2780
Epoch: 185, Loss: 1.3202, Train: 0.4286, Val: 0.2360, Test: 0.2680
Epoch: 186, Loss: 1.3099, Train: 0.3929, Val: 0.2360, Test: 0.2700
Epoch: 187, Loss: 1.3012, Train: 0.4143, Val: 0.2380, Test: 0.2670
Epoch: 188, Loss: 1.2856, Train: 0.4286, Val: 0.2420, Test: 0.2810
Epoch: 189, Loss: 1.2427, Train: 0.4500, Val: 0.2420, Test: 0.2830
Epoch: 190, Loss: 1.2204, Train: 0.4643, Val: 0.2580, Test: 0.2930
Epoch: 191, Loss: 1.3334, Train: 0.4357, Val: 0.2520, Test: 0.2950
Epoch: 192, Loss: 1.2433, Train: 0.4571, Val: 0.2700, Test: 0.3030
Epoch: 193, Loss: 1.3911, Train: 0.4643, Val: 0.2920, Test: 0.3120
Epoch: 194, Loss: 1.2024, Train: 0.4643, Val: 0.2940, Test: 0.3230
Epoch: 195, Loss: 1.2166, Train: 0.4786, Val: 0.3080, Test: 0.3370
Epoch: 196, Loss: 1.2609, Train: 0.4571, Val: 0.3100, Test: 0.3330
Epoch: 197, Loss: 1.2128, Train: 0.4643, Val: 0.3160, Test: 0.3350
Epoch: 198, Loss: 1.1734, Train: 0.4643, Val: 0.3260, Test: 0.3420
Epoch: 199, Loss: 1.1902, Train: 0.4571, Val: 0.3180, Test: 0.3420
Epoch: 200, Loss: 1.2499, Train: 0.4571, Val: 0.3220, Test: 0.3400
MAD:  0.6087
Best Test Accuracy: 0.3420, Val Accuracy: 0.3260, Train Accuracy: 0.4643
Training completed.
Seed:  3
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 8.6882, Train: 0.1571, Val: 0.0840, Test: 0.0910
Epoch: 2, Loss: 5.3992, Train: 0.1429, Val: 0.1100, Test: 0.1050
Epoch: 3, Loss: 4.2497, Train: 0.1429, Val: 0.1020, Test: 0.0850
Epoch: 4, Loss: 3.6495, Train: 0.1357, Val: 0.1100, Test: 0.0950
Epoch: 5, Loss: 3.8076, Train: 0.1571, Val: 0.1060, Test: 0.0970
Epoch: 6, Loss: 3.0569, Train: 0.1571, Val: 0.1100, Test: 0.1020
Epoch: 7, Loss: 3.0659, Train: 0.1571, Val: 0.1100, Test: 0.1070
Epoch: 8, Loss: 2.7287, Train: 0.1643, Val: 0.1140, Test: 0.1050
Epoch: 9, Loss: 2.3385, Train: 0.1571, Val: 0.1140, Test: 0.1050
Epoch: 10, Loss: 2.5544, Train: 0.1929, Val: 0.1200, Test: 0.1050
Epoch: 11, Loss: 2.2509, Train: 0.1857, Val: 0.1220, Test: 0.1050
Epoch: 12, Loss: 2.2031, Train: 0.1857, Val: 0.1240, Test: 0.1100
Epoch: 13, Loss: 2.3948, Train: 0.1786, Val: 0.1280, Test: 0.1190
Epoch: 14, Loss: 2.5485, Train: 0.1786, Val: 0.1160, Test: 0.1240
Epoch: 15, Loss: 2.2130, Train: 0.2071, Val: 0.1160, Test: 0.1270
Epoch: 16, Loss: 2.0771, Train: 0.1929, Val: 0.1320, Test: 0.1300
Epoch: 17, Loss: 2.2197, Train: 0.1929, Val: 0.1320, Test: 0.1320
Epoch: 18, Loss: 2.2348, Train: 0.1929, Val: 0.1360, Test: 0.1300
Epoch: 19, Loss: 2.1767, Train: 0.1786, Val: 0.1280, Test: 0.1230
Epoch: 20, Loss: 2.2620, Train: 0.1786, Val: 0.1320, Test: 0.1330
Epoch: 21, Loss: 2.2393, Train: 0.1714, Val: 0.1280, Test: 0.1350
Epoch: 22, Loss: 2.1641, Train: 0.1786, Val: 0.1140, Test: 0.1330
Epoch: 23, Loss: 2.1566, Train: 0.1786, Val: 0.1140, Test: 0.1310
Epoch: 24, Loss: 2.0710, Train: 0.1714, Val: 0.1080, Test: 0.1330
Epoch: 25, Loss: 1.9934, Train: 0.1643, Val: 0.1060, Test: 0.1270
Epoch: 26, Loss: 2.0941, Train: 0.1643, Val: 0.1080, Test: 0.1250
Epoch: 27, Loss: 2.0014, Train: 0.1786, Val: 0.1080, Test: 0.1270
Epoch: 28, Loss: 2.0273, Train: 0.1857, Val: 0.1040, Test: 0.1250
Epoch: 29, Loss: 2.0218, Train: 0.1857, Val: 0.0980, Test: 0.1250
Epoch: 30, Loss: 2.1754, Train: 0.1786, Val: 0.0920, Test: 0.1180
Epoch: 31, Loss: 2.0076, Train: 0.1786, Val: 0.0920, Test: 0.1160
Epoch: 32, Loss: 1.9580, Train: 0.1857, Val: 0.0880, Test: 0.1160
Epoch: 33, Loss: 1.8573, Train: 0.1786, Val: 0.0900, Test: 0.1110
Epoch: 34, Loss: 1.9421, Train: 0.1714, Val: 0.0900, Test: 0.1110
Epoch: 35, Loss: 2.0931, Train: 0.1571, Val: 0.0880, Test: 0.1070
Epoch: 36, Loss: 1.9131, Train: 0.1571, Val: 0.0860, Test: 0.1050
Epoch: 37, Loss: 1.9994, Train: 0.1500, Val: 0.0880, Test: 0.1040
Epoch: 38, Loss: 1.9275, Train: 0.1500, Val: 0.0880, Test: 0.1050
Epoch: 39, Loss: 2.0299, Train: 0.1500, Val: 0.0900, Test: 0.1040
Epoch: 40, Loss: 1.9855, Train: 0.1500, Val: 0.0880, Test: 0.1040
Epoch: 41, Loss: 1.9547, Train: 0.1429, Val: 0.0900, Test: 0.1060
Epoch: 42, Loss: 1.9029, Train: 0.1500, Val: 0.0920, Test: 0.1080
Epoch: 43, Loss: 1.9374, Train: 0.1500, Val: 0.0920, Test: 0.1070
Epoch: 44, Loss: 1.8871, Train: 0.1429, Val: 0.0960, Test: 0.1080
Epoch: 45, Loss: 1.9659, Train: 0.1571, Val: 0.0960, Test: 0.1080
Epoch: 46, Loss: 1.9341, Train: 0.1714, Val: 0.0940, Test: 0.1070
Epoch: 47, Loss: 1.9151, Train: 0.1786, Val: 0.0920, Test: 0.1080
Epoch: 48, Loss: 1.8920, Train: 0.1929, Val: 0.0900, Test: 0.1110
Epoch: 49, Loss: 1.9181, Train: 0.2143, Val: 0.0940, Test: 0.1140
Epoch: 50, Loss: 1.9362, Train: 0.2214, Val: 0.0960, Test: 0.1140
Epoch: 51, Loss: 1.9053, Train: 0.2214, Val: 0.1000, Test: 0.1160
Epoch: 52, Loss: 1.8545, Train: 0.2214, Val: 0.1000, Test: 0.1180
Epoch: 53, Loss: 1.9005, Train: 0.2286, Val: 0.1000, Test: 0.1170
Epoch: 54, Loss: 1.9665, Train: 0.2286, Val: 0.1000, Test: 0.1170
Epoch: 55, Loss: 2.0621, Train: 0.2286, Val: 0.1000, Test: 0.1170
Epoch: 56, Loss: 1.9016, Train: 0.2214, Val: 0.1000, Test: 0.1180
Epoch: 57, Loss: 1.8983, Train: 0.2286, Val: 0.1000, Test: 0.1170
Epoch: 58, Loss: 1.9330, Train: 0.2286, Val: 0.0980, Test: 0.1170
Epoch: 59, Loss: 1.8765, Train: 0.2214, Val: 0.1000, Test: 0.1170
Epoch: 60, Loss: 1.8755, Train: 0.2143, Val: 0.1020, Test: 0.1180
Epoch: 61, Loss: 1.8774, Train: 0.2000, Val: 0.1040, Test: 0.1230
Epoch: 62, Loss: 1.9439, Train: 0.2143, Val: 0.1060, Test: 0.1230
Epoch: 63, Loss: 1.8853, Train: 0.1929, Val: 0.1040, Test: 0.1240
Epoch: 64, Loss: 1.8828, Train: 0.2000, Val: 0.1060, Test: 0.1300
Epoch: 65, Loss: 2.2510, Train: 0.1929, Val: 0.1080, Test: 0.1290
Epoch: 66, Loss: 1.9829, Train: 0.1929, Val: 0.1060, Test: 0.1320
Epoch: 67, Loss: 1.8480, Train: 0.2000, Val: 0.1100, Test: 0.1360
Epoch: 68, Loss: 1.8925, Train: 0.2071, Val: 0.1140, Test: 0.1310
Epoch: 69, Loss: 1.8397, Train: 0.2143, Val: 0.1140, Test: 0.1380
Epoch: 70, Loss: 1.8982, Train: 0.2214, Val: 0.1140, Test: 0.1430
Epoch: 71, Loss: 1.8236, Train: 0.2357, Val: 0.1160, Test: 0.1460
Epoch: 72, Loss: 1.8358, Train: 0.2071, Val: 0.1220, Test: 0.1430
Epoch: 73, Loss: 1.8097, Train: 0.2000, Val: 0.1280, Test: 0.1470
Epoch: 74, Loss: 1.7835, Train: 0.2000, Val: 0.1280, Test: 0.1500
Epoch: 75, Loss: 1.8207, Train: 0.2143, Val: 0.1280, Test: 0.1460
Epoch: 76, Loss: 1.7691, Train: 0.2214, Val: 0.1320, Test: 0.1440
Epoch: 77, Loss: 1.7596, Train: 0.2214, Val: 0.1300, Test: 0.1400
Epoch: 78, Loss: 1.8398, Train: 0.2286, Val: 0.1240, Test: 0.1400
Epoch: 79, Loss: 1.8529, Train: 0.2357, Val: 0.1260, Test: 0.1410
Epoch: 80, Loss: 1.8034, Train: 0.2357, Val: 0.1280, Test: 0.1420
Epoch: 81, Loss: 1.7612, Train: 0.2500, Val: 0.1280, Test: 0.1400
Epoch: 82, Loss: 1.7671, Train: 0.2500, Val: 0.1260, Test: 0.1410
Epoch: 83, Loss: 1.7992, Train: 0.2429, Val: 0.1260, Test: 0.1410
Epoch: 84, Loss: 1.7492, Train: 0.2429, Val: 0.1280, Test: 0.1400
Epoch: 85, Loss: 1.7252, Train: 0.2429, Val: 0.1260, Test: 0.1400
Epoch: 86, Loss: 1.8321, Train: 0.2429, Val: 0.1260, Test: 0.1410
Epoch: 87, Loss: 1.7385, Train: 0.2571, Val: 0.1320, Test: 0.1420
Epoch: 88, Loss: 1.7434, Train: 0.2571, Val: 0.1320, Test: 0.1420
Epoch: 89, Loss: 1.7320, Train: 0.2571, Val: 0.1320, Test: 0.1450
Epoch: 90, Loss: 1.7151, Train: 0.2571, Val: 0.1320, Test: 0.1450
Epoch: 91, Loss: 1.7674, Train: 0.2571, Val: 0.1340, Test: 0.1450
Epoch: 92, Loss: 1.7421, Train: 0.2571, Val: 0.1380, Test: 0.1450
Epoch: 93, Loss: 1.7199, Train: 0.2571, Val: 0.1380, Test: 0.1450
Epoch: 94, Loss: 1.6984, Train: 0.2571, Val: 0.1360, Test: 0.1450
Epoch: 95, Loss: 1.7025, Train: 0.2714, Val: 0.1360, Test: 0.1470
Epoch: 96, Loss: 1.7462, Train: 0.2714, Val: 0.1360, Test: 0.1490
Epoch: 97, Loss: 1.7174, Train: 0.2714, Val: 0.1360, Test: 0.1490
Epoch: 98, Loss: 1.7360, Train: 0.2714, Val: 0.1360, Test: 0.1490
Epoch: 99, Loss: 1.7040, Train: 0.2714, Val: 0.1360, Test: 0.1490
Epoch: 100, Loss: 1.7974, Train: 0.2714, Val: 0.1360, Test: 0.1500
Epoch: 101, Loss: 1.6964, Train: 0.2714, Val: 0.1360, Test: 0.1510
Epoch: 102, Loss: 1.6856, Train: 0.2714, Val: 0.1360, Test: 0.1510
Epoch: 103, Loss: 1.7341, Train: 0.2714, Val: 0.1380, Test: 0.1510
Epoch: 104, Loss: 1.6660, Train: 0.2714, Val: 0.1360, Test: 0.1520
Epoch: 105, Loss: 1.6950, Train: 0.2714, Val: 0.1380, Test: 0.1520
Epoch: 106, Loss: 1.7180, Train: 0.2714, Val: 0.1380, Test: 0.1520
Epoch: 107, Loss: 1.7207, Train: 0.2714, Val: 0.1420, Test: 0.1530
Epoch: 108, Loss: 1.6719, Train: 0.2714, Val: 0.1420, Test: 0.1550
Epoch: 109, Loss: 1.6740, Train: 0.2714, Val: 0.1420, Test: 0.1560
Epoch: 110, Loss: 1.6678, Train: 0.2714, Val: 0.1440, Test: 0.1570
Epoch: 111, Loss: 1.6889, Train: 0.2714, Val: 0.1440, Test: 0.1580
Epoch: 112, Loss: 1.6441, Train: 0.2714, Val: 0.1460, Test: 0.1590
Epoch: 113, Loss: 1.6512, Train: 0.2714, Val: 0.1480, Test: 0.1580
Epoch: 114, Loss: 1.6814, Train: 0.2714, Val: 0.1480, Test: 0.1590
Epoch: 115, Loss: 1.6504, Train: 0.2786, Val: 0.1480, Test: 0.1590
Epoch: 116, Loss: 1.6408, Train: 0.2786, Val: 0.1480, Test: 0.1600
Epoch: 117, Loss: 1.6103, Train: 0.2786, Val: 0.1500, Test: 0.1600
Epoch: 118, Loss: 1.6913, Train: 0.2786, Val: 0.1500, Test: 0.1600
Epoch: 119, Loss: 1.6229, Train: 0.2786, Val: 0.1500, Test: 0.1600
Epoch: 120, Loss: 1.6562, Train: 0.2786, Val: 0.1500, Test: 0.1610
Epoch: 121, Loss: 1.6482, Train: 0.2786, Val: 0.1500, Test: 0.1620
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 122, Loss: 1.6433, Train: 0.2786, Val: 0.1500, Test: 0.1640
Epoch: 123, Loss: 1.6297, Train: 0.2786, Val: 0.1500, Test: 0.1640
Epoch: 124, Loss: 1.6527, Train: 0.2786, Val: 0.1520, Test: 0.1640
Epoch: 125, Loss: 1.6183, Train: 0.2786, Val: 0.1520, Test: 0.1640
Epoch: 126, Loss: 1.6273, Train: 0.2786, Val: 0.1520, Test: 0.1650
Epoch: 127, Loss: 1.6287, Train: 0.2786, Val: 0.1520, Test: 0.1650
Epoch: 128, Loss: 1.6833, Train: 0.2786, Val: 0.1560, Test: 0.1660
Epoch: 129, Loss: 1.6792, Train: 0.2786, Val: 0.1560, Test: 0.1660
Epoch: 130, Loss: 1.6204, Train: 0.2786, Val: 0.1560, Test: 0.1660
Epoch: 131, Loss: 1.6338, Train: 0.2786, Val: 0.1580, Test: 0.1660
Epoch: 132, Loss: 1.6188, Train: 0.2786, Val: 0.1580, Test: 0.1660
Epoch: 133, Loss: 1.6409, Train: 0.2786, Val: 0.1560, Test: 0.1660
Epoch: 134, Loss: 1.6521, Train: 0.2786, Val: 0.1560, Test: 0.1660
Epoch: 135, Loss: 1.6131, Train: 0.2786, Val: 0.1560, Test: 0.1650
Epoch: 136, Loss: 1.5719, Train: 0.2786, Val: 0.1580, Test: 0.1650
Epoch: 137, Loss: 1.6360, Train: 0.2786, Val: 0.1580, Test: 0.1650
Epoch: 138, Loss: 1.6011, Train: 0.2786, Val: 0.1600, Test: 0.1630
Epoch: 139, Loss: 1.6523, Train: 0.2786, Val: 0.1600, Test: 0.1620
Epoch: 140, Loss: 1.5931, Train: 0.2786, Val: 0.1620, Test: 0.1620
Epoch: 141, Loss: 1.6303, Train: 0.2786, Val: 0.1620, Test: 0.1620
Epoch: 142, Loss: 1.6093, Train: 0.2786, Val: 0.1620, Test: 0.1620
Epoch: 143, Loss: 1.5935, Train: 0.2786, Val: 0.1640, Test: 0.1630
Epoch: 144, Loss: 1.6034, Train: 0.2786, Val: 0.1680, Test: 0.1650
Epoch: 145, Loss: 1.6387, Train: 0.2786, Val: 0.1700, Test: 0.1680
Epoch: 146, Loss: 1.5740, Train: 0.2786, Val: 0.1700, Test: 0.1680
Epoch: 147, Loss: 1.6131, Train: 0.2786, Val: 0.1660, Test: 0.1680
Epoch: 148, Loss: 1.7718, Train: 0.2786, Val: 0.1640, Test: 0.1670
Epoch: 149, Loss: 1.5810, Train: 0.2857, Val: 0.1720, Test: 0.1730
Epoch: 150, Loss: 1.5655, Train: 0.2857, Val: 0.1740, Test: 0.1800
Epoch: 151, Loss: 1.6127, Train: 0.2929, Val: 0.1880, Test: 0.1900
Epoch: 152, Loss: 1.6129, Train: 0.2929, Val: 0.1900, Test: 0.2020
Epoch: 153, Loss: 1.5289, Train: 0.3143, Val: 0.2100, Test: 0.2060
Epoch: 154, Loss: 1.5903, Train: 0.3429, Val: 0.2320, Test: 0.2200
Epoch: 155, Loss: 1.6320, Train: 0.3571, Val: 0.2360, Test: 0.2350
Epoch: 156, Loss: 1.5443, Train: 0.3571, Val: 0.2320, Test: 0.2370
Epoch: 157, Loss: 1.5431, Train: 0.3714, Val: 0.2300, Test: 0.2350
Epoch: 158, Loss: 1.5360, Train: 0.3643, Val: 0.2220, Test: 0.2370
Epoch: 159, Loss: 1.5418, Train: 0.3643, Val: 0.2220, Test: 0.2340
Epoch: 160, Loss: 1.5580, Train: 0.3643, Val: 0.2240, Test: 0.2420
Epoch: 161, Loss: 1.5691, Train: 0.3786, Val: 0.2260, Test: 0.2480
Epoch: 162, Loss: 1.4915, Train: 0.3714, Val: 0.2300, Test: 0.2510
Epoch: 163, Loss: 1.5489, Train: 0.3857, Val: 0.2340, Test: 0.2550
Epoch: 164, Loss: 1.5319, Train: 0.3929, Val: 0.2440, Test: 0.2670
Epoch: 165, Loss: 1.5333, Train: 0.3929, Val: 0.2520, Test: 0.2750
Epoch: 166, Loss: 1.5208, Train: 0.4071, Val: 0.2720, Test: 0.2850
Epoch: 167, Loss: 1.5405, Train: 0.4000, Val: 0.2740, Test: 0.2920
Epoch: 168, Loss: 1.5461, Train: 0.4071, Val: 0.2760, Test: 0.2900
Epoch: 169, Loss: 1.5527, Train: 0.4000, Val: 0.2780, Test: 0.2930
Epoch: 170, Loss: 1.5773, Train: 0.4071, Val: 0.2760, Test: 0.2910
Epoch: 171, Loss: 1.5319, Train: 0.4286, Val: 0.2660, Test: 0.2840
Epoch: 172, Loss: 1.5042, Train: 0.4357, Val: 0.2600, Test: 0.2820
Epoch: 173, Loss: 1.4974, Train: 0.4357, Val: 0.2620, Test: 0.2850
Epoch: 174, Loss: 1.4794, Train: 0.4286, Val: 0.2520, Test: 0.2800
Epoch: 175, Loss: 1.5070, Train: 0.4286, Val: 0.2520, Test: 0.2810
Epoch: 176, Loss: 1.4401, Train: 0.4357, Val: 0.2460, Test: 0.2770
Epoch: 177, Loss: 1.5128, Train: 0.4357, Val: 0.2300, Test: 0.2610
Epoch: 178, Loss: 1.4974, Train: 0.4071, Val: 0.2240, Test: 0.2500
Epoch: 179, Loss: 1.4788, Train: 0.3929, Val: 0.2100, Test: 0.2370
Epoch: 180, Loss: 1.4508, Train: 0.3929, Val: 0.2040, Test: 0.2390
Epoch: 181, Loss: 1.4702, Train: 0.3929, Val: 0.2000, Test: 0.2370
Epoch: 182, Loss: 1.4725, Train: 0.3929, Val: 0.1960, Test: 0.2410
Epoch: 183, Loss: 1.5285, Train: 0.4143, Val: 0.1980, Test: 0.2480
Epoch: 184, Loss: 1.4837, Train: 0.4214, Val: 0.2160, Test: 0.2520
Epoch: 185, Loss: 1.4752, Train: 0.4357, Val: 0.2320, Test: 0.2640
Epoch: 186, Loss: 1.3902, Train: 0.4429, Val: 0.2520, Test: 0.2810
Epoch: 187, Loss: 1.5537, Train: 0.4571, Val: 0.2640, Test: 0.2920
Epoch: 188, Loss: 1.4284, Train: 0.4643, Val: 0.2680, Test: 0.3030
Epoch: 189, Loss: 1.5853, Train: 0.4786, Val: 0.2640, Test: 0.3270
Epoch: 190, Loss: 1.4459, Train: 0.4857, Val: 0.2740, Test: 0.3370
Epoch: 191, Loss: 1.3857, Train: 0.4857, Val: 0.2740, Test: 0.3390
Epoch: 192, Loss: 1.3476, Train: 0.4929, Val: 0.2880, Test: 0.3440
Epoch: 193, Loss: 1.4289, Train: 0.4857, Val: 0.2860, Test: 0.3330
Epoch: 194, Loss: 1.4262, Train: 0.4786, Val: 0.2700, Test: 0.3260
Epoch: 195, Loss: 1.4230, Train: 0.4643, Val: 0.2540, Test: 0.3110
Epoch: 196, Loss: 1.3454, Train: 0.4357, Val: 0.2420, Test: 0.3050
Epoch: 197, Loss: 1.4193, Train: 0.4286, Val: 0.2360, Test: 0.2890
Epoch: 198, Loss: 1.4240, Train: 0.4286, Val: 0.2340, Test: 0.2840
Epoch: 199, Loss: 1.3550, Train: 0.4214, Val: 0.2340, Test: 0.2810
Epoch: 200, Loss: 1.4039, Train: 0.4214, Val: 0.2320, Test: 0.2770
MAD:  0.4463
Best Test Accuracy: 0.3440, Val Accuracy: 0.2880, Train Accuracy: 0.4929
Training completed.
Seed:  4
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 7.7770, Train: 0.1643, Val: 0.1420, Test: 0.1680
Epoch: 2, Loss: 4.7487, Train: 0.1500, Val: 0.1620, Test: 0.1610
Epoch: 3, Loss: 4.4497, Train: 0.1643, Val: 0.1780, Test: 0.1580
Epoch: 4, Loss: 3.6347, Train: 0.1786, Val: 0.1860, Test: 0.1780
Epoch: 5, Loss: 3.4605, Train: 0.2143, Val: 0.2060, Test: 0.1860
Epoch: 6, Loss: 3.1286, Train: 0.2000, Val: 0.1980, Test: 0.1880
Epoch: 7, Loss: 2.4649, Train: 0.1643, Val: 0.1520, Test: 0.1150
Epoch: 8, Loss: 3.0385, Train: 0.1643, Val: 0.1520, Test: 0.1180
Epoch: 9, Loss: 2.3761, Train: 0.1857, Val: 0.1420, Test: 0.1090
Epoch: 10, Loss: 2.4163, Train: 0.1857, Val: 0.1220, Test: 0.1050
Epoch: 11, Loss: 2.3513, Train: 0.1929, Val: 0.1140, Test: 0.1030
Epoch: 12, Loss: 2.6826, Train: 0.1929, Val: 0.1120, Test: 0.1020
Epoch: 13, Loss: 2.2067, Train: 0.2000, Val: 0.1140, Test: 0.1010
Epoch: 14, Loss: 2.3017, Train: 0.1929, Val: 0.1120, Test: 0.0990
Epoch: 15, Loss: 2.2678, Train: 0.1857, Val: 0.1120, Test: 0.1000
Epoch: 16, Loss: 2.1271, Train: 0.1857, Val: 0.1140, Test: 0.1030
Epoch: 17, Loss: 1.9608, Train: 0.1857, Val: 0.1180, Test: 0.0990
Epoch: 18, Loss: 2.1257, Train: 0.1857, Val: 0.1280, Test: 0.1120
Epoch: 19, Loss: 2.1859, Train: 0.2214, Val: 0.1220, Test: 0.1110
Epoch: 20, Loss: 2.3131, Train: 0.2286, Val: 0.1300, Test: 0.1200
Epoch: 21, Loss: 2.0908, Train: 0.2357, Val: 0.1540, Test: 0.1260
Epoch: 22, Loss: 2.1745, Train: 0.2357, Val: 0.1580, Test: 0.1330
Epoch: 23, Loss: 1.9713, Train: 0.2214, Val: 0.1680, Test: 0.1530
Epoch: 24, Loss: 1.9249, Train: 0.2000, Val: 0.1560, Test: 0.1490
Epoch: 25, Loss: 1.9553, Train: 0.2143, Val: 0.1560, Test: 0.1390
Epoch: 26, Loss: 2.0991, Train: 0.2071, Val: 0.1400, Test: 0.1290
Epoch: 27, Loss: 1.9960, Train: 0.2000, Val: 0.1300, Test: 0.1220
Epoch: 28, Loss: 2.0213, Train: 0.1929, Val: 0.1200, Test: 0.1220
Epoch: 29, Loss: 1.9732, Train: 0.1857, Val: 0.1120, Test: 0.1160
Epoch: 30, Loss: 1.9704, Train: 0.1857, Val: 0.1060, Test: 0.1110
Epoch: 31, Loss: 2.0019, Train: 0.1786, Val: 0.1000, Test: 0.1090
Epoch: 32, Loss: 1.8599, Train: 0.1714, Val: 0.0980, Test: 0.1070
Epoch: 33, Loss: 1.9549, Train: 0.1643, Val: 0.0860, Test: 0.1050
Epoch: 34, Loss: 2.0452, Train: 0.1643, Val: 0.0800, Test: 0.1010
Epoch: 35, Loss: 2.1365, Train: 0.1643, Val: 0.0780, Test: 0.1020
Epoch: 36, Loss: 2.0342, Train: 0.1643, Val: 0.0780, Test: 0.1010
Epoch: 37, Loss: 1.9845, Train: 0.1643, Val: 0.0760, Test: 0.1010
Epoch: 38, Loss: 1.9692, Train: 0.1643, Val: 0.0780, Test: 0.0990
Epoch: 39, Loss: 1.9486, Train: 0.1643, Val: 0.0780, Test: 0.0980
Epoch: 40, Loss: 2.0474, Train: 0.1714, Val: 0.0780, Test: 0.0950
Epoch: 41, Loss: 1.9717, Train: 0.1714, Val: 0.0780, Test: 0.0950
Epoch: 42, Loss: 2.0024, Train: 0.1714, Val: 0.0780, Test: 0.0950
Epoch: 43, Loss: 2.1337, Train: 0.1714, Val: 0.0760, Test: 0.0980
Epoch: 44, Loss: 2.0148, Train: 0.1714, Val: 0.0760, Test: 0.0980
Epoch: 45, Loss: 1.9397, Train: 0.1714, Val: 0.0760, Test: 0.0980
Epoch: 46, Loss: 1.9553, Train: 0.1714, Val: 0.0760, Test: 0.0980
Epoch: 47, Loss: 1.8987, Train: 0.1857, Val: 0.0740, Test: 0.0990
Epoch: 48, Loss: 2.6530, Train: 0.1857, Val: 0.0740, Test: 0.1000
Epoch: 49, Loss: 2.2122, Train: 0.1857, Val: 0.0740, Test: 0.1000
Epoch: 50, Loss: 1.9657, Train: 0.1857, Val: 0.0740, Test: 0.0990
Epoch: 51, Loss: 1.8882, Train: 0.1857, Val: 0.0720, Test: 0.0990
Epoch: 52, Loss: 1.9301, Train: 0.1857, Val: 0.0720, Test: 0.0990
Epoch: 53, Loss: 1.9700, Train: 0.1857, Val: 0.0720, Test: 0.0990
Epoch: 54, Loss: 2.0879, Train: 0.1857, Val: 0.0740, Test: 0.0990
Epoch: 55, Loss: 1.8896, Train: 0.1929, Val: 0.0760, Test: 0.0990
Epoch: 56, Loss: 2.1020, Train: 0.1857, Val: 0.0760, Test: 0.1000
Epoch: 57, Loss: 1.8743, Train: 0.1857, Val: 0.0780, Test: 0.0990
Epoch: 58, Loss: 1.9545, Train: 0.1929, Val: 0.0760, Test: 0.1010
Epoch: 59, Loss: 1.9331, Train: 0.1929, Val: 0.0760, Test: 0.1020
Epoch: 60, Loss: 1.8399, Train: 0.1929, Val: 0.0760, Test: 0.1030
Epoch: 61, Loss: 1.9806, Train: 0.2000, Val: 0.0760, Test: 0.1060
Epoch: 62, Loss: 1.9304, Train: 0.2000, Val: 0.0800, Test: 0.1060
Epoch: 63, Loss: 1.8169, Train: 0.2000, Val: 0.0840, Test: 0.1060
Epoch: 64, Loss: 1.9225, Train: 0.2071, Val: 0.0840, Test: 0.1060
Epoch: 65, Loss: 1.8815, Train: 0.2143, Val: 0.0840, Test: 0.1070
Epoch: 66, Loss: 1.8311, Train: 0.2214, Val: 0.0840, Test: 0.1070
Epoch: 67, Loss: 1.8717, Train: 0.2286, Val: 0.0840, Test: 0.1070
Epoch: 68, Loss: 1.8098, Train: 0.2286, Val: 0.0840, Test: 0.1070
Epoch: 69, Loss: 1.8354, Train: 0.2286, Val: 0.0840, Test: 0.1070
Epoch: 70, Loss: 1.8612, Train: 0.2286, Val: 0.0860, Test: 0.1070
Epoch: 71, Loss: 1.7924, Train: 0.2286, Val: 0.0860, Test: 0.1070
Epoch: 72, Loss: 1.8542, Train: 0.2286, Val: 0.0860, Test: 0.1060
Epoch: 73, Loss: 1.8531, Train: 0.2286, Val: 0.0880, Test: 0.1060
Epoch: 74, Loss: 1.8731, Train: 0.2357, Val: 0.0880, Test: 0.1060
Epoch: 75, Loss: 1.8183, Train: 0.2357, Val: 0.0880, Test: 0.1060
Epoch: 76, Loss: 1.8201, Train: 0.2357, Val: 0.0900, Test: 0.1060
Epoch: 77, Loss: 1.8201, Train: 0.2357, Val: 0.0900, Test: 0.1060
Epoch: 78, Loss: 1.8676, Train: 0.2357, Val: 0.0900, Test: 0.1060
Epoch: 79, Loss: 1.8453, Train: 0.2500, Val: 0.0900, Test: 0.1060
Epoch: 80, Loss: 1.8675, Train: 0.2500, Val: 0.0920, Test: 0.1060
Epoch: 81, Loss: 2.0302, Train: 0.2500, Val: 0.0900, Test: 0.1070
Epoch: 82, Loss: 1.7584, Train: 0.2571, Val: 0.0960, Test: 0.1100
Epoch: 83, Loss: 1.8096, Train: 0.2571, Val: 0.0960, Test: 0.1110
Epoch: 84, Loss: 1.8176, Train: 0.2571, Val: 0.0960, Test: 0.1120
Epoch: 85, Loss: 1.7406, Train: 0.2643, Val: 0.0940, Test: 0.1160
Epoch: 86, Loss: 1.8025, Train: 0.2643, Val: 0.0960, Test: 0.1170
Epoch: 87, Loss: 1.7417, Train: 0.2643, Val: 0.0960, Test: 0.1170
Epoch: 88, Loss: 1.8148, Train: 0.2571, Val: 0.1000, Test: 0.1170
Epoch: 89, Loss: 1.7932, Train: 0.2571, Val: 0.1000, Test: 0.1160
Epoch: 90, Loss: 1.8845, Train: 0.2571, Val: 0.1020, Test: 0.1200
Epoch: 91, Loss: 1.7863, Train: 0.2571, Val: 0.1060, Test: 0.1250
Epoch: 92, Loss: 1.7999, Train: 0.2714, Val: 0.1060, Test: 0.1270
Epoch: 93, Loss: 1.8266, Train: 0.2786, Val: 0.1040, Test: 0.1320
Epoch: 94, Loss: 1.7583, Train: 0.2786, Val: 0.1080, Test: 0.1330
Epoch: 95, Loss: 1.7004, Train: 0.2857, Val: 0.1100, Test: 0.1360
Epoch: 96, Loss: 1.6773, Train: 0.2929, Val: 0.1140, Test: 0.1360
Epoch: 97, Loss: 1.7101, Train: 0.2929, Val: 0.1120, Test: 0.1380
Epoch: 98, Loss: 1.6782, Train: 0.2929, Val: 0.1140, Test: 0.1410
Epoch: 99, Loss: 1.6638, Train: 0.2929, Val: 0.1180, Test: 0.1420
Epoch: 100, Loss: 1.7202, Train: 0.3000, Val: 0.1160, Test: 0.1410
Epoch: 101, Loss: 1.6530, Train: 0.3000, Val: 0.1160, Test: 0.1420
Epoch: 102, Loss: 1.6505, Train: 0.3000, Val: 0.1160, Test: 0.1440
Epoch: 103, Loss: 1.6833, Train: 0.3000, Val: 0.1140, Test: 0.1430
Epoch: 104, Loss: 1.6605, Train: 0.3000, Val: 0.1140, Test: 0.1430
Epoch: 105, Loss: 1.7256, Train: 0.3000, Val: 0.1140, Test: 0.1420
Epoch: 106, Loss: 1.6727, Train: 0.2929, Val: 0.1080, Test: 0.1410
Epoch: 107, Loss: 1.7073, Train: 0.2929, Val: 0.1080, Test: 0.1420
Epoch: 108, Loss: 1.6165, Train: 0.2929, Val: 0.1080, Test: 0.1420
Epoch: 109, Loss: 1.6565, Train: 0.2929, Val: 0.1100, Test: 0.1430
Epoch: 110, Loss: 1.7555, Train: 0.3000, Val: 0.1100, Test: 0.1420
Epoch: 111, Loss: 1.6467, Train: 0.3000, Val: 0.1080, Test: 0.1440
Epoch: 112, Loss: 1.6815, Train: 0.3000, Val: 0.1100, Test: 0.1450
Epoch: 113, Loss: 1.5678, Train: 0.3000, Val: 0.1080, Test: 0.1470
Epoch: 114, Loss: 1.7707, Train: 0.3071, Val: 0.1100, Test: 0.1480
Epoch: 115, Loss: 1.6442, Train: 0.3071, Val: 0.1140, Test: 0.1490
Epoch: 116, Loss: 1.5899, Train: 0.3000, Val: 0.1160, Test: 0.1520
Epoch: 117, Loss: 1.6088, Train: 0.3000, Val: 0.1240, Test: 0.1520
Epoch: 118, Loss: 1.5901, Train: 0.3000, Val: 0.1280, Test: 0.1530
Epoch: 119, Loss: 1.7049, Train: 0.3000, Val: 0.1260, Test: 0.1540
Epoch: 120, Loss: 1.5969, Train: 0.3000, Val: 0.1280, Test: 0.1560
Epoch: 121, Loss: 1.6121, Train: 0.3000, Val: 0.1280, Test: 0.1550
Epoch: 122, Loss: 1.6148, Train: 0.3000, Val: 0.1280, Test: 0.1540
Epoch: 123, Loss: 1.6661, Train: 0.3000, Val: 0.1260, Test: 0.1540
Epoch: 124, Loss: 1.6266, Train: 0.3000, Val: 0.1220, Test: 0.1550
Epoch: 125, Loss: 1.5529, Train: 0.3000, Val: 0.1200, Test: 0.1550
Epoch: 126, Loss: 1.5598, Train: 0.2929, Val: 0.1220, Test: 0.1530
Epoch: 127, Loss: 1.6185, Train: 0.2929, Val: 0.1200, Test: 0.1510
Epoch: 128, Loss: 1.5514, Train: 0.2929, Val: 0.1200, Test: 0.1520
Epoch: 129, Loss: 1.6413, Train: 0.2929, Val: 0.1180, Test: 0.1530
Epoch: 130, Loss: 1.5826, Train: 0.2929, Val: 0.1200, Test: 0.1540
Epoch: 131, Loss: 1.5308, Train: 0.3000, Val: 0.1200, Test: 0.1540
Epoch: 132, Loss: 1.5560, Train: 0.3000, Val: 0.1220, Test: 0.1550
Epoch: 133, Loss: 1.5385, Train: 0.3000, Val: 0.1340, Test: 0.1540
Epoch: 134, Loss: 1.5268, Train: 0.3000, Val: 0.1380, Test: 0.1550
Epoch: 135, Loss: 1.5613, Train: 0.3000, Val: 0.1400, Test: 0.1540
Epoch: 136, Loss: 1.5318, Train: 0.3000, Val: 0.1400, Test: 0.1570
Epoch: 137, Loss: 1.6337, Train: 0.3000, Val: 0.1380, Test: 0.1600
Epoch: 138, Loss: 1.7215, Train: 0.3071, Val: 0.1420, Test: 0.1620
Epoch: 139, Loss: 1.5337, Train: 0.3071, Val: 0.1420, Test: 0.1620
Epoch: 140, Loss: 1.5688, Train: 0.3143, Val: 0.1480, Test: 0.1630
Epoch: 141, Loss: 1.5195, Train: 0.3143, Val: 0.1520, Test: 0.1670
Epoch: 142, Loss: 1.5439, Train: 0.2929, Val: 0.1500, Test: 0.1730
Epoch: 143, Loss: 1.5282, Train: 0.2857, Val: 0.1520, Test: 0.1710
Epoch: 144, Loss: 1.7223, Train: 0.3000, Val: 0.1560, Test: 0.1710
Epoch: 145, Loss: 1.4978, Train: 0.3000, Val: 0.1620, Test: 0.1720
Epoch: 146, Loss: 1.4529, Train: 0.3000, Val: 0.1640, Test: 0.1720
Epoch: 147, Loss: 1.5213, Train: 0.2857, Val: 0.1580, Test: 0.1740
Epoch: 148, Loss: 1.4744, Train: 0.2857, Val: 0.1600, Test: 0.1740
Epoch: 149, Loss: 1.4366, Train: 0.2857, Val: 0.1600, Test: 0.1700
Epoch: 150, Loss: 1.4669, Train: 0.2857, Val: 0.1680, Test: 0.1730
Epoch: 151, Loss: 1.4171, Train: 0.2929, Val: 0.1680, Test: 0.1780
Epoch: 152, Loss: 1.5255, Train: 0.2929, Val: 0.1680, Test: 0.1840
Epoch: 153, Loss: 1.4355, Train: 0.3071, Val: 0.1740, Test: 0.1880
Epoch: 154, Loss: 1.4260, Train: 0.3000, Val: 0.1800, Test: 0.1940
Epoch: 155, Loss: 1.4406, Train: 0.3000, Val: 0.1880, Test: 0.1980
Epoch: 156, Loss: 1.3823, Train: 0.2929, Val: 0.1900, Test: 0.2030
Epoch: 157, Loss: 1.4023, Train: 0.3143, Val: 0.2020, Test: 0.2070
Epoch: 158, Loss: 1.5176, Train: 0.3286, Val: 0.2000, Test: 0.2110
Epoch: 159, Loss: 1.4074, Train: 0.3286, Val: 0.2060, Test: 0.2160
Epoch: 160, Loss: 1.5302, Train: 0.3357, Val: 0.2020, Test: 0.2160
Epoch: 161, Loss: 1.3871, Train: 0.3571, Val: 0.2040, Test: 0.2110
Epoch: 162, Loss: 1.3839, Train: 0.3571, Val: 0.2000, Test: 0.2130
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 163, Loss: 1.4736, Train: 0.3571, Val: 0.1860, Test: 0.2100
Epoch: 164, Loss: 1.4104, Train: 0.3571, Val: 0.1860, Test: 0.2110
Epoch: 165, Loss: 1.4254, Train: 0.3643, Val: 0.1860, Test: 0.2160
Epoch: 166, Loss: 1.3238, Train: 0.3500, Val: 0.1860, Test: 0.2150
Epoch: 167, Loss: 1.3755, Train: 0.3357, Val: 0.1820, Test: 0.2120
Epoch: 168, Loss: 1.3580, Train: 0.3143, Val: 0.1800, Test: 0.2060
Epoch: 169, Loss: 1.3189, Train: 0.3071, Val: 0.1800, Test: 0.2000
Epoch: 170, Loss: 1.3912, Train: 0.3071, Val: 0.1760, Test: 0.1930
Epoch: 171, Loss: 1.4127, Train: 0.3071, Val: 0.1720, Test: 0.1870
Epoch: 172, Loss: 1.3159, Train: 0.3071, Val: 0.1760, Test: 0.1890
Epoch: 173, Loss: 1.3338, Train: 0.3071, Val: 0.1820, Test: 0.1960
Epoch: 174, Loss: 1.3091, Train: 0.3214, Val: 0.1900, Test: 0.2170
Epoch: 175, Loss: 1.2570, Train: 0.3500, Val: 0.2200, Test: 0.2390
Epoch: 176, Loss: 1.3420, Train: 0.3429, Val: 0.2240, Test: 0.2430
Epoch: 177, Loss: 1.3022, Train: 0.3500, Val: 0.2240, Test: 0.2500
Epoch: 178, Loss: 1.4226, Train: 0.3286, Val: 0.2120, Test: 0.2340
Epoch: 179, Loss: 1.3031, Train: 0.2929, Val: 0.2120, Test: 0.2220
Epoch: 180, Loss: 1.2603, Train: 0.3000, Val: 0.2100, Test: 0.2200
Epoch: 181, Loss: 1.3136, Train: 0.2929, Val: 0.2100, Test: 0.2170
Epoch: 182, Loss: 1.3035, Train: 0.3000, Val: 0.2100, Test: 0.2280
Epoch: 183, Loss: 1.2805, Train: 0.3214, Val: 0.2080, Test: 0.2220
Epoch: 184, Loss: 1.1924, Train: 0.3357, Val: 0.2060, Test: 0.2280
Epoch: 185, Loss: 1.3306, Train: 0.3357, Val: 0.2160, Test: 0.2370
Epoch: 186, Loss: 1.3128, Train: 0.3429, Val: 0.2420, Test: 0.2580
Epoch: 187, Loss: 1.1896, Train: 0.3643, Val: 0.2500, Test: 0.2640
Epoch: 188, Loss: 1.2457, Train: 0.3714, Val: 0.2480, Test: 0.2610
Epoch: 189, Loss: 1.1991, Train: 0.3714, Val: 0.2340, Test: 0.2510
Epoch: 190, Loss: 1.2374, Train: 0.3571, Val: 0.2140, Test: 0.2330
Epoch: 191, Loss: 1.1973, Train: 0.3429, Val: 0.2040, Test: 0.2120
Epoch: 192, Loss: 1.0990, Train: 0.3429, Val: 0.1960, Test: 0.2100
Epoch: 193, Loss: 1.2215, Train: 0.3357, Val: 0.1860, Test: 0.2110
Epoch: 194, Loss: 1.2353, Train: 0.3357, Val: 0.1840, Test: 0.2090
Epoch: 195, Loss: 1.1826, Train: 0.3429, Val: 0.1900, Test: 0.2170
Epoch: 196, Loss: 1.1715, Train: 0.3643, Val: 0.1960, Test: 0.2350
Epoch: 197, Loss: 1.1787, Train: 0.4143, Val: 0.2280, Test: 0.2550
Epoch: 198, Loss: 1.2369, Train: 0.4286, Val: 0.2520, Test: 0.2790
Epoch: 199, Loss: 1.1402, Train: 0.4429, Val: 0.2520, Test: 0.2810
Epoch: 200, Loss: 1.2429, Train: 0.4429, Val: 0.2400, Test: 0.2710
MAD:  0.5244
Best Test Accuracy: 0.2810, Val Accuracy: 0.2520, Train Accuracy: 0.4429
Training completed.
Seed:  5
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 6.5411, Train: 0.2071, Val: 0.1500, Test: 0.1570
Epoch: 2, Loss: 5.7957, Train: 0.1929, Val: 0.1560, Test: 0.1520
Epoch: 3, Loss: 5.2839, Train: 0.2143, Val: 0.1640, Test: 0.1620
Epoch: 4, Loss: 4.5485, Train: 0.2500, Val: 0.1900, Test: 0.1890
Epoch: 5, Loss: 3.5032, Train: 0.3000, Val: 0.2100, Test: 0.2100
Epoch: 6, Loss: 3.7145, Train: 0.3000, Val: 0.2120, Test: 0.2130
Epoch: 7, Loss: 3.3121, Train: 0.3143, Val: 0.2240, Test: 0.2190
Epoch: 8, Loss: 2.7102, Train: 0.3000, Val: 0.1980, Test: 0.2110
Epoch: 9, Loss: 2.7716, Train: 0.2643, Val: 0.1920, Test: 0.1990
Epoch: 10, Loss: 2.6832, Train: 0.2571, Val: 0.1720, Test: 0.1970
Epoch: 11, Loss: 3.0051, Train: 0.2571, Val: 0.1760, Test: 0.1870
Epoch: 12, Loss: 2.2503, Train: 0.2500, Val: 0.1780, Test: 0.1830
Epoch: 13, Loss: 2.8305, Train: 0.2643, Val: 0.1740, Test: 0.1870
Epoch: 14, Loss: 2.5204, Train: 0.2429, Val: 0.1800, Test: 0.1660
Epoch: 15, Loss: 2.2900, Train: 0.2429, Val: 0.1720, Test: 0.1690
Epoch: 16, Loss: 2.2668, Train: 0.2286, Val: 0.1800, Test: 0.1630
Epoch: 17, Loss: 2.2017, Train: 0.2000, Val: 0.1780, Test: 0.1620
Epoch: 18, Loss: 2.1935, Train: 0.1786, Val: 0.1820, Test: 0.1720
Epoch: 19, Loss: 2.2373, Train: 0.2000, Val: 0.1860, Test: 0.1840
Epoch: 20, Loss: 2.2240, Train: 0.2143, Val: 0.1860, Test: 0.1890
Epoch: 21, Loss: 2.1584, Train: 0.2214, Val: 0.1880, Test: 0.2050
Epoch: 22, Loss: 2.0410, Train: 0.2214, Val: 0.2000, Test: 0.2080
Epoch: 23, Loss: 2.2358, Train: 0.2214, Val: 0.2000, Test: 0.2150
Epoch: 24, Loss: 2.3209, Train: 0.2214, Val: 0.2040, Test: 0.2160
Epoch: 25, Loss: 2.2321, Train: 0.2286, Val: 0.2040, Test: 0.2290
Epoch: 26, Loss: 2.1255, Train: 0.2429, Val: 0.2060, Test: 0.2230
Epoch: 27, Loss: 2.1110, Train: 0.2500, Val: 0.2100, Test: 0.2080
Epoch: 28, Loss: 2.0566, Train: 0.2429, Val: 0.1960, Test: 0.2060
Epoch: 29, Loss: 2.0577, Train: 0.2143, Val: 0.1840, Test: 0.1990
Epoch: 30, Loss: 2.0465, Train: 0.2071, Val: 0.1680, Test: 0.1920
Epoch: 31, Loss: 2.0029, Train: 0.1929, Val: 0.1640, Test: 0.1850
Epoch: 32, Loss: 2.2903, Train: 0.2000, Val: 0.1540, Test: 0.1800
Epoch: 33, Loss: 2.0683, Train: 0.1786, Val: 0.1420, Test: 0.1760
Epoch: 34, Loss: 1.9556, Train: 0.1786, Val: 0.1320, Test: 0.1710
Epoch: 35, Loss: 1.9460, Train: 0.1857, Val: 0.1320, Test: 0.1750
Epoch: 36, Loss: 2.1568, Train: 0.1786, Val: 0.1300, Test: 0.1620
Epoch: 37, Loss: 1.9917, Train: 0.1786, Val: 0.1220, Test: 0.1560
Epoch: 38, Loss: 1.9521, Train: 0.1786, Val: 0.1240, Test: 0.1560
Epoch: 39, Loss: 2.0073, Train: 0.1714, Val: 0.1160, Test: 0.1530
Epoch: 40, Loss: 2.0192, Train: 0.1714, Val: 0.1120, Test: 0.1470
Epoch: 41, Loss: 1.9426, Train: 0.1857, Val: 0.1060, Test: 0.1520
Epoch: 42, Loss: 1.9855, Train: 0.1786, Val: 0.1120, Test: 0.1540
Epoch: 43, Loss: 1.9766, Train: 0.1786, Val: 0.1140, Test: 0.1540
Epoch: 44, Loss: 2.0203, Train: 0.1786, Val: 0.1080, Test: 0.1510
Epoch: 45, Loss: 2.0666, Train: 0.1786, Val: 0.1040, Test: 0.1480
Epoch: 46, Loss: 1.9387, Train: 0.1857, Val: 0.1060, Test: 0.1520
Epoch: 47, Loss: 1.9255, Train: 0.1786, Val: 0.1100, Test: 0.1490
Epoch: 48, Loss: 1.9441, Train: 0.1786, Val: 0.1140, Test: 0.1430
Epoch: 49, Loss: 1.9227, Train: 0.2000, Val: 0.0940, Test: 0.1400
Epoch: 50, Loss: 2.2857, Train: 0.1929, Val: 0.0840, Test: 0.1210
Epoch: 51, Loss: 1.9927, Train: 0.2214, Val: 0.0820, Test: 0.1170
Epoch: 52, Loss: 1.9242, Train: 0.2143, Val: 0.0800, Test: 0.1090
Epoch: 53, Loss: 2.0366, Train: 0.2000, Val: 0.0780, Test: 0.1070
Epoch: 54, Loss: 1.9766, Train: 0.2000, Val: 0.0800, Test: 0.1040
Epoch: 55, Loss: 1.9235, Train: 0.1929, Val: 0.0800, Test: 0.1000
Epoch: 56, Loss: 2.0808, Train: 0.1929, Val: 0.0760, Test: 0.0970
Epoch: 57, Loss: 1.9336, Train: 0.1929, Val: 0.0760, Test: 0.0970
Epoch: 58, Loss: 1.9225, Train: 0.1929, Val: 0.0760, Test: 0.0970
Epoch: 59, Loss: 1.9370, Train: 0.1929, Val: 0.0760, Test: 0.0960
Epoch: 60, Loss: 1.9387, Train: 0.1929, Val: 0.0760, Test: 0.0960
Epoch: 61, Loss: 1.9455, Train: 0.1929, Val: 0.0760, Test: 0.0960
Epoch: 62, Loss: 1.8884, Train: 0.1929, Val: 0.0760, Test: 0.0960
Epoch: 63, Loss: 2.0630, Train: 0.1929, Val: 0.0760, Test: 0.0970
Epoch: 64, Loss: 1.9386, Train: 0.1929, Val: 0.0740, Test: 0.0980
Epoch: 65, Loss: 1.8910, Train: 0.1929, Val: 0.0740, Test: 0.0980
Epoch: 66, Loss: 1.9436, Train: 0.1929, Val: 0.0740, Test: 0.0980
Epoch: 67, Loss: 1.9817, Train: 0.1929, Val: 0.0740, Test: 0.0980
Epoch: 68, Loss: 1.8224, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 69, Loss: 1.8547, Train: 0.1929, Val: 0.0720, Test: 0.1020
Epoch: 70, Loss: 1.7961, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 71, Loss: 1.7934, Train: 0.2000, Val: 0.0720, Test: 0.1010
Epoch: 72, Loss: 1.8158, Train: 0.2071, Val: 0.0740, Test: 0.1010
Epoch: 73, Loss: 1.7947, Train: 0.2071, Val: 0.0740, Test: 0.1010
Epoch: 74, Loss: 1.8007, Train: 0.2071, Val: 0.0740, Test: 0.1020
Epoch: 75, Loss: 1.8001, Train: 0.2071, Val: 0.0740, Test: 0.1020
Epoch: 76, Loss: 1.8489, Train: 0.2071, Val: 0.0740, Test: 0.1020
Epoch: 77, Loss: 1.8684, Train: 0.2143, Val: 0.0740, Test: 0.1020
Epoch: 78, Loss: 1.8424, Train: 0.2143, Val: 0.0740, Test: 0.1020
Epoch: 79, Loss: 1.8162, Train: 0.2143, Val: 0.0740, Test: 0.1030
Epoch: 80, Loss: 1.7989, Train: 0.2143, Val: 0.0740, Test: 0.1030
Epoch: 81, Loss: 1.8213, Train: 0.2143, Val: 0.0740, Test: 0.1030
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 82, Loss: 1.7997, Train: 0.2143, Val: 0.0740, Test: 0.1050
Epoch: 83, Loss: 1.8231, Train: 0.2143, Val: 0.0780, Test: 0.1050
Epoch: 84, Loss: 1.7733, Train: 0.2143, Val: 0.0820, Test: 0.1050
Epoch: 85, Loss: 2.1486, Train: 0.2143, Val: 0.0820, Test: 0.1060
Epoch: 86, Loss: 1.8523, Train: 0.2143, Val: 0.0820, Test: 0.1060
Epoch: 87, Loss: 1.7872, Train: 0.2143, Val: 0.0820, Test: 0.1060
Epoch: 88, Loss: 1.7322, Train: 0.2286, Val: 0.0820, Test: 0.1060
Epoch: 89, Loss: 1.8893, Train: 0.2286, Val: 0.0840, Test: 0.1060
Epoch: 90, Loss: 1.9058, Train: 0.2286, Val: 0.0860, Test: 0.1060
Epoch: 91, Loss: 1.7515, Train: 0.2357, Val: 0.0860, Test: 0.1060
Epoch: 92, Loss: 1.7745, Train: 0.2357, Val: 0.0860, Test: 0.1070
Epoch: 93, Loss: 1.7131, Train: 0.2357, Val: 0.0860, Test: 0.1100
Epoch: 94, Loss: 1.6967, Train: 0.2429, Val: 0.0860, Test: 0.1130
Epoch: 95, Loss: 1.7559, Train: 0.2429, Val: 0.0860, Test: 0.1130
Epoch: 96, Loss: 1.7327, Train: 0.2429, Val: 0.0840, Test: 0.1130
Epoch: 97, Loss: 1.7131, Train: 0.2429, Val: 0.0840, Test: 0.1120
Epoch: 98, Loss: 1.6983, Train: 0.2500, Val: 0.0840, Test: 0.1130
Epoch: 99, Loss: 1.6736, Train: 0.2500, Val: 0.0860, Test: 0.1140
Epoch: 100, Loss: 1.6889, Train: 0.2571, Val: 0.0860, Test: 0.1140
Epoch: 101, Loss: 1.6981, Train: 0.2571, Val: 0.0900, Test: 0.1140
Epoch: 102, Loss: 1.7010, Train: 0.2571, Val: 0.0900, Test: 0.1140
Epoch: 103, Loss: 1.7528, Train: 0.2571, Val: 0.0920, Test: 0.1150
Epoch: 104, Loss: 1.6808, Train: 0.2643, Val: 0.0920, Test: 0.1160
Epoch: 105, Loss: 1.6966, Train: 0.2643, Val: 0.0960, Test: 0.1170
Epoch: 106, Loss: 1.6989, Train: 0.2643, Val: 0.0980, Test: 0.1180
Epoch: 107, Loss: 1.7120, Train: 0.2643, Val: 0.0980, Test: 0.1190
Epoch: 108, Loss: 1.6847, Train: 0.2714, Val: 0.0980, Test: 0.1190
Epoch: 109, Loss: 1.6802, Train: 0.2714, Val: 0.0980, Test: 0.1200
Epoch: 110, Loss: 1.6840, Train: 0.2714, Val: 0.1000, Test: 0.1190
Epoch: 111, Loss: 1.6978, Train: 0.2714, Val: 0.1000, Test: 0.1190
Epoch: 112, Loss: 1.7329, Train: 0.2786, Val: 0.1000, Test: 0.1190
Epoch: 113, Loss: 1.7380, Train: 0.2786, Val: 0.1000, Test: 0.1190
Epoch: 114, Loss: 1.6419, Train: 0.2786, Val: 0.1020, Test: 0.1190
Epoch: 115, Loss: 1.6371, Train: 0.2786, Val: 0.1020, Test: 0.1210
Epoch: 116, Loss: 1.6781, Train: 0.2786, Val: 0.1040, Test: 0.1210
Epoch: 117, Loss: 1.7364, Train: 0.2857, Val: 0.1040, Test: 0.1210
Epoch: 118, Loss: 1.6368, Train: 0.2857, Val: 0.1040, Test: 0.1210
Epoch: 119, Loss: 1.6775, Train: 0.2857, Val: 0.1040, Test: 0.1210
Epoch: 120, Loss: 1.6620, Train: 0.2857, Val: 0.1040, Test: 0.1210
Epoch: 121, Loss: 1.6406, Train: 0.2857, Val: 0.1040, Test: 0.1210
Epoch: 122, Loss: 1.6047, Train: 0.2857, Val: 0.1040, Test: 0.1210
Epoch: 123, Loss: 1.6163, Train: 0.2857, Val: 0.1040, Test: 0.1230
Epoch: 124, Loss: 1.5910, Train: 0.2857, Val: 0.1040, Test: 0.1240
Epoch: 125, Loss: 1.6204, Train: 0.2857, Val: 0.1040, Test: 0.1240
Epoch: 126, Loss: 1.5945, Train: 0.2857, Val: 0.1060, Test: 0.1250
Epoch: 127, Loss: 1.6024, Train: 0.2857, Val: 0.1060, Test: 0.1270
Epoch: 128, Loss: 1.5885, Train: 0.2857, Val: 0.1060, Test: 0.1270
Epoch: 129, Loss: 1.6480, Train: 0.2857, Val: 0.1080, Test: 0.1290
Epoch: 130, Loss: 1.6149, Train: 0.2857, Val: 0.1080, Test: 0.1320
Epoch: 131, Loss: 1.6214, Train: 0.2857, Val: 0.1080, Test: 0.1320
Epoch: 132, Loss: 1.6491, Train: 0.2857, Val: 0.1100, Test: 0.1350
Epoch: 133, Loss: 1.5883, Train: 0.2857, Val: 0.1100, Test: 0.1360
Epoch: 134, Loss: 1.6878, Train: 0.2857, Val: 0.1100, Test: 0.1380
Epoch: 135, Loss: 1.6220, Train: 0.2857, Val: 0.1140, Test: 0.1410
Epoch: 136, Loss: 1.6247, Train: 0.2857, Val: 0.1160, Test: 0.1430
Epoch: 137, Loss: 1.5927, Train: 0.2857, Val: 0.1160, Test: 0.1440
Epoch: 138, Loss: 1.5759, Train: 0.2857, Val: 0.1160, Test: 0.1440
Epoch: 139, Loss: 1.5789, Train: 0.2857, Val: 0.1160, Test: 0.1440
Epoch: 140, Loss: 1.6009, Train: 0.2857, Val: 0.1160, Test: 0.1450
Epoch: 141, Loss: 1.6264, Train: 0.2857, Val: 0.1160, Test: 0.1450
Epoch: 142, Loss: 1.6084, Train: 0.2857, Val: 0.1160, Test: 0.1460
Epoch: 143, Loss: 1.5722, Train: 0.2857, Val: 0.1160, Test: 0.1460
Epoch: 144, Loss: 1.5495, Train: 0.2857, Val: 0.1160, Test: 0.1450
Epoch: 145, Loss: 1.6535, Train: 0.2857, Val: 0.1140, Test: 0.1450
Epoch: 146, Loss: 1.5494, Train: 0.2857, Val: 0.1160, Test: 0.1440
Epoch: 147, Loss: 1.5556, Train: 0.2857, Val: 0.1180, Test: 0.1440
Epoch: 148, Loss: 1.5525, Train: 0.2857, Val: 0.1180, Test: 0.1420
Epoch: 149, Loss: 1.7059, Train: 0.2857, Val: 0.1180, Test: 0.1420
Epoch: 150, Loss: 1.5318, Train: 0.2857, Val: 0.1180, Test: 0.1420
Epoch: 151, Loss: 1.5801, Train: 0.2857, Val: 0.1200, Test: 0.1430
Epoch: 152, Loss: 1.6132, Train: 0.2857, Val: 0.1200, Test: 0.1430
Epoch: 153, Loss: 1.5187, Train: 0.2857, Val: 0.1240, Test: 0.1440
Epoch: 154, Loss: 1.4737, Train: 0.2929, Val: 0.1240, Test: 0.1450
Epoch: 155, Loss: 1.4943, Train: 0.2929, Val: 0.1260, Test: 0.1450
Epoch: 156, Loss: 1.5474, Train: 0.2929, Val: 0.1260, Test: 0.1460
Epoch: 157, Loss: 1.4870, Train: 0.2929, Val: 0.1260, Test: 0.1490
Epoch: 158, Loss: 1.5186, Train: 0.2929, Val: 0.1260, Test: 0.1520
Epoch: 159, Loss: 1.5583, Train: 0.2929, Val: 0.1260, Test: 0.1560
Epoch: 160, Loss: 1.5019, Train: 0.2929, Val: 0.1220, Test: 0.1600
Epoch: 161, Loss: 1.4979, Train: 0.3071, Val: 0.1240, Test: 0.1610
Epoch: 162, Loss: 1.5628, Train: 0.3143, Val: 0.1260, Test: 0.1620
Epoch: 163, Loss: 1.4769, Train: 0.3214, Val: 0.1260, Test: 0.1630
Epoch: 164, Loss: 1.4521, Train: 0.3214, Val: 0.1280, Test: 0.1660
Epoch: 165, Loss: 1.4747, Train: 0.3214, Val: 0.1300, Test: 0.1680
Epoch: 166, Loss: 1.4759, Train: 0.3357, Val: 0.1320, Test: 0.1750
Epoch: 167, Loss: 1.5246, Train: 0.3357, Val: 0.1320, Test: 0.1750
Epoch: 168, Loss: 1.4829, Train: 0.3500, Val: 0.1340, Test: 0.1770
Epoch: 169, Loss: 1.5613, Train: 0.3500, Val: 0.1360, Test: 0.1770
Epoch: 170, Loss: 1.4593, Train: 0.3500, Val: 0.1320, Test: 0.1750
Epoch: 171, Loss: 1.4603, Train: 0.3357, Val: 0.1320, Test: 0.1700
Epoch: 172, Loss: 1.4319, Train: 0.3357, Val: 0.1300, Test: 0.1700
Epoch: 173, Loss: 1.4898, Train: 0.3286, Val: 0.1300, Test: 0.1610
Epoch: 174, Loss: 1.4456, Train: 0.3214, Val: 0.1300, Test: 0.1590
Epoch: 175, Loss: 1.4493, Train: 0.3286, Val: 0.1300, Test: 0.1600
Epoch: 176, Loss: 1.5641, Train: 0.3357, Val: 0.1360, Test: 0.1660
Epoch: 177, Loss: 1.4895, Train: 0.3429, Val: 0.1380, Test: 0.1700
Epoch: 178, Loss: 1.4301, Train: 0.3500, Val: 0.1460, Test: 0.1810
Epoch: 179, Loss: 1.4085, Train: 0.3500, Val: 0.1520, Test: 0.1860
Epoch: 180, Loss: 1.5032, Train: 0.3500, Val: 0.1580, Test: 0.1870
Epoch: 181, Loss: 1.3950, Train: 0.3429, Val: 0.1700, Test: 0.1920
Epoch: 182, Loss: 1.4400, Train: 0.3429, Val: 0.1660, Test: 0.1940
Epoch: 183, Loss: 1.4128, Train: 0.3286, Val: 0.1600, Test: 0.1900
Epoch: 184, Loss: 1.3812, Train: 0.3143, Val: 0.1560, Test: 0.1880
Epoch: 185, Loss: 1.4006, Train: 0.3071, Val: 0.1580, Test: 0.1830
Epoch: 186, Loss: 1.4453, Train: 0.3071, Val: 0.1400, Test: 0.1770
Epoch: 187, Loss: 1.4579, Train: 0.3071, Val: 0.1320, Test: 0.1680
Epoch: 188, Loss: 1.4607, Train: 0.3000, Val: 0.1280, Test: 0.1660
Epoch: 189, Loss: 1.3600, Train: 0.3000, Val: 0.1280, Test: 0.1660
Epoch: 190, Loss: 1.3389, Train: 0.3000, Val: 0.1320, Test: 0.1660
Epoch: 191, Loss: 1.3895, Train: 0.3071, Val: 0.1320, Test: 0.1760
Epoch: 192, Loss: 1.3703, Train: 0.3143, Val: 0.1400, Test: 0.1830
Epoch: 193, Loss: 1.3659, Train: 0.3214, Val: 0.1440, Test: 0.1870
Epoch: 194, Loss: 1.3308, Train: 0.3214, Val: 0.1540, Test: 0.1940
Epoch: 195, Loss: 1.3483, Train: 0.3214, Val: 0.1560, Test: 0.2010
Epoch: 196, Loss: 1.3213, Train: 0.3214, Val: 0.1640, Test: 0.2030
Epoch: 197, Loss: 1.3239, Train: 0.3214, Val: 0.1640, Test: 0.2090
Epoch: 198, Loss: 1.4407, Train: 0.3214, Val: 0.1680, Test: 0.2110
Epoch: 199, Loss: 1.3462, Train: 0.3214, Val: 0.1660, Test: 0.2100
Epoch: 200, Loss: 1.3099, Train: 0.3214, Val: 0.1600, Test: 0.2010
MAD:  0.155
Best Test Accuracy: 0.2290, Val Accuracy: 0.2040, Train Accuracy: 0.2286
Training completed.
Seed:  6
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 6.7228, Train: 0.2071, Val: 0.0880, Test: 0.1140
Epoch: 2, Loss: 4.3572, Train: 0.1429, Val: 0.0600, Test: 0.0650
Epoch: 3, Loss: 4.0213, Train: 0.1643, Val: 0.0900, Test: 0.0850
Epoch: 4, Loss: 3.6029, Train: 0.1643, Val: 0.1220, Test: 0.1080
Epoch: 5, Loss: 3.3115, Train: 0.1786, Val: 0.1300, Test: 0.1230
Epoch: 6, Loss: 3.1424, Train: 0.1714, Val: 0.1180, Test: 0.1300
Epoch: 7, Loss: 2.8065, Train: 0.1286, Val: 0.1160, Test: 0.1260
Epoch: 8, Loss: 2.7842, Train: 0.1143, Val: 0.1180, Test: 0.1190
Epoch: 9, Loss: 2.4558, Train: 0.1000, Val: 0.1240, Test: 0.1120
Epoch: 10, Loss: 2.2386, Train: 0.1214, Val: 0.1180, Test: 0.1120
Epoch: 11, Loss: 2.5624, Train: 0.1500, Val: 0.1200, Test: 0.1110
Epoch: 12, Loss: 2.3503, Train: 0.1286, Val: 0.1280, Test: 0.1160
Epoch: 13, Loss: 2.3674, Train: 0.1500, Val: 0.1440, Test: 0.1320
Epoch: 14, Loss: 2.2431, Train: 0.1929, Val: 0.1600, Test: 0.1540
Epoch: 15, Loss: 2.3821, Train: 0.2071, Val: 0.1840, Test: 0.1860
Epoch: 16, Loss: 2.1599, Train: 0.2143, Val: 0.2180, Test: 0.2170
Epoch: 17, Loss: 2.2406, Train: 0.2571, Val: 0.2340, Test: 0.2570
Epoch: 18, Loss: 2.2247, Train: 0.2857, Val: 0.2360, Test: 0.2580
Epoch: 19, Loss: 2.1436, Train: 0.3000, Val: 0.2340, Test: 0.2660
Epoch: 20, Loss: 2.1296, Train: 0.2714, Val: 0.2400, Test: 0.2720
Epoch: 21, Loss: 2.1122, Train: 0.2571, Val: 0.2300, Test: 0.2600
Epoch: 22, Loss: 1.9637, Train: 0.2429, Val: 0.2320, Test: 0.2410
Epoch: 23, Loss: 2.0928, Train: 0.2357, Val: 0.2400, Test: 0.2320
Epoch: 24, Loss: 2.0911, Train: 0.2429, Val: 0.2400, Test: 0.2070
Epoch: 25, Loss: 2.1366, Train: 0.2643, Val: 0.2300, Test: 0.2050
Epoch: 26, Loss: 2.3849, Train: 0.2714, Val: 0.2200, Test: 0.1900
Epoch: 27, Loss: 2.1186, Train: 0.2214, Val: 0.1960, Test: 0.1720
Epoch: 28, Loss: 2.0033, Train: 0.2429, Val: 0.1820, Test: 0.1670
Epoch: 29, Loss: 2.0682, Train: 0.2571, Val: 0.1720, Test: 0.1660
Epoch: 30, Loss: 2.1720, Train: 0.2429, Val: 0.1600, Test: 0.1560
Epoch: 31, Loss: 2.0128, Train: 0.2571, Val: 0.1420, Test: 0.1460
Epoch: 32, Loss: 2.0022, Train: 0.2786, Val: 0.1380, Test: 0.1430
Epoch: 33, Loss: 2.0367, Train: 0.2929, Val: 0.1300, Test: 0.1430
Epoch: 34, Loss: 2.0169, Train: 0.2857, Val: 0.1260, Test: 0.1310
Epoch: 35, Loss: 2.0252, Train: 0.2643, Val: 0.1160, Test: 0.1260
Epoch: 36, Loss: 1.9480, Train: 0.2500, Val: 0.1200, Test: 0.1280
Epoch: 37, Loss: 2.4507, Train: 0.2500, Val: 0.1100, Test: 0.1180
Epoch: 38, Loss: 1.9848, Train: 0.2571, Val: 0.1040, Test: 0.1160
Epoch: 39, Loss: 1.9757, Train: 0.2500, Val: 0.1040, Test: 0.1120
Epoch: 40, Loss: 2.0015, Train: 0.2357, Val: 0.1020, Test: 0.1110
Epoch: 41, Loss: 2.0242, Train: 0.2143, Val: 0.0940, Test: 0.1100
Epoch: 42, Loss: 2.0431, Train: 0.2143, Val: 0.0920, Test: 0.1130
Epoch: 43, Loss: 2.0753, Train: 0.2143, Val: 0.0900, Test: 0.1120
Epoch: 44, Loss: 1.9683, Train: 0.2143, Val: 0.0900, Test: 0.1110
Epoch: 45, Loss: 2.1031, Train: 0.2143, Val: 0.0900, Test: 0.1100
Epoch: 46, Loss: 1.9634, Train: 0.2143, Val: 0.0880, Test: 0.1100
Epoch: 47, Loss: 1.9407, Train: 0.2143, Val: 0.0860, Test: 0.1080
Epoch: 48, Loss: 1.9793, Train: 0.2143, Val: 0.0840, Test: 0.1060
Epoch: 49, Loss: 1.9435, Train: 0.2071, Val: 0.0820, Test: 0.1060
Epoch: 50, Loss: 1.9786, Train: 0.2071, Val: 0.0820, Test: 0.1060
Epoch: 51, Loss: 1.9238, Train: 0.2071, Val: 0.0820, Test: 0.1070
Epoch: 52, Loss: 1.9438, Train: 0.2000, Val: 0.0820, Test: 0.1070
Epoch: 53, Loss: 1.9788, Train: 0.2000, Val: 0.0820, Test: 0.1070
Epoch: 54, Loss: 1.9170, Train: 0.2000, Val: 0.0820, Test: 0.1070
Epoch: 55, Loss: 1.9231, Train: 0.2000, Val: 0.0820, Test: 0.1080
Epoch: 56, Loss: 1.9124, Train: 0.2000, Val: 0.0820, Test: 0.1070
Epoch: 57, Loss: 1.8734, Train: 0.2000, Val: 0.0760, Test: 0.1070
Epoch: 58, Loss: 1.8840, Train: 0.2000, Val: 0.0760, Test: 0.1080
Epoch: 59, Loss: 1.9826, Train: 0.2000, Val: 0.0760, Test: 0.1080
Epoch: 60, Loss: 1.9425, Train: 0.2000, Val: 0.0760, Test: 0.1070
Epoch: 61, Loss: 1.8979, Train: 0.2000, Val: 0.0760, Test: 0.1090
Epoch: 62, Loss: 2.0165, Train: 0.2000, Val: 0.0800, Test: 0.1090
Epoch: 63, Loss: 1.9068, Train: 0.2071, Val: 0.0800, Test: 0.1090
Epoch: 64, Loss: 1.8911, Train: 0.2071, Val: 0.0800, Test: 0.1090
Epoch: 65, Loss: 1.9719, Train: 0.2071, Val: 0.0800, Test: 0.1090
Epoch: 66, Loss: 1.8344, Train: 0.2071, Val: 0.0800, Test: 0.1100
Epoch: 67, Loss: 1.8997, Train: 0.2071, Val: 0.0820, Test: 0.1100
Epoch: 68, Loss: 1.9680, Train: 0.2071, Val: 0.0900, Test: 0.1110
Epoch: 69, Loss: 1.8832, Train: 0.2214, Val: 0.0900, Test: 0.1110
Epoch: 70, Loss: 1.9873, Train: 0.2286, Val: 0.0900, Test: 0.1110
Epoch: 71, Loss: 1.8291, Train: 0.2286, Val: 0.0900, Test: 0.1110
Epoch: 72, Loss: 1.8533, Train: 0.2357, Val: 0.0920, Test: 0.1110
Epoch: 73, Loss: 1.9502, Train: 0.2357, Val: 0.0920, Test: 0.1110
Epoch: 74, Loss: 1.8080, Train: 0.2357, Val: 0.0920, Test: 0.1120
Epoch: 75, Loss: 1.8156, Train: 0.2357, Val: 0.0940, Test: 0.1130
Epoch: 76, Loss: 1.8222, Train: 0.2357, Val: 0.0940, Test: 0.1130
Epoch: 77, Loss: 1.8668, Train: 0.2357, Val: 0.0940, Test: 0.1120
Epoch: 78, Loss: 1.8897, Train: 0.2429, Val: 0.0940, Test: 0.1120
Epoch: 79, Loss: 1.8563, Train: 0.2429, Val: 0.0940, Test: 0.1120
Epoch: 80, Loss: 1.8652, Train: 0.2429, Val: 0.0940, Test: 0.1120
Epoch: 81, Loss: 1.8533, Train: 0.2357, Val: 0.0920, Test: 0.1110
Epoch: 82, Loss: 1.9143, Train: 0.2357, Val: 0.0920, Test: 0.1100
Epoch: 83, Loss: 1.7862, Train: 0.2357, Val: 0.0920, Test: 0.1100
Epoch: 84, Loss: 1.8149, Train: 0.2357, Val: 0.0900, Test: 0.1110
Epoch: 85, Loss: 1.7890, Train: 0.2429, Val: 0.0920, Test: 0.1120
Epoch: 86, Loss: 1.8308, Train: 0.2357, Val: 0.0920, Test: 0.1130
Epoch: 87, Loss: 1.7726, Train: 0.2357, Val: 0.0940, Test: 0.1130
Epoch: 88, Loss: 1.7422, Train: 0.2429, Val: 0.0960, Test: 0.1140
Epoch: 89, Loss: 1.8005, Train: 0.2500, Val: 0.0980, Test: 0.1150
Epoch: 90, Loss: 1.7407, Train: 0.2500, Val: 0.1020, Test: 0.1170
Epoch: 91, Loss: 1.7319, Train: 0.2714, Val: 0.1060, Test: 0.1200
Epoch: 92, Loss: 1.7441, Train: 0.2714, Val: 0.1080, Test: 0.1230
Epoch: 93, Loss: 1.7222, Train: 0.2714, Val: 0.1080, Test: 0.1230
Epoch: 94, Loss: 1.7825, Train: 0.2714, Val: 0.1080, Test: 0.1240
Epoch: 95, Loss: 1.7239, Train: 0.2714, Val: 0.1020, Test: 0.1230
Epoch: 96, Loss: 1.7399, Train: 0.2643, Val: 0.1020, Test: 0.1230
Epoch: 97, Loss: 1.7231, Train: 0.2643, Val: 0.1060, Test: 0.1250
Epoch: 98, Loss: 1.7168, Train: 0.2643, Val: 0.1060, Test: 0.1270
Epoch: 99, Loss: 1.7501, Train: 0.2714, Val: 0.1080, Test: 0.1320
Epoch: 100, Loss: 1.7644, Train: 0.2643, Val: 0.1100, Test: 0.1320
Epoch: 101, Loss: 1.6979, Train: 0.2643, Val: 0.1060, Test: 0.1350
Epoch: 102, Loss: 1.7328, Train: 0.2786, Val: 0.1140, Test: 0.1390
Epoch: 103, Loss: 1.7011, Train: 0.2786, Val: 0.1140, Test: 0.1440
Epoch: 104, Loss: 1.7071, Train: 0.2857, Val: 0.1200, Test: 0.1480
Epoch: 105, Loss: 1.7033, Train: 0.2857, Val: 0.1220, Test: 0.1470
Epoch: 106, Loss: 1.6992, Train: 0.2929, Val: 0.1220, Test: 0.1460
Epoch: 107, Loss: 1.6798, Train: 0.2929, Val: 0.1220, Test: 0.1480
Epoch: 108, Loss: 1.7063, Train: 0.3000, Val: 0.1200, Test: 0.1550
Epoch: 109, Loss: 1.6517, Train: 0.3000, Val: 0.1220, Test: 0.1570
Epoch: 110, Loss: 1.7227, Train: 0.2857, Val: 0.1220, Test: 0.1550
Epoch: 111, Loss: 1.6424, Train: 0.2857, Val: 0.1200, Test: 0.1540
Epoch: 112, Loss: 1.7168, Train: 0.2857, Val: 0.1200, Test: 0.1500
Epoch: 113, Loss: 1.6730, Train: 0.2857, Val: 0.1220, Test: 0.1500
Epoch: 114, Loss: 1.6676, Train: 0.2857, Val: 0.1200, Test: 0.1480
Epoch: 115, Loss: 1.7646, Train: 0.2857, Val: 0.1220, Test: 0.1480
Epoch: 116, Loss: 1.6742, Train: 0.2857, Val: 0.1220, Test: 0.1460
Epoch: 117, Loss: 1.6513, Train: 0.2857, Val: 0.1200, Test: 0.1450
Epoch: 118, Loss: 1.6822, Train: 0.2857, Val: 0.1180, Test: 0.1440
Epoch: 119, Loss: 1.6100, Train: 0.2857, Val: 0.1140, Test: 0.1430
Epoch: 120, Loss: 1.6331, Train: 0.2857, Val: 0.1140, Test: 0.1430
Epoch: 121, Loss: 1.6185, Train: 0.2857, Val: 0.1140, Test: 0.1430
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 122, Loss: 1.6381, Train: 0.2857, Val: 0.1140, Test: 0.1430
Epoch: 123, Loss: 1.6143, Train: 0.2857, Val: 0.1140, Test: 0.1450
Epoch: 124, Loss: 1.6544, Train: 0.2857, Val: 0.1140, Test: 0.1480
Epoch: 125, Loss: 1.6419, Train: 0.2857, Val: 0.1140, Test: 0.1500
Epoch: 126, Loss: 1.6576, Train: 0.2857, Val: 0.1140, Test: 0.1520
Epoch: 127, Loss: 1.6827, Train: 0.2929, Val: 0.1180, Test: 0.1510
Epoch: 128, Loss: 1.5982, Train: 0.2929, Val: 0.1160, Test: 0.1540
Epoch: 129, Loss: 1.6096, Train: 0.2929, Val: 0.1220, Test: 0.1560
Epoch: 130, Loss: 1.5832, Train: 0.2929, Val: 0.1260, Test: 0.1620
Epoch: 131, Loss: 1.6267, Train: 0.3071, Val: 0.1260, Test: 0.1620
Epoch: 132, Loss: 1.5778, Train: 0.3071, Val: 0.1280, Test: 0.1650
Epoch: 133, Loss: 1.5628, Train: 0.3143, Val: 0.1340, Test: 0.1700
Epoch: 134, Loss: 1.5837, Train: 0.3143, Val: 0.1340, Test: 0.1720
Epoch: 135, Loss: 1.5882, Train: 0.3143, Val: 0.1380, Test: 0.1730
Epoch: 136, Loss: 1.5568, Train: 0.3143, Val: 0.1440, Test: 0.1750
Epoch: 137, Loss: 1.5695, Train: 0.3143, Val: 0.1460, Test: 0.1790
Epoch: 138, Loss: 1.6046, Train: 0.3143, Val: 0.1440, Test: 0.1760
Epoch: 139, Loss: 1.6627, Train: 0.3143, Val: 0.1460, Test: 0.1750
Epoch: 140, Loss: 1.5555, Train: 0.3143, Val: 0.1460, Test: 0.1740
Epoch: 141, Loss: 1.6111, Train: 0.3214, Val: 0.1480, Test: 0.1750
Epoch: 142, Loss: 1.6186, Train: 0.3214, Val: 0.1460, Test: 0.1720
Epoch: 143, Loss: 1.5187, Train: 0.3214, Val: 0.1500, Test: 0.1690
Epoch: 144, Loss: 1.5202, Train: 0.3214, Val: 0.1420, Test: 0.1670
Epoch: 145, Loss: 1.5766, Train: 0.3214, Val: 0.1440, Test: 0.1660
Epoch: 146, Loss: 1.5337, Train: 0.3214, Val: 0.1520, Test: 0.1670
Epoch: 147, Loss: 1.5471, Train: 0.3143, Val: 0.1560, Test: 0.1720
Epoch: 148, Loss: 1.5829, Train: 0.3286, Val: 0.1660, Test: 0.1840
Epoch: 149, Loss: 1.4809, Train: 0.3714, Val: 0.1720, Test: 0.1970
Epoch: 150, Loss: 1.5370, Train: 0.3857, Val: 0.1840, Test: 0.2060
Epoch: 151, Loss: 1.5382, Train: 0.3857, Val: 0.2000, Test: 0.2190
Epoch: 152, Loss: 1.5990, Train: 0.3929, Val: 0.2060, Test: 0.2310
Epoch: 153, Loss: 1.4676, Train: 0.4000, Val: 0.2120, Test: 0.2370
Epoch: 154, Loss: 1.5105, Train: 0.4071, Val: 0.2140, Test: 0.2450
Epoch: 155, Loss: 1.5698, Train: 0.4000, Val: 0.2160, Test: 0.2450
Epoch: 156, Loss: 1.4776, Train: 0.4143, Val: 0.2180, Test: 0.2460
Epoch: 157, Loss: 1.4771, Train: 0.4143, Val: 0.2300, Test: 0.2560
Epoch: 158, Loss: 1.4898, Train: 0.4214, Val: 0.2340, Test: 0.2590
Epoch: 159, Loss: 1.4676, Train: 0.4214, Val: 0.2220, Test: 0.2570
Epoch: 160, Loss: 1.4220, Train: 0.4286, Val: 0.2100, Test: 0.2490
Epoch: 161, Loss: 1.4663, Train: 0.4286, Val: 0.2100, Test: 0.2490
Epoch: 162, Loss: 1.5104, Train: 0.4357, Val: 0.2060, Test: 0.2480
Epoch: 163, Loss: 1.4775, Train: 0.4357, Val: 0.2060, Test: 0.2510
Epoch: 164, Loss: 1.4495, Train: 0.4429, Val: 0.2160, Test: 0.2600
Epoch: 165, Loss: 1.4093, Train: 0.4500, Val: 0.2220, Test: 0.2650
Epoch: 166, Loss: 1.3858, Train: 0.4643, Val: 0.2380, Test: 0.2750
Epoch: 167, Loss: 1.4427, Train: 0.4929, Val: 0.2540, Test: 0.2840
Epoch: 168, Loss: 1.5083, Train: 0.5214, Val: 0.2760, Test: 0.2860
Epoch: 169, Loss: 1.4122, Train: 0.5357, Val: 0.2820, Test: 0.2950
Epoch: 170, Loss: 1.4093, Train: 0.5429, Val: 0.2840, Test: 0.3010
Epoch: 171, Loss: 1.3465, Train: 0.5286, Val: 0.2720, Test: 0.3000
Epoch: 172, Loss: 1.3272, Train: 0.5286, Val: 0.2660, Test: 0.2910
Epoch: 173, Loss: 1.4100, Train: 0.5286, Val: 0.2580, Test: 0.2850
Epoch: 174, Loss: 1.3738, Train: 0.5000, Val: 0.2500, Test: 0.2780
Epoch: 175, Loss: 1.3558, Train: 0.4786, Val: 0.2400, Test: 0.2670
Epoch: 176, Loss: 1.3491, Train: 0.4714, Val: 0.2380, Test: 0.2560
Epoch: 177, Loss: 1.3184, Train: 0.4714, Val: 0.2340, Test: 0.2600
Epoch: 178, Loss: 1.2896, Train: 0.4786, Val: 0.2380, Test: 0.2650
Epoch: 179, Loss: 1.3602, Train: 0.4857, Val: 0.2500, Test: 0.2740
Epoch: 180, Loss: 1.2891, Train: 0.5000, Val: 0.2640, Test: 0.2860
Epoch: 181, Loss: 1.4159, Train: 0.5071, Val: 0.2600, Test: 0.2920
Epoch: 182, Loss: 1.3853, Train: 0.5071, Val: 0.2760, Test: 0.2990
Epoch: 183, Loss: 1.2505, Train: 0.5143, Val: 0.2880, Test: 0.3050
Epoch: 184, Loss: 1.2249, Train: 0.5214, Val: 0.3000, Test: 0.3210
Epoch: 185, Loss: 1.2735, Train: 0.5286, Val: 0.3120, Test: 0.3270
Epoch: 186, Loss: 1.1988, Train: 0.5500, Val: 0.3180, Test: 0.3370
Epoch: 187, Loss: 1.2671, Train: 0.5571, Val: 0.3060, Test: 0.3350
Epoch: 188, Loss: 1.2644, Train: 0.5571, Val: 0.2860, Test: 0.3320
Epoch: 189, Loss: 1.1821, Train: 0.5500, Val: 0.2860, Test: 0.3290
Epoch: 190, Loss: 1.3186, Train: 0.5357, Val: 0.2880, Test: 0.3260
Epoch: 191, Loss: 1.1283, Train: 0.5286, Val: 0.2880, Test: 0.3250
Epoch: 192, Loss: 1.5643, Train: 0.5214, Val: 0.2820, Test: 0.3310
Epoch: 193, Loss: 1.3971, Train: 0.5214, Val: 0.2900, Test: 0.3330
Epoch: 194, Loss: 1.1163, Train: 0.5500, Val: 0.3060, Test: 0.3350
Epoch: 195, Loss: 1.1953, Train: 0.5714, Val: 0.3320, Test: 0.3520
Epoch: 196, Loss: 1.0585, Train: 0.6000, Val: 0.3540, Test: 0.3720
Epoch: 197, Loss: 1.0612, Train: 0.6071, Val: 0.3620, Test: 0.3950
Epoch: 198, Loss: 1.1123, Train: 0.6071, Val: 0.3720, Test: 0.4040
Epoch: 199, Loss: 1.0603, Train: 0.6071, Val: 0.3740, Test: 0.4020
Epoch: 200, Loss: 1.3405, Train: 0.6143, Val: 0.3580, Test: 0.3960
MAD:  0.6202
Best Test Accuracy: 0.4040, Val Accuracy: 0.3720, Train Accuracy: 0.6071
Training completed.
Seed:  7
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 6.1359, Train: 0.1429, Val: 0.1280, Test: 0.1320
Epoch: 2, Loss: 5.1262, Train: 0.1286, Val: 0.1640, Test: 0.1830
Epoch: 3, Loss: 4.3451, Train: 0.1286, Val: 0.2860, Test: 0.3030
Epoch: 4, Loss: 4.3281, Train: 0.1429, Val: 0.3100, Test: 0.3160
Epoch: 5, Loss: 3.4582, Train: 0.1429, Val: 0.3100, Test: 0.3150
Epoch: 6, Loss: 3.6639, Train: 0.1429, Val: 0.3100, Test: 0.3160
Epoch: 7, Loss: 2.8631, Train: 0.1429, Val: 0.3100, Test: 0.3180
Epoch: 8, Loss: 2.6929, Train: 0.1500, Val: 0.3140, Test: 0.3200
Epoch: 9, Loss: 2.8454, Train: 0.1571, Val: 0.3080, Test: 0.3160
Epoch: 10, Loss: 2.4589, Train: 0.1714, Val: 0.3160, Test: 0.3200
Epoch: 11, Loss: 2.8537, Train: 0.1857, Val: 0.3100, Test: 0.3260
Epoch: 12, Loss: 2.5144, Train: 0.1929, Val: 0.2840, Test: 0.3130
Epoch: 13, Loss: 2.6923, Train: 0.2143, Val: 0.2760, Test: 0.3080
Epoch: 14, Loss: 2.3013, Train: 0.2143, Val: 0.2720, Test: 0.2910
Epoch: 15, Loss: 2.6266, Train: 0.2214, Val: 0.2660, Test: 0.2880
Epoch: 16, Loss: 2.3940, Train: 0.2214, Val: 0.2500, Test: 0.2570
Epoch: 17, Loss: 2.2134, Train: 0.2000, Val: 0.2360, Test: 0.2340
Epoch: 18, Loss: 2.1135, Train: 0.2143, Val: 0.2140, Test: 0.2200
Epoch: 19, Loss: 2.2037, Train: 0.2357, Val: 0.2060, Test: 0.1970
Epoch: 20, Loss: 2.1495, Train: 0.2357, Val: 0.1960, Test: 0.1860
Epoch: 21, Loss: 2.2707, Train: 0.2643, Val: 0.1780, Test: 0.1880
Epoch: 22, Loss: 2.1509, Train: 0.2714, Val: 0.1600, Test: 0.1790
Epoch: 23, Loss: 2.3307, Train: 0.2786, Val: 0.1480, Test: 0.1670
Epoch: 24, Loss: 2.0995, Train: 0.2857, Val: 0.1320, Test: 0.1500
Epoch: 25, Loss: 2.1800, Train: 0.2714, Val: 0.1280, Test: 0.1450
Epoch: 26, Loss: 1.9998, Train: 0.2571, Val: 0.1240, Test: 0.1330
Epoch: 27, Loss: 2.0697, Train: 0.2500, Val: 0.1140, Test: 0.1190
Epoch: 28, Loss: 1.9307, Train: 0.2429, Val: 0.0960, Test: 0.1180
Epoch: 29, Loss: 1.9872, Train: 0.2286, Val: 0.0960, Test: 0.1150
Epoch: 30, Loss: 1.9752, Train: 0.2214, Val: 0.0920, Test: 0.1130
Epoch: 31, Loss: 1.9459, Train: 0.2214, Val: 0.0880, Test: 0.1100
Epoch: 32, Loss: 2.0096, Train: 0.2071, Val: 0.0920, Test: 0.1090
Epoch: 33, Loss: 2.1043, Train: 0.2071, Val: 0.0900, Test: 0.1070
Epoch: 34, Loss: 2.0525, Train: 0.2143, Val: 0.0880, Test: 0.1020
Epoch: 35, Loss: 2.0558, Train: 0.2000, Val: 0.0880, Test: 0.1020
Epoch: 36, Loss: 2.0172, Train: 0.2000, Val: 0.0900, Test: 0.1050
Epoch: 37, Loss: 1.9626, Train: 0.2071, Val: 0.0980, Test: 0.1100
Epoch: 38, Loss: 2.0032, Train: 0.2000, Val: 0.0960, Test: 0.1100
Epoch: 39, Loss: 1.9310, Train: 0.2000, Val: 0.0940, Test: 0.1110
Epoch: 40, Loss: 2.0086, Train: 0.2000, Val: 0.0960, Test: 0.1120
Epoch: 41, Loss: 1.9944, Train: 0.1929, Val: 0.0960, Test: 0.1140
Epoch: 42, Loss: 1.9636, Train: 0.1929, Val: 0.0960, Test: 0.1120
Epoch: 43, Loss: 2.0064, Train: 0.1857, Val: 0.0960, Test: 0.1100
Epoch: 44, Loss: 1.9886, Train: 0.1857, Val: 0.0960, Test: 0.1060
Epoch: 45, Loss: 2.1681, Train: 0.1857, Val: 0.0940, Test: 0.1040
Epoch: 46, Loss: 1.9940, Train: 0.1857, Val: 0.0880, Test: 0.1040
Epoch: 47, Loss: 2.0462, Train: 0.1857, Val: 0.0900, Test: 0.1040
Epoch: 48, Loss: 1.9891, Train: 0.1857, Val: 0.0880, Test: 0.1040
Epoch: 49, Loss: 1.8459, Train: 0.1857, Val: 0.0860, Test: 0.1020
Epoch: 50, Loss: 1.9004, Train: 0.1786, Val: 0.0840, Test: 0.1010
Epoch: 51, Loss: 1.9999, Train: 0.1786, Val: 0.0840, Test: 0.1010
Epoch: 52, Loss: 2.0925, Train: 0.1857, Val: 0.0820, Test: 0.1020
Epoch: 53, Loss: 2.0324, Train: 0.1857, Val: 0.0840, Test: 0.1000
Epoch: 54, Loss: 2.0312, Train: 0.1857, Val: 0.0820, Test: 0.1000
Epoch: 55, Loss: 1.9694, Train: 0.1929, Val: 0.0800, Test: 0.1010
Epoch: 56, Loss: 1.9073, Train: 0.1929, Val: 0.0800, Test: 0.1010
Epoch: 57, Loss: 1.9163, Train: 0.1929, Val: 0.0800, Test: 0.1000
Epoch: 58, Loss: 1.9643, Train: 0.1786, Val: 0.0780, Test: 0.1000
Epoch: 59, Loss: 1.9068, Train: 0.1786, Val: 0.0780, Test: 0.0980
Epoch: 60, Loss: 1.9599, Train: 0.1786, Val: 0.0740, Test: 0.0950
Epoch: 61, Loss: 1.9433, Train: 0.1786, Val: 0.0740, Test: 0.0950
Epoch: 62, Loss: 2.0593, Train: 0.1786, Val: 0.0760, Test: 0.0950
Epoch: 63, Loss: 2.0006, Train: 0.1786, Val: 0.0760, Test: 0.0950
Epoch: 64, Loss: 1.9125, Train: 0.1786, Val: 0.0760, Test: 0.0950
Epoch: 65, Loss: 1.9076, Train: 0.1857, Val: 0.0760, Test: 0.0980
Epoch: 66, Loss: 1.9416, Train: 0.1857, Val: 0.0760, Test: 0.0990
Epoch: 67, Loss: 1.9953, Train: 0.1857, Val: 0.0760, Test: 0.0990
Epoch: 68, Loss: 2.0010, Train: 0.1857, Val: 0.0760, Test: 0.0990
Epoch: 69, Loss: 1.9236, Train: 0.1857, Val: 0.0760, Test: 0.0990
Epoch: 70, Loss: 1.8606, Train: 0.1857, Val: 0.0760, Test: 0.1000
Epoch: 71, Loss: 1.8866, Train: 0.1857, Val: 0.0760, Test: 0.1000
Epoch: 72, Loss: 1.8661, Train: 0.1857, Val: 0.0760, Test: 0.1000
Epoch: 73, Loss: 1.9052, Train: 0.1857, Val: 0.0760, Test: 0.1000
Epoch: 74, Loss: 1.8717, Train: 0.1929, Val: 0.0780, Test: 0.1010
Epoch: 75, Loss: 1.8869, Train: 0.1929, Val: 0.0780, Test: 0.1010
Epoch: 76, Loss: 1.8169, Train: 0.1929, Val: 0.0780, Test: 0.1030
Epoch: 77, Loss: 1.8161, Train: 0.1929, Val: 0.0780, Test: 0.1030
Epoch: 78, Loss: 1.8191, Train: 0.1929, Val: 0.0780, Test: 0.1030
Epoch: 79, Loss: 1.8450, Train: 0.1929, Val: 0.0780, Test: 0.1050
Epoch: 80, Loss: 1.8024, Train: 0.2000, Val: 0.0780, Test: 0.1050
Epoch: 81, Loss: 1.9461, Train: 0.2000, Val: 0.0780, Test: 0.1060
Epoch: 82, Loss: 1.8514, Train: 0.2000, Val: 0.0780, Test: 0.1060
Epoch: 83, Loss: 1.8598, Train: 0.2000, Val: 0.0780, Test: 0.1070
Epoch: 84, Loss: 1.8156, Train: 0.2000, Val: 0.0780, Test: 0.1080
Epoch: 85, Loss: 1.8256, Train: 0.2000, Val: 0.0780, Test: 0.1080
Epoch: 86, Loss: 1.8437, Train: 0.2071, Val: 0.0780, Test: 0.1080
Epoch: 87, Loss: 1.7773, Train: 0.2071, Val: 0.0800, Test: 0.1080
Epoch: 88, Loss: 1.8274, Train: 0.2071, Val: 0.0800, Test: 0.1080
Epoch: 89, Loss: 1.8160, Train: 0.2143, Val: 0.0820, Test: 0.1080
Epoch: 90, Loss: 1.7492, Train: 0.2214, Val: 0.0880, Test: 0.1100
Epoch: 91, Loss: 1.7846, Train: 0.2214, Val: 0.0880, Test: 0.1100
Epoch: 92, Loss: 1.7498, Train: 0.2357, Val: 0.0880, Test: 0.1100
Epoch: 93, Loss: 1.7318, Train: 0.2357, Val: 0.0900, Test: 0.1120
Epoch: 94, Loss: 1.6959, Train: 0.2357, Val: 0.0940, Test: 0.1120
Epoch: 95, Loss: 1.7674, Train: 0.2357, Val: 0.0940, Test: 0.1140
Epoch: 96, Loss: 1.7744, Train: 0.2429, Val: 0.1000, Test: 0.1160
Epoch: 97, Loss: 1.8031, Train: 0.2429, Val: 0.1020, Test: 0.1170
Epoch: 98, Loss: 1.7405, Train: 0.2500, Val: 0.1000, Test: 0.1180
Epoch: 99, Loss: 1.7154, Train: 0.2643, Val: 0.0960, Test: 0.1200
Epoch: 100, Loss: 1.7393, Train: 0.2643, Val: 0.0980, Test: 0.1200
Epoch: 101, Loss: 1.7029, Train: 0.2643, Val: 0.0980, Test: 0.1210
Epoch: 102, Loss: 1.7734, Train: 0.2643, Val: 0.0980, Test: 0.1240
Epoch: 103, Loss: 1.6747, Train: 0.2643, Val: 0.0980, Test: 0.1250
Epoch: 104, Loss: 1.7237, Train: 0.2643, Val: 0.0980, Test: 0.1240
Epoch: 105, Loss: 1.7372, Train: 0.2714, Val: 0.0980, Test: 0.1260
Epoch: 106, Loss: 1.7315, Train: 0.2714, Val: 0.1000, Test: 0.1290
Epoch: 107, Loss: 1.6697, Train: 0.2714, Val: 0.1020, Test: 0.1310
Epoch: 108, Loss: 1.7238, Train: 0.2714, Val: 0.1020, Test: 0.1320
Epoch: 109, Loss: 1.6645, Train: 0.2786, Val: 0.1020, Test: 0.1340
Epoch: 110, Loss: 1.6942, Train: 0.2786, Val: 0.1040, Test: 0.1340
Epoch: 111, Loss: 1.6455, Train: 0.2786, Val: 0.1040, Test: 0.1350
Epoch: 112, Loss: 1.6843, Train: 0.2786, Val: 0.1060, Test: 0.1340
Epoch: 113, Loss: 1.6483, Train: 0.2786, Val: 0.1060, Test: 0.1350
Epoch: 114, Loss: 1.6721, Train: 0.2786, Val: 0.1080, Test: 0.1350
Epoch: 115, Loss: 1.6671, Train: 0.2786, Val: 0.1080, Test: 0.1370
Epoch: 116, Loss: 1.6746, Train: 0.2786, Val: 0.1080, Test: 0.1370
Epoch: 117, Loss: 1.7122, Train: 0.2786, Val: 0.1080, Test: 0.1360
Epoch: 118, Loss: 1.6211, Train: 0.2786, Val: 0.1080, Test: 0.1360
Epoch: 119, Loss: 1.6450, Train: 0.2786, Val: 0.1120, Test: 0.1370
Epoch: 120, Loss: 1.6896, Train: 0.2786, Val: 0.1120, Test: 0.1370
Epoch: 121, Loss: 1.6412, Train: 0.2786, Val: 0.1140, Test: 0.1370
Epoch: 122, Loss: 1.6132, Train: 0.2786, Val: 0.1140, Test: 0.1370
Epoch: 123, Loss: 1.6510, Train: 0.2786, Val: 0.1140, Test: 0.1370
Epoch: 124, Loss: 1.6207, Train: 0.2786, Val: 0.1140, Test: 0.1380
Epoch: 125, Loss: 1.5874, Train: 0.2786, Val: 0.1140, Test: 0.1390
Epoch: 126, Loss: 1.6277, Train: 0.2857, Val: 0.1140, Test: 0.1390
Epoch: 127, Loss: 1.6409, Train: 0.2857, Val: 0.1160, Test: 0.1380
Epoch: 128, Loss: 1.6237, Train: 0.2857, Val: 0.1140, Test: 0.1400
Epoch: 129, Loss: 1.6000, Train: 0.2857, Val: 0.1140, Test: 0.1400
Epoch: 130, Loss: 1.6204, Train: 0.2857, Val: 0.1140, Test: 0.1420
Epoch: 131, Loss: 1.6051, Train: 0.2857, Val: 0.1140, Test: 0.1420
Epoch: 132, Loss: 1.6591, Train: 0.2857, Val: 0.1140, Test: 0.1420
Epoch: 133, Loss: 1.6524, Train: 0.2857, Val: 0.1140, Test: 0.1440
Epoch: 134, Loss: 1.6103, Train: 0.2857, Val: 0.1140, Test: 0.1460
Epoch: 135, Loss: 1.6346, Train: 0.2857, Val: 0.1120, Test: 0.1470
Epoch: 136, Loss: 1.6089, Train: 0.2857, Val: 0.1140, Test: 0.1460
Epoch: 137, Loss: 1.6398, Train: 0.2857, Val: 0.1160, Test: 0.1500
Epoch: 138, Loss: 1.6142, Train: 0.2857, Val: 0.1160, Test: 0.1510
Epoch: 139, Loss: 1.5687, Train: 0.2857, Val: 0.1160, Test: 0.1500
Epoch: 140, Loss: 1.6416, Train: 0.2857, Val: 0.1220, Test: 0.1510
Epoch: 141, Loss: 1.5663, Train: 0.2857, Val: 0.1220, Test: 0.1510
Epoch: 142, Loss: 1.5577, Train: 0.2857, Val: 0.1220, Test: 0.1530
Epoch: 143, Loss: 1.5621, Train: 0.2857, Val: 0.1220, Test: 0.1530
Epoch: 144, Loss: 1.5472, Train: 0.2929, Val: 0.1240, Test: 0.1530
Epoch: 145, Loss: 1.6074, Train: 0.2929, Val: 0.1280, Test: 0.1550
Epoch: 146, Loss: 1.5694, Train: 0.2929, Val: 0.1280, Test: 0.1570
Epoch: 147, Loss: 1.5340, Train: 0.2929, Val: 0.1300, Test: 0.1570
Epoch: 148, Loss: 1.7355, Train: 0.2929, Val: 0.1280, Test: 0.1550
Epoch: 149, Loss: 1.6397, Train: 0.2929, Val: 0.1320, Test: 0.1550
Epoch: 150, Loss: 1.5333, Train: 0.2929, Val: 0.1320, Test: 0.1570
Epoch: 151, Loss: 1.5154, Train: 0.3000, Val: 0.1340, Test: 0.1560
Epoch: 152, Loss: 1.6412, Train: 0.3000, Val: 0.1340, Test: 0.1590
Epoch: 153, Loss: 1.4894, Train: 0.3071, Val: 0.1360, Test: 0.1640
Epoch: 154, Loss: 1.5394, Train: 0.3071, Val: 0.1360, Test: 0.1640
Epoch: 155, Loss: 1.5254, Train: 0.3071, Val: 0.1380, Test: 0.1610
Epoch: 156, Loss: 1.5114, Train: 0.3000, Val: 0.1380, Test: 0.1620
Epoch: 157, Loss: 1.5189, Train: 0.3071, Val: 0.1360, Test: 0.1620
Epoch: 158, Loss: 1.4927, Train: 0.3071, Val: 0.1360, Test: 0.1640
Epoch: 159, Loss: 1.4980, Train: 0.3071, Val: 0.1360, Test: 0.1650
Epoch: 160, Loss: 1.5094, Train: 0.3071, Val: 0.1360, Test: 0.1680
Epoch: 161, Loss: 1.4677, Train: 0.3143, Val: 0.1400, Test: 0.1740
Epoch: 162, Loss: 1.4793, Train: 0.3143, Val: 0.1480, Test: 0.1800
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 163, Loss: 1.5029, Train: 0.3143, Val: 0.1500, Test: 0.1870
Epoch: 164, Loss: 1.5943, Train: 0.3214, Val: 0.1500, Test: 0.1870
Epoch: 165, Loss: 1.4428, Train: 0.3214, Val: 0.1540, Test: 0.1910
Epoch: 166, Loss: 1.4446, Train: 0.3214, Val: 0.1640, Test: 0.1960
Epoch: 167, Loss: 1.4801, Train: 0.3357, Val: 0.1780, Test: 0.2050
Epoch: 168, Loss: 1.5021, Train: 0.3429, Val: 0.1740, Test: 0.2090
Epoch: 169, Loss: 1.4375, Train: 0.3643, Val: 0.1860, Test: 0.2170
Epoch: 170, Loss: 1.4283, Train: 0.3643, Val: 0.1980, Test: 0.2160
Epoch: 171, Loss: 1.4265, Train: 0.3857, Val: 0.2060, Test: 0.2230
Epoch: 172, Loss: 1.7805, Train: 0.3929, Val: 0.2120, Test: 0.2300
Epoch: 173, Loss: 1.4569, Train: 0.3929, Val: 0.2160, Test: 0.2330
Epoch: 174, Loss: 1.5163, Train: 0.3786, Val: 0.2020, Test: 0.2280
Epoch: 175, Loss: 1.3815, Train: 0.3500, Val: 0.1980, Test: 0.2210
Epoch: 176, Loss: 1.4194, Train: 0.3500, Val: 0.1940, Test: 0.2170
Epoch: 177, Loss: 1.4116, Train: 0.3500, Val: 0.1880, Test: 0.2130
Epoch: 178, Loss: 1.6541, Train: 0.3500, Val: 0.1800, Test: 0.2120
Epoch: 179, Loss: 1.7284, Train: 0.3500, Val: 0.1800, Test: 0.2110
Epoch: 180, Loss: 1.3617, Train: 0.3500, Val: 0.1720, Test: 0.2120
Epoch: 181, Loss: 1.4405, Train: 0.3429, Val: 0.1700, Test: 0.2070
Epoch: 182, Loss: 1.3394, Train: 0.3429, Val: 0.1680, Test: 0.2090
Epoch: 183, Loss: 1.4861, Train: 0.3500, Val: 0.1760, Test: 0.2120
Epoch: 184, Loss: 1.4391, Train: 0.3571, Val: 0.1800, Test: 0.2170
Epoch: 185, Loss: 1.3335, Train: 0.3714, Val: 0.1900, Test: 0.2220
Epoch: 186, Loss: 1.3707, Train: 0.3714, Val: 0.1820, Test: 0.2220
Epoch: 187, Loss: 1.5168, Train: 0.3714, Val: 0.1860, Test: 0.2240
Epoch: 188, Loss: 1.3587, Train: 0.3714, Val: 0.1820, Test: 0.2170
Epoch: 189, Loss: 1.3383, Train: 0.3429, Val: 0.1780, Test: 0.2160
Epoch: 190, Loss: 1.3236, Train: 0.3357, Val: 0.1640, Test: 0.2060
Epoch: 191, Loss: 1.3568, Train: 0.3286, Val: 0.1600, Test: 0.1980
Epoch: 192, Loss: 1.3123, Train: 0.3286, Val: 0.1600, Test: 0.1940
Epoch: 193, Loss: 1.2229, Train: 0.3286, Val: 0.1660, Test: 0.2000
Epoch: 194, Loss: 1.2879, Train: 0.3429, Val: 0.1940, Test: 0.2140
Epoch: 195, Loss: 1.1998, Train: 0.3429, Val: 0.2080, Test: 0.2220
Epoch: 196, Loss: 1.3198, Train: 0.3643, Val: 0.2180, Test: 0.2240
Epoch: 197, Loss: 1.3968, Train: 0.3857, Val: 0.2280, Test: 0.2390
Epoch: 198, Loss: 1.2607, Train: 0.4000, Val: 0.2320, Test: 0.2530
Epoch: 199, Loss: 1.1811, Train: 0.4071, Val: 0.2460, Test: 0.2710
Epoch: 200, Loss: 1.2086, Train: 0.4286, Val: 0.2580, Test: 0.2750
MAD:  0.2137
Best Test Accuracy: 0.3260, Val Accuracy: 0.3100, Train Accuracy: 0.1857
Training completed.
Seed:  8
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 7.5130, Train: 0.1857, Val: 0.2620, Test: 0.2680
Epoch: 2, Loss: 5.9048, Train: 0.2214, Val: 0.1900, Test: 0.1950
Epoch: 3, Loss: 4.4450, Train: 0.1929, Val: 0.1460, Test: 0.1530
Epoch: 4, Loss: 3.5440, Train: 0.2143, Val: 0.1440, Test: 0.1540
Epoch: 5, Loss: 3.2081, Train: 0.1714, Val: 0.1620, Test: 0.1890
Epoch: 6, Loss: 3.2867, Train: 0.1643, Val: 0.1700, Test: 0.1700
Epoch: 7, Loss: 2.9287, Train: 0.1500, Val: 0.1620, Test: 0.1590
Epoch: 8, Loss: 2.5337, Train: 0.1500, Val: 0.1580, Test: 0.1540
Epoch: 9, Loss: 2.4571, Train: 0.1500, Val: 0.1620, Test: 0.1540
Epoch: 10, Loss: 2.6488, Train: 0.1500, Val: 0.1620, Test: 0.1520
Epoch: 11, Loss: 2.2970, Train: 0.1500, Val: 0.1640, Test: 0.1510
Epoch: 12, Loss: 2.4362, Train: 0.1571, Val: 0.1760, Test: 0.1510
Epoch: 13, Loss: 2.3736, Train: 0.1643, Val: 0.1800, Test: 0.1520
Epoch: 14, Loss: 2.2839, Train: 0.1786, Val: 0.1900, Test: 0.1620
Epoch: 15, Loss: 2.3283, Train: 0.1786, Val: 0.2040, Test: 0.1810
Epoch: 16, Loss: 2.1490, Train: 0.2429, Val: 0.2400, Test: 0.2020
Epoch: 17, Loss: 1.9997, Train: 0.2143, Val: 0.2400, Test: 0.2090
Epoch: 18, Loss: 2.1012, Train: 0.2143, Val: 0.2120, Test: 0.1990
Epoch: 19, Loss: 2.1590, Train: 0.2143, Val: 0.2060, Test: 0.1830
Epoch: 20, Loss: 2.0868, Train: 0.2071, Val: 0.1980, Test: 0.1720
Epoch: 21, Loss: 2.2046, Train: 0.2143, Val: 0.1840, Test: 0.1710
Epoch: 22, Loss: 2.1820, Train: 0.2143, Val: 0.1740, Test: 0.1680
Epoch: 23, Loss: 2.1166, Train: 0.2071, Val: 0.1700, Test: 0.1650
Epoch: 24, Loss: 2.0434, Train: 0.2000, Val: 0.1680, Test: 0.1640
Epoch: 25, Loss: 1.9884, Train: 0.2143, Val: 0.1660, Test: 0.1630
Epoch: 26, Loss: 2.1134, Train: 0.2286, Val: 0.1660, Test: 0.1630
Epoch: 27, Loss: 2.0095, Train: 0.2357, Val: 0.1700, Test: 0.1620
Epoch: 28, Loss: 2.0679, Train: 0.2357, Val: 0.1720, Test: 0.1670
Epoch: 29, Loss: 2.0450, Train: 0.2429, Val: 0.1720, Test: 0.1640
Epoch: 30, Loss: 2.1221, Train: 0.2500, Val: 0.1720, Test: 0.1660
Epoch: 31, Loss: 1.9984, Train: 0.2571, Val: 0.1800, Test: 0.1640
Epoch: 32, Loss: 1.9645, Train: 0.2643, Val: 0.1680, Test: 0.1660
Epoch: 33, Loss: 2.0353, Train: 0.2571, Val: 0.1620, Test: 0.1620
Epoch: 34, Loss: 1.9835, Train: 0.2571, Val: 0.1520, Test: 0.1670
Epoch: 35, Loss: 1.9299, Train: 0.2571, Val: 0.1360, Test: 0.1500
Epoch: 36, Loss: 1.9261, Train: 0.2643, Val: 0.1320, Test: 0.1390
Epoch: 37, Loss: 1.9966, Train: 0.2500, Val: 0.1180, Test: 0.1300
Epoch: 38, Loss: 2.1061, Train: 0.2500, Val: 0.1060, Test: 0.1280
Epoch: 39, Loss: 1.9520, Train: 0.2286, Val: 0.0940, Test: 0.1220
Epoch: 40, Loss: 1.9318, Train: 0.2214, Val: 0.0860, Test: 0.1070
Epoch: 41, Loss: 2.0732, Train: 0.2143, Val: 0.0820, Test: 0.1040
Epoch: 42, Loss: 2.0463, Train: 0.1929, Val: 0.0780, Test: 0.1030
Epoch: 43, Loss: 1.9401, Train: 0.1929, Val: 0.0780, Test: 0.0990
Epoch: 44, Loss: 1.9573, Train: 0.2000, Val: 0.0760, Test: 0.1000
Epoch: 45, Loss: 2.1086, Train: 0.2000, Val: 0.0760, Test: 0.0990
Epoch: 46, Loss: 2.1412, Train: 0.2000, Val: 0.0740, Test: 0.0980
Epoch: 47, Loss: 1.8998, Train: 0.2000, Val: 0.0740, Test: 0.0980
Epoch: 48, Loss: 2.0820, Train: 0.2000, Val: 0.0740, Test: 0.0990
Epoch: 49, Loss: 2.1006, Train: 0.1929, Val: 0.0740, Test: 0.0980
Epoch: 50, Loss: 1.9498, Train: 0.1929, Val: 0.0740, Test: 0.0970
Epoch: 51, Loss: 1.9306, Train: 0.1857, Val: 0.0740, Test: 0.0960
Epoch: 52, Loss: 2.0051, Train: 0.1857, Val: 0.0740, Test: 0.0960
Epoch: 53, Loss: 1.9631, Train: 0.1857, Val: 0.0740, Test: 0.0960
Epoch: 54, Loss: 1.9506, Train: 0.1929, Val: 0.0740, Test: 0.0970
Epoch: 55, Loss: 1.9447, Train: 0.1929, Val: 0.0720, Test: 0.0980
Epoch: 56, Loss: 1.8681, Train: 0.1929, Val: 0.0720, Test: 0.0990
Epoch: 57, Loss: 1.9863, Train: 0.1857, Val: 0.0720, Test: 0.1010
Epoch: 58, Loss: 1.9270, Train: 0.1857, Val: 0.0720, Test: 0.1010
Epoch: 59, Loss: 1.9129, Train: 0.1857, Val: 0.0720, Test: 0.1010
Epoch: 60, Loss: 1.9917, Train: 0.1857, Val: 0.0720, Test: 0.1010
Epoch: 61, Loss: 1.9730, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 62, Loss: 1.9067, Train: 0.2071, Val: 0.0720, Test: 0.1010
Epoch: 63, Loss: 1.8748, Train: 0.2143, Val: 0.0720, Test: 0.1020
Epoch: 64, Loss: 1.8880, Train: 0.2143, Val: 0.0720, Test: 0.1030
Epoch: 65, Loss: 1.9107, Train: 0.2214, Val: 0.0720, Test: 0.1040
Epoch: 66, Loss: 1.9048, Train: 0.2286, Val: 0.0720, Test: 0.1040
Epoch: 67, Loss: 2.0212, Train: 0.2143, Val: 0.0720, Test: 0.1050
Epoch: 68, Loss: 1.8728, Train: 0.2143, Val: 0.0720, Test: 0.1040
Epoch: 69, Loss: 2.0830, Train: 0.2143, Val: 0.0720, Test: 0.1040
Epoch: 70, Loss: 1.9208, Train: 0.2143, Val: 0.0720, Test: 0.1040
Epoch: 71, Loss: 1.8621, Train: 0.2143, Val: 0.0740, Test: 0.1040
Epoch: 72, Loss: 1.7967, Train: 0.2143, Val: 0.0740, Test: 0.1040
Epoch: 73, Loss: 1.8586, Train: 0.2143, Val: 0.0740, Test: 0.1040
Epoch: 74, Loss: 1.8738, Train: 0.2143, Val: 0.0740, Test: 0.1040
Epoch: 75, Loss: 1.8589, Train: 0.2143, Val: 0.0740, Test: 0.1040
Epoch: 76, Loss: 1.8547, Train: 0.2143, Val: 0.0740, Test: 0.1040
Epoch: 77, Loss: 1.8487, Train: 0.2214, Val: 0.0760, Test: 0.1040
Epoch: 78, Loss: 1.8235, Train: 0.2214, Val: 0.0760, Test: 0.1060
Epoch: 79, Loss: 1.8329, Train: 0.2214, Val: 0.0760, Test: 0.1060
Epoch: 80, Loss: 1.8398, Train: 0.2286, Val: 0.0760, Test: 0.1050
Epoch: 81, Loss: 1.8457, Train: 0.2357, Val: 0.0760, Test: 0.1050
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 82, Loss: 1.7601, Train: 0.2357, Val: 0.0800, Test: 0.1050
Epoch: 83, Loss: 1.7945, Train: 0.2357, Val: 0.0800, Test: 0.1050
Epoch: 84, Loss: 1.7730, Train: 0.2357, Val: 0.0840, Test: 0.1060
Epoch: 85, Loss: 1.7777, Train: 0.2357, Val: 0.0840, Test: 0.1060
Epoch: 86, Loss: 1.8201, Train: 0.2357, Val: 0.0880, Test: 0.1070
Epoch: 87, Loss: 1.8543, Train: 0.2429, Val: 0.0900, Test: 0.1070
Epoch: 88, Loss: 1.7904, Train: 0.2429, Val: 0.0900, Test: 0.1080
Epoch: 89, Loss: 1.7459, Train: 0.2429, Val: 0.0940, Test: 0.1100
Epoch: 90, Loss: 2.0958, Train: 0.2429, Val: 0.0940, Test: 0.1100
Epoch: 91, Loss: 1.8290, Train: 0.2429, Val: 0.0940, Test: 0.1100
Epoch: 92, Loss: 1.8595, Train: 0.2500, Val: 0.0940, Test: 0.1100
Epoch: 93, Loss: 1.8709, Train: 0.2571, Val: 0.0940, Test: 0.1110
Epoch: 94, Loss: 1.7600, Train: 0.2571, Val: 0.0940, Test: 0.1110
Epoch: 95, Loss: 1.7407, Train: 0.2571, Val: 0.0940, Test: 0.1130
Epoch: 96, Loss: 1.7487, Train: 0.2571, Val: 0.0940, Test: 0.1140
Epoch: 97, Loss: 1.8494, Train: 0.2571, Val: 0.0980, Test: 0.1160
Epoch: 98, Loss: 1.7259, Train: 0.2571, Val: 0.1000, Test: 0.1180
Epoch: 99, Loss: 1.7394, Train: 0.2571, Val: 0.1040, Test: 0.1190
Epoch: 100, Loss: 1.7057, Train: 0.2643, Val: 0.1040, Test: 0.1220
Epoch: 101, Loss: 1.7270, Train: 0.2714, Val: 0.1080, Test: 0.1220
Epoch: 102, Loss: 1.6883, Train: 0.2714, Val: 0.1060, Test: 0.1240
Epoch: 103, Loss: 1.7164, Train: 0.2714, Val: 0.1100, Test: 0.1280
Epoch: 104, Loss: 1.7604, Train: 0.2786, Val: 0.1080, Test: 0.1290
Epoch: 105, Loss: 1.7537, Train: 0.2786, Val: 0.1120, Test: 0.1320
Epoch: 106, Loss: 1.6768, Train: 0.2786, Val: 0.1120, Test: 0.1340
Epoch: 107, Loss: 1.7628, Train: 0.2786, Val: 0.1140, Test: 0.1350
Epoch: 108, Loss: 1.6893, Train: 0.2857, Val: 0.1140, Test: 0.1340
Epoch: 109, Loss: 1.6662, Train: 0.2857, Val: 0.1120, Test: 0.1390
Epoch: 110, Loss: 1.7142, Train: 0.2857, Val: 0.1120, Test: 0.1420
Epoch: 111, Loss: 1.6784, Train: 0.2857, Val: 0.1100, Test: 0.1470
Epoch: 112, Loss: 1.6473, Train: 0.2857, Val: 0.1120, Test: 0.1490
Epoch: 113, Loss: 1.7341, Train: 0.2857, Val: 0.1120, Test: 0.1480
Epoch: 114, Loss: 1.6509, Train: 0.2857, Val: 0.1120, Test: 0.1480
Epoch: 115, Loss: 1.6531, Train: 0.2929, Val: 0.1140, Test: 0.1520
Epoch: 116, Loss: 1.6774, Train: 0.2929, Val: 0.1180, Test: 0.1520
Epoch: 117, Loss: 1.6634, Train: 0.2929, Val: 0.1180, Test: 0.1520
Epoch: 118, Loss: 1.7315, Train: 0.2857, Val: 0.1140, Test: 0.1500
Epoch: 119, Loss: 1.6563, Train: 0.2857, Val: 0.1120, Test: 0.1490
Epoch: 120, Loss: 1.6918, Train: 0.2857, Val: 0.1120, Test: 0.1470
Epoch: 121, Loss: 1.6888, Train: 0.2857, Val: 0.1140, Test: 0.1460
Epoch: 122, Loss: 1.6345, Train: 0.2857, Val: 0.1120, Test: 0.1460
Epoch: 123, Loss: 1.6600, Train: 0.2857, Val: 0.1120, Test: 0.1470
Epoch: 124, Loss: 1.6362, Train: 0.2857, Val: 0.1120, Test: 0.1460
Epoch: 125, Loss: 1.6041, Train: 0.2857, Val: 0.1120, Test: 0.1460
Epoch: 126, Loss: 1.6214, Train: 0.2857, Val: 0.1120, Test: 0.1470
Epoch: 127, Loss: 1.6128, Train: 0.2857, Val: 0.1120, Test: 0.1500
Epoch: 128, Loss: 1.6286, Train: 0.2857, Val: 0.1160, Test: 0.1530
Epoch: 129, Loss: 1.6615, Train: 0.3000, Val: 0.1180, Test: 0.1570
Epoch: 130, Loss: 1.7033, Train: 0.3000, Val: 0.1220, Test: 0.1670
Epoch: 131, Loss: 1.6244, Train: 0.3000, Val: 0.1260, Test: 0.1730
Epoch: 132, Loss: 1.6482, Train: 0.3143, Val: 0.1280, Test: 0.1790
Epoch: 133, Loss: 1.6304, Train: 0.3286, Val: 0.1340, Test: 0.1800
Epoch: 134, Loss: 1.5612, Train: 0.3286, Val: 0.1420, Test: 0.1820
Epoch: 135, Loss: 1.6056, Train: 0.3286, Val: 0.1480, Test: 0.1850
Epoch: 136, Loss: 1.5842, Train: 0.3357, Val: 0.1520, Test: 0.1870
Epoch: 137, Loss: 1.5660, Train: 0.3357, Val: 0.1500, Test: 0.1880
Epoch: 138, Loss: 1.6177, Train: 0.3357, Val: 0.1500, Test: 0.1870
Epoch: 139, Loss: 1.9280, Train: 0.3357, Val: 0.1500, Test: 0.1860
Epoch: 140, Loss: 1.5508, Train: 0.3357, Val: 0.1500, Test: 0.1840
Epoch: 141, Loss: 1.5683, Train: 0.3286, Val: 0.1420, Test: 0.1840
Epoch: 142, Loss: 1.6015, Train: 0.3143, Val: 0.1340, Test: 0.1820
Epoch: 143, Loss: 1.5823, Train: 0.3143, Val: 0.1320, Test: 0.1790
Epoch: 144, Loss: 1.5455, Train: 0.3143, Val: 0.1320, Test: 0.1780
Epoch: 145, Loss: 1.5571, Train: 0.3143, Val: 0.1340, Test: 0.1790
Epoch: 146, Loss: 1.5577, Train: 0.3214, Val: 0.1420, Test: 0.1830
Epoch: 147, Loss: 1.5476, Train: 0.3214, Val: 0.1400, Test: 0.1860
Epoch: 148, Loss: 1.5291, Train: 0.3357, Val: 0.1380, Test: 0.1900
Epoch: 149, Loss: 1.5106, Train: 0.3500, Val: 0.1380, Test: 0.1950
Epoch: 150, Loss: 1.5249, Train: 0.3643, Val: 0.1580, Test: 0.2010
Epoch: 151, Loss: 1.5102, Train: 0.3714, Val: 0.1680, Test: 0.2110
Epoch: 152, Loss: 1.5351, Train: 0.3786, Val: 0.1800, Test: 0.2180
Epoch: 153, Loss: 1.4736, Train: 0.4000, Val: 0.1840, Test: 0.2210
Epoch: 154, Loss: 1.6698, Train: 0.4000, Val: 0.1840, Test: 0.2200
Epoch: 155, Loss: 1.4970, Train: 0.4071, Val: 0.1820, Test: 0.2200
Epoch: 156, Loss: 1.5008, Train: 0.4071, Val: 0.1800, Test: 0.2190
Epoch: 157, Loss: 1.5125, Train: 0.3929, Val: 0.1740, Test: 0.2160
Epoch: 158, Loss: 1.5013, Train: 0.3929, Val: 0.1760, Test: 0.2110
Epoch: 159, Loss: 1.4914, Train: 0.3857, Val: 0.1620, Test: 0.2100
Epoch: 160, Loss: 1.4542, Train: 0.3714, Val: 0.1600, Test: 0.2070
Epoch: 161, Loss: 1.5274, Train: 0.3643, Val: 0.1580, Test: 0.2070
Epoch: 162, Loss: 1.4734, Train: 0.3571, Val: 0.1580, Test: 0.2060
Epoch: 163, Loss: 1.4804, Train: 0.3571, Val: 0.1580, Test: 0.2070
Epoch: 164, Loss: 1.5762, Train: 0.3643, Val: 0.1600, Test: 0.2120
Epoch: 165, Loss: 1.4508, Train: 0.3714, Val: 0.1600, Test: 0.2130
Epoch: 166, Loss: 1.4788, Train: 0.3714, Val: 0.1560, Test: 0.2100
Epoch: 167, Loss: 1.4220, Train: 0.3643, Val: 0.1580, Test: 0.2110
Epoch: 168, Loss: 1.4263, Train: 0.3643, Val: 0.1640, Test: 0.2130
Epoch: 169, Loss: 1.4805, Train: 0.3643, Val: 0.1620, Test: 0.2120
Epoch: 170, Loss: 1.3774, Train: 0.3643, Val: 0.1540, Test: 0.2120
Epoch: 171, Loss: 1.4055, Train: 0.3643, Val: 0.1540, Test: 0.2090
Epoch: 172, Loss: 1.5230, Train: 0.3643, Val: 0.1640, Test: 0.2070
Epoch: 173, Loss: 1.4190, Train: 0.3643, Val: 0.1640, Test: 0.2130
Epoch: 174, Loss: 1.4428, Train: 0.3643, Val: 0.1700, Test: 0.2170
Epoch: 175, Loss: 1.5006, Train: 0.3643, Val: 0.1680, Test: 0.2130
Epoch: 176, Loss: 1.4433, Train: 0.3643, Val: 0.1640, Test: 0.2130
Epoch: 177, Loss: 1.4033, Train: 0.3643, Val: 0.1720, Test: 0.2170
Epoch: 178, Loss: 1.3564, Train: 0.3714, Val: 0.1740, Test: 0.2170
Epoch: 179, Loss: 1.3964, Train: 0.3714, Val: 0.1780, Test: 0.2210
Epoch: 180, Loss: 1.4384, Train: 0.3714, Val: 0.1800, Test: 0.2210
Epoch: 181, Loss: 1.4264, Train: 0.3714, Val: 0.1820, Test: 0.2220
Epoch: 182, Loss: 1.4483, Train: 0.3714, Val: 0.1800, Test: 0.2240
Epoch: 183, Loss: 1.4843, Train: 0.3714, Val: 0.1820, Test: 0.2260
Epoch: 184, Loss: 1.3958, Train: 0.3929, Val: 0.1840, Test: 0.2260
Epoch: 185, Loss: 1.4258, Train: 0.3929, Val: 0.1820, Test: 0.2250
Epoch: 186, Loss: 1.3308, Train: 0.3929, Val: 0.1860, Test: 0.2280
Epoch: 187, Loss: 1.4476, Train: 0.3857, Val: 0.1800, Test: 0.2200
Epoch: 188, Loss: 1.3547, Train: 0.3857, Val: 0.1720, Test: 0.2170
Epoch: 189, Loss: 1.4011, Train: 0.3857, Val: 0.1680, Test: 0.2120
Epoch: 190, Loss: 1.3740, Train: 0.3857, Val: 0.1660, Test: 0.2110
Epoch: 191, Loss: 1.2808, Train: 0.3857, Val: 0.1660, Test: 0.2120
Epoch: 192, Loss: 1.3452, Train: 0.3857, Val: 0.1700, Test: 0.2110
Epoch: 193, Loss: 1.3940, Train: 0.3857, Val: 0.1720, Test: 0.2130
Epoch: 194, Loss: 1.2933, Train: 0.3857, Val: 0.1780, Test: 0.2170
Epoch: 195, Loss: 1.4045, Train: 0.3857, Val: 0.1780, Test: 0.2220
Epoch: 196, Loss: 1.2715, Train: 0.3857, Val: 0.1740, Test: 0.2230
Epoch: 197, Loss: 1.2173, Train: 0.3786, Val: 0.1740, Test: 0.2270
Epoch: 198, Loss: 1.2903, Train: 0.3786, Val: 0.1820, Test: 0.2310
Epoch: 199, Loss: 1.2749, Train: 0.3786, Val: 0.1900, Test: 0.2370
Epoch: 200, Loss: 1.3336, Train: 0.3929, Val: 0.2080, Test: 0.2440
MAD:  0.0995
Best Test Accuracy: 0.2680, Val Accuracy: 0.2620, Train Accuracy: 0.1857
Training completed.
Seed:  9
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-9): 9 x GCNConv(128, 128)
    (10): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 7.6971, Train: 0.2429, Val: 0.2300, Test: 0.2200
Epoch: 2, Loss: 5.0926, Train: 0.1429, Val: 0.1220, Test: 0.1300
Epoch: 3, Loss: 4.1178, Train: 0.1500, Val: 0.1020, Test: 0.1200
Epoch: 4, Loss: 3.9671, Train: 0.1786, Val: 0.1280, Test: 0.1160
Epoch: 5, Loss: 3.1901, Train: 0.1500, Val: 0.0980, Test: 0.0900
Epoch: 6, Loss: 3.2174, Train: 0.1429, Val: 0.0820, Test: 0.0780
Epoch: 7, Loss: 2.6185, Train: 0.1500, Val: 0.0700, Test: 0.0720
Epoch: 8, Loss: 2.5760, Train: 0.1571, Val: 0.0660, Test: 0.0680
Epoch: 9, Loss: 2.4102, Train: 0.1571, Val: 0.0640, Test: 0.0650
Epoch: 10, Loss: 2.4522, Train: 0.1571, Val: 0.0620, Test: 0.0650
Epoch: 11, Loss: 2.7247, Train: 0.1500, Val: 0.0600, Test: 0.0650
Epoch: 12, Loss: 2.3216, Train: 0.1500, Val: 0.0600, Test: 0.0660
Epoch: 13, Loss: 2.2886, Train: 0.1500, Val: 0.0660, Test: 0.0680
Epoch: 14, Loss: 2.3492, Train: 0.1571, Val: 0.0680, Test: 0.0760
Epoch: 15, Loss: 2.1871, Train: 0.1714, Val: 0.0740, Test: 0.0800
Epoch: 16, Loss: 2.3914, Train: 0.1786, Val: 0.0760, Test: 0.0880
Epoch: 17, Loss: 2.0740, Train: 0.1857, Val: 0.0980, Test: 0.1110
Epoch: 18, Loss: 2.1408, Train: 0.2357, Val: 0.1340, Test: 0.1350
Epoch: 19, Loss: 2.1088, Train: 0.2786, Val: 0.1260, Test: 0.1420
Epoch: 20, Loss: 2.1058, Train: 0.2500, Val: 0.1260, Test: 0.1430
Epoch: 21, Loss: 2.0645, Train: 0.2500, Val: 0.1360, Test: 0.1540
Epoch: 22, Loss: 2.0703, Train: 0.2500, Val: 0.1340, Test: 0.1500
Epoch: 23, Loss: 2.1617, Train: 0.2571, Val: 0.1360, Test: 0.1550
Epoch: 24, Loss: 2.0702, Train: 0.2643, Val: 0.1380, Test: 0.1500
Epoch: 25, Loss: 2.0507, Train: 0.2643, Val: 0.1380, Test: 0.1500
Epoch: 26, Loss: 2.0318, Train: 0.2214, Val: 0.1340, Test: 0.1490
Epoch: 27, Loss: 2.0587, Train: 0.1857, Val: 0.1440, Test: 0.1440
Epoch: 28, Loss: 1.9042, Train: 0.1857, Val: 0.1460, Test: 0.1370
Epoch: 29, Loss: 2.0053, Train: 0.1786, Val: 0.1420, Test: 0.1310
Epoch: 30, Loss: 1.9181, Train: 0.1714, Val: 0.1420, Test: 0.1350
Epoch: 31, Loss: 2.0011, Train: 0.1714, Val: 0.1380, Test: 0.1330
Epoch: 32, Loss: 2.0848, Train: 0.1571, Val: 0.1360, Test: 0.1350
Epoch: 33, Loss: 1.9492, Train: 0.1571, Val: 0.1340, Test: 0.1370
Epoch: 34, Loss: 1.9605, Train: 0.1643, Val: 0.1300, Test: 0.1370
Epoch: 35, Loss: 1.9486, Train: 0.1857, Val: 0.1240, Test: 0.1290
Epoch: 36, Loss: 1.9362, Train: 0.1929, Val: 0.1200, Test: 0.1220
Epoch: 37, Loss: 2.0129, Train: 0.2071, Val: 0.1160, Test: 0.1220
Epoch: 38, Loss: 2.0505, Train: 0.2071, Val: 0.1040, Test: 0.1210
Epoch: 39, Loss: 1.9853, Train: 0.2214, Val: 0.1000, Test: 0.1150
Epoch: 40, Loss: 2.1238, Train: 0.2143, Val: 0.0960, Test: 0.1100
Epoch: 41, Loss: 1.8726, Train: 0.2143, Val: 0.0920, Test: 0.1090
Epoch: 42, Loss: 2.0145, Train: 0.2000, Val: 0.0880, Test: 0.1030
Epoch: 43, Loss: 1.8860, Train: 0.2000, Val: 0.0880, Test: 0.1000
Epoch: 44, Loss: 2.0457, Train: 0.2000, Val: 0.0880, Test: 0.1010
Epoch: 45, Loss: 1.9708, Train: 0.2071, Val: 0.0840, Test: 0.1000
Epoch: 46, Loss: 1.9751, Train: 0.2071, Val: 0.0820, Test: 0.1000
Epoch: 47, Loss: 1.8958, Train: 0.2071, Val: 0.0800, Test: 0.1010
Epoch: 48, Loss: 1.9589, Train: 0.2143, Val: 0.0760, Test: 0.1010
Epoch: 49, Loss: 1.9492, Train: 0.2143, Val: 0.0720, Test: 0.0990
Epoch: 50, Loss: 2.1836, Train: 0.2143, Val: 0.0720, Test: 0.1000
Epoch: 51, Loss: 2.0317, Train: 0.2071, Val: 0.0720, Test: 0.0990
Epoch: 52, Loss: 1.9547, Train: 0.2071, Val: 0.0720, Test: 0.0990
Epoch: 53, Loss: 1.9466, Train: 0.2000, Val: 0.0720, Test: 0.0990
Epoch: 54, Loss: 1.9549, Train: 0.2000, Val: 0.0720, Test: 0.0970
Epoch: 55, Loss: 1.8935, Train: 0.2000, Val: 0.0720, Test: 0.0970
Epoch: 56, Loss: 1.9779, Train: 0.2000, Val: 0.0720, Test: 0.0970
Epoch: 57, Loss: 1.9128, Train: 0.2000, Val: 0.0720, Test: 0.0970
Epoch: 58, Loss: 1.8885, Train: 0.2000, Val: 0.0720, Test: 0.0960
Epoch: 59, Loss: 1.8862, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 60, Loss: 1.8625, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 61, Loss: 1.9166, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 62, Loss: 1.8728, Train: 0.2000, Val: 0.0740, Test: 0.0960
Epoch: 63, Loss: 1.9725, Train: 0.2000, Val: 0.0740, Test: 0.0960
Epoch: 64, Loss: 1.9200, Train: 0.2000, Val: 0.0740, Test: 0.0970
Epoch: 65, Loss: 1.8712, Train: 0.2000, Val: 0.0760, Test: 0.0980
Epoch: 66, Loss: 1.9601, Train: 0.2214, Val: 0.0780, Test: 0.1000
Epoch: 67, Loss: 1.8279, Train: 0.2286, Val: 0.0800, Test: 0.1050
Epoch: 68, Loss: 1.8523, Train: 0.2429, Val: 0.0800, Test: 0.1040
Epoch: 69, Loss: 1.8368, Train: 0.2429, Val: 0.0780, Test: 0.1060
Epoch: 70, Loss: 1.8655, Train: 0.2429, Val: 0.0780, Test: 0.1080
Epoch: 71, Loss: 1.8197, Train: 0.2429, Val: 0.0760, Test: 0.1090
Epoch: 72, Loss: 1.8824, Train: 0.2500, Val: 0.0800, Test: 0.1120
Epoch: 73, Loss: 1.9214, Train: 0.2500, Val: 0.0840, Test: 0.1110
Epoch: 74, Loss: 1.8644, Train: 0.2571, Val: 0.0860, Test: 0.1130
Epoch: 75, Loss: 1.8415, Train: 0.2714, Val: 0.0860, Test: 0.1120
Epoch: 76, Loss: 1.8697, Train: 0.2714, Val: 0.0860, Test: 0.1180
Epoch: 77, Loss: 1.8284, Train: 0.2714, Val: 0.0880, Test: 0.1180
Epoch: 78, Loss: 1.8835, Train: 0.2714, Val: 0.0880, Test: 0.1180
Epoch: 79, Loss: 1.8762, Train: 0.2786, Val: 0.0880, Test: 0.1180
Epoch: 80, Loss: 1.8206, Train: 0.2714, Val: 0.0880, Test: 0.1180
Epoch: 81, Loss: 1.7838, Train: 0.2786, Val: 0.0900, Test: 0.1190
Epoch: 82, Loss: 1.7850, Train: 0.2786, Val: 0.0920, Test: 0.1200
Epoch: 83, Loss: 1.8161, Train: 0.2786, Val: 0.0920, Test: 0.1210
Epoch: 84, Loss: 2.0564, Train: 0.2786, Val: 0.0920, Test: 0.1220
Epoch: 85, Loss: 1.7556, Train: 0.2714, Val: 0.0920, Test: 0.1230
Epoch: 86, Loss: 1.8505, Train: 0.2786, Val: 0.0900, Test: 0.1250
Epoch: 87, Loss: 1.8762, Train: 0.2786, Val: 0.0920, Test: 0.1260
Epoch: 88, Loss: 1.7151, Train: 0.2857, Val: 0.0960, Test: 0.1260
Epoch: 89, Loss: 1.8244, Train: 0.2929, Val: 0.0940, Test: 0.1280
Epoch: 90, Loss: 1.7422, Train: 0.3000, Val: 0.0980, Test: 0.1280
Epoch: 91, Loss: 1.7612, Train: 0.3071, Val: 0.0980, Test: 0.1310
Epoch: 92, Loss: 1.8206, Train: 0.3071, Val: 0.1020, Test: 0.1320
Epoch: 93, Loss: 1.7647, Train: 0.3000, Val: 0.1040, Test: 0.1320
Epoch: 94, Loss: 1.7675, Train: 0.3000, Val: 0.1020, Test: 0.1320
Epoch: 95, Loss: 1.7083, Train: 0.2929, Val: 0.1040, Test: 0.1350
Epoch: 96, Loss: 1.7488, Train: 0.2929, Val: 0.1060, Test: 0.1330
Epoch: 97, Loss: 1.8017, Train: 0.2929, Val: 0.1100, Test: 0.1350
Epoch: 98, Loss: 1.7254, Train: 0.2929, Val: 0.1100, Test: 0.1360
Epoch: 99, Loss: 1.7460, Train: 0.2857, Val: 0.1100, Test: 0.1350
Epoch: 100, Loss: 1.6719, Train: 0.3000, Val: 0.1100, Test: 0.1350
Epoch: 101, Loss: 1.7083, Train: 0.2929, Val: 0.1120, Test: 0.1340
Epoch: 102, Loss: 1.7316, Train: 0.3000, Val: 0.1140, Test: 0.1370
Epoch: 103, Loss: 1.7605, Train: 0.3071, Val: 0.1180, Test: 0.1400
Epoch: 104, Loss: 1.7059, Train: 0.3000, Val: 0.1180, Test: 0.1430
Epoch: 105, Loss: 1.7278, Train: 0.3000, Val: 0.1240, Test: 0.1480
Epoch: 106, Loss: 1.6543, Train: 0.3214, Val: 0.1300, Test: 0.1490
Epoch: 107, Loss: 1.6876, Train: 0.3143, Val: 0.1260, Test: 0.1510
Epoch: 108, Loss: 1.6254, Train: 0.3143, Val: 0.1320, Test: 0.1570
Epoch: 109, Loss: 1.6593, Train: 0.3214, Val: 0.1340, Test: 0.1590
Epoch: 110, Loss: 1.5714, Train: 0.3143, Val: 0.1400, Test: 0.1620
Epoch: 111, Loss: 1.6592, Train: 0.3286, Val: 0.1380, Test: 0.1640
Epoch: 112, Loss: 1.5640, Train: 0.3286, Val: 0.1440, Test: 0.1690
Epoch: 113, Loss: 1.7219, Train: 0.3214, Val: 0.1440, Test: 0.1760
Epoch: 114, Loss: 1.6304, Train: 0.3357, Val: 0.1520, Test: 0.1780
Epoch: 115, Loss: 1.5983, Train: 0.3500, Val: 0.1580, Test: 0.1820
Epoch: 116, Loss: 1.6456, Train: 0.3500, Val: 0.1620, Test: 0.1870
Epoch: 117, Loss: 1.5830, Train: 0.3500, Val: 0.1620, Test: 0.1860
Epoch: 118, Loss: 1.5849, Train: 0.3357, Val: 0.1720, Test: 0.1900
Epoch: 119, Loss: 1.6704, Train: 0.3429, Val: 0.1760, Test: 0.1980
Epoch: 120, Loss: 1.5826, Train: 0.3357, Val: 0.1760, Test: 0.1980
Epoch: 121, Loss: 1.6319, Train: 0.3429, Val: 0.1740, Test: 0.1950
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 122, Loss: 1.5742, Train: 0.3500, Val: 0.1760, Test: 0.1970
Epoch: 123, Loss: 1.6561, Train: 0.3500, Val: 0.1720, Test: 0.1980
Epoch: 124, Loss: 1.6206, Train: 0.3714, Val: 0.1780, Test: 0.2010
Epoch: 125, Loss: 1.6913, Train: 0.3714, Val: 0.1840, Test: 0.2040
Epoch: 126, Loss: 1.6319, Train: 0.3857, Val: 0.1840, Test: 0.2050
Epoch: 127, Loss: 1.6312, Train: 0.3929, Val: 0.1800, Test: 0.2020
Epoch: 128, Loss: 1.5525, Train: 0.3786, Val: 0.1780, Test: 0.1990
Epoch: 129, Loss: 1.5258, Train: 0.3786, Val: 0.1760, Test: 0.1990
Epoch: 130, Loss: 1.6057, Train: 0.3714, Val: 0.1720, Test: 0.1990
Epoch: 131, Loss: 1.6322, Train: 0.3643, Val: 0.1680, Test: 0.1970
Epoch: 132, Loss: 1.5486, Train: 0.3643, Val: 0.1700, Test: 0.1990
Epoch: 133, Loss: 1.5611, Train: 0.3643, Val: 0.1700, Test: 0.2000
Epoch: 134, Loss: 1.5236, Train: 0.3571, Val: 0.1720, Test: 0.1980
Epoch: 135, Loss: 1.5397, Train: 0.3571, Val: 0.1760, Test: 0.1990
Epoch: 136, Loss: 1.5187, Train: 0.3643, Val: 0.1760, Test: 0.2020
Epoch: 137, Loss: 1.5299, Train: 0.3786, Val: 0.1760, Test: 0.2010
Epoch: 138, Loss: 1.5928, Train: 0.3714, Val: 0.1820, Test: 0.2020
Epoch: 139, Loss: 1.5210, Train: 0.3786, Val: 0.1840, Test: 0.2010
Epoch: 140, Loss: 1.5148, Train: 0.3786, Val: 0.1800, Test: 0.2010
Epoch: 141, Loss: 1.5463, Train: 0.3857, Val: 0.1820, Test: 0.2020
Epoch: 142, Loss: 1.5249, Train: 0.3857, Val: 0.1800, Test: 0.2080
Epoch: 143, Loss: 1.4786, Train: 0.3786, Val: 0.1860, Test: 0.2070
Epoch: 144, Loss: 1.6714, Train: 0.3786, Val: 0.1860, Test: 0.2090
Epoch: 145, Loss: 1.4997, Train: 0.3857, Val: 0.1820, Test: 0.2110
Epoch: 146, Loss: 1.4398, Train: 0.3857, Val: 0.1860, Test: 0.2040
Epoch: 147, Loss: 1.4628, Train: 0.3714, Val: 0.1860, Test: 0.2070
Epoch: 148, Loss: 1.5183, Train: 0.3714, Val: 0.1820, Test: 0.2050
Epoch: 149, Loss: 1.4988, Train: 0.3786, Val: 0.1780, Test: 0.2040
Epoch: 150, Loss: 1.5568, Train: 0.3643, Val: 0.1780, Test: 0.2030
Epoch: 151, Loss: 1.4652, Train: 0.3714, Val: 0.1840, Test: 0.2030
Epoch: 152, Loss: 1.5401, Train: 0.3929, Val: 0.1840, Test: 0.2080
Epoch: 153, Loss: 1.4737, Train: 0.3929, Val: 0.1800, Test: 0.2100
Epoch: 154, Loss: 1.4480, Train: 0.3857, Val: 0.1800, Test: 0.2110
Epoch: 155, Loss: 1.4424, Train: 0.3857, Val: 0.1880, Test: 0.2170
Epoch: 156, Loss: 1.5404, Train: 0.3929, Val: 0.1880, Test: 0.2190
Epoch: 157, Loss: 1.4829, Train: 0.4000, Val: 0.1860, Test: 0.2240
Epoch: 158, Loss: 1.4679, Train: 0.4071, Val: 0.1860, Test: 0.2250
Epoch: 159, Loss: 1.4305, Train: 0.4286, Val: 0.1780, Test: 0.2230
Epoch: 160, Loss: 1.4606, Train: 0.4286, Val: 0.1840, Test: 0.2190
Epoch: 161, Loss: 1.4050, Train: 0.4357, Val: 0.1860, Test: 0.2170
Epoch: 162, Loss: 1.5363, Train: 0.4286, Val: 0.1840, Test: 0.2140
Epoch: 163, Loss: 1.3817, Train: 0.4357, Val: 0.1880, Test: 0.2140
Epoch: 164, Loss: 1.4018, Train: 0.4286, Val: 0.1820, Test: 0.2120
Epoch: 165, Loss: 1.3788, Train: 0.4214, Val: 0.1800, Test: 0.2080
Epoch: 166, Loss: 1.4371, Train: 0.4214, Val: 0.1840, Test: 0.2080
Epoch: 167, Loss: 1.4634, Train: 0.4214, Val: 0.1860, Test: 0.2060
Epoch: 168, Loss: 1.3895, Train: 0.4071, Val: 0.1860, Test: 0.2110
Epoch: 169, Loss: 1.5675, Train: 0.4071, Val: 0.1880, Test: 0.2120
Epoch: 170, Loss: 1.3903, Train: 0.4071, Val: 0.1860, Test: 0.2170
Epoch: 171, Loss: 1.3766, Train: 0.4286, Val: 0.1860, Test: 0.2220
Epoch: 172, Loss: 1.3988, Train: 0.4286, Val: 0.1940, Test: 0.2250
Epoch: 173, Loss: 1.3984, Train: 0.4286, Val: 0.1940, Test: 0.2280
Epoch: 174, Loss: 1.3269, Train: 0.4357, Val: 0.1960, Test: 0.2310
Epoch: 175, Loss: 1.3583, Train: 0.4357, Val: 0.1980, Test: 0.2310
Epoch: 176, Loss: 1.3397, Train: 0.4357, Val: 0.1980, Test: 0.2320
Epoch: 177, Loss: 1.3294, Train: 0.4286, Val: 0.1980, Test: 0.2330
Epoch: 178, Loss: 1.3469, Train: 0.4286, Val: 0.1980, Test: 0.2330
Epoch: 179, Loss: 1.3408, Train: 0.4286, Val: 0.2000, Test: 0.2340
Epoch: 180, Loss: 1.3335, Train: 0.4286, Val: 0.2000, Test: 0.2350
Epoch: 181, Loss: 1.3206, Train: 0.4286, Val: 0.2000, Test: 0.2360
Epoch: 182, Loss: 1.3429, Train: 0.4286, Val: 0.2020, Test: 0.2370
Epoch: 183, Loss: 1.3217, Train: 0.4429, Val: 0.2020, Test: 0.2360
Epoch: 184, Loss: 1.2690, Train: 0.4429, Val: 0.2020, Test: 0.2370
Epoch: 185, Loss: 1.4363, Train: 0.4500, Val: 0.2000, Test: 0.2360
Epoch: 186, Loss: 1.3352, Train: 0.4500, Val: 0.1980, Test: 0.2360
Epoch: 187, Loss: 1.3372, Train: 0.4571, Val: 0.2000, Test: 0.2350
Epoch: 188, Loss: 1.2910, Train: 0.4571, Val: 0.2040, Test: 0.2340
Epoch: 189, Loss: 1.2545, Train: 0.4571, Val: 0.2060, Test: 0.2350
Epoch: 190, Loss: 1.2779, Train: 0.4571, Val: 0.2060, Test: 0.2360
Epoch: 191, Loss: 1.2060, Train: 0.4643, Val: 0.2080, Test: 0.2430
Epoch: 192, Loss: 1.2607, Train: 0.4714, Val: 0.2080, Test: 0.2440
Epoch: 193, Loss: 1.2391, Train: 0.4714, Val: 0.2080, Test: 0.2440
Epoch: 194, Loss: 1.6375, Train: 0.4643, Val: 0.2080, Test: 0.2460
Epoch: 195, Loss: 1.2223, Train: 0.4643, Val: 0.2060, Test: 0.2460
Epoch: 196, Loss: 1.2321, Train: 0.4643, Val: 0.2060, Test: 0.2440
Epoch: 197, Loss: 1.2926, Train: 0.4643, Val: 0.2080, Test: 0.2420
Epoch: 198, Loss: 1.2223, Train: 0.4500, Val: 0.2040, Test: 0.2400
Epoch: 199, Loss: 1.2396, Train: 0.4500, Val: 0.2040, Test: 0.2390
Epoch: 200, Loss: 1.2657, Train: 0.4429, Val: 0.2080, Test: 0.2430
MAD:  0.4606
Best Test Accuracy: 0.2460, Val Accuracy: 0.2080, Train Accuracy: 0.4643
Training completed.
Average Test Accuracy:  0.32309999999999994 ± 0.06321305244963259
Average MAD:  0.43045 ± 0.191887150429621
