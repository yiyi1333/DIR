Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8420, Train: 0.1714, Val: 0.0260, Test: 0.0310
Epoch: 2, Loss: 4.7882, Train: 0.3429, Val: 0.1220, Test: 0.1300
Epoch: 3, Loss: 4.6982, Train: 0.4714, Val: 0.2060, Test: 0.2340
Epoch: 4, Loss: 4.6572, Train: 0.6071, Val: 0.2960, Test: 0.3240
Epoch: 5, Loss: 4.5440, Train: 0.6857, Val: 0.3720, Test: 0.3980
Epoch: 6, Loss: 4.4891, Train: 0.7429, Val: 0.4140, Test: 0.4560
Epoch: 7, Loss: 4.5055, Train: 0.7929, Val: 0.4420, Test: 0.4810
Epoch: 8, Loss: 4.1482, Train: 0.8071, Val: 0.4660, Test: 0.4920
Epoch: 9, Loss: 4.3065, Train: 0.8429, Val: 0.4940, Test: 0.5350
Epoch: 10, Loss: 4.2724, Train: 0.8643, Val: 0.5320, Test: 0.5610
Epoch: 11, Loss: 4.0029, Train: 0.9143, Val: 0.5420, Test: 0.5860
Epoch: 12, Loss: 3.9321, Train: 0.9286, Val: 0.5680, Test: 0.6040
Epoch: 13, Loss: 3.9588, Train: 0.9714, Val: 0.5840, Test: 0.6220
Epoch: 14, Loss: 3.8974, Train: 0.9786, Val: 0.6160, Test: 0.6530
Epoch: 15, Loss: 3.9518, Train: 0.9857, Val: 0.6400, Test: 0.6770
Epoch: 16, Loss: 3.7481, Train: 0.9929, Val: 0.6580, Test: 0.6910
Epoch: 17, Loss: 3.6221, Train: 0.9929, Val: 0.6820, Test: 0.7060
Epoch: 18, Loss: 3.9397, Train: 0.9929, Val: 0.6880, Test: 0.7170
Epoch: 19, Loss: 4.0292, Train: 0.9929, Val: 0.7140, Test: 0.7240
Epoch: 20, Loss: 3.9672, Train: 0.9929, Val: 0.7200, Test: 0.7260
Epoch: 21, Loss: 3.4317, Train: 0.9929, Val: 0.7240, Test: 0.7340
Epoch: 22, Loss: 3.4949, Train: 0.9929, Val: 0.7160, Test: 0.7380
Epoch: 23, Loss: 3.6728, Train: 1.0000, Val: 0.7100, Test: 0.7390
Epoch: 24, Loss: 3.8245, Train: 1.0000, Val: 0.7040, Test: 0.7370
Epoch: 25, Loss: 3.9012, Train: 1.0000, Val: 0.7040, Test: 0.7310
Epoch: 26, Loss: 3.6273, Train: 1.0000, Val: 0.6980, Test: 0.7350
Epoch: 27, Loss: 3.5527, Train: 1.0000, Val: 0.6980, Test: 0.7340
Epoch: 28, Loss: 3.5301, Train: 1.0000, Val: 0.7040, Test: 0.7310
Epoch: 29, Loss: 3.3371, Train: 1.0000, Val: 0.7100, Test: 0.7320
Epoch: 30, Loss: 3.5607, Train: 1.0000, Val: 0.7120, Test: 0.7320
Epoch: 31, Loss: 3.4271, Train: 1.0000, Val: 0.7100, Test: 0.7330
Epoch: 32, Loss: 3.2858, Train: 1.0000, Val: 0.7060, Test: 0.7340
Epoch: 33, Loss: 3.6224, Train: 1.0000, Val: 0.7040, Test: 0.7370
Epoch: 34, Loss: 3.2776, Train: 1.0000, Val: 0.7040, Test: 0.7370
Epoch: 35, Loss: 3.2661, Train: 1.0000, Val: 0.7040, Test: 0.7390
Epoch: 36, Loss: 3.4076, Train: 1.0000, Val: 0.7120, Test: 0.7430
Epoch: 37, Loss: 3.2703, Train: 1.0000, Val: 0.7160, Test: 0.7490
Epoch: 38, Loss: 3.0946, Train: 1.0000, Val: 0.7180, Test: 0.7480
Epoch: 39, Loss: 3.3789, Train: 1.0000, Val: 0.7220, Test: 0.7510
Epoch: 40, Loss: 3.2301, Train: 1.0000, Val: 0.7320, Test: 0.7530
Epoch: 41, Loss: 3.2447, Train: 1.0000, Val: 0.7380, Test: 0.7570
Epoch: 42, Loss: 3.5547, Train: 1.0000, Val: 0.7440, Test: 0.7620
Epoch: 43, Loss: 3.2478, Train: 1.0000, Val: 0.7400, Test: 0.7630
Epoch: 44, Loss: 3.3482, Train: 1.0000, Val: 0.7460, Test: 0.7650
Epoch: 45, Loss: 3.1917, Train: 1.0000, Val: 0.7480, Test: 0.7660
Epoch: 46, Loss: 3.5281, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 47, Loss: 3.3393, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 48, Loss: 3.1739, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 49, Loss: 3.3359, Train: 1.0000, Val: 0.7540, Test: 0.7730
Epoch: 50, Loss: 3.3793, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 51, Loss: 3.3655, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 52, Loss: 3.2318, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 53, Loss: 3.1231, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 54, Loss: 3.2078, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 55, Loss: 3.1367, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 56, Loss: 3.1878, Train: 1.0000, Val: 0.7540, Test: 0.7710
Epoch: 57, Loss: 3.2703, Train: 1.0000, Val: 0.7540, Test: 0.7700
Epoch: 58, Loss: 3.1048, Train: 1.0000, Val: 0.7520, Test: 0.7710
Epoch: 59, Loss: 3.3239, Train: 1.0000, Val: 0.7520, Test: 0.7700
Epoch: 60, Loss: 3.1194, Train: 1.0000, Val: 0.7520, Test: 0.7670
Epoch: 61, Loss: 3.2579, Train: 1.0000, Val: 0.7520, Test: 0.7700
Epoch: 62, Loss: 3.5600, Train: 1.0000, Val: 0.7480, Test: 0.7690
Epoch: 63, Loss: 3.0743, Train: 1.0000, Val: 0.7500, Test: 0.7680
Epoch: 64, Loss: 3.1097, Train: 1.0000, Val: 0.7480, Test: 0.7650
Epoch: 65, Loss: 3.2531, Train: 1.0000, Val: 0.7460, Test: 0.7630
Epoch: 66, Loss: 3.1961, Train: 1.0000, Val: 0.7440, Test: 0.7630
Epoch: 67, Loss: 3.2088, Train: 1.0000, Val: 0.7420, Test: 0.7630
Epoch: 68, Loss: 2.8105, Train: 1.0000, Val: 0.7420, Test: 0.7610
Epoch: 69, Loss: 3.0940, Train: 1.0000, Val: 0.7400, Test: 0.7620
Epoch: 70, Loss: 3.3563, Train: 1.0000, Val: 0.7380, Test: 0.7570
Epoch: 71, Loss: 3.1483, Train: 1.0000, Val: 0.7380, Test: 0.7530
Epoch: 72, Loss: 2.9937, Train: 1.0000, Val: 0.7360, Test: 0.7520
Epoch: 73, Loss: 2.8807, Train: 1.0000, Val: 0.7360, Test: 0.7520
Epoch: 74, Loss: 3.2607, Train: 1.0000, Val: 0.7360, Test: 0.7500
Epoch: 75, Loss: 2.8843, Train: 1.0000, Val: 0.7380, Test: 0.7490
Epoch: 76, Loss: 3.0407, Train: 1.0000, Val: 0.7380, Test: 0.7490
Epoch: 77, Loss: 3.0107, Train: 1.0000, Val: 0.7400, Test: 0.7480
Epoch: 78, Loss: 3.2818, Train: 1.0000, Val: 0.7400, Test: 0.7470
Epoch: 79, Loss: 2.7832, Train: 1.0000, Val: 0.7380, Test: 0.7460
Epoch: 80, Loss: 3.0399, Train: 1.0000, Val: 0.7380, Test: 0.7460
Epoch: 81, Loss: 2.8978, Train: 1.0000, Val: 0.7360, Test: 0.7460
Epoch: 82, Loss: 2.9667, Train: 1.0000, Val: 0.7320, Test: 0.7450
Epoch: 83, Loss: 2.7838, Train: 1.0000, Val: 0.7320, Test: 0.7450
Epoch: 84, Loss: 3.3385, Train: 1.0000, Val: 0.7260, Test: 0.7430
Epoch: 85, Loss: 2.9262, Train: 1.0000, Val: 0.7260, Test: 0.7430
Epoch: 86, Loss: 2.7711, Train: 1.0000, Val: 0.7240, Test: 0.7380
Epoch: 87, Loss: 2.9400, Train: 1.0000, Val: 0.7240, Test: 0.7410
Epoch: 88, Loss: 3.0246, Train: 1.0000, Val: 0.7240, Test: 0.7410
Epoch: 89, Loss: 3.0866, Train: 1.0000, Val: 0.7240, Test: 0.7410
Epoch: 90, Loss: 3.1988, Train: 1.0000, Val: 0.7260, Test: 0.7440
Epoch: 91, Loss: 2.8409, Train: 1.0000, Val: 0.7300, Test: 0.7480
Epoch: 92, Loss: 2.9112, Train: 1.0000, Val: 0.7300, Test: 0.7510
Epoch: 93, Loss: 3.0378, Train: 1.0000, Val: 0.7340, Test: 0.7520
Epoch: 94, Loss: 2.9671, Train: 1.0000, Val: 0.7360, Test: 0.7570
Epoch: 95, Loss: 2.8884, Train: 1.0000, Val: 0.7360, Test: 0.7580
Epoch: 96, Loss: 2.5935, Train: 1.0000, Val: 0.7380, Test: 0.7590
Epoch: 97, Loss: 2.7856, Train: 1.0000, Val: 0.7400, Test: 0.7630
Epoch: 98, Loss: 2.8777, Train: 1.0000, Val: 0.7400, Test: 0.7620
Epoch: 99, Loss: 2.8726, Train: 1.0000, Val: 0.7420, Test: 0.7620
Epoch: 100, Loss: 3.1823, Train: 1.0000, Val: 0.7480, Test: 0.7570
Epoch: 101, Loss: 2.8064, Train: 1.0000, Val: 0.7480, Test: 0.7570
Epoch: 102, Loss: 2.9541, Train: 1.0000, Val: 0.7480, Test: 0.7570
Epoch: 103, Loss: 2.5958, Train: 1.0000, Val: 0.7440, Test: 0.7560
Epoch: 104, Loss: 3.0792, Train: 1.0000, Val: 0.7440, Test: 0.7550
Epoch: 105, Loss: 2.6192, Train: 1.0000, Val: 0.7420, Test: 0.7570
Epoch: 106, Loss: 2.6423, Train: 1.0000, Val: 0.7440, Test: 0.7540
Epoch: 107, Loss: 2.8404, Train: 1.0000, Val: 0.7440, Test: 0.7540
Epoch: 108, Loss: 2.8523, Train: 1.0000, Val: 0.7440, Test: 0.7530
Epoch: 109, Loss: 2.9813, Train: 1.0000, Val: 0.7440, Test: 0.7490
Epoch: 110, Loss: 3.0090, Train: 1.0000, Val: 0.7440, Test: 0.7500
Epoch: 111, Loss: 2.8565, Train: 1.0000, Val: 0.7420, Test: 0.7490
Epoch: 112, Loss: 3.0178, Train: 1.0000, Val: 0.7400, Test: 0.7490
Epoch: 113, Loss: 3.0308, Train: 1.0000, Val: 0.7340, Test: 0.7480
Epoch: 114, Loss: 2.9665, Train: 1.0000, Val: 0.7340, Test: 0.7490
Epoch: 115, Loss: 2.8632, Train: 1.0000, Val: 0.7300, Test: 0.7490
Epoch: 116, Loss: 3.1352, Train: 1.0000, Val: 0.7320, Test: 0.7440
Epoch: 117, Loss: 2.9362, Train: 1.0000, Val: 0.7300, Test: 0.7430
Epoch: 118, Loss: 2.6773, Train: 1.0000, Val: 0.7300, Test: 0.7420
Epoch: 119, Loss: 3.2864, Train: 1.0000, Val: 0.7300, Test: 0.7430
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 2.8355, Train: 1.0000, Val: 0.7280, Test: 0.7430
Epoch: 121, Loss: 2.9675, Train: 1.0000, Val: 0.7280, Test: 0.7420
Epoch: 122, Loss: 2.6300, Train: 1.0000, Val: 0.7280, Test: 0.7410
Epoch: 123, Loss: 2.8099, Train: 1.0000, Val: 0.7280, Test: 0.7400
Epoch: 124, Loss: 2.9924, Train: 1.0000, Val: 0.7280, Test: 0.7410
Epoch: 125, Loss: 2.8899, Train: 1.0000, Val: 0.7300, Test: 0.7390
Epoch: 126, Loss: 2.4891, Train: 1.0000, Val: 0.7300, Test: 0.7410
Epoch: 127, Loss: 3.0681, Train: 1.0000, Val: 0.7300, Test: 0.7400
Epoch: 128, Loss: 2.5969, Train: 1.0000, Val: 0.7280, Test: 0.7420
Epoch: 129, Loss: 2.8305, Train: 1.0000, Val: 0.7300, Test: 0.7430
Epoch: 130, Loss: 2.6400, Train: 1.0000, Val: 0.7340, Test: 0.7440
Epoch: 131, Loss: 2.8858, Train: 1.0000, Val: 0.7380, Test: 0.7430
Epoch: 132, Loss: 2.5792, Train: 1.0000, Val: 0.7360, Test: 0.7420
Epoch: 133, Loss: 2.5804, Train: 1.0000, Val: 0.7400, Test: 0.7420
Epoch: 134, Loss: 2.7491, Train: 1.0000, Val: 0.7380, Test: 0.7400
Epoch: 135, Loss: 2.7846, Train: 1.0000, Val: 0.7360, Test: 0.7360
Epoch: 136, Loss: 2.9593, Train: 1.0000, Val: 0.7360, Test: 0.7360
Epoch: 137, Loss: 2.6460, Train: 1.0000, Val: 0.7340, Test: 0.7360
Epoch: 138, Loss: 2.5701, Train: 1.0000, Val: 0.7340, Test: 0.7370
Epoch: 139, Loss: 2.4059, Train: 1.0000, Val: 0.7360, Test: 0.7370
Epoch: 140, Loss: 2.7009, Train: 1.0000, Val: 0.7340, Test: 0.7360
Epoch: 141, Loss: 2.8058, Train: 1.0000, Val: 0.7320, Test: 0.7350
Epoch: 142, Loss: 3.0102, Train: 1.0000, Val: 0.7320, Test: 0.7360
Epoch: 143, Loss: 2.7397, Train: 1.0000, Val: 0.7320, Test: 0.7340
Epoch: 144, Loss: 2.6572, Train: 1.0000, Val: 0.7320, Test: 0.7350
Epoch: 145, Loss: 2.6703, Train: 1.0000, Val: 0.7300, Test: 0.7350
Epoch: 146, Loss: 2.5721, Train: 1.0000, Val: 0.7300, Test: 0.7350
Epoch: 147, Loss: 2.8542, Train: 1.0000, Val: 0.7300, Test: 0.7380
Epoch: 148, Loss: 2.8616, Train: 1.0000, Val: 0.7300, Test: 0.7390
Epoch: 149, Loss: 2.5521, Train: 1.0000, Val: 0.7300, Test: 0.7390
Epoch: 150, Loss: 2.7332, Train: 1.0000, Val: 0.7320, Test: 0.7360
Epoch: 151, Loss: 2.3494, Train: 1.0000, Val: 0.7320, Test: 0.7380
Epoch: 152, Loss: 2.5699, Train: 1.0000, Val: 0.7340, Test: 0.7380
Epoch: 153, Loss: 2.6330, Train: 1.0000, Val: 0.7340, Test: 0.7380
Epoch: 154, Loss: 2.5392, Train: 1.0000, Val: 0.7320, Test: 0.7390
Epoch: 155, Loss: 2.5027, Train: 1.0000, Val: 0.7340, Test: 0.7390
Epoch: 156, Loss: 2.5731, Train: 1.0000, Val: 0.7360, Test: 0.7380
Epoch: 157, Loss: 2.6872, Train: 1.0000, Val: 0.7340, Test: 0.7360
Epoch: 158, Loss: 2.6330, Train: 1.0000, Val: 0.7340, Test: 0.7350
Epoch: 159, Loss: 2.6240, Train: 1.0000, Val: 0.7340, Test: 0.7360
Epoch: 160, Loss: 2.6567, Train: 1.0000, Val: 0.7280, Test: 0.7370
Epoch: 161, Loss: 2.1981, Train: 1.0000, Val: 0.7280, Test: 0.7360
Epoch: 162, Loss: 2.6410, Train: 1.0000, Val: 0.7260, Test: 0.7360
Epoch: 163, Loss: 2.5256, Train: 1.0000, Val: 0.7260, Test: 0.7370
Epoch: 164, Loss: 2.5467, Train: 1.0000, Val: 0.7260, Test: 0.7360
Epoch: 165, Loss: 2.2759, Train: 1.0000, Val: 0.7240, Test: 0.7350
Epoch: 166, Loss: 2.6653, Train: 1.0000, Val: 0.7220, Test: 0.7340
Epoch: 167, Loss: 2.7189, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 168, Loss: 2.6873, Train: 1.0000, Val: 0.7200, Test: 0.7300
Epoch: 169, Loss: 2.7345, Train: 1.0000, Val: 0.7200, Test: 0.7280
Epoch: 170, Loss: 2.6151, Train: 1.0000, Val: 0.7200, Test: 0.7280
Epoch: 171, Loss: 2.5637, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 172, Loss: 2.4280, Train: 1.0000, Val: 0.7200, Test: 0.7300
Epoch: 173, Loss: 2.4197, Train: 1.0000, Val: 0.7180, Test: 0.7290
Epoch: 174, Loss: 2.5853, Train: 1.0000, Val: 0.7200, Test: 0.7330
Epoch: 175, Loss: 2.6070, Train: 1.0000, Val: 0.7200, Test: 0.7350
Epoch: 176, Loss: 2.4093, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 177, Loss: 2.7405, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 178, Loss: 2.5874, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 179, Loss: 2.4173, Train: 1.0000, Val: 0.7180, Test: 0.7320
Epoch: 180, Loss: 2.6572, Train: 1.0000, Val: 0.7180, Test: 0.7320
Epoch: 181, Loss: 2.6796, Train: 1.0000, Val: 0.7180, Test: 0.7320
Epoch: 182, Loss: 2.4356, Train: 1.0000, Val: 0.7160, Test: 0.7300
Epoch: 183, Loss: 2.5192, Train: 1.0000, Val: 0.7160, Test: 0.7300
Epoch: 184, Loss: 2.5258, Train: 1.0000, Val: 0.7160, Test: 0.7270
Epoch: 185, Loss: 2.5922, Train: 1.0000, Val: 0.7140, Test: 0.7270
Epoch: 186, Loss: 2.6477, Train: 1.0000, Val: 0.7120, Test: 0.7240
Epoch: 187, Loss: 2.2010, Train: 1.0000, Val: 0.7140, Test: 0.7250
Epoch: 188, Loss: 2.3015, Train: 1.0000, Val: 0.7160, Test: 0.7250
Epoch: 189, Loss: 2.2669, Train: 1.0000, Val: 0.7180, Test: 0.7260
Epoch: 190, Loss: 2.3975, Train: 1.0000, Val: 0.7220, Test: 0.7260
Epoch: 191, Loss: 2.5686, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 192, Loss: 2.6126, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 193, Loss: 2.3992, Train: 1.0000, Val: 0.7180, Test: 0.7270
Epoch: 194, Loss: 2.5418, Train: 1.0000, Val: 0.7180, Test: 0.7260
Epoch: 195, Loss: 2.3999, Train: 1.0000, Val: 0.7160, Test: 0.7260
Epoch: 196, Loss: 2.4969, Train: 1.0000, Val: 0.7100, Test: 0.7240
Epoch: 197, Loss: 2.6594, Train: 1.0000, Val: 0.7100, Test: 0.7220
Epoch: 198, Loss: 2.3497, Train: 1.0000, Val: 0.7100, Test: 0.7210
Epoch: 199, Loss: 2.5391, Train: 1.0000, Val: 0.7100, Test: 0.7210
Epoch: 200, Loss: 2.4433, Train: 1.0000, Val: 0.7120, Test: 0.7200
MAD:  0.39
Best Test Accuracy: 0.7730, Val Accuracy: 0.7540, Train Accuracy: 1.0000
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8637, Train: 0.0643, Val: 0.0340, Test: 0.0240
Epoch: 2, Loss: 4.8079, Train: 0.2214, Val: 0.1020, Test: 0.1160
Epoch: 3, Loss: 4.7517, Train: 0.3714, Val: 0.2200, Test: 0.2230
Epoch: 4, Loss: 4.6753, Train: 0.4786, Val: 0.3300, Test: 0.3100
Epoch: 5, Loss: 4.6347, Train: 0.5214, Val: 0.3880, Test: 0.3630
Epoch: 6, Loss: 4.5477, Train: 0.6071, Val: 0.4120, Test: 0.4150
Epoch: 7, Loss: 4.4771, Train: 0.6714, Val: 0.4400, Test: 0.4430
Epoch: 8, Loss: 4.3733, Train: 0.6929, Val: 0.4680, Test: 0.4830
Epoch: 9, Loss: 4.1900, Train: 0.7500, Val: 0.5020, Test: 0.5080
Epoch: 10, Loss: 4.2295, Train: 0.8071, Val: 0.5160, Test: 0.5250
Epoch: 11, Loss: 4.2358, Train: 0.8286, Val: 0.5320, Test: 0.5410
Epoch: 12, Loss: 4.2075, Train: 0.8571, Val: 0.5480, Test: 0.5550
Epoch: 13, Loss: 4.0140, Train: 0.8786, Val: 0.5560, Test: 0.5700
Epoch: 14, Loss: 4.2118, Train: 0.9214, Val: 0.5580, Test: 0.5850
Epoch: 15, Loss: 3.7953, Train: 0.9429, Val: 0.5740, Test: 0.6070
Epoch: 16, Loss: 3.8804, Train: 0.9571, Val: 0.5960, Test: 0.6210
Epoch: 17, Loss: 3.9403, Train: 0.9643, Val: 0.6000, Test: 0.6540
Epoch: 18, Loss: 3.9172, Train: 0.9643, Val: 0.6240, Test: 0.6720
Epoch: 19, Loss: 4.0524, Train: 0.9786, Val: 0.6640, Test: 0.6830
Epoch: 20, Loss: 3.7744, Train: 0.9857, Val: 0.6800, Test: 0.6900
Epoch: 21, Loss: 3.7349, Train: 0.9857, Val: 0.6980, Test: 0.6980
Epoch: 22, Loss: 3.7596, Train: 0.9857, Val: 0.7020, Test: 0.7050
Epoch: 23, Loss: 3.5316, Train: 0.9929, Val: 0.6960, Test: 0.7000
Epoch: 24, Loss: 3.7918, Train: 0.9929, Val: 0.6960, Test: 0.7030
Epoch: 25, Loss: 3.5022, Train: 0.9929, Val: 0.6980, Test: 0.7140
Epoch: 26, Loss: 3.7374, Train: 1.0000, Val: 0.7000, Test: 0.7210
Epoch: 27, Loss: 3.6664, Train: 1.0000, Val: 0.7060, Test: 0.7240
Epoch: 28, Loss: 3.3365, Train: 1.0000, Val: 0.7020, Test: 0.7310
Epoch: 29, Loss: 3.5654, Train: 1.0000, Val: 0.7020, Test: 0.7370
Epoch: 30, Loss: 3.9050, Train: 1.0000, Val: 0.7060, Test: 0.7420
Epoch: 31, Loss: 3.4157, Train: 1.0000, Val: 0.7080, Test: 0.7420
Epoch: 32, Loss: 3.4660, Train: 1.0000, Val: 0.7100, Test: 0.7420
Epoch: 33, Loss: 3.3872, Train: 1.0000, Val: 0.7180, Test: 0.7440
Epoch: 34, Loss: 3.2558, Train: 1.0000, Val: 0.7220, Test: 0.7470
Epoch: 35, Loss: 3.2677, Train: 1.0000, Val: 0.7200, Test: 0.7530
Epoch: 36, Loss: 3.6643, Train: 1.0000, Val: 0.7180, Test: 0.7560
Epoch: 37, Loss: 3.0637, Train: 1.0000, Val: 0.7200, Test: 0.7550
Epoch: 38, Loss: 3.4216, Train: 1.0000, Val: 0.7220, Test: 0.7580
Epoch: 39, Loss: 3.4230, Train: 1.0000, Val: 0.7240, Test: 0.7610
Epoch: 40, Loss: 3.2359, Train: 1.0000, Val: 0.7300, Test: 0.7670
Epoch: 41, Loss: 3.4149, Train: 1.0000, Val: 0.7300, Test: 0.7660
Epoch: 42, Loss: 3.3424, Train: 1.0000, Val: 0.7300, Test: 0.7630
Epoch: 43, Loss: 3.1894, Train: 1.0000, Val: 0.7280, Test: 0.7640
Epoch: 44, Loss: 3.1854, Train: 1.0000, Val: 0.7280, Test: 0.7650
Epoch: 45, Loss: 3.2030, Train: 1.0000, Val: 0.7300, Test: 0.7650
Epoch: 46, Loss: 3.3061, Train: 1.0000, Val: 0.7280, Test: 0.7620
Epoch: 47, Loss: 3.6004, Train: 1.0000, Val: 0.7320, Test: 0.7630
Epoch: 48, Loss: 3.2907, Train: 1.0000, Val: 0.7360, Test: 0.7580
Epoch: 49, Loss: 3.3527, Train: 1.0000, Val: 0.7320, Test: 0.7600
Epoch: 50, Loss: 3.0312, Train: 1.0000, Val: 0.7320, Test: 0.7620
Epoch: 51, Loss: 3.3519, Train: 1.0000, Val: 0.7320, Test: 0.7610
Epoch: 52, Loss: 3.0916, Train: 1.0000, Val: 0.7320, Test: 0.7620
Epoch: 53, Loss: 3.0667, Train: 1.0000, Val: 0.7320, Test: 0.7590
Epoch: 54, Loss: 2.9687, Train: 1.0000, Val: 0.7340, Test: 0.7550
Epoch: 55, Loss: 3.2470, Train: 1.0000, Val: 0.7340, Test: 0.7520
Epoch: 56, Loss: 3.2337, Train: 1.0000, Val: 0.7300, Test: 0.7520
Epoch: 57, Loss: 3.1793, Train: 1.0000, Val: 0.7300, Test: 0.7520
Epoch: 58, Loss: 3.0253, Train: 1.0000, Val: 0.7280, Test: 0.7510
Epoch: 59, Loss: 3.2076, Train: 1.0000, Val: 0.7300, Test: 0.7490
Epoch: 60, Loss: 2.9260, Train: 1.0000, Val: 0.7300, Test: 0.7490
Epoch: 61, Loss: 3.2175, Train: 1.0000, Val: 0.7280, Test: 0.7500
Epoch: 62, Loss: 3.1077, Train: 1.0000, Val: 0.7280, Test: 0.7480
Epoch: 63, Loss: 3.1808, Train: 1.0000, Val: 0.7280, Test: 0.7480
Epoch: 64, Loss: 3.2489, Train: 1.0000, Val: 0.7260, Test: 0.7490
Epoch: 65, Loss: 3.4169, Train: 1.0000, Val: 0.7240, Test: 0.7510
Epoch: 66, Loss: 2.9644, Train: 1.0000, Val: 0.7220, Test: 0.7500
Epoch: 67, Loss: 3.1528, Train: 1.0000, Val: 0.7240, Test: 0.7530
Epoch: 68, Loss: 3.0830, Train: 1.0000, Val: 0.7240, Test: 0.7510
Epoch: 69, Loss: 2.9360, Train: 1.0000, Val: 0.7240, Test: 0.7500
Epoch: 70, Loss: 2.8545, Train: 1.0000, Val: 0.7260, Test: 0.7480
Epoch: 71, Loss: 3.1676, Train: 1.0000, Val: 0.7260, Test: 0.7490
Epoch: 72, Loss: 3.0160, Train: 1.0000, Val: 0.7240, Test: 0.7510
Epoch: 73, Loss: 3.0492, Train: 1.0000, Val: 0.7240, Test: 0.7520
Epoch: 74, Loss: 3.3173, Train: 1.0000, Val: 0.7220, Test: 0.7510
Epoch: 75, Loss: 3.1224, Train: 1.0000, Val: 0.7240, Test: 0.7530
Epoch: 76, Loss: 3.0478, Train: 1.0000, Val: 0.7240, Test: 0.7530
Epoch: 77, Loss: 2.8480, Train: 1.0000, Val: 0.7240, Test: 0.7540
Epoch: 78, Loss: 2.9471, Train: 1.0000, Val: 0.7240, Test: 0.7510
Epoch: 79, Loss: 2.9077, Train: 1.0000, Val: 0.7240, Test: 0.7520
Epoch: 80, Loss: 3.1980, Train: 1.0000, Val: 0.7240, Test: 0.7510
Epoch: 81, Loss: 3.1119, Train: 1.0000, Val: 0.7260, Test: 0.7500
Epoch: 82, Loss: 3.0896, Train: 1.0000, Val: 0.7260, Test: 0.7500
Epoch: 83, Loss: 2.9574, Train: 1.0000, Val: 0.7260, Test: 0.7500
Epoch: 84, Loss: 2.6223, Train: 1.0000, Val: 0.7260, Test: 0.7500
Epoch: 85, Loss: 2.8533, Train: 1.0000, Val: 0.7260, Test: 0.7500
Epoch: 86, Loss: 2.8976, Train: 1.0000, Val: 0.7260, Test: 0.7490
Epoch: 87, Loss: 3.0320, Train: 1.0000, Val: 0.7220, Test: 0.7480
Epoch: 88, Loss: 3.2501, Train: 1.0000, Val: 0.7200, Test: 0.7470
Epoch: 89, Loss: 2.8227, Train: 1.0000, Val: 0.7200, Test: 0.7470
Epoch: 90, Loss: 2.6707, Train: 1.0000, Val: 0.7220, Test: 0.7460
Epoch: 91, Loss: 3.1873, Train: 1.0000, Val: 0.7220, Test: 0.7460
Epoch: 92, Loss: 3.2686, Train: 1.0000, Val: 0.7240, Test: 0.7440
Epoch: 93, Loss: 2.8380, Train: 1.0000, Val: 0.7280, Test: 0.7440
Epoch: 94, Loss: 2.7470, Train: 1.0000, Val: 0.7280, Test: 0.7440
Epoch: 95, Loss: 2.8175, Train: 1.0000, Val: 0.7280, Test: 0.7470
Epoch: 96, Loss: 3.1420, Train: 1.0000, Val: 0.7260, Test: 0.7470
Epoch: 97, Loss: 2.8834, Train: 1.0000, Val: 0.7260, Test: 0.7430
Epoch: 98, Loss: 2.7833, Train: 1.0000, Val: 0.7260, Test: 0.7420
Epoch: 99, Loss: 2.8688, Train: 1.0000, Val: 0.7260, Test: 0.7430
Epoch: 100, Loss: 2.5434, Train: 1.0000, Val: 0.7260, Test: 0.7440
Epoch: 101, Loss: 3.1548, Train: 1.0000, Val: 0.7280, Test: 0.7440
Epoch: 102, Loss: 2.7911, Train: 1.0000, Val: 0.7280, Test: 0.7440
Epoch: 103, Loss: 2.6992, Train: 1.0000, Val: 0.7280, Test: 0.7450
Epoch: 104, Loss: 3.0419, Train: 1.0000, Val: 0.7280, Test: 0.7490
Epoch: 105, Loss: 2.9751, Train: 1.0000, Val: 0.7280, Test: 0.7510
Epoch: 106, Loss: 2.6685, Train: 1.0000, Val: 0.7280, Test: 0.7520
Epoch: 107, Loss: 2.8326, Train: 1.0000, Val: 0.7280, Test: 0.7530
Epoch: 108, Loss: 2.6905, Train: 1.0000, Val: 0.7260, Test: 0.7530
Epoch: 109, Loss: 2.7709, Train: 1.0000, Val: 0.7260, Test: 0.7550
Epoch: 110, Loss: 3.0054, Train: 1.0000, Val: 0.7240, Test: 0.7530
Epoch: 111, Loss: 2.9052, Train: 1.0000, Val: 0.7220, Test: 0.7530
Epoch: 112, Loss: 2.6023, Train: 1.0000, Val: 0.7220, Test: 0.7510
Epoch: 113, Loss: 2.7127, Train: 1.0000, Val: 0.7200, Test: 0.7480
Epoch: 114, Loss: 2.7165, Train: 1.0000, Val: 0.7220, Test: 0.7470
Epoch: 115, Loss: 3.0241, Train: 1.0000, Val: 0.7220, Test: 0.7460
Epoch: 116, Loss: 3.1075, Train: 1.0000, Val: 0.7200, Test: 0.7470
Epoch: 117, Loss: 2.7151, Train: 1.0000, Val: 0.7200, Test: 0.7440
Epoch: 118, Loss: 2.9050, Train: 1.0000, Val: 0.7200, Test: 0.7430
Epoch: 119, Loss: 2.8010, Train: 1.0000, Val: 0.7200, Test: 0.7430
Epoch: 120, Loss: 2.7129, Train: 1.0000, Val: 0.7180, Test: 0.7420
Epoch: 121, Loss: 3.0235, Train: 1.0000, Val: 0.7200, Test: 0.7420
Epoch: 122, Loss: 3.0283, Train: 1.0000, Val: 0.7160, Test: 0.7410
Epoch: 123, Loss: 2.7069, Train: 1.0000, Val: 0.7160, Test: 0.7410
Epoch: 124, Loss: 2.6034, Train: 1.0000, Val: 0.7160, Test: 0.7440
Epoch: 125, Loss: 2.7031, Train: 1.0000, Val: 0.7160, Test: 0.7440
Epoch: 126, Loss: 2.6326, Train: 1.0000, Val: 0.7180, Test: 0.7420
Epoch: 127, Loss: 2.5643, Train: 1.0000, Val: 0.7220, Test: 0.7410
Epoch: 128, Loss: 2.6566, Train: 1.0000, Val: 0.7220, Test: 0.7400
Epoch: 129, Loss: 2.8336, Train: 1.0000, Val: 0.7220, Test: 0.7390
Epoch: 130, Loss: 2.9008, Train: 1.0000, Val: 0.7220, Test: 0.7390
Epoch: 131, Loss: 2.9513, Train: 1.0000, Val: 0.7220, Test: 0.7410
Epoch: 132, Loss: 2.6852, Train: 1.0000, Val: 0.7200, Test: 0.7410
Epoch: 133, Loss: 2.7281, Train: 1.0000, Val: 0.7200, Test: 0.7400
Epoch: 134, Loss: 2.8394, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 135, Loss: 3.1395, Train: 1.0000, Val: 0.7180, Test: 0.7370
Epoch: 136, Loss: 3.0305, Train: 1.0000, Val: 0.7220, Test: 0.7370
Epoch: 137, Loss: 2.5963, Train: 1.0000, Val: 0.7220, Test: 0.7370
Epoch: 138, Loss: 2.8661, Train: 1.0000, Val: 0.7200, Test: 0.7350
Epoch: 139, Loss: 2.8461, Train: 1.0000, Val: 0.7180, Test: 0.7350
Epoch: 140, Loss: 2.8560, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 141, Loss: 2.7829, Train: 1.0000, Val: 0.7180, Test: 0.7320
Epoch: 142, Loss: 2.6252, Train: 1.0000, Val: 0.7180, Test: 0.7320
Epoch: 143, Loss: 2.6541, Train: 1.0000, Val: 0.7160, Test: 0.7310
Epoch: 144, Loss: 2.8438, Train: 1.0000, Val: 0.7160, Test: 0.7310
Epoch: 145, Loss: 2.8226, Train: 1.0000, Val: 0.7160, Test: 0.7330
Epoch: 146, Loss: 2.5310, Train: 1.0000, Val: 0.7160, Test: 0.7290
Epoch: 147, Loss: 2.7856, Train: 1.0000, Val: 0.7160, Test: 0.7290
Epoch: 148, Loss: 2.2883, Train: 1.0000, Val: 0.7160, Test: 0.7280
Epoch: 149, Loss: 2.6056, Train: 1.0000, Val: 0.7140, Test: 0.7270
Epoch: 150, Loss: 2.6111, Train: 1.0000, Val: 0.7140, Test: 0.7270
Epoch: 151, Loss: 2.4107, Train: 1.0000, Val: 0.7160, Test: 0.7250
Epoch: 152, Loss: 3.1390, Train: 1.0000, Val: 0.7160, Test: 0.7240
Epoch: 153, Loss: 2.7265, Train: 1.0000, Val: 0.7180, Test: 0.7240
Epoch: 154, Loss: 2.6438, Train: 1.0000, Val: 0.7180, Test: 0.7240
Epoch: 155, Loss: 2.5557, Train: 1.0000, Val: 0.7180, Test: 0.7240
Epoch: 156, Loss: 2.8682, Train: 1.0000, Val: 0.7180, Test: 0.7250
Epoch: 157, Loss: 2.4440, Train: 1.0000, Val: 0.7200, Test: 0.7300
Epoch: 158, Loss: 2.5132, Train: 1.0000, Val: 0.7200, Test: 0.7300
Epoch: 159, Loss: 2.7652, Train: 1.0000, Val: 0.7200, Test: 0.7310
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 160, Loss: 2.4546, Train: 1.0000, Val: 0.7220, Test: 0.7320
Epoch: 161, Loss: 2.8009, Train: 1.0000, Val: 0.7200, Test: 0.7340
Epoch: 162, Loss: 2.8550, Train: 1.0000, Val: 0.7180, Test: 0.7340
Epoch: 163, Loss: 2.2284, Train: 1.0000, Val: 0.7220, Test: 0.7360
Epoch: 164, Loss: 2.2424, Train: 1.0000, Val: 0.7240, Test: 0.7350
Epoch: 165, Loss: 2.3932, Train: 1.0000, Val: 0.7260, Test: 0.7310
Epoch: 166, Loss: 2.6547, Train: 1.0000, Val: 0.7240, Test: 0.7290
Epoch: 167, Loss: 2.3314, Train: 1.0000, Val: 0.7220, Test: 0.7280
Epoch: 168, Loss: 2.6020, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 169, Loss: 2.9699, Train: 1.0000, Val: 0.7180, Test: 0.7260
Epoch: 170, Loss: 2.5373, Train: 1.0000, Val: 0.7180, Test: 0.7270
Epoch: 171, Loss: 2.8175, Train: 1.0000, Val: 0.7180, Test: 0.7250
Epoch: 172, Loss: 2.6246, Train: 1.0000, Val: 0.7160, Test: 0.7220
Epoch: 173, Loss: 2.5481, Train: 1.0000, Val: 0.7160, Test: 0.7190
Epoch: 174, Loss: 2.8228, Train: 1.0000, Val: 0.7160, Test: 0.7190
Epoch: 175, Loss: 2.7156, Train: 1.0000, Val: 0.7160, Test: 0.7160
Epoch: 176, Loss: 2.4746, Train: 1.0000, Val: 0.7160, Test: 0.7160
Epoch: 177, Loss: 2.5796, Train: 1.0000, Val: 0.7120, Test: 0.7180
Epoch: 178, Loss: 2.5964, Train: 1.0000, Val: 0.7120, Test: 0.7170
Epoch: 179, Loss: 2.5809, Train: 1.0000, Val: 0.7120, Test: 0.7170
Epoch: 180, Loss: 2.2816, Train: 1.0000, Val: 0.7120, Test: 0.7190
Epoch: 181, Loss: 2.6204, Train: 1.0000, Val: 0.7120, Test: 0.7200
Epoch: 182, Loss: 2.3959, Train: 1.0000, Val: 0.7120, Test: 0.7220
Epoch: 183, Loss: 2.6609, Train: 1.0000, Val: 0.7140, Test: 0.7250
Epoch: 184, Loss: 2.4877, Train: 1.0000, Val: 0.7140, Test: 0.7250
Epoch: 185, Loss: 2.7733, Train: 1.0000, Val: 0.7140, Test: 0.7220
Epoch: 186, Loss: 2.3675, Train: 1.0000, Val: 0.7120, Test: 0.7230
Epoch: 187, Loss: 2.4199, Train: 1.0000, Val: 0.7180, Test: 0.7230
Epoch: 188, Loss: 2.7663, Train: 1.0000, Val: 0.7180, Test: 0.7220
Epoch: 189, Loss: 2.5467, Train: 1.0000, Val: 0.7160, Test: 0.7180
Epoch: 190, Loss: 2.8319, Train: 1.0000, Val: 0.7160, Test: 0.7180
Epoch: 191, Loss: 2.2393, Train: 1.0000, Val: 0.7160, Test: 0.7160
Epoch: 192, Loss: 2.5651, Train: 1.0000, Val: 0.7140, Test: 0.7140
Epoch: 193, Loss: 2.5415, Train: 1.0000, Val: 0.7140, Test: 0.7150
Epoch: 194, Loss: 2.4850, Train: 1.0000, Val: 0.7120, Test: 0.7140
Epoch: 195, Loss: 2.5862, Train: 1.0000, Val: 0.7120, Test: 0.7150
Epoch: 196, Loss: 2.8429, Train: 1.0000, Val: 0.7120, Test: 0.7140
Epoch: 197, Loss: 2.3025, Train: 1.0000, Val: 0.7120, Test: 0.7140
Epoch: 198, Loss: 2.3776, Train: 1.0000, Val: 0.7120, Test: 0.7150
Epoch: 199, Loss: 2.6911, Train: 1.0000, Val: 0.7100, Test: 0.7130
Epoch: 200, Loss: 2.8538, Train: 1.0000, Val: 0.7100, Test: 0.7110
MAD:  0.3336
Best Test Accuracy: 0.7670, Val Accuracy: 0.7300, Train Accuracy: 1.0000
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8730, Train: 0.0429, Val: 0.0160, Test: 0.0140
Epoch: 2, Loss: 4.8081, Train: 0.2286, Val: 0.0780, Test: 0.0600
Epoch: 3, Loss: 4.7541, Train: 0.4357, Val: 0.1460, Test: 0.1540
Epoch: 4, Loss: 4.6853, Train: 0.5286, Val: 0.2200, Test: 0.2320
Epoch: 5, Loss: 4.6057, Train: 0.5786, Val: 0.2580, Test: 0.2780
Epoch: 6, Loss: 4.5958, Train: 0.6500, Val: 0.2880, Test: 0.3050
Epoch: 7, Loss: 4.4380, Train: 0.7000, Val: 0.3080, Test: 0.3200
Epoch: 8, Loss: 4.2749, Train: 0.7357, Val: 0.3300, Test: 0.3330
Epoch: 9, Loss: 4.2022, Train: 0.7500, Val: 0.3420, Test: 0.3570
Epoch: 10, Loss: 4.0972, Train: 0.7714, Val: 0.3500, Test: 0.3640
Epoch: 11, Loss: 4.2131, Train: 0.8143, Val: 0.3620, Test: 0.3760
Epoch: 12, Loss: 4.0372, Train: 0.8357, Val: 0.3760, Test: 0.3900
Epoch: 13, Loss: 4.2229, Train: 0.8500, Val: 0.3900, Test: 0.4180
Epoch: 14, Loss: 4.1349, Train: 0.8786, Val: 0.4120, Test: 0.4390
Epoch: 15, Loss: 4.0120, Train: 0.9286, Val: 0.4320, Test: 0.4730
Epoch: 16, Loss: 3.9274, Train: 0.9500, Val: 0.4780, Test: 0.5180
Epoch: 17, Loss: 3.9419, Train: 0.9571, Val: 0.5260, Test: 0.5640
Epoch: 18, Loss: 3.6752, Train: 0.9857, Val: 0.5800, Test: 0.6050
Epoch: 19, Loss: 3.8362, Train: 0.9857, Val: 0.6180, Test: 0.6420
Epoch: 20, Loss: 3.6340, Train: 0.9857, Val: 0.6440, Test: 0.6700
Epoch: 21, Loss: 3.9939, Train: 0.9857, Val: 0.6740, Test: 0.6920
Epoch: 22, Loss: 4.1262, Train: 0.9857, Val: 0.6960, Test: 0.7050
Epoch: 23, Loss: 3.5043, Train: 0.9929, Val: 0.7140, Test: 0.7080
Epoch: 24, Loss: 3.6287, Train: 0.9929, Val: 0.7240, Test: 0.7220
Epoch: 25, Loss: 3.7479, Train: 1.0000, Val: 0.7240, Test: 0.7270
Epoch: 26, Loss: 3.6819, Train: 1.0000, Val: 0.7260, Test: 0.7300
Epoch: 27, Loss: 3.6199, Train: 1.0000, Val: 0.7280, Test: 0.7290
Epoch: 28, Loss: 3.9454, Train: 1.0000, Val: 0.7220, Test: 0.7280
Epoch: 29, Loss: 3.7747, Train: 1.0000, Val: 0.7160, Test: 0.7320
Epoch: 30, Loss: 3.4798, Train: 1.0000, Val: 0.7080, Test: 0.7290
Epoch: 31, Loss: 3.5688, Train: 1.0000, Val: 0.7160, Test: 0.7300
Epoch: 32, Loss: 3.3400, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 33, Loss: 3.2690, Train: 1.0000, Val: 0.7280, Test: 0.7330
Epoch: 34, Loss: 3.3151, Train: 1.0000, Val: 0.7320, Test: 0.7330
Epoch: 35, Loss: 3.3774, Train: 1.0000, Val: 0.7420, Test: 0.7380
Epoch: 36, Loss: 3.6085, Train: 1.0000, Val: 0.7440, Test: 0.7440
Epoch: 37, Loss: 3.3586, Train: 1.0000, Val: 0.7480, Test: 0.7450
Epoch: 38, Loss: 3.5248, Train: 1.0000, Val: 0.7460, Test: 0.7480
Epoch: 39, Loss: 3.4413, Train: 1.0000, Val: 0.7500, Test: 0.7520
Epoch: 40, Loss: 3.1295, Train: 1.0000, Val: 0.7540, Test: 0.7590
Epoch: 41, Loss: 3.1432, Train: 1.0000, Val: 0.7580, Test: 0.7590
Epoch: 42, Loss: 3.2513, Train: 1.0000, Val: 0.7580, Test: 0.7560
Epoch: 43, Loss: 3.4413, Train: 1.0000, Val: 0.7540, Test: 0.7570
Epoch: 44, Loss: 3.1880, Train: 1.0000, Val: 0.7580, Test: 0.7560
Epoch: 45, Loss: 3.3193, Train: 1.0000, Val: 0.7580, Test: 0.7570
Epoch: 46, Loss: 3.5547, Train: 1.0000, Val: 0.7560, Test: 0.7600
Epoch: 47, Loss: 3.4600, Train: 1.0000, Val: 0.7560, Test: 0.7630
Epoch: 48, Loss: 3.3290, Train: 1.0000, Val: 0.7540, Test: 0.7640
Epoch: 49, Loss: 3.2316, Train: 1.0000, Val: 0.7540, Test: 0.7640
Epoch: 50, Loss: 3.1943, Train: 1.0000, Val: 0.7580, Test: 0.7650
Epoch: 51, Loss: 3.4721, Train: 1.0000, Val: 0.7600, Test: 0.7660
Epoch: 52, Loss: 3.1778, Train: 1.0000, Val: 0.7600, Test: 0.7640
Epoch: 53, Loss: 3.4146, Train: 1.0000, Val: 0.7580, Test: 0.7660
Epoch: 54, Loss: 3.0269, Train: 1.0000, Val: 0.7580, Test: 0.7660
Epoch: 55, Loss: 3.2411, Train: 1.0000, Val: 0.7560, Test: 0.7640
Epoch: 56, Loss: 3.4159, Train: 1.0000, Val: 0.7500, Test: 0.7640
Epoch: 57, Loss: 3.4685, Train: 1.0000, Val: 0.7540, Test: 0.7630
Epoch: 58, Loss: 3.1990, Train: 1.0000, Val: 0.7520, Test: 0.7630
Epoch: 59, Loss: 3.4044, Train: 1.0000, Val: 0.7500, Test: 0.7620
Epoch: 60, Loss: 3.1092, Train: 1.0000, Val: 0.7480, Test: 0.7620
Epoch: 61, Loss: 3.1873, Train: 1.0000, Val: 0.7420, Test: 0.7610
Epoch: 62, Loss: 3.1431, Train: 1.0000, Val: 0.7400, Test: 0.7600
Epoch: 63, Loss: 2.9306, Train: 1.0000, Val: 0.7400, Test: 0.7600
Epoch: 64, Loss: 3.1987, Train: 1.0000, Val: 0.7440, Test: 0.7620
Epoch: 65, Loss: 3.3964, Train: 1.0000, Val: 0.7440, Test: 0.7580
Epoch: 66, Loss: 3.1531, Train: 1.0000, Val: 0.7380, Test: 0.7550
Epoch: 67, Loss: 3.0568, Train: 1.0000, Val: 0.7400, Test: 0.7550
Epoch: 68, Loss: 3.0650, Train: 1.0000, Val: 0.7400, Test: 0.7540
Epoch: 69, Loss: 2.8280, Train: 1.0000, Val: 0.7380, Test: 0.7530
Epoch: 70, Loss: 3.1729, Train: 1.0000, Val: 0.7380, Test: 0.7510
Epoch: 71, Loss: 3.0354, Train: 1.0000, Val: 0.7400, Test: 0.7480
Epoch: 72, Loss: 3.1931, Train: 1.0000, Val: 0.7320, Test: 0.7490
Epoch: 73, Loss: 2.9963, Train: 1.0000, Val: 0.7340, Test: 0.7460
Epoch: 74, Loss: 3.2256, Train: 1.0000, Val: 0.7300, Test: 0.7470
Epoch: 75, Loss: 3.1076, Train: 1.0000, Val: 0.7300, Test: 0.7480
Epoch: 76, Loss: 3.1476, Train: 1.0000, Val: 0.7300, Test: 0.7480
Epoch: 77, Loss: 2.9613, Train: 1.0000, Val: 0.7300, Test: 0.7470
Epoch: 78, Loss: 3.1209, Train: 1.0000, Val: 0.7300, Test: 0.7470
Epoch: 79, Loss: 2.9178, Train: 1.0000, Val: 0.7320, Test: 0.7490
Epoch: 80, Loss: 2.8403, Train: 1.0000, Val: 0.7320, Test: 0.7480
Epoch: 81, Loss: 3.2405, Train: 1.0000, Val: 0.7340, Test: 0.7470
Epoch: 82, Loss: 2.9733, Train: 1.0000, Val: 0.7340, Test: 0.7450
Epoch: 83, Loss: 3.2750, Train: 1.0000, Val: 0.7360, Test: 0.7440
Epoch: 84, Loss: 2.9081, Train: 1.0000, Val: 0.7380, Test: 0.7460
Epoch: 85, Loss: 3.3092, Train: 1.0000, Val: 0.7340, Test: 0.7450
Epoch: 86, Loss: 2.9666, Train: 1.0000, Val: 0.7360, Test: 0.7450
Epoch: 87, Loss: 3.0704, Train: 1.0000, Val: 0.7400, Test: 0.7460
Epoch: 88, Loss: 3.2624, Train: 1.0000, Val: 0.7420, Test: 0.7470
Epoch: 89, Loss: 2.7602, Train: 1.0000, Val: 0.7420, Test: 0.7470
Epoch: 90, Loss: 3.0099, Train: 1.0000, Val: 0.7400, Test: 0.7460
Epoch: 91, Loss: 2.9084, Train: 1.0000, Val: 0.7380, Test: 0.7460
Epoch: 92, Loss: 3.1362, Train: 1.0000, Val: 0.7380, Test: 0.7490
Epoch: 93, Loss: 3.0554, Train: 1.0000, Val: 0.7380, Test: 0.7500
Epoch: 94, Loss: 2.8908, Train: 1.0000, Val: 0.7360, Test: 0.7500
Epoch: 95, Loss: 2.8861, Train: 1.0000, Val: 0.7340, Test: 0.7520
Epoch: 96, Loss: 3.0868, Train: 1.0000, Val: 0.7340, Test: 0.7530
Epoch: 97, Loss: 2.9645, Train: 1.0000, Val: 0.7340, Test: 0.7530
Epoch: 98, Loss: 2.8686, Train: 1.0000, Val: 0.7340, Test: 0.7510
Epoch: 99, Loss: 2.8848, Train: 1.0000, Val: 0.7380, Test: 0.7500
Epoch: 100, Loss: 2.8908, Train: 1.0000, Val: 0.7380, Test: 0.7480
Epoch: 101, Loss: 2.6348, Train: 1.0000, Val: 0.7400, Test: 0.7470
Epoch: 102, Loss: 3.1372, Train: 1.0000, Val: 0.7400, Test: 0.7460
Epoch: 103, Loss: 3.1314, Train: 1.0000, Val: 0.7380, Test: 0.7460
Epoch: 104, Loss: 2.7834, Train: 1.0000, Val: 0.7380, Test: 0.7450
Epoch: 105, Loss: 2.9400, Train: 1.0000, Val: 0.7360, Test: 0.7430
Epoch: 106, Loss: 2.8561, Train: 1.0000, Val: 0.7360, Test: 0.7460
Epoch: 107, Loss: 2.8871, Train: 1.0000, Val: 0.7340, Test: 0.7460
Epoch: 108, Loss: 2.9431, Train: 1.0000, Val: 0.7340, Test: 0.7480
Epoch: 109, Loss: 2.9740, Train: 1.0000, Val: 0.7320, Test: 0.7500
Epoch: 110, Loss: 2.5371, Train: 1.0000, Val: 0.7320, Test: 0.7490
Epoch: 111, Loss: 2.4946, Train: 1.0000, Val: 0.7300, Test: 0.7470
Epoch: 112, Loss: 3.0993, Train: 1.0000, Val: 0.7320, Test: 0.7460
Epoch: 113, Loss: 3.0282, Train: 1.0000, Val: 0.7300, Test: 0.7450
Epoch: 114, Loss: 2.9671, Train: 1.0000, Val: 0.7320, Test: 0.7430
Epoch: 115, Loss: 2.7444, Train: 1.0000, Val: 0.7300, Test: 0.7420
Epoch: 116, Loss: 2.5503, Train: 1.0000, Val: 0.7300, Test: 0.7420
Epoch: 117, Loss: 2.9584, Train: 1.0000, Val: 0.7280, Test: 0.7410
Epoch: 118, Loss: 2.9043, Train: 1.0000, Val: 0.7280, Test: 0.7380
Epoch: 119, Loss: 2.8024, Train: 1.0000, Val: 0.7240, Test: 0.7380
Epoch: 120, Loss: 2.7844, Train: 1.0000, Val: 0.7220, Test: 0.7410
Epoch: 121, Loss: 2.5082, Train: 1.0000, Val: 0.7240, Test: 0.7390
Epoch: 122, Loss: 2.6149, Train: 1.0000, Val: 0.7220, Test: 0.7360
Epoch: 123, Loss: 2.6728, Train: 1.0000, Val: 0.7240, Test: 0.7330
Epoch: 124, Loss: 2.6199, Train: 1.0000, Val: 0.7240, Test: 0.7320
Epoch: 125, Loss: 2.6670, Train: 1.0000, Val: 0.7240, Test: 0.7290
Epoch: 126, Loss: 2.6638, Train: 1.0000, Val: 0.7220, Test: 0.7270
Epoch: 127, Loss: 2.6378, Train: 1.0000, Val: 0.7240, Test: 0.7260
Epoch: 128, Loss: 2.4681, Train: 1.0000, Val: 0.7240, Test: 0.7270
Epoch: 129, Loss: 3.0046, Train: 1.0000, Val: 0.7240, Test: 0.7280
Epoch: 130, Loss: 2.9565, Train: 1.0000, Val: 0.7220, Test: 0.7280
Epoch: 131, Loss: 2.7493, Train: 1.0000, Val: 0.7200, Test: 0.7280
Epoch: 132, Loss: 2.6870, Train: 1.0000, Val: 0.7200, Test: 0.7310
Epoch: 133, Loss: 2.7785, Train: 1.0000, Val: 0.7220, Test: 0.7320
Epoch: 134, Loss: 2.7028, Train: 1.0000, Val: 0.7240, Test: 0.7330
Epoch: 135, Loss: 2.6981, Train: 1.0000, Val: 0.7220, Test: 0.7300
Epoch: 136, Loss: 2.5991, Train: 1.0000, Val: 0.7220, Test: 0.7320
Epoch: 137, Loss: 2.8794, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 138, Loss: 2.7750, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 139, Loss: 3.0425, Train: 1.0000, Val: 0.7220, Test: 0.7360
Epoch: 140, Loss: 2.6209, Train: 1.0000, Val: 0.7220, Test: 0.7350
Epoch: 141, Loss: 2.6668, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 142, Loss: 2.8171, Train: 1.0000, Val: 0.7220, Test: 0.7320
Epoch: 143, Loss: 2.6494, Train: 1.0000, Val: 0.7220, Test: 0.7350
Epoch: 144, Loss: 2.7857, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 145, Loss: 2.8290, Train: 1.0000, Val: 0.7220, Test: 0.7310
Epoch: 146, Loss: 2.4448, Train: 1.0000, Val: 0.7220, Test: 0.7280
Epoch: 147, Loss: 2.8342, Train: 1.0000, Val: 0.7220, Test: 0.7280
Epoch: 148, Loss: 2.5776, Train: 1.0000, Val: 0.7220, Test: 0.7280
Epoch: 149, Loss: 2.5353, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 150, Loss: 2.5790, Train: 1.0000, Val: 0.7200, Test: 0.7250
Epoch: 151, Loss: 3.0461, Train: 1.0000, Val: 0.7200, Test: 0.7230
Epoch: 152, Loss: 2.4789, Train: 1.0000, Val: 0.7220, Test: 0.7220
Epoch: 153, Loss: 2.5566, Train: 1.0000, Val: 0.7200, Test: 0.7220
Epoch: 154, Loss: 2.3295, Train: 1.0000, Val: 0.7200, Test: 0.7220
Epoch: 155, Loss: 2.3011, Train: 1.0000, Val: 0.7200, Test: 0.7210
Epoch: 156, Loss: 2.4644, Train: 1.0000, Val: 0.7220, Test: 0.7210
Epoch: 157, Loss: 2.4740, Train: 1.0000, Val: 0.7220, Test: 0.7170
Epoch: 158, Loss: 2.6391, Train: 1.0000, Val: 0.7240, Test: 0.7190
Epoch: 159, Loss: 2.8278, Train: 1.0000, Val: 0.7260, Test: 0.7250
Epoch: 160, Loss: 2.5244, Train: 1.0000, Val: 0.7280, Test: 0.7240
Epoch: 161, Loss: 2.6369, Train: 1.0000, Val: 0.7280, Test: 0.7220
Epoch: 162, Loss: 2.9451, Train: 1.0000, Val: 0.7280, Test: 0.7210
Epoch: 163, Loss: 2.4977, Train: 1.0000, Val: 0.7280, Test: 0.7190
Epoch: 164, Loss: 2.8442, Train: 1.0000, Val: 0.7280, Test: 0.7180
Epoch: 165, Loss: 2.6571, Train: 1.0000, Val: 0.7280, Test: 0.7180
Epoch: 166, Loss: 2.4697, Train: 1.0000, Val: 0.7260, Test: 0.7180
Epoch: 167, Loss: 2.6803, Train: 1.0000, Val: 0.7260, Test: 0.7210
Epoch: 168, Loss: 2.6959, Train: 1.0000, Val: 0.7300, Test: 0.7190
Epoch: 169, Loss: 2.7140, Train: 1.0000, Val: 0.7300, Test: 0.7200
Epoch: 170, Loss: 2.5756, Train: 1.0000, Val: 0.7280, Test: 0.7220
Epoch: 171, Loss: 2.6542, Train: 1.0000, Val: 0.7340, Test: 0.7200
Epoch: 172, Loss: 2.4621, Train: 1.0000, Val: 0.7320, Test: 0.7210
Epoch: 173, Loss: 2.6639, Train: 1.0000, Val: 0.7300, Test: 0.7180
Epoch: 174, Loss: 2.6019, Train: 1.0000, Val: 0.7300, Test: 0.7190
Epoch: 175, Loss: 2.4620, Train: 1.0000, Val: 0.7260, Test: 0.7170
Epoch: 176, Loss: 2.6840, Train: 1.0000, Val: 0.7240, Test: 0.7180
Epoch: 177, Loss: 2.8061, Train: 1.0000, Val: 0.7240, Test: 0.7180
Epoch: 178, Loss: 2.6033, Train: 1.0000, Val: 0.7220, Test: 0.7190
Epoch: 179, Loss: 2.3513, Train: 1.0000, Val: 0.7200, Test: 0.7150
Epoch: 180, Loss: 2.5828, Train: 1.0000, Val: 0.7200, Test: 0.7140
Epoch: 181, Loss: 2.4330, Train: 1.0000, Val: 0.7240, Test: 0.7140
Epoch: 182, Loss: 2.2770, Train: 1.0000, Val: 0.7240, Test: 0.7130
Epoch: 183, Loss: 2.9159, Train: 1.0000, Val: 0.7220, Test: 0.7120
Epoch: 184, Loss: 2.5158, Train: 1.0000, Val: 0.7240, Test: 0.7100
Epoch: 185, Loss: 2.4316, Train: 1.0000, Val: 0.7200, Test: 0.7100
Epoch: 186, Loss: 2.7602, Train: 1.0000, Val: 0.7200, Test: 0.7080
Epoch: 187, Loss: 2.3853, Train: 1.0000, Val: 0.7200, Test: 0.7090
Epoch: 188, Loss: 2.4082, Train: 1.0000, Val: 0.7160, Test: 0.7110
Epoch: 189, Loss: 2.2174, Train: 1.0000, Val: 0.7160, Test: 0.7090
Epoch: 190, Loss: 2.5466, Train: 1.0000, Val: 0.7160, Test: 0.7090
Epoch: 191, Loss: 2.4311, Train: 1.0000, Val: 0.7200, Test: 0.7070
Epoch: 192, Loss: 2.2913, Train: 1.0000, Val: 0.7180, Test: 0.7050
Epoch: 193, Loss: 2.5326, Train: 1.0000, Val: 0.7180, Test: 0.7100
Epoch: 194, Loss: 2.7846, Train: 1.0000, Val: 0.7160, Test: 0.7110
Epoch: 195, Loss: 2.3779, Train: 1.0000, Val: 0.7160, Test: 0.7110
Epoch: 196, Loss: 2.6997, Train: 1.0000, Val: 0.7220, Test: 0.7100
Epoch: 197, Loss: 2.5912, Train: 1.0000, Val: 0.7180, Test: 0.7060
Epoch: 198, Loss: 2.5139, Train: 1.0000, Val: 0.7160, Test: 0.7020
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 199, Loss: 2.4762, Train: 1.0000, Val: 0.7160, Test: 0.7030
Epoch: 200, Loss: 2.3701, Train: 1.0000, Val: 0.7160, Test: 0.7020
MAD:  0.3788
Best Test Accuracy: 0.7660, Val Accuracy: 0.7600, Train Accuracy: 1.0000
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8704, Train: 0.0857, Val: 0.0360, Test: 0.0390
Epoch: 2, Loss: 4.8159, Train: 0.2714, Val: 0.1240, Test: 0.1010
Epoch: 3, Loss: 4.7381, Train: 0.4571, Val: 0.1960, Test: 0.2060
Epoch: 4, Loss: 4.6446, Train: 0.5929, Val: 0.2680, Test: 0.2900
Epoch: 5, Loss: 4.6075, Train: 0.6714, Val: 0.3320, Test: 0.3640
Epoch: 6, Loss: 4.5933, Train: 0.7571, Val: 0.3880, Test: 0.4240
Epoch: 7, Loss: 4.4352, Train: 0.8214, Val: 0.4300, Test: 0.4770
Epoch: 8, Loss: 4.4705, Train: 0.8286, Val: 0.4560, Test: 0.5160
Epoch: 9, Loss: 4.2314, Train: 0.8500, Val: 0.4860, Test: 0.5440
Epoch: 10, Loss: 4.3762, Train: 0.8571, Val: 0.5300, Test: 0.5700
Epoch: 11, Loss: 4.2850, Train: 0.8786, Val: 0.5700, Test: 0.5870
Epoch: 12, Loss: 3.9722, Train: 0.9000, Val: 0.6080, Test: 0.6080
Epoch: 13, Loss: 4.0422, Train: 0.9286, Val: 0.6220, Test: 0.6280
Epoch: 14, Loss: 3.9638, Train: 0.9429, Val: 0.6280, Test: 0.6500
Epoch: 15, Loss: 3.9459, Train: 0.9429, Val: 0.6340, Test: 0.6630
Epoch: 16, Loss: 3.6889, Train: 0.9714, Val: 0.6460, Test: 0.6770
Epoch: 17, Loss: 3.8387, Train: 0.9714, Val: 0.6660, Test: 0.6940
Epoch: 18, Loss: 3.8056, Train: 0.9929, Val: 0.6760, Test: 0.7010
Epoch: 19, Loss: 3.9451, Train: 0.9929, Val: 0.6980, Test: 0.7120
Epoch: 20, Loss: 3.9339, Train: 0.9929, Val: 0.6980, Test: 0.7190
Epoch: 21, Loss: 3.5068, Train: 0.9929, Val: 0.6960, Test: 0.7230
Epoch: 22, Loss: 3.6874, Train: 0.9929, Val: 0.6980, Test: 0.7220
Epoch: 23, Loss: 3.5410, Train: 0.9929, Val: 0.7040, Test: 0.7220
Epoch: 24, Loss: 3.8020, Train: 0.9929, Val: 0.7020, Test: 0.7180
Epoch: 25, Loss: 3.8998, Train: 0.9929, Val: 0.7040, Test: 0.7140
Epoch: 26, Loss: 3.4853, Train: 0.9929, Val: 0.6940, Test: 0.7130
Epoch: 27, Loss: 3.7739, Train: 0.9929, Val: 0.6920, Test: 0.7140
Epoch: 28, Loss: 3.9076, Train: 0.9929, Val: 0.6980, Test: 0.7130
Epoch: 29, Loss: 3.5351, Train: 0.9929, Val: 0.6960, Test: 0.7090
Epoch: 30, Loss: 3.0244, Train: 0.9929, Val: 0.6980, Test: 0.7060
Epoch: 31, Loss: 3.3985, Train: 0.9929, Val: 0.6980, Test: 0.7080
Epoch: 32, Loss: 3.6178, Train: 0.9929, Val: 0.7000, Test: 0.7120
Epoch: 33, Loss: 3.3896, Train: 0.9929, Val: 0.7040, Test: 0.7130
Epoch: 34, Loss: 3.6220, Train: 0.9929, Val: 0.7060, Test: 0.7160
Epoch: 35, Loss: 3.4370, Train: 0.9929, Val: 0.7100, Test: 0.7220
Epoch: 36, Loss: 3.4414, Train: 0.9929, Val: 0.7160, Test: 0.7250
Epoch: 37, Loss: 3.1785, Train: 0.9929, Val: 0.7180, Test: 0.7300
Epoch: 38, Loss: 3.4409, Train: 0.9929, Val: 0.7200, Test: 0.7340
Epoch: 39, Loss: 3.3192, Train: 1.0000, Val: 0.7160, Test: 0.7340
Epoch: 40, Loss: 3.1726, Train: 1.0000, Val: 0.7240, Test: 0.7420
Epoch: 41, Loss: 3.0084, Train: 1.0000, Val: 0.7280, Test: 0.7480
Epoch: 42, Loss: 3.6190, Train: 1.0000, Val: 0.7320, Test: 0.7500
Epoch: 43, Loss: 3.5927, Train: 1.0000, Val: 0.7300, Test: 0.7460
Epoch: 44, Loss: 3.4075, Train: 1.0000, Val: 0.7260, Test: 0.7500
Epoch: 45, Loss: 3.2606, Train: 1.0000, Val: 0.7260, Test: 0.7510
Epoch: 46, Loss: 3.2764, Train: 1.0000, Val: 0.7280, Test: 0.7520
Epoch: 47, Loss: 3.4951, Train: 1.0000, Val: 0.7320, Test: 0.7550
Epoch: 48, Loss: 3.6827, Train: 1.0000, Val: 0.7380, Test: 0.7570
Epoch: 49, Loss: 3.6604, Train: 1.0000, Val: 0.7480, Test: 0.7590
Epoch: 50, Loss: 3.4911, Train: 1.0000, Val: 0.7520, Test: 0.7610
Epoch: 51, Loss: 3.2478, Train: 1.0000, Val: 0.7480, Test: 0.7600
Epoch: 52, Loss: 2.8404, Train: 1.0000, Val: 0.7480, Test: 0.7610
Epoch: 53, Loss: 3.1729, Train: 1.0000, Val: 0.7480, Test: 0.7590
Epoch: 54, Loss: 3.3348, Train: 1.0000, Val: 0.7480, Test: 0.7580
Epoch: 55, Loss: 3.2290, Train: 1.0000, Val: 0.7480, Test: 0.7590
Epoch: 56, Loss: 3.1967, Train: 1.0000, Val: 0.7480, Test: 0.7580
Epoch: 57, Loss: 3.0319, Train: 1.0000, Val: 0.7480, Test: 0.7590
Epoch: 58, Loss: 2.9243, Train: 1.0000, Val: 0.7460, Test: 0.7600
Epoch: 59, Loss: 3.0849, Train: 1.0000, Val: 0.7440, Test: 0.7600
Epoch: 60, Loss: 3.3100, Train: 1.0000, Val: 0.7400, Test: 0.7570
Epoch: 61, Loss: 3.1617, Train: 1.0000, Val: 0.7400, Test: 0.7570
Epoch: 62, Loss: 3.2090, Train: 1.0000, Val: 0.7420, Test: 0.7550
Epoch: 63, Loss: 3.4343, Train: 1.0000, Val: 0.7420, Test: 0.7570
Epoch: 64, Loss: 3.3330, Train: 1.0000, Val: 0.7440, Test: 0.7530
Epoch: 65, Loss: 3.0316, Train: 1.0000, Val: 0.7400, Test: 0.7520
Epoch: 66, Loss: 3.2534, Train: 1.0000, Val: 0.7420, Test: 0.7520
Epoch: 67, Loss: 3.2612, Train: 1.0000, Val: 0.7440, Test: 0.7500
Epoch: 68, Loss: 3.0760, Train: 1.0000, Val: 0.7400, Test: 0.7500
Epoch: 69, Loss: 2.9056, Train: 1.0000, Val: 0.7400, Test: 0.7490
Epoch: 70, Loss: 3.2785, Train: 1.0000, Val: 0.7400, Test: 0.7470
Epoch: 71, Loss: 3.2981, Train: 1.0000, Val: 0.7380, Test: 0.7440
Epoch: 72, Loss: 3.1489, Train: 1.0000, Val: 0.7340, Test: 0.7430
Epoch: 73, Loss: 2.9321, Train: 1.0000, Val: 0.7360, Test: 0.7430
Epoch: 74, Loss: 3.1379, Train: 1.0000, Val: 0.7360, Test: 0.7430
Epoch: 75, Loss: 2.9628, Train: 1.0000, Val: 0.7360, Test: 0.7430
Epoch: 76, Loss: 3.2874, Train: 1.0000, Val: 0.7360, Test: 0.7430
Epoch: 77, Loss: 2.8302, Train: 1.0000, Val: 0.7360, Test: 0.7430
Epoch: 78, Loss: 3.2529, Train: 1.0000, Val: 0.7360, Test: 0.7440
Epoch: 79, Loss: 3.4087, Train: 1.0000, Val: 0.7360, Test: 0.7470
Epoch: 80, Loss: 2.9349, Train: 1.0000, Val: 0.7360, Test: 0.7460
Epoch: 81, Loss: 3.0321, Train: 1.0000, Val: 0.7360, Test: 0.7470
Epoch: 82, Loss: 2.9816, Train: 1.0000, Val: 0.7380, Test: 0.7470
Epoch: 83, Loss: 2.6370, Train: 1.0000, Val: 0.7420, Test: 0.7470
Epoch: 84, Loss: 2.9701, Train: 1.0000, Val: 0.7420, Test: 0.7470
Epoch: 85, Loss: 3.1738, Train: 1.0000, Val: 0.7400, Test: 0.7460
Epoch: 86, Loss: 2.8964, Train: 1.0000, Val: 0.7360, Test: 0.7460
Epoch: 87, Loss: 2.7627, Train: 1.0000, Val: 0.7340, Test: 0.7460
Epoch: 88, Loss: 2.7603, Train: 1.0000, Val: 0.7360, Test: 0.7450
Epoch: 89, Loss: 3.1468, Train: 1.0000, Val: 0.7360, Test: 0.7440
Epoch: 90, Loss: 3.1211, Train: 1.0000, Val: 0.7360, Test: 0.7420
Epoch: 91, Loss: 2.9907, Train: 1.0000, Val: 0.7360, Test: 0.7410
Epoch: 92, Loss: 3.0310, Train: 1.0000, Val: 0.7340, Test: 0.7420
Epoch: 93, Loss: 2.8869, Train: 1.0000, Val: 0.7340, Test: 0.7420
Epoch: 94, Loss: 2.9708, Train: 1.0000, Val: 0.7360, Test: 0.7390
Epoch: 95, Loss: 2.9564, Train: 1.0000, Val: 0.7340, Test: 0.7380
Epoch: 96, Loss: 2.8478, Train: 1.0000, Val: 0.7340, Test: 0.7380
Epoch: 97, Loss: 2.8759, Train: 1.0000, Val: 0.7340, Test: 0.7370
Epoch: 98, Loss: 3.0040, Train: 1.0000, Val: 0.7340, Test: 0.7340
Epoch: 99, Loss: 3.1265, Train: 1.0000, Val: 0.7320, Test: 0.7350
Epoch: 100, Loss: 2.8036, Train: 1.0000, Val: 0.7320, Test: 0.7370
Epoch: 101, Loss: 3.0403, Train: 1.0000, Val: 0.7300, Test: 0.7370
Epoch: 102, Loss: 2.8338, Train: 1.0000, Val: 0.7280, Test: 0.7380
Epoch: 103, Loss: 2.8134, Train: 1.0000, Val: 0.7280, Test: 0.7370
Epoch: 104, Loss: 2.8795, Train: 1.0000, Val: 0.7280, Test: 0.7380
Epoch: 105, Loss: 3.1010, Train: 1.0000, Val: 0.7280, Test: 0.7370
Epoch: 106, Loss: 2.9194, Train: 1.0000, Val: 0.7280, Test: 0.7370
Epoch: 107, Loss: 2.9542, Train: 1.0000, Val: 0.7280, Test: 0.7380
Epoch: 108, Loss: 2.9436, Train: 1.0000, Val: 0.7280, Test: 0.7370
Epoch: 109, Loss: 2.8570, Train: 1.0000, Val: 0.7260, Test: 0.7360
Epoch: 110, Loss: 2.8425, Train: 1.0000, Val: 0.7260, Test: 0.7360
Epoch: 111, Loss: 2.7287, Train: 1.0000, Val: 0.7280, Test: 0.7370
Epoch: 112, Loss: 2.8758, Train: 1.0000, Val: 0.7280, Test: 0.7360
Epoch: 113, Loss: 2.8494, Train: 1.0000, Val: 0.7260, Test: 0.7380
Epoch: 114, Loss: 2.7480, Train: 1.0000, Val: 0.7240, Test: 0.7330
Epoch: 115, Loss: 2.6699, Train: 1.0000, Val: 0.7240, Test: 0.7320
Epoch: 116, Loss: 2.7980, Train: 1.0000, Val: 0.7240, Test: 0.7300
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 117, Loss: 2.7364, Train: 1.0000, Val: 0.7220, Test: 0.7310
Epoch: 118, Loss: 3.0150, Train: 1.0000, Val: 0.7200, Test: 0.7290
Epoch: 119, Loss: 3.0058, Train: 1.0000, Val: 0.7200, Test: 0.7280
Epoch: 120, Loss: 2.7028, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 121, Loss: 2.8388, Train: 1.0000, Val: 0.7220, Test: 0.7270
Epoch: 122, Loss: 2.7758, Train: 1.0000, Val: 0.7240, Test: 0.7260
Epoch: 123, Loss: 2.9141, Train: 1.0000, Val: 0.7240, Test: 0.7250
Epoch: 124, Loss: 2.6061, Train: 1.0000, Val: 0.7260, Test: 0.7250
Epoch: 125, Loss: 2.8863, Train: 1.0000, Val: 0.7260, Test: 0.7260
Epoch: 126, Loss: 2.9333, Train: 1.0000, Val: 0.7300, Test: 0.7260
Epoch: 127, Loss: 2.5915, Train: 1.0000, Val: 0.7280, Test: 0.7260
Epoch: 128, Loss: 2.5886, Train: 1.0000, Val: 0.7280, Test: 0.7260
Epoch: 129, Loss: 2.5520, Train: 1.0000, Val: 0.7260, Test: 0.7280
Epoch: 130, Loss: 2.5636, Train: 1.0000, Val: 0.7240, Test: 0.7280
Epoch: 131, Loss: 2.8310, Train: 1.0000, Val: 0.7220, Test: 0.7270
Epoch: 132, Loss: 2.7439, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 133, Loss: 2.5558, Train: 1.0000, Val: 0.7220, Test: 0.7280
Epoch: 134, Loss: 2.7511, Train: 1.0000, Val: 0.7220, Test: 0.7290
Epoch: 135, Loss: 2.6976, Train: 1.0000, Val: 0.7220, Test: 0.7310
Epoch: 136, Loss: 2.8607, Train: 1.0000, Val: 0.7220, Test: 0.7340
Epoch: 137, Loss: 2.8688, Train: 1.0000, Val: 0.7220, Test: 0.7340
Epoch: 138, Loss: 2.7792, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 139, Loss: 2.9517, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 140, Loss: 2.4647, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 141, Loss: 2.6667, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 142, Loss: 2.7360, Train: 1.0000, Val: 0.7220, Test: 0.7350
Epoch: 143, Loss: 3.0895, Train: 1.0000, Val: 0.7220, Test: 0.7350
Epoch: 144, Loss: 2.6695, Train: 1.0000, Val: 0.7220, Test: 0.7340
Epoch: 145, Loss: 2.6564, Train: 1.0000, Val: 0.7220, Test: 0.7350
Epoch: 146, Loss: 2.4453, Train: 1.0000, Val: 0.7220, Test: 0.7330
Epoch: 147, Loss: 2.3372, Train: 1.0000, Val: 0.7240, Test: 0.7310
Epoch: 148, Loss: 3.1202, Train: 1.0000, Val: 0.7240, Test: 0.7300
Epoch: 149, Loss: 2.5846, Train: 1.0000, Val: 0.7240, Test: 0.7290
Epoch: 150, Loss: 2.5919, Train: 1.0000, Val: 0.7240, Test: 0.7280
Epoch: 151, Loss: 2.7501, Train: 1.0000, Val: 0.7240, Test: 0.7280
Epoch: 152, Loss: 2.5894, Train: 1.0000, Val: 0.7260, Test: 0.7270
Epoch: 153, Loss: 2.5784, Train: 1.0000, Val: 0.7260, Test: 0.7250
Epoch: 154, Loss: 2.7029, Train: 1.0000, Val: 0.7240, Test: 0.7240
Epoch: 155, Loss: 2.7423, Train: 1.0000, Val: 0.7240, Test: 0.7240
Epoch: 156, Loss: 2.6050, Train: 1.0000, Val: 0.7240, Test: 0.7230
Epoch: 157, Loss: 2.4243, Train: 1.0000, Val: 0.7240, Test: 0.7230
Epoch: 158, Loss: 2.5335, Train: 1.0000, Val: 0.7200, Test: 0.7220
Epoch: 159, Loss: 2.5943, Train: 1.0000, Val: 0.7200, Test: 0.7220
Epoch: 160, Loss: 2.3045, Train: 1.0000, Val: 0.7200, Test: 0.7200
Epoch: 161, Loss: 2.5203, Train: 1.0000, Val: 0.7200, Test: 0.7190
Epoch: 162, Loss: 2.3344, Train: 1.0000, Val: 0.7200, Test: 0.7190
Epoch: 163, Loss: 2.5638, Train: 1.0000, Val: 0.7200, Test: 0.7180
Epoch: 164, Loss: 2.7465, Train: 1.0000, Val: 0.7200, Test: 0.7180
Epoch: 165, Loss: 2.6476, Train: 1.0000, Val: 0.7220, Test: 0.7150
Epoch: 166, Loss: 2.6696, Train: 1.0000, Val: 0.7220, Test: 0.7140
Epoch: 167, Loss: 2.6726, Train: 1.0000, Val: 0.7220, Test: 0.7170
Epoch: 168, Loss: 2.4473, Train: 1.0000, Val: 0.7220, Test: 0.7170
Epoch: 169, Loss: 2.7505, Train: 1.0000, Val: 0.7220, Test: 0.7140
Epoch: 170, Loss: 2.7626, Train: 1.0000, Val: 0.7220, Test: 0.7120
Epoch: 171, Loss: 2.6552, Train: 1.0000, Val: 0.7220, Test: 0.7120
Epoch: 172, Loss: 2.4836, Train: 1.0000, Val: 0.7220, Test: 0.7120
Epoch: 173, Loss: 2.5509, Train: 1.0000, Val: 0.7220, Test: 0.7120
Epoch: 174, Loss: 2.3901, Train: 1.0000, Val: 0.7220, Test: 0.7120
Epoch: 175, Loss: 2.3978, Train: 1.0000, Val: 0.7220, Test: 0.7110
Epoch: 176, Loss: 2.6183, Train: 1.0000, Val: 0.7240, Test: 0.7160
Epoch: 177, Loss: 2.5862, Train: 1.0000, Val: 0.7240, Test: 0.7130
Epoch: 178, Loss: 2.6939, Train: 1.0000, Val: 0.7240, Test: 0.7130
Epoch: 179, Loss: 2.4908, Train: 1.0000, Val: 0.7220, Test: 0.7140
Epoch: 180, Loss: 2.5127, Train: 1.0000, Val: 0.7220, Test: 0.7140
Epoch: 181, Loss: 2.9640, Train: 1.0000, Val: 0.7220, Test: 0.7150
Epoch: 182, Loss: 2.6133, Train: 1.0000, Val: 0.7200, Test: 0.7170
Epoch: 183, Loss: 2.4263, Train: 1.0000, Val: 0.7160, Test: 0.7130
Epoch: 184, Loss: 2.4011, Train: 1.0000, Val: 0.7160, Test: 0.7100
Epoch: 185, Loss: 2.6128, Train: 1.0000, Val: 0.7160, Test: 0.7100
Epoch: 186, Loss: 2.5215, Train: 1.0000, Val: 0.7140, Test: 0.7110
Epoch: 187, Loss: 2.5499, Train: 1.0000, Val: 0.7160, Test: 0.7120
Epoch: 188, Loss: 2.7298, Train: 1.0000, Val: 0.7160, Test: 0.7120
Epoch: 189, Loss: 2.4502, Train: 1.0000, Val: 0.7140, Test: 0.7120
Epoch: 190, Loss: 2.7095, Train: 1.0000, Val: 0.7120, Test: 0.7110
Epoch: 191, Loss: 2.8145, Train: 1.0000, Val: 0.7140, Test: 0.7110
Epoch: 192, Loss: 2.7931, Train: 1.0000, Val: 0.7140, Test: 0.7110
Epoch: 193, Loss: 2.4688, Train: 1.0000, Val: 0.7140, Test: 0.7110
Epoch: 194, Loss: 2.4541, Train: 1.0000, Val: 0.7160, Test: 0.7100
Epoch: 195, Loss: 2.5344, Train: 1.0000, Val: 0.7160, Test: 0.7090
Epoch: 196, Loss: 2.3946, Train: 1.0000, Val: 0.7160, Test: 0.7080
Epoch: 197, Loss: 2.6843, Train: 1.0000, Val: 0.7180, Test: 0.7100
Epoch: 198, Loss: 2.4467, Train: 1.0000, Val: 0.7180, Test: 0.7070
Epoch: 199, Loss: 2.3747, Train: 1.0000, Val: 0.7200, Test: 0.7050
Epoch: 200, Loss: 2.5086, Train: 1.0000, Val: 0.7200, Test: 0.7070
MAD:  0.3827
Best Test Accuracy: 0.7610, Val Accuracy: 0.7520, Train Accuracy: 1.0000
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8314, Train: 0.1214, Val: 0.0380, Test: 0.0420
Epoch: 2, Loss: 4.7625, Train: 0.2500, Val: 0.0820, Test: 0.1000
Epoch: 3, Loss: 4.7634, Train: 0.3571, Val: 0.1220, Test: 0.1310
Epoch: 4, Loss: 4.6485, Train: 0.4071, Val: 0.1580, Test: 0.1560
Epoch: 5, Loss: 4.5968, Train: 0.4857, Val: 0.1740, Test: 0.1820
Epoch: 6, Loss: 4.5263, Train: 0.5429, Val: 0.2060, Test: 0.2120
Epoch: 7, Loss: 4.5607, Train: 0.5857, Val: 0.2280, Test: 0.2390
Epoch: 8, Loss: 4.4377, Train: 0.6071, Val: 0.2500, Test: 0.2640
Epoch: 9, Loss: 4.2844, Train: 0.6214, Val: 0.2780, Test: 0.2890
Epoch: 10, Loss: 4.2102, Train: 0.6357, Val: 0.2940, Test: 0.3100
Epoch: 11, Loss: 4.1995, Train: 0.6714, Val: 0.3220, Test: 0.3290
Epoch: 12, Loss: 4.1055, Train: 0.7143, Val: 0.3540, Test: 0.3670
Epoch: 13, Loss: 4.2523, Train: 0.7714, Val: 0.3880, Test: 0.3990
Epoch: 14, Loss: 3.7874, Train: 0.7714, Val: 0.4060, Test: 0.4270
Epoch: 15, Loss: 4.0528, Train: 0.8000, Val: 0.4380, Test: 0.4600
Epoch: 16, Loss: 3.7905, Train: 0.8214, Val: 0.4700, Test: 0.4900
Epoch: 17, Loss: 4.0163, Train: 0.8286, Val: 0.5080, Test: 0.5310
Epoch: 18, Loss: 3.7511, Train: 0.8500, Val: 0.5380, Test: 0.5650
Epoch: 19, Loss: 3.9639, Train: 0.8429, Val: 0.5580, Test: 0.5870
Epoch: 20, Loss: 3.8245, Train: 0.8500, Val: 0.5780, Test: 0.5960
Epoch: 21, Loss: 3.8812, Train: 0.8500, Val: 0.5880, Test: 0.6160
Epoch: 22, Loss: 3.9153, Train: 0.8500, Val: 0.5960, Test: 0.6180
Epoch: 23, Loss: 3.7323, Train: 0.8500, Val: 0.6040, Test: 0.6280
Epoch: 24, Loss: 3.8094, Train: 0.8571, Val: 0.6020, Test: 0.6290
Epoch: 25, Loss: 3.8326, Train: 0.8571, Val: 0.6040, Test: 0.6350
Epoch: 26, Loss: 3.5507, Train: 0.8714, Val: 0.6100, Test: 0.6340
Epoch: 27, Loss: 3.7998, Train: 0.8786, Val: 0.6140, Test: 0.6390
Epoch: 28, Loss: 3.5020, Train: 0.8786, Val: 0.6160, Test: 0.6400
Epoch: 29, Loss: 3.4007, Train: 0.8929, Val: 0.6160, Test: 0.6410
Epoch: 30, Loss: 3.5682, Train: 0.9000, Val: 0.6120, Test: 0.6430
Epoch: 31, Loss: 3.4983, Train: 0.9000, Val: 0.6120, Test: 0.6420
Epoch: 32, Loss: 3.7581, Train: 0.9071, Val: 0.6180, Test: 0.6450
Epoch: 33, Loss: 3.5143, Train: 0.9071, Val: 0.6160, Test: 0.6480
Epoch: 34, Loss: 3.5443, Train: 0.9071, Val: 0.6220, Test: 0.6470
Epoch: 35, Loss: 3.6249, Train: 0.9214, Val: 0.6180, Test: 0.6460
Epoch: 36, Loss: 3.5248, Train: 0.9429, Val: 0.6220, Test: 0.6470
Epoch: 37, Loss: 3.6869, Train: 0.9500, Val: 0.6260, Test: 0.6450
Epoch: 38, Loss: 3.4262, Train: 0.9571, Val: 0.6320, Test: 0.6500
Epoch: 39, Loss: 3.4100, Train: 0.9643, Val: 0.6300, Test: 0.6520
Epoch: 40, Loss: 3.6422, Train: 0.9643, Val: 0.6320, Test: 0.6550
Epoch: 41, Loss: 3.4961, Train: 0.9643, Val: 0.6340, Test: 0.6560
Epoch: 42, Loss: 3.6937, Train: 0.9643, Val: 0.6340, Test: 0.6590
Epoch: 43, Loss: 3.4989, Train: 0.9643, Val: 0.6400, Test: 0.6630
Epoch: 44, Loss: 3.3903, Train: 0.9643, Val: 0.6380, Test: 0.6650
Epoch: 45, Loss: 3.4540, Train: 0.9643, Val: 0.6360, Test: 0.6680
Epoch: 46, Loss: 3.4103, Train: 0.9643, Val: 0.6340, Test: 0.6700
Epoch: 47, Loss: 3.2626, Train: 0.9643, Val: 0.6380, Test: 0.6700
Epoch: 48, Loss: 3.3527, Train: 0.9714, Val: 0.6420, Test: 0.6730
Epoch: 49, Loss: 3.2636, Train: 0.9714, Val: 0.6460, Test: 0.6720
Epoch: 50, Loss: 3.3546, Train: 0.9786, Val: 0.6480, Test: 0.6740
Epoch: 51, Loss: 3.1557, Train: 0.9786, Val: 0.6460, Test: 0.6750
Epoch: 52, Loss: 3.3771, Train: 0.9786, Val: 0.6480, Test: 0.6770
Epoch: 53, Loss: 3.2724, Train: 0.9786, Val: 0.6500, Test: 0.6780
Epoch: 54, Loss: 3.5728, Train: 0.9786, Val: 0.6500, Test: 0.6790
Epoch: 55, Loss: 3.2560, Train: 0.9857, Val: 0.6540, Test: 0.6800
Epoch: 56, Loss: 3.2341, Train: 0.9857, Val: 0.6560, Test: 0.6850
Epoch: 57, Loss: 3.2433, Train: 0.9857, Val: 0.6640, Test: 0.6870
Epoch: 58, Loss: 2.9307, Train: 0.9857, Val: 0.6640, Test: 0.6850
Epoch: 59, Loss: 3.3957, Train: 0.9857, Val: 0.6660, Test: 0.6870
Epoch: 60, Loss: 3.1129, Train: 0.9857, Val: 0.6700, Test: 0.6860
Epoch: 61, Loss: 3.1738, Train: 0.9929, Val: 0.6660, Test: 0.6890
Epoch: 62, Loss: 3.3521, Train: 0.9929, Val: 0.6640, Test: 0.6890
Epoch: 63, Loss: 3.1313, Train: 0.9929, Val: 0.6640, Test: 0.6900
Epoch: 64, Loss: 3.3227, Train: 0.9929, Val: 0.6680, Test: 0.6920
Epoch: 65, Loss: 3.2333, Train: 0.9929, Val: 0.6640, Test: 0.6930
Epoch: 66, Loss: 3.0494, Train: 0.9929, Val: 0.6680, Test: 0.6940
Epoch: 67, Loss: 3.0964, Train: 0.9929, Val: 0.6680, Test: 0.6950
Epoch: 68, Loss: 3.2212, Train: 0.9929, Val: 0.6740, Test: 0.6960
Epoch: 69, Loss: 3.2923, Train: 0.9929, Val: 0.6740, Test: 0.6960
Epoch: 70, Loss: 3.0703, Train: 0.9929, Val: 0.6760, Test: 0.6950
Epoch: 71, Loss: 3.3959, Train: 0.9929, Val: 0.6780, Test: 0.6980
Epoch: 72, Loss: 3.1735, Train: 0.9929, Val: 0.6740, Test: 0.6990
Epoch: 73, Loss: 3.1369, Train: 0.9929, Val: 0.6720, Test: 0.6990
Epoch: 74, Loss: 3.1216, Train: 0.9929, Val: 0.6740, Test: 0.7000
Epoch: 75, Loss: 3.1840, Train: 0.9929, Val: 0.6760, Test: 0.7020
Epoch: 76, Loss: 3.1717, Train: 0.9929, Val: 0.6740, Test: 0.7000
Epoch: 77, Loss: 2.9550, Train: 0.9929, Val: 0.6720, Test: 0.6960
Epoch: 78, Loss: 2.7604, Train: 0.9929, Val: 0.6680, Test: 0.6970
Epoch: 79, Loss: 3.2662, Train: 1.0000, Val: 0.6700, Test: 0.6960
Epoch: 80, Loss: 2.7875, Train: 1.0000, Val: 0.6720, Test: 0.6930
Epoch: 81, Loss: 3.1568, Train: 1.0000, Val: 0.6760, Test: 0.6940
Epoch: 82, Loss: 3.0378, Train: 1.0000, Val: 0.6780, Test: 0.6940
Epoch: 83, Loss: 3.1636, Train: 1.0000, Val: 0.6820, Test: 0.6940
Epoch: 84, Loss: 3.0844, Train: 1.0000, Val: 0.6780, Test: 0.6960
Epoch: 85, Loss: 3.1117, Train: 1.0000, Val: 0.6740, Test: 0.6960
Epoch: 86, Loss: 3.1523, Train: 1.0000, Val: 0.6740, Test: 0.6950
Epoch: 87, Loss: 3.3024, Train: 1.0000, Val: 0.6740, Test: 0.6940
Epoch: 88, Loss: 3.2267, Train: 1.0000, Val: 0.6740, Test: 0.6920
Epoch: 89, Loss: 3.0329, Train: 1.0000, Val: 0.6760, Test: 0.6930
Epoch: 90, Loss: 3.0184, Train: 1.0000, Val: 0.6800, Test: 0.6920
Epoch: 91, Loss: 2.9421, Train: 1.0000, Val: 0.6800, Test: 0.6930
Epoch: 92, Loss: 2.9344, Train: 1.0000, Val: 0.6780, Test: 0.6910
Epoch: 93, Loss: 3.0943, Train: 1.0000, Val: 0.6780, Test: 0.6920
Epoch: 94, Loss: 3.0174, Train: 1.0000, Val: 0.6780, Test: 0.6940
Epoch: 95, Loss: 3.1306, Train: 1.0000, Val: 0.6780, Test: 0.6950
Epoch: 96, Loss: 2.9081, Train: 1.0000, Val: 0.6760, Test: 0.6980
Epoch: 97, Loss: 3.0195, Train: 1.0000, Val: 0.6780, Test: 0.6980
Epoch: 98, Loss: 3.0498, Train: 1.0000, Val: 0.6780, Test: 0.6980
Epoch: 99, Loss: 2.7998, Train: 1.0000, Val: 0.6780, Test: 0.6960
Epoch: 100, Loss: 2.8075, Train: 1.0000, Val: 0.6720, Test: 0.6950
Epoch: 101, Loss: 3.0112, Train: 1.0000, Val: 0.6720, Test: 0.6930
Epoch: 102, Loss: 3.0357, Train: 1.0000, Val: 0.6700, Test: 0.6940
Epoch: 103, Loss: 2.9307, Train: 1.0000, Val: 0.6700, Test: 0.6940
Epoch: 104, Loss: 2.8656, Train: 1.0000, Val: 0.6700, Test: 0.6930
Epoch: 105, Loss: 2.4553, Train: 1.0000, Val: 0.6700, Test: 0.6910
Epoch: 106, Loss: 2.9500, Train: 1.0000, Val: 0.6700, Test: 0.6950
Epoch: 107, Loss: 3.2225, Train: 1.0000, Val: 0.6720, Test: 0.6970
Epoch: 108, Loss: 2.8280, Train: 1.0000, Val: 0.6720, Test: 0.6980
Epoch: 109, Loss: 3.0640, Train: 1.0000, Val: 0.6700, Test: 0.6980
Epoch: 110, Loss: 2.5808, Train: 1.0000, Val: 0.6680, Test: 0.6980
Epoch: 111, Loss: 2.4853, Train: 1.0000, Val: 0.6660, Test: 0.6960
Epoch: 112, Loss: 2.8495, Train: 1.0000, Val: 0.6680, Test: 0.6960
Epoch: 113, Loss: 2.6493, Train: 1.0000, Val: 0.6680, Test: 0.6970
Epoch: 114, Loss: 2.9398, Train: 1.0000, Val: 0.6640, Test: 0.6950
Epoch: 115, Loss: 2.7991, Train: 1.0000, Val: 0.6660, Test: 0.6940
Epoch: 116, Loss: 2.7974, Train: 1.0000, Val: 0.6660, Test: 0.6950
Epoch: 117, Loss: 2.8460, Train: 1.0000, Val: 0.6660, Test: 0.6930
Epoch: 118, Loss: 2.5466, Train: 1.0000, Val: 0.6660, Test: 0.6950
Epoch: 119, Loss: 2.9208, Train: 1.0000, Val: 0.6680, Test: 0.6960
Epoch: 120, Loss: 2.7989, Train: 1.0000, Val: 0.6680, Test: 0.6970
Epoch: 121, Loss: 2.6308, Train: 1.0000, Val: 0.6680, Test: 0.6960
Epoch: 122, Loss: 2.8411, Train: 1.0000, Val: 0.6680, Test: 0.6970
Epoch: 123, Loss: 2.6843, Train: 1.0000, Val: 0.6680, Test: 0.6990
Epoch: 124, Loss: 2.5841, Train: 1.0000, Val: 0.6680, Test: 0.6990
Epoch: 125, Loss: 2.7006, Train: 1.0000, Val: 0.6680, Test: 0.6990
Epoch: 126, Loss: 2.6501, Train: 1.0000, Val: 0.6680, Test: 0.6980
Epoch: 127, Loss: 2.5084, Train: 1.0000, Val: 0.6680, Test: 0.6980
Epoch: 128, Loss: 2.8834, Train: 1.0000, Val: 0.6680, Test: 0.6990
Epoch: 129, Loss: 2.7518, Train: 1.0000, Val: 0.6660, Test: 0.6970
Epoch: 130, Loss: 2.6742, Train: 1.0000, Val: 0.6660, Test: 0.6970
Epoch: 131, Loss: 2.9594, Train: 1.0000, Val: 0.6700, Test: 0.6970
Epoch: 132, Loss: 2.8406, Train: 1.0000, Val: 0.6700, Test: 0.6970
Epoch: 133, Loss: 2.9046, Train: 1.0000, Val: 0.6700, Test: 0.6960
Epoch: 134, Loss: 2.7646, Train: 1.0000, Val: 0.6700, Test: 0.6960
Epoch: 135, Loss: 2.9852, Train: 1.0000, Val: 0.6720, Test: 0.6970
Epoch: 136, Loss: 2.6697, Train: 1.0000, Val: 0.6720, Test: 0.6990
Epoch: 137, Loss: 2.8254, Train: 1.0000, Val: 0.6700, Test: 0.6970
Epoch: 138, Loss: 2.6049, Train: 1.0000, Val: 0.6700, Test: 0.6950
Epoch: 139, Loss: 2.5391, Train: 1.0000, Val: 0.6700, Test: 0.6980
Epoch: 140, Loss: 2.6226, Train: 1.0000, Val: 0.6700, Test: 0.6980
Epoch: 141, Loss: 2.9063, Train: 1.0000, Val: 0.6680, Test: 0.6970
Epoch: 142, Loss: 2.6951, Train: 1.0000, Val: 0.6680, Test: 0.6970
Epoch: 143, Loss: 2.5690, Train: 1.0000, Val: 0.6680, Test: 0.6950
Epoch: 144, Loss: 2.9146, Train: 1.0000, Val: 0.6680, Test: 0.6940
Epoch: 145, Loss: 2.5371, Train: 1.0000, Val: 0.6680, Test: 0.6940
Epoch: 146, Loss: 2.7731, Train: 1.0000, Val: 0.6660, Test: 0.6930
Epoch: 147, Loss: 2.7008, Train: 1.0000, Val: 0.6660, Test: 0.6930
Epoch: 148, Loss: 2.5365, Train: 1.0000, Val: 0.6640, Test: 0.6930
Epoch: 149, Loss: 2.6072, Train: 1.0000, Val: 0.6660, Test: 0.6930
Epoch: 150, Loss: 2.7619, Train: 1.0000, Val: 0.6620, Test: 0.6920
Epoch: 151, Loss: 2.7929, Train: 1.0000, Val: 0.6620, Test: 0.6900
Epoch: 152, Loss: 2.2160, Train: 1.0000, Val: 0.6620, Test: 0.6890
Epoch: 153, Loss: 2.3285, Train: 1.0000, Val: 0.6620, Test: 0.6890
Epoch: 154, Loss: 3.0966, Train: 1.0000, Val: 0.6600, Test: 0.6900
Epoch: 155, Loss: 2.3350, Train: 1.0000, Val: 0.6620, Test: 0.6900
Epoch: 156, Loss: 2.7112, Train: 1.0000, Val: 0.6620, Test: 0.6910
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 157, Loss: 2.4945, Train: 1.0000, Val: 0.6680, Test: 0.6900
Epoch: 158, Loss: 2.7468, Train: 1.0000, Val: 0.6660, Test: 0.6880
Epoch: 159, Loss: 2.5982, Train: 1.0000, Val: 0.6700, Test: 0.6860
Epoch: 160, Loss: 2.5727, Train: 1.0000, Val: 0.6700, Test: 0.6840
Epoch: 161, Loss: 2.7844, Train: 1.0000, Val: 0.6680, Test: 0.6850
Epoch: 162, Loss: 2.6157, Train: 1.0000, Val: 0.6680, Test: 0.6830
Epoch: 163, Loss: 2.5507, Train: 1.0000, Val: 0.6660, Test: 0.6840
Epoch: 164, Loss: 2.3369, Train: 1.0000, Val: 0.6640, Test: 0.6840
Epoch: 165, Loss: 2.4824, Train: 1.0000, Val: 0.6640, Test: 0.6830
Epoch: 166, Loss: 2.5718, Train: 1.0000, Val: 0.6660, Test: 0.6830
Epoch: 167, Loss: 2.3760, Train: 1.0000, Val: 0.6660, Test: 0.6840
Epoch: 168, Loss: 2.6271, Train: 1.0000, Val: 0.6660, Test: 0.6820
Epoch: 169, Loss: 2.6514, Train: 1.0000, Val: 0.6660, Test: 0.6810
Epoch: 170, Loss: 2.8801, Train: 1.0000, Val: 0.6620, Test: 0.6800
Epoch: 171, Loss: 2.4301, Train: 1.0000, Val: 0.6640, Test: 0.6820
Epoch: 172, Loss: 2.4227, Train: 1.0000, Val: 0.6640, Test: 0.6760
Epoch: 173, Loss: 2.7388, Train: 1.0000, Val: 0.6640, Test: 0.6740
Epoch: 174, Loss: 2.4530, Train: 1.0000, Val: 0.6640, Test: 0.6740
Epoch: 175, Loss: 2.7121, Train: 1.0000, Val: 0.6640, Test: 0.6730
Epoch: 176, Loss: 2.5866, Train: 1.0000, Val: 0.6620, Test: 0.6730
Epoch: 177, Loss: 2.5656, Train: 1.0000, Val: 0.6600, Test: 0.6740
Epoch: 178, Loss: 2.6758, Train: 1.0000, Val: 0.6640, Test: 0.6740
Epoch: 179, Loss: 2.5633, Train: 1.0000, Val: 0.6640, Test: 0.6760
Epoch: 180, Loss: 2.4284, Train: 1.0000, Val: 0.6660, Test: 0.6770
Epoch: 181, Loss: 2.5095, Train: 1.0000, Val: 0.6680, Test: 0.6800
Epoch: 182, Loss: 2.5840, Train: 1.0000, Val: 0.6660, Test: 0.6790
Epoch: 183, Loss: 2.6190, Train: 1.0000, Val: 0.6660, Test: 0.6810
Epoch: 184, Loss: 2.5730, Train: 1.0000, Val: 0.6640, Test: 0.6810
Epoch: 185, Loss: 2.3544, Train: 1.0000, Val: 0.6660, Test: 0.6780
Epoch: 186, Loss: 2.3820, Train: 1.0000, Val: 0.6660, Test: 0.6770
Epoch: 187, Loss: 2.1882, Train: 1.0000, Val: 0.6640, Test: 0.6770
Epoch: 188, Loss: 2.5420, Train: 1.0000, Val: 0.6640, Test: 0.6780
Epoch: 189, Loss: 3.0085, Train: 1.0000, Val: 0.6660, Test: 0.6760
Epoch: 190, Loss: 2.4677, Train: 1.0000, Val: 0.6680, Test: 0.6730
Epoch: 191, Loss: 2.5009, Train: 1.0000, Val: 0.6660, Test: 0.6710
Epoch: 192, Loss: 2.4564, Train: 1.0000, Val: 0.6620, Test: 0.6720
Epoch: 193, Loss: 2.4807, Train: 1.0000, Val: 0.6620, Test: 0.6700
Epoch: 194, Loss: 2.6333, Train: 1.0000, Val: 0.6620, Test: 0.6680
Epoch: 195, Loss: 2.6156, Train: 1.0000, Val: 0.6620, Test: 0.6680
Epoch: 196, Loss: 2.7084, Train: 1.0000, Val: 0.6600, Test: 0.6690
Epoch: 197, Loss: 2.6749, Train: 1.0000, Val: 0.6580, Test: 0.6680
Epoch: 198, Loss: 2.4415, Train: 1.0000, Val: 0.6560, Test: 0.6680
Epoch: 199, Loss: 2.2747, Train: 1.0000, Val: 0.6540, Test: 0.6670
Epoch: 200, Loss: 2.2981, Train: 1.0000, Val: 0.6560, Test: 0.6670
MAD:  0.2208
Best Test Accuracy: 0.7020, Val Accuracy: 0.6760, Train Accuracy: 0.9929
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8810, Train: 0.0429, Val: 0.0200, Test: 0.0220
Epoch: 2, Loss: 4.8349, Train: 0.1857, Val: 0.0780, Test: 0.0770
Epoch: 3, Loss: 4.7982, Train: 0.2500, Val: 0.1540, Test: 0.1390
Epoch: 4, Loss: 4.7306, Train: 0.3571, Val: 0.2000, Test: 0.1890
Epoch: 5, Loss: 4.6989, Train: 0.4500, Val: 0.2260, Test: 0.2210
Epoch: 6, Loss: 4.6524, Train: 0.4714, Val: 0.2480, Test: 0.2500
Epoch: 7, Loss: 4.4121, Train: 0.5071, Val: 0.2720, Test: 0.2650
Epoch: 8, Loss: 4.4016, Train: 0.5143, Val: 0.2900, Test: 0.2860
Epoch: 9, Loss: 4.3867, Train: 0.5429, Val: 0.3020, Test: 0.2990
Epoch: 10, Loss: 4.3310, Train: 0.5429, Val: 0.3100, Test: 0.3150
Epoch: 11, Loss: 4.2409, Train: 0.5714, Val: 0.3180, Test: 0.3290
Epoch: 12, Loss: 3.9858, Train: 0.5857, Val: 0.3220, Test: 0.3360
Epoch: 13, Loss: 4.0094, Train: 0.6214, Val: 0.3280, Test: 0.3390
Epoch: 14, Loss: 4.1595, Train: 0.7143, Val: 0.3400, Test: 0.3520
Epoch: 15, Loss: 3.9846, Train: 0.7643, Val: 0.3600, Test: 0.3760
Epoch: 16, Loss: 4.2055, Train: 0.8143, Val: 0.3840, Test: 0.3980
Epoch: 17, Loss: 4.1653, Train: 0.8857, Val: 0.4220, Test: 0.4240
Epoch: 18, Loss: 3.8017, Train: 0.9143, Val: 0.4600, Test: 0.4550
Epoch: 19, Loss: 4.0131, Train: 0.9500, Val: 0.5260, Test: 0.5080
Epoch: 20, Loss: 3.7720, Train: 0.9857, Val: 0.5820, Test: 0.5680
Epoch: 21, Loss: 3.9871, Train: 0.9857, Val: 0.6180, Test: 0.6080
Epoch: 22, Loss: 3.9542, Train: 1.0000, Val: 0.6460, Test: 0.6600
Epoch: 23, Loss: 3.6318, Train: 1.0000, Val: 0.6740, Test: 0.6960
Epoch: 24, Loss: 3.9888, Train: 0.9929, Val: 0.6920, Test: 0.7250
Epoch: 25, Loss: 3.5824, Train: 0.9929, Val: 0.7120, Test: 0.7310
Epoch: 26, Loss: 3.6040, Train: 0.9929, Val: 0.7280, Test: 0.7310
Epoch: 27, Loss: 3.2763, Train: 1.0000, Val: 0.7360, Test: 0.7340
Epoch: 28, Loss: 3.7476, Train: 1.0000, Val: 0.7340, Test: 0.7420
Epoch: 29, Loss: 3.7776, Train: 1.0000, Val: 0.7400, Test: 0.7510
Epoch: 30, Loss: 3.4645, Train: 1.0000, Val: 0.7300, Test: 0.7500
Epoch: 31, Loss: 3.2276, Train: 1.0000, Val: 0.7320, Test: 0.7510
Epoch: 32, Loss: 3.5854, Train: 1.0000, Val: 0.7340, Test: 0.7540
Epoch: 33, Loss: 3.7121, Train: 1.0000, Val: 0.7320, Test: 0.7550
Epoch: 34, Loss: 3.4105, Train: 1.0000, Val: 0.7360, Test: 0.7590
Epoch: 35, Loss: 3.5580, Train: 1.0000, Val: 0.7360, Test: 0.7550
Epoch: 36, Loss: 3.1780, Train: 1.0000, Val: 0.7420, Test: 0.7530
Epoch: 37, Loss: 3.1909, Train: 1.0000, Val: 0.7440, Test: 0.7570
Epoch: 38, Loss: 3.5041, Train: 1.0000, Val: 0.7360, Test: 0.7670
Epoch: 39, Loss: 3.2868, Train: 1.0000, Val: 0.7280, Test: 0.7670
Epoch: 40, Loss: 3.5248, Train: 1.0000, Val: 0.7260, Test: 0.7610
Epoch: 41, Loss: 3.5502, Train: 1.0000, Val: 0.7260, Test: 0.7640
Epoch: 42, Loss: 3.2743, Train: 1.0000, Val: 0.7300, Test: 0.7580
Epoch: 43, Loss: 3.1744, Train: 1.0000, Val: 0.7300, Test: 0.7540
Epoch: 44, Loss: 3.3699, Train: 1.0000, Val: 0.7260, Test: 0.7520
Epoch: 45, Loss: 3.5817, Train: 1.0000, Val: 0.7260, Test: 0.7520
Epoch: 46, Loss: 3.3969, Train: 1.0000, Val: 0.7260, Test: 0.7550
Epoch: 47, Loss: 3.3381, Train: 1.0000, Val: 0.7220, Test: 0.7520
Epoch: 48, Loss: 3.5230, Train: 1.0000, Val: 0.7200, Test: 0.7520
Epoch: 49, Loss: 3.4755, Train: 1.0000, Val: 0.7220, Test: 0.7520
Epoch: 50, Loss: 3.3696, Train: 1.0000, Val: 0.7200, Test: 0.7490
Epoch: 51, Loss: 3.4635, Train: 1.0000, Val: 0.7200, Test: 0.7450
Epoch: 52, Loss: 3.3481, Train: 1.0000, Val: 0.7200, Test: 0.7460
Epoch: 53, Loss: 3.0222, Train: 1.0000, Val: 0.7220, Test: 0.7460
Epoch: 54, Loss: 3.4061, Train: 1.0000, Val: 0.7240, Test: 0.7450
Epoch: 55, Loss: 3.4348, Train: 1.0000, Val: 0.7260, Test: 0.7430
Epoch: 56, Loss: 3.2908, Train: 1.0000, Val: 0.7260, Test: 0.7440
Epoch: 57, Loss: 3.0641, Train: 1.0000, Val: 0.7240, Test: 0.7490
Epoch: 58, Loss: 3.0884, Train: 1.0000, Val: 0.7260, Test: 0.7530
Epoch: 59, Loss: 3.2697, Train: 1.0000, Val: 0.7260, Test: 0.7510
Epoch: 60, Loss: 3.3464, Train: 1.0000, Val: 0.7280, Test: 0.7530
Epoch: 61, Loss: 3.2923, Train: 1.0000, Val: 0.7300, Test: 0.7540
Epoch: 62, Loss: 3.1565, Train: 1.0000, Val: 0.7340, Test: 0.7520
Epoch: 63, Loss: 3.1384, Train: 1.0000, Val: 0.7380, Test: 0.7550
Epoch: 64, Loss: 3.3467, Train: 1.0000, Val: 0.7380, Test: 0.7530
Epoch: 65, Loss: 3.4758, Train: 1.0000, Val: 0.7400, Test: 0.7500
Epoch: 66, Loss: 3.1180, Train: 1.0000, Val: 0.7420, Test: 0.7480
Epoch: 67, Loss: 3.4651, Train: 1.0000, Val: 0.7420, Test: 0.7470
Epoch: 68, Loss: 3.2722, Train: 1.0000, Val: 0.7420, Test: 0.7510
Epoch: 69, Loss: 3.1975, Train: 1.0000, Val: 0.7460, Test: 0.7520
Epoch: 70, Loss: 2.9640, Train: 1.0000, Val: 0.7480, Test: 0.7520
Epoch: 71, Loss: 3.2127, Train: 1.0000, Val: 0.7480, Test: 0.7520
Epoch: 72, Loss: 3.2798, Train: 1.0000, Val: 0.7440, Test: 0.7520
Epoch: 73, Loss: 3.2990, Train: 1.0000, Val: 0.7440, Test: 0.7530
Epoch: 74, Loss: 3.3485, Train: 1.0000, Val: 0.7440, Test: 0.7540
Epoch: 75, Loss: 2.8483, Train: 1.0000, Val: 0.7460, Test: 0.7510
Epoch: 76, Loss: 3.0998, Train: 1.0000, Val: 0.7440, Test: 0.7500
Epoch: 77, Loss: 3.2563, Train: 1.0000, Val: 0.7420, Test: 0.7480
Epoch: 78, Loss: 3.1854, Train: 1.0000, Val: 0.7400, Test: 0.7460
Epoch: 79, Loss: 2.7954, Train: 1.0000, Val: 0.7400, Test: 0.7470
Epoch: 80, Loss: 2.9004, Train: 1.0000, Val: 0.7400, Test: 0.7480
Epoch: 81, Loss: 3.3409, Train: 1.0000, Val: 0.7400, Test: 0.7470
Epoch: 82, Loss: 2.6828, Train: 1.0000, Val: 0.7360, Test: 0.7490
Epoch: 83, Loss: 3.2037, Train: 1.0000, Val: 0.7320, Test: 0.7480
Epoch: 84, Loss: 3.0842, Train: 1.0000, Val: 0.7300, Test: 0.7480
Epoch: 85, Loss: 3.0658, Train: 1.0000, Val: 0.7300, Test: 0.7470
Epoch: 86, Loss: 2.9264, Train: 1.0000, Val: 0.7280, Test: 0.7450
Epoch: 87, Loss: 2.8991, Train: 1.0000, Val: 0.7280, Test: 0.7430
Epoch: 88, Loss: 2.6903, Train: 1.0000, Val: 0.7280, Test: 0.7420
Epoch: 89, Loss: 3.1785, Train: 1.0000, Val: 0.7300, Test: 0.7420
Epoch: 90, Loss: 2.9739, Train: 1.0000, Val: 0.7300, Test: 0.7420
Epoch: 91, Loss: 2.9477, Train: 1.0000, Val: 0.7300, Test: 0.7420
Epoch: 92, Loss: 3.0528, Train: 1.0000, Val: 0.7280, Test: 0.7390
Epoch: 93, Loss: 2.8896, Train: 1.0000, Val: 0.7260, Test: 0.7390
Epoch: 94, Loss: 2.9542, Train: 1.0000, Val: 0.7260, Test: 0.7400
Epoch: 95, Loss: 2.9466, Train: 1.0000, Val: 0.7280, Test: 0.7400
Epoch: 96, Loss: 3.0109, Train: 1.0000, Val: 0.7240, Test: 0.7390
Epoch: 97, Loss: 3.1820, Train: 1.0000, Val: 0.7220, Test: 0.7390
Epoch: 98, Loss: 3.4220, Train: 1.0000, Val: 0.7220, Test: 0.7370
Epoch: 99, Loss: 3.1216, Train: 1.0000, Val: 0.7220, Test: 0.7390
Epoch: 100, Loss: 2.7755, Train: 1.0000, Val: 0.7220, Test: 0.7390
Epoch: 101, Loss: 2.6872, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 102, Loss: 3.0278, Train: 1.0000, Val: 0.7180, Test: 0.7370
Epoch: 103, Loss: 3.0313, Train: 1.0000, Val: 0.7180, Test: 0.7390
Epoch: 104, Loss: 2.6670, Train: 1.0000, Val: 0.7160, Test: 0.7370
Epoch: 105, Loss: 2.7907, Train: 1.0000, Val: 0.7220, Test: 0.7370
Epoch: 106, Loss: 3.0859, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 107, Loss: 2.9631, Train: 1.0000, Val: 0.7220, Test: 0.7400
Epoch: 108, Loss: 3.0759, Train: 1.0000, Val: 0.7240, Test: 0.7410
Epoch: 109, Loss: 2.7400, Train: 1.0000, Val: 0.7260, Test: 0.7420
Epoch: 110, Loss: 2.8433, Train: 1.0000, Val: 0.7260, Test: 0.7450
Epoch: 111, Loss: 2.8884, Train: 1.0000, Val: 0.7260, Test: 0.7430
Epoch: 112, Loss: 2.6792, Train: 1.0000, Val: 0.7260, Test: 0.7440
Epoch: 113, Loss: 2.6013, Train: 1.0000, Val: 0.7260, Test: 0.7420
Epoch: 114, Loss: 2.5033, Train: 1.0000, Val: 0.7260, Test: 0.7420
Epoch: 115, Loss: 2.6833, Train: 1.0000, Val: 0.7280, Test: 0.7430
Epoch: 116, Loss: 2.9288, Train: 1.0000, Val: 0.7280, Test: 0.7440
Epoch: 117, Loss: 2.7683, Train: 1.0000, Val: 0.7280, Test: 0.7440
Epoch: 118, Loss: 2.5304, Train: 1.0000, Val: 0.7240, Test: 0.7420
Epoch: 119, Loss: 2.6868, Train: 1.0000, Val: 0.7200, Test: 0.7400
Epoch: 120, Loss: 2.8545, Train: 1.0000, Val: 0.7200, Test: 0.7390
Epoch: 121, Loss: 2.6729, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 122, Loss: 2.7040, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 123, Loss: 2.8206, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 124, Loss: 2.8794, Train: 1.0000, Val: 0.7200, Test: 0.7400
Epoch: 125, Loss: 2.8215, Train: 1.0000, Val: 0.7200, Test: 0.7400
Epoch: 126, Loss: 2.5933, Train: 1.0000, Val: 0.7180, Test: 0.7390
Epoch: 127, Loss: 2.6678, Train: 1.0000, Val: 0.7180, Test: 0.7350
Epoch: 128, Loss: 2.8477, Train: 1.0000, Val: 0.7180, Test: 0.7360
Epoch: 129, Loss: 2.8036, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 130, Loss: 2.7682, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 131, Loss: 2.6996, Train: 1.0000, Val: 0.7180, Test: 0.7320
Epoch: 132, Loss: 2.7771, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 133, Loss: 2.7747, Train: 1.0000, Val: 0.7180, Test: 0.7340
Epoch: 134, Loss: 2.8838, Train: 1.0000, Val: 0.7200, Test: 0.7370
Epoch: 135, Loss: 2.5578, Train: 1.0000, Val: 0.7180, Test: 0.7380
Epoch: 136, Loss: 2.8760, Train: 1.0000, Val: 0.7160, Test: 0.7380
Epoch: 137, Loss: 2.7831, Train: 1.0000, Val: 0.7160, Test: 0.7390
Epoch: 138, Loss: 2.6610, Train: 1.0000, Val: 0.7160, Test: 0.7390
Epoch: 139, Loss: 2.6681, Train: 1.0000, Val: 0.7160, Test: 0.7370
Epoch: 140, Loss: 2.6961, Train: 1.0000, Val: 0.7160, Test: 0.7360
Epoch: 141, Loss: 2.6553, Train: 1.0000, Val: 0.7160, Test: 0.7360
Epoch: 142, Loss: 2.5006, Train: 1.0000, Val: 0.7160, Test: 0.7340
Epoch: 143, Loss: 2.5306, Train: 1.0000, Val: 0.7140, Test: 0.7340
Epoch: 144, Loss: 2.5422, Train: 1.0000, Val: 0.7120, Test: 0.7350
Epoch: 145, Loss: 2.5344, Train: 1.0000, Val: 0.7140, Test: 0.7360
Epoch: 146, Loss: 2.6127, Train: 1.0000, Val: 0.7160, Test: 0.7360
Epoch: 147, Loss: 2.7245, Train: 1.0000, Val: 0.7180, Test: 0.7350
Epoch: 148, Loss: 2.9008, Train: 1.0000, Val: 0.7200, Test: 0.7350
Epoch: 149, Loss: 2.4270, Train: 1.0000, Val: 0.7180, Test: 0.7350
Epoch: 150, Loss: 2.8407, Train: 1.0000, Val: 0.7180, Test: 0.7360
Epoch: 151, Loss: 2.7241, Train: 1.0000, Val: 0.7160, Test: 0.7350
Epoch: 152, Loss: 2.4935, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 153, Loss: 2.4847, Train: 1.0000, Val: 0.7180, Test: 0.7340
Epoch: 154, Loss: 2.3909, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 155, Loss: 2.7984, Train: 1.0000, Val: 0.7180, Test: 0.7310
Epoch: 156, Loss: 2.7530, Train: 1.0000, Val: 0.7180, Test: 0.7300
Epoch: 157, Loss: 2.4343, Train: 1.0000, Val: 0.7160, Test: 0.7280
Epoch: 158, Loss: 2.5880, Train: 1.0000, Val: 0.7140, Test: 0.7270
Epoch: 159, Loss: 2.7285, Train: 1.0000, Val: 0.7120, Test: 0.7270
Epoch: 160, Loss: 2.7002, Train: 1.0000, Val: 0.7080, Test: 0.7250
Epoch: 161, Loss: 2.3432, Train: 1.0000, Val: 0.7080, Test: 0.7240
Epoch: 162, Loss: 3.1999, Train: 1.0000, Val: 0.7080, Test: 0.7230
Epoch: 163, Loss: 2.6102, Train: 1.0000, Val: 0.7080, Test: 0.7240
Epoch: 164, Loss: 2.8855, Train: 1.0000, Val: 0.7080, Test: 0.7210
Epoch: 165, Loss: 2.5186, Train: 1.0000, Val: 0.7060, Test: 0.7210
Epoch: 166, Loss: 2.7028, Train: 1.0000, Val: 0.7040, Test: 0.7200
Epoch: 167, Loss: 2.7175, Train: 1.0000, Val: 0.7020, Test: 0.7210
Epoch: 168, Loss: 2.7640, Train: 1.0000, Val: 0.7020, Test: 0.7200
Epoch: 169, Loss: 2.3767, Train: 1.0000, Val: 0.7020, Test: 0.7230
Epoch: 170, Loss: 2.5874, Train: 1.0000, Val: 0.7020, Test: 0.7240
Epoch: 171, Loss: 2.6173, Train: 1.0000, Val: 0.7040, Test: 0.7230
Epoch: 172, Loss: 2.4844, Train: 1.0000, Val: 0.7060, Test: 0.7240
Epoch: 173, Loss: 2.4468, Train: 1.0000, Val: 0.7060, Test: 0.7230
Epoch: 174, Loss: 2.6094, Train: 1.0000, Val: 0.7060, Test: 0.7220
Epoch: 175, Loss: 2.3738, Train: 1.0000, Val: 0.7080, Test: 0.7220
Epoch: 176, Loss: 2.1399, Train: 1.0000, Val: 0.7060, Test: 0.7190
Epoch: 177, Loss: 2.3019, Train: 1.0000, Val: 0.7060, Test: 0.7190
Epoch: 178, Loss: 2.4699, Train: 1.0000, Val: 0.7100, Test: 0.7180
Epoch: 179, Loss: 2.6844, Train: 1.0000, Val: 0.7080, Test: 0.7200
Epoch: 180, Loss: 2.4220, Train: 1.0000, Val: 0.7080, Test: 0.7170
Epoch: 181, Loss: 2.5751, Train: 1.0000, Val: 0.7080, Test: 0.7180
Epoch: 182, Loss: 2.5192, Train: 1.0000, Val: 0.7080, Test: 0.7160
Epoch: 183, Loss: 2.6293, Train: 1.0000, Val: 0.7080, Test: 0.7170
Epoch: 184, Loss: 2.4110, Train: 1.0000, Val: 0.7080, Test: 0.7170
Epoch: 185, Loss: 2.5819, Train: 1.0000, Val: 0.7060, Test: 0.7160
Epoch: 186, Loss: 2.5049, Train: 1.0000, Val: 0.7040, Test: 0.7150
Epoch: 187, Loss: 2.6840, Train: 1.0000, Val: 0.7040, Test: 0.7140
Epoch: 188, Loss: 2.7410, Train: 1.0000, Val: 0.7040, Test: 0.7160
Epoch: 189, Loss: 2.5373, Train: 1.0000, Val: 0.7040, Test: 0.7160
Epoch: 190, Loss: 2.5743, Train: 1.0000, Val: 0.7040, Test: 0.7160
Epoch: 191, Loss: 2.8634, Train: 1.0000, Val: 0.6980, Test: 0.7150
Epoch: 192, Loss: 2.5290, Train: 1.0000, Val: 0.7000, Test: 0.7150
Epoch: 193, Loss: 2.5048, Train: 1.0000, Val: 0.6940, Test: 0.7150
Epoch: 194, Loss: 2.5766, Train: 1.0000, Val: 0.6940, Test: 0.7150
Epoch: 195, Loss: 2.4315, Train: 1.0000, Val: 0.6960, Test: 0.7140
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 196, Loss: 2.3990, Train: 1.0000, Val: 0.6960, Test: 0.7120
Epoch: 197, Loss: 2.6589, Train: 1.0000, Val: 0.7000, Test: 0.7130
Epoch: 198, Loss: 2.5681, Train: 1.0000, Val: 0.7020, Test: 0.7130
Epoch: 199, Loss: 2.3704, Train: 1.0000, Val: 0.7000, Test: 0.7140
Epoch: 200, Loss: 2.5688, Train: 1.0000, Val: 0.7020, Test: 0.7140
MAD:  0.3229
Best Test Accuracy: 0.7670, Val Accuracy: 0.7360, Train Accuracy: 1.0000
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8247, Train: 0.1429, Val: 0.0780, Test: 0.1060
Epoch: 2, Loss: 4.7432, Train: 0.3357, Val: 0.1600, Test: 0.1800
Epoch: 3, Loss: 4.7054, Train: 0.4357, Val: 0.2580, Test: 0.2750
Epoch: 4, Loss: 4.6080, Train: 0.5500, Val: 0.3060, Test: 0.3330
Epoch: 5, Loss: 4.5316, Train: 0.6071, Val: 0.3600, Test: 0.3600
Epoch: 6, Loss: 4.4494, Train: 0.6643, Val: 0.3740, Test: 0.3950
Epoch: 7, Loss: 4.4182, Train: 0.7214, Val: 0.4040, Test: 0.4230
Epoch: 8, Loss: 4.2691, Train: 0.7714, Val: 0.4280, Test: 0.4590
Epoch: 9, Loss: 4.3453, Train: 0.8143, Val: 0.4720, Test: 0.4870
Epoch: 10, Loss: 4.2804, Train: 0.8500, Val: 0.5040, Test: 0.5200
Epoch: 11, Loss: 4.1067, Train: 0.8786, Val: 0.5320, Test: 0.5570
Epoch: 12, Loss: 4.0946, Train: 0.8929, Val: 0.5760, Test: 0.5910
Epoch: 13, Loss: 4.0440, Train: 0.9071, Val: 0.6060, Test: 0.6270
Epoch: 14, Loss: 3.9676, Train: 0.9357, Val: 0.6320, Test: 0.6630
Epoch: 15, Loss: 4.0269, Train: 0.9643, Val: 0.6580, Test: 0.6880
Epoch: 16, Loss: 3.8293, Train: 0.9714, Val: 0.6820, Test: 0.7130
Epoch: 17, Loss: 3.7160, Train: 0.9786, Val: 0.6960, Test: 0.7220
Epoch: 18, Loss: 3.7271, Train: 1.0000, Val: 0.7140, Test: 0.7350
Epoch: 19, Loss: 3.4813, Train: 1.0000, Val: 0.7140, Test: 0.7470
Epoch: 20, Loss: 3.8749, Train: 1.0000, Val: 0.7280, Test: 0.7520
Epoch: 21, Loss: 3.7585, Train: 1.0000, Val: 0.7240, Test: 0.7480
Epoch: 22, Loss: 3.8358, Train: 1.0000, Val: 0.7300, Test: 0.7470
Epoch: 23, Loss: 3.5589, Train: 1.0000, Val: 0.7340, Test: 0.7480
Epoch: 24, Loss: 3.6607, Train: 1.0000, Val: 0.7360, Test: 0.7470
Epoch: 25, Loss: 3.5192, Train: 1.0000, Val: 0.7360, Test: 0.7390
Epoch: 26, Loss: 3.5467, Train: 1.0000, Val: 0.7400, Test: 0.7340
Epoch: 27, Loss: 3.3370, Train: 1.0000, Val: 0.7300, Test: 0.7380
Epoch: 28, Loss: 3.2967, Train: 1.0000, Val: 0.7240, Test: 0.7340
Epoch: 29, Loss: 3.6313, Train: 1.0000, Val: 0.7260, Test: 0.7360
Epoch: 30, Loss: 3.7215, Train: 1.0000, Val: 0.7260, Test: 0.7320
Epoch: 31, Loss: 3.3385, Train: 1.0000, Val: 0.7260, Test: 0.7330
Epoch: 32, Loss: 3.6930, Train: 1.0000, Val: 0.7260, Test: 0.7350
Epoch: 33, Loss: 3.7151, Train: 1.0000, Val: 0.7300, Test: 0.7350
Epoch: 34, Loss: 3.4003, Train: 1.0000, Val: 0.7280, Test: 0.7390
Epoch: 35, Loss: 3.4851, Train: 1.0000, Val: 0.7340, Test: 0.7370
Epoch: 36, Loss: 3.4046, Train: 1.0000, Val: 0.7320, Test: 0.7360
Epoch: 37, Loss: 3.4276, Train: 1.0000, Val: 0.7300, Test: 0.7410
Epoch: 38, Loss: 3.1902, Train: 1.0000, Val: 0.7360, Test: 0.7450
Epoch: 39, Loss: 3.4511, Train: 1.0000, Val: 0.7400, Test: 0.7490
Epoch: 40, Loss: 3.1952, Train: 1.0000, Val: 0.7400, Test: 0.7530
Epoch: 41, Loss: 3.5496, Train: 1.0000, Val: 0.7400, Test: 0.7510
Epoch: 42, Loss: 3.4350, Train: 1.0000, Val: 0.7480, Test: 0.7510
Epoch: 43, Loss: 2.8933, Train: 1.0000, Val: 0.7480, Test: 0.7540
Epoch: 44, Loss: 3.3007, Train: 1.0000, Val: 0.7500, Test: 0.7550
Epoch: 45, Loss: 3.3571, Train: 1.0000, Val: 0.7440, Test: 0.7560
Epoch: 46, Loss: 3.5360, Train: 1.0000, Val: 0.7460, Test: 0.7540
Epoch: 47, Loss: 2.9755, Train: 1.0000, Val: 0.7440, Test: 0.7550
Epoch: 48, Loss: 3.2353, Train: 1.0000, Val: 0.7400, Test: 0.7540
Epoch: 49, Loss: 3.6222, Train: 1.0000, Val: 0.7440, Test: 0.7550
Epoch: 50, Loss: 3.1915, Train: 1.0000, Val: 0.7420, Test: 0.7540
Epoch: 51, Loss: 3.2226, Train: 1.0000, Val: 0.7420, Test: 0.7560
Epoch: 52, Loss: 3.5050, Train: 1.0000, Val: 0.7420, Test: 0.7540
Epoch: 53, Loss: 3.1740, Train: 1.0000, Val: 0.7400, Test: 0.7550
Epoch: 54, Loss: 3.4660, Train: 1.0000, Val: 0.7400, Test: 0.7540
Epoch: 55, Loss: 3.2695, Train: 1.0000, Val: 0.7400, Test: 0.7540
Epoch: 56, Loss: 3.4408, Train: 1.0000, Val: 0.7380, Test: 0.7550
Epoch: 57, Loss: 3.5503, Train: 1.0000, Val: 0.7380, Test: 0.7560
Epoch: 58, Loss: 3.3889, Train: 1.0000, Val: 0.7380, Test: 0.7570
Epoch: 59, Loss: 2.9940, Train: 1.0000, Val: 0.7400, Test: 0.7560
Epoch: 60, Loss: 3.4376, Train: 1.0000, Val: 0.7420, Test: 0.7560
Epoch: 61, Loss: 3.3576, Train: 1.0000, Val: 0.7420, Test: 0.7540
Epoch: 62, Loss: 3.0623, Train: 1.0000, Val: 0.7460, Test: 0.7550
Epoch: 63, Loss: 3.0346, Train: 1.0000, Val: 0.7420, Test: 0.7540
Epoch: 64, Loss: 3.3980, Train: 1.0000, Val: 0.7420, Test: 0.7540
Epoch: 65, Loss: 3.3951, Train: 1.0000, Val: 0.7420, Test: 0.7540
Epoch: 66, Loss: 2.9360, Train: 1.0000, Val: 0.7420, Test: 0.7540
Epoch: 67, Loss: 3.0199, Train: 1.0000, Val: 0.7460, Test: 0.7540
Epoch: 68, Loss: 3.1200, Train: 1.0000, Val: 0.7460, Test: 0.7550
Epoch: 69, Loss: 2.8789, Train: 1.0000, Val: 0.7400, Test: 0.7550
Epoch: 70, Loss: 3.1748, Train: 1.0000, Val: 0.7400, Test: 0.7560
Epoch: 71, Loss: 3.2754, Train: 1.0000, Val: 0.7400, Test: 0.7560
Epoch: 72, Loss: 3.0710, Train: 1.0000, Val: 0.7400, Test: 0.7540
Epoch: 73, Loss: 2.9774, Train: 1.0000, Val: 0.7380, Test: 0.7540
Epoch: 74, Loss: 3.1874, Train: 1.0000, Val: 0.7360, Test: 0.7530
Epoch: 75, Loss: 3.2233, Train: 1.0000, Val: 0.7360, Test: 0.7500
Epoch: 76, Loss: 2.9039, Train: 1.0000, Val: 0.7360, Test: 0.7510
Epoch: 77, Loss: 2.7929, Train: 1.0000, Val: 0.7340, Test: 0.7510
Epoch: 78, Loss: 2.9537, Train: 1.0000, Val: 0.7320, Test: 0.7530
Epoch: 79, Loss: 2.9409, Train: 1.0000, Val: 0.7300, Test: 0.7520
Epoch: 80, Loss: 2.9880, Train: 1.0000, Val: 0.7300, Test: 0.7500
Epoch: 81, Loss: 3.0530, Train: 1.0000, Val: 0.7280, Test: 0.7490
Epoch: 82, Loss: 2.8985, Train: 1.0000, Val: 0.7260, Test: 0.7470
Epoch: 83, Loss: 3.2628, Train: 1.0000, Val: 0.7260, Test: 0.7460
Epoch: 84, Loss: 2.9875, Train: 1.0000, Val: 0.7240, Test: 0.7480
Epoch: 85, Loss: 2.8755, Train: 1.0000, Val: 0.7260, Test: 0.7490
Epoch: 86, Loss: 3.0875, Train: 1.0000, Val: 0.7240, Test: 0.7490
Epoch: 87, Loss: 2.8899, Train: 1.0000, Val: 0.7240, Test: 0.7480
Epoch: 88, Loss: 3.0818, Train: 1.0000, Val: 0.7260, Test: 0.7460
Epoch: 89, Loss: 3.0208, Train: 1.0000, Val: 0.7260, Test: 0.7460
Epoch: 90, Loss: 2.8214, Train: 1.0000, Val: 0.7260, Test: 0.7460
Epoch: 91, Loss: 2.9421, Train: 1.0000, Val: 0.7260, Test: 0.7450
Epoch: 92, Loss: 3.0281, Train: 1.0000, Val: 0.7240, Test: 0.7450
Epoch: 93, Loss: 3.2002, Train: 1.0000, Val: 0.7260, Test: 0.7440
Epoch: 94, Loss: 3.1620, Train: 1.0000, Val: 0.7240, Test: 0.7440
Epoch: 95, Loss: 3.0242, Train: 1.0000, Val: 0.7240, Test: 0.7440
Epoch: 96, Loss: 3.0883, Train: 1.0000, Val: 0.7240, Test: 0.7450
Epoch: 97, Loss: 2.9344, Train: 1.0000, Val: 0.7260, Test: 0.7450
Epoch: 98, Loss: 3.1682, Train: 1.0000, Val: 0.7260, Test: 0.7450
Epoch: 99, Loss: 2.6010, Train: 1.0000, Val: 0.7260, Test: 0.7450
Epoch: 100, Loss: 2.8555, Train: 1.0000, Val: 0.7260, Test: 0.7460
Epoch: 101, Loss: 3.1337, Train: 1.0000, Val: 0.7260, Test: 0.7460
Epoch: 102, Loss: 3.1529, Train: 1.0000, Val: 0.7280, Test: 0.7460
Epoch: 103, Loss: 2.8628, Train: 1.0000, Val: 0.7280, Test: 0.7460
Epoch: 104, Loss: 2.9082, Train: 1.0000, Val: 0.7300, Test: 0.7480
Epoch: 105, Loss: 2.8181, Train: 1.0000, Val: 0.7320, Test: 0.7490
Epoch: 106, Loss: 2.7898, Train: 1.0000, Val: 0.7300, Test: 0.7480
Epoch: 107, Loss: 2.8530, Train: 1.0000, Val: 0.7300, Test: 0.7480
Epoch: 108, Loss: 2.8185, Train: 1.0000, Val: 0.7300, Test: 0.7470
Epoch: 109, Loss: 2.8759, Train: 1.0000, Val: 0.7300, Test: 0.7500
Epoch: 110, Loss: 2.8191, Train: 1.0000, Val: 0.7300, Test: 0.7500
Epoch: 111, Loss: 3.1973, Train: 1.0000, Val: 0.7280, Test: 0.7500
Epoch: 112, Loss: 2.8947, Train: 1.0000, Val: 0.7300, Test: 0.7490
Epoch: 113, Loss: 2.8951, Train: 1.0000, Val: 0.7300, Test: 0.7500
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 114, Loss: 2.8039, Train: 1.0000, Val: 0.7280, Test: 0.7500
Epoch: 115, Loss: 3.0132, Train: 1.0000, Val: 0.7280, Test: 0.7510
Epoch: 116, Loss: 2.8593, Train: 1.0000, Val: 0.7280, Test: 0.7480
Epoch: 117, Loss: 2.4097, Train: 1.0000, Val: 0.7260, Test: 0.7460
Epoch: 118, Loss: 2.7743, Train: 1.0000, Val: 0.7240, Test: 0.7470
Epoch: 119, Loss: 2.8275, Train: 1.0000, Val: 0.7240, Test: 0.7470
Epoch: 120, Loss: 2.3385, Train: 1.0000, Val: 0.7240, Test: 0.7480
Epoch: 121, Loss: 2.7152, Train: 1.0000, Val: 0.7220, Test: 0.7480
Epoch: 122, Loss: 3.0001, Train: 1.0000, Val: 0.7200, Test: 0.7460
Epoch: 123, Loss: 2.7016, Train: 1.0000, Val: 0.7200, Test: 0.7450
Epoch: 124, Loss: 2.7197, Train: 1.0000, Val: 0.7200, Test: 0.7450
Epoch: 125, Loss: 2.6641, Train: 1.0000, Val: 0.7200, Test: 0.7450
Epoch: 126, Loss: 2.6511, Train: 1.0000, Val: 0.7180, Test: 0.7440
Epoch: 127, Loss: 2.7136, Train: 1.0000, Val: 0.7160, Test: 0.7430
Epoch: 128, Loss: 2.7278, Train: 1.0000, Val: 0.7220, Test: 0.7420
Epoch: 129, Loss: 2.8926, Train: 1.0000, Val: 0.7220, Test: 0.7420
Epoch: 130, Loss: 2.4135, Train: 1.0000, Val: 0.7220, Test: 0.7410
Epoch: 131, Loss: 2.3991, Train: 1.0000, Val: 0.7220, Test: 0.7420
Epoch: 132, Loss: 2.6788, Train: 1.0000, Val: 0.7200, Test: 0.7410
Epoch: 133, Loss: 2.5479, Train: 1.0000, Val: 0.7160, Test: 0.7410
Epoch: 134, Loss: 2.6571, Train: 1.0000, Val: 0.7160, Test: 0.7390
Epoch: 135, Loss: 2.5771, Train: 1.0000, Val: 0.7160, Test: 0.7390
Epoch: 136, Loss: 2.8813, Train: 1.0000, Val: 0.7140, Test: 0.7390
Epoch: 137, Loss: 2.8302, Train: 1.0000, Val: 0.7140, Test: 0.7390
Epoch: 138, Loss: 2.4533, Train: 1.0000, Val: 0.7120, Test: 0.7390
Epoch: 139, Loss: 2.7739, Train: 1.0000, Val: 0.7140, Test: 0.7400
Epoch: 140, Loss: 2.8770, Train: 1.0000, Val: 0.7140, Test: 0.7400
Epoch: 141, Loss: 2.8066, Train: 1.0000, Val: 0.7140, Test: 0.7400
Epoch: 142, Loss: 2.8032, Train: 1.0000, Val: 0.7100, Test: 0.7410
Epoch: 143, Loss: 2.4033, Train: 1.0000, Val: 0.7060, Test: 0.7400
Epoch: 144, Loss: 2.4554, Train: 1.0000, Val: 0.7100, Test: 0.7380
Epoch: 145, Loss: 2.3617, Train: 1.0000, Val: 0.7100, Test: 0.7380
Epoch: 146, Loss: 2.7747, Train: 1.0000, Val: 0.7080, Test: 0.7380
Epoch: 147, Loss: 2.7191, Train: 1.0000, Val: 0.7080, Test: 0.7380
Epoch: 148, Loss: 2.3832, Train: 1.0000, Val: 0.7080, Test: 0.7410
Epoch: 149, Loss: 2.9409, Train: 1.0000, Val: 0.7120, Test: 0.7400
Epoch: 150, Loss: 2.5149, Train: 1.0000, Val: 0.7120, Test: 0.7400
Epoch: 151, Loss: 2.8227, Train: 1.0000, Val: 0.7100, Test: 0.7390
Epoch: 152, Loss: 2.4119, Train: 1.0000, Val: 0.7140, Test: 0.7390
Epoch: 153, Loss: 2.6800, Train: 1.0000, Val: 0.7140, Test: 0.7390
Epoch: 154, Loss: 2.6281, Train: 1.0000, Val: 0.7180, Test: 0.7380
Epoch: 155, Loss: 2.5571, Train: 1.0000, Val: 0.7180, Test: 0.7380
Epoch: 156, Loss: 2.6165, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 157, Loss: 2.5224, Train: 1.0000, Val: 0.7200, Test: 0.7400
Epoch: 158, Loss: 2.6796, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 159, Loss: 2.6298, Train: 1.0000, Val: 0.7180, Test: 0.7380
Epoch: 160, Loss: 2.7659, Train: 1.0000, Val: 0.7140, Test: 0.7370
Epoch: 161, Loss: 2.3742, Train: 1.0000, Val: 0.7160, Test: 0.7350
Epoch: 162, Loss: 2.6399, Train: 1.0000, Val: 0.7160, Test: 0.7340
Epoch: 163, Loss: 2.8061, Train: 1.0000, Val: 0.7160, Test: 0.7320
Epoch: 164, Loss: 2.6124, Train: 1.0000, Val: 0.7160, Test: 0.7320
Epoch: 165, Loss: 2.7172, Train: 1.0000, Val: 0.7160, Test: 0.7330
Epoch: 166, Loss: 2.6759, Train: 1.0000, Val: 0.7140, Test: 0.7300
Epoch: 167, Loss: 2.7530, Train: 1.0000, Val: 0.7160, Test: 0.7310
Epoch: 168, Loss: 2.5741, Train: 1.0000, Val: 0.7180, Test: 0.7320
Epoch: 169, Loss: 2.5893, Train: 1.0000, Val: 0.7180, Test: 0.7310
Epoch: 170, Loss: 2.3657, Train: 1.0000, Val: 0.7120, Test: 0.7310
Epoch: 171, Loss: 2.6932, Train: 1.0000, Val: 0.7120, Test: 0.7290
Epoch: 172, Loss: 2.4531, Train: 1.0000, Val: 0.7140, Test: 0.7300
Epoch: 173, Loss: 2.7269, Train: 1.0000, Val: 0.7120, Test: 0.7290
Epoch: 174, Loss: 2.5844, Train: 1.0000, Val: 0.7100, Test: 0.7290
Epoch: 175, Loss: 2.4505, Train: 1.0000, Val: 0.7100, Test: 0.7280
Epoch: 176, Loss: 2.6761, Train: 1.0000, Val: 0.7080, Test: 0.7280
Epoch: 177, Loss: 2.8591, Train: 1.0000, Val: 0.7080, Test: 0.7280
Epoch: 178, Loss: 2.5260, Train: 1.0000, Val: 0.7080, Test: 0.7280
Epoch: 179, Loss: 2.5523, Train: 1.0000, Val: 0.7080, Test: 0.7280
Epoch: 180, Loss: 2.7058, Train: 1.0000, Val: 0.7140, Test: 0.7230
Epoch: 181, Loss: 2.7663, Train: 1.0000, Val: 0.7160, Test: 0.7230
Epoch: 182, Loss: 2.6932, Train: 1.0000, Val: 0.7160, Test: 0.7230
Epoch: 183, Loss: 2.4468, Train: 1.0000, Val: 0.7160, Test: 0.7200
Epoch: 184, Loss: 2.4935, Train: 1.0000, Val: 0.7120, Test: 0.7180
Epoch: 185, Loss: 2.4761, Train: 1.0000, Val: 0.7100, Test: 0.7180
Epoch: 186, Loss: 2.5317, Train: 1.0000, Val: 0.7100, Test: 0.7170
Epoch: 187, Loss: 2.3777, Train: 1.0000, Val: 0.7080, Test: 0.7190
Epoch: 188, Loss: 2.6446, Train: 1.0000, Val: 0.7080, Test: 0.7180
Epoch: 189, Loss: 2.3329, Train: 1.0000, Val: 0.7080, Test: 0.7160
Epoch: 190, Loss: 2.4665, Train: 1.0000, Val: 0.7080, Test: 0.7160
Epoch: 191, Loss: 2.3887, Train: 1.0000, Val: 0.7060, Test: 0.7140
Epoch: 192, Loss: 2.4317, Train: 1.0000, Val: 0.7060, Test: 0.7130
Epoch: 193, Loss: 2.4622, Train: 1.0000, Val: 0.7060, Test: 0.7130
Epoch: 194, Loss: 2.2382, Train: 1.0000, Val: 0.7080, Test: 0.7130
Epoch: 195, Loss: 2.4495, Train: 1.0000, Val: 0.7060, Test: 0.7130
Epoch: 196, Loss: 2.5699, Train: 1.0000, Val: 0.7040, Test: 0.7110
Epoch: 197, Loss: 2.5196, Train: 1.0000, Val: 0.7060, Test: 0.7110
Epoch: 198, Loss: 2.5443, Train: 1.0000, Val: 0.7060, Test: 0.7100
Epoch: 199, Loss: 2.4240, Train: 1.0000, Val: 0.7060, Test: 0.7090
Epoch: 200, Loss: 2.5656, Train: 1.0000, Val: 0.7060, Test: 0.7120
MAD:  0.3508
Best Test Accuracy: 0.7570, Val Accuracy: 0.7380, Train Accuracy: 1.0000
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8686, Train: 0.1143, Val: 0.0220, Test: 0.0320
Epoch: 2, Loss: 4.8167, Train: 0.2429, Val: 0.0760, Test: 0.0930
Epoch: 3, Loss: 4.7571, Train: 0.3714, Val: 0.1600, Test: 0.1710
Epoch: 4, Loss: 4.6805, Train: 0.5000, Val: 0.2380, Test: 0.2490
Epoch: 5, Loss: 4.6042, Train: 0.5786, Val: 0.3140, Test: 0.2970
Epoch: 6, Loss: 4.5812, Train: 0.6071, Val: 0.3360, Test: 0.3380
Epoch: 7, Loss: 4.4563, Train: 0.6429, Val: 0.3560, Test: 0.3600
Epoch: 8, Loss: 4.4524, Train: 0.6714, Val: 0.3620, Test: 0.3760
Epoch: 9, Loss: 4.4135, Train: 0.7143, Val: 0.3760, Test: 0.3930
Epoch: 10, Loss: 4.2853, Train: 0.7429, Val: 0.3880, Test: 0.4140
Epoch: 11, Loss: 4.2438, Train: 0.7929, Val: 0.4000, Test: 0.4400
Epoch: 12, Loss: 4.1436, Train: 0.8357, Val: 0.4140, Test: 0.4580
Epoch: 13, Loss: 3.7756, Train: 0.8714, Val: 0.4380, Test: 0.4860
Epoch: 14, Loss: 4.0421, Train: 0.8929, Val: 0.4720, Test: 0.5100
Epoch: 15, Loss: 3.9178, Train: 0.9214, Val: 0.4920, Test: 0.5340
Epoch: 16, Loss: 3.7376, Train: 0.9429, Val: 0.5240, Test: 0.5610
Epoch: 17, Loss: 3.6457, Train: 0.9714, Val: 0.5660, Test: 0.5890
Epoch: 18, Loss: 3.7192, Train: 0.9786, Val: 0.5960, Test: 0.6230
Epoch: 19, Loss: 3.8971, Train: 0.9857, Val: 0.6260, Test: 0.6560
Epoch: 20, Loss: 3.9268, Train: 0.9857, Val: 0.6380, Test: 0.6700
Epoch: 21, Loss: 3.6918, Train: 0.9857, Val: 0.6460, Test: 0.6880
Epoch: 22, Loss: 3.8667, Train: 0.9857, Val: 0.6580, Test: 0.6980
Epoch: 23, Loss: 3.5669, Train: 0.9929, Val: 0.6640, Test: 0.7050
Epoch: 24, Loss: 3.9084, Train: 0.9929, Val: 0.6620, Test: 0.7110
Epoch: 25, Loss: 3.6926, Train: 0.9929, Val: 0.6680, Test: 0.7120
Epoch: 26, Loss: 3.7330, Train: 0.9929, Val: 0.6720, Test: 0.7110
Epoch: 27, Loss: 3.5737, Train: 1.0000, Val: 0.6820, Test: 0.7150
Epoch: 28, Loss: 3.7140, Train: 1.0000, Val: 0.6840, Test: 0.7240
Epoch: 29, Loss: 3.4010, Train: 1.0000, Val: 0.6920, Test: 0.7310
Epoch: 30, Loss: 3.5101, Train: 1.0000, Val: 0.6980, Test: 0.7360
Epoch: 31, Loss: 3.4348, Train: 1.0000, Val: 0.7160, Test: 0.7380
Epoch: 32, Loss: 3.3956, Train: 1.0000, Val: 0.7280, Test: 0.7440
Epoch: 33, Loss: 3.5361, Train: 1.0000, Val: 0.7300, Test: 0.7540
Epoch: 34, Loss: 3.6505, Train: 1.0000, Val: 0.7360, Test: 0.7560
Epoch: 35, Loss: 3.2434, Train: 1.0000, Val: 0.7360, Test: 0.7570
Epoch: 36, Loss: 3.6606, Train: 1.0000, Val: 0.7300, Test: 0.7600
Epoch: 37, Loss: 3.4357, Train: 1.0000, Val: 0.7300, Test: 0.7620
Epoch: 38, Loss: 3.5133, Train: 1.0000, Val: 0.7300, Test: 0.7590
Epoch: 39, Loss: 3.4963, Train: 1.0000, Val: 0.7320, Test: 0.7580
Epoch: 40, Loss: 3.4495, Train: 1.0000, Val: 0.7320, Test: 0.7580
Epoch: 41, Loss: 3.2733, Train: 1.0000, Val: 0.7360, Test: 0.7590
Epoch: 42, Loss: 3.2975, Train: 1.0000, Val: 0.7400, Test: 0.7570
Epoch: 43, Loss: 3.3816, Train: 1.0000, Val: 0.7400, Test: 0.7570
Epoch: 44, Loss: 3.1245, Train: 1.0000, Val: 0.7400, Test: 0.7560
Epoch: 45, Loss: 3.2787, Train: 1.0000, Val: 0.7420, Test: 0.7550
Epoch: 46, Loss: 3.0969, Train: 1.0000, Val: 0.7400, Test: 0.7570
Epoch: 47, Loss: 3.3931, Train: 1.0000, Val: 0.7380, Test: 0.7540
Epoch: 48, Loss: 3.3641, Train: 1.0000, Val: 0.7380, Test: 0.7530
Epoch: 49, Loss: 3.4689, Train: 1.0000, Val: 0.7380, Test: 0.7520
Epoch: 50, Loss: 3.5182, Train: 1.0000, Val: 0.7380, Test: 0.7530
Epoch: 51, Loss: 3.0905, Train: 1.0000, Val: 0.7360, Test: 0.7530
Epoch: 52, Loss: 3.2938, Train: 1.0000, Val: 0.7340, Test: 0.7540
Epoch: 53, Loss: 3.2113, Train: 1.0000, Val: 0.7360, Test: 0.7530
Epoch: 54, Loss: 3.2019, Train: 1.0000, Val: 0.7360, Test: 0.7520
Epoch: 55, Loss: 3.2622, Train: 1.0000, Val: 0.7340, Test: 0.7510
Epoch: 56, Loss: 3.3662, Train: 1.0000, Val: 0.7360, Test: 0.7540
Epoch: 57, Loss: 3.4464, Train: 1.0000, Val: 0.7380, Test: 0.7540
Epoch: 58, Loss: 3.4043, Train: 1.0000, Val: 0.7400, Test: 0.7560
Epoch: 59, Loss: 3.1903, Train: 1.0000, Val: 0.7400, Test: 0.7550
Epoch: 60, Loss: 3.0560, Train: 1.0000, Val: 0.7380, Test: 0.7570
Epoch: 61, Loss: 2.9030, Train: 1.0000, Val: 0.7360, Test: 0.7570
Epoch: 62, Loss: 3.2318, Train: 1.0000, Val: 0.7340, Test: 0.7560
Epoch: 63, Loss: 3.0727, Train: 1.0000, Val: 0.7380, Test: 0.7560
Epoch: 64, Loss: 3.1062, Train: 1.0000, Val: 0.7340, Test: 0.7570
Epoch: 65, Loss: 2.9737, Train: 1.0000, Val: 0.7340, Test: 0.7560
Epoch: 66, Loss: 3.1757, Train: 1.0000, Val: 0.7360, Test: 0.7560
Epoch: 67, Loss: 2.8731, Train: 1.0000, Val: 0.7380, Test: 0.7530
Epoch: 68, Loss: 3.0967, Train: 1.0000, Val: 0.7380, Test: 0.7530
Epoch: 69, Loss: 3.2473, Train: 1.0000, Val: 0.7380, Test: 0.7520
Epoch: 70, Loss: 3.1724, Train: 1.0000, Val: 0.7380, Test: 0.7520
Epoch: 71, Loss: 3.3155, Train: 1.0000, Val: 0.7400, Test: 0.7510
Epoch: 72, Loss: 2.8950, Train: 1.0000, Val: 0.7420, Test: 0.7510
Epoch: 73, Loss: 3.0610, Train: 1.0000, Val: 0.7420, Test: 0.7490
Epoch: 74, Loss: 2.9172, Train: 1.0000, Val: 0.7400, Test: 0.7480
Epoch: 75, Loss: 3.1182, Train: 1.0000, Val: 0.7400, Test: 0.7470
Epoch: 76, Loss: 3.1114, Train: 1.0000, Val: 0.7420, Test: 0.7480
Epoch: 77, Loss: 2.7535, Train: 1.0000, Val: 0.7420, Test: 0.7490
Epoch: 78, Loss: 3.2544, Train: 1.0000, Val: 0.7400, Test: 0.7490
Epoch: 79, Loss: 2.9654, Train: 1.0000, Val: 0.7400, Test: 0.7480
Epoch: 80, Loss: 3.0189, Train: 1.0000, Val: 0.7400, Test: 0.7450
Epoch: 81, Loss: 3.0805, Train: 1.0000, Val: 0.7400, Test: 0.7450
Epoch: 82, Loss: 2.9841, Train: 1.0000, Val: 0.7380, Test: 0.7470
Epoch: 83, Loss: 2.9740, Train: 1.0000, Val: 0.7380, Test: 0.7470
Epoch: 84, Loss: 3.0631, Train: 1.0000, Val: 0.7380, Test: 0.7460
Epoch: 85, Loss: 3.0360, Train: 1.0000, Val: 0.7400, Test: 0.7460
Epoch: 86, Loss: 2.9794, Train: 1.0000, Val: 0.7400, Test: 0.7460
Epoch: 87, Loss: 2.7206, Train: 1.0000, Val: 0.7400, Test: 0.7450
Epoch: 88, Loss: 3.0655, Train: 1.0000, Val: 0.7400, Test: 0.7470
Epoch: 89, Loss: 2.8421, Train: 1.0000, Val: 0.7380, Test: 0.7430
Epoch: 90, Loss: 3.0910, Train: 1.0000, Val: 0.7380, Test: 0.7410
Epoch: 91, Loss: 2.9547, Train: 1.0000, Val: 0.7360, Test: 0.7400
Epoch: 92, Loss: 2.9449, Train: 1.0000, Val: 0.7340, Test: 0.7380
Epoch: 93, Loss: 3.0516, Train: 1.0000, Val: 0.7360, Test: 0.7390
Epoch: 94, Loss: 3.0495, Train: 1.0000, Val: 0.7360, Test: 0.7410
Epoch: 95, Loss: 3.1324, Train: 1.0000, Val: 0.7360, Test: 0.7420
Epoch: 96, Loss: 3.0583, Train: 1.0000, Val: 0.7360, Test: 0.7420
Epoch: 97, Loss: 2.9697, Train: 1.0000, Val: 0.7360, Test: 0.7400
Epoch: 98, Loss: 2.7314, Train: 1.0000, Val: 0.7340, Test: 0.7390
Epoch: 99, Loss: 3.1718, Train: 1.0000, Val: 0.7320, Test: 0.7390
Epoch: 100, Loss: 2.9417, Train: 1.0000, Val: 0.7360, Test: 0.7390
Epoch: 101, Loss: 2.9126, Train: 1.0000, Val: 0.7360, Test: 0.7410
Epoch: 102, Loss: 2.8529, Train: 1.0000, Val: 0.7360, Test: 0.7410
Epoch: 103, Loss: 2.5391, Train: 1.0000, Val: 0.7380, Test: 0.7410
Epoch: 104, Loss: 3.1075, Train: 1.0000, Val: 0.7380, Test: 0.7410
Epoch: 105, Loss: 2.9754, Train: 1.0000, Val: 0.7380, Test: 0.7410
Epoch: 106, Loss: 2.6890, Train: 1.0000, Val: 0.7380, Test: 0.7400
Epoch: 107, Loss: 2.5528, Train: 1.0000, Val: 0.7400, Test: 0.7420
Epoch: 108, Loss: 2.9610, Train: 1.0000, Val: 0.7400, Test: 0.7410
Epoch: 109, Loss: 2.8118, Train: 1.0000, Val: 0.7380, Test: 0.7420
Epoch: 110, Loss: 2.8386, Train: 1.0000, Val: 0.7360, Test: 0.7400
Epoch: 111, Loss: 2.9294, Train: 1.0000, Val: 0.7360, Test: 0.7400
Epoch: 112, Loss: 2.8766, Train: 1.0000, Val: 0.7360, Test: 0.7400
Epoch: 113, Loss: 2.7253, Train: 1.0000, Val: 0.7340, Test: 0.7420
Epoch: 114, Loss: 2.8935, Train: 1.0000, Val: 0.7320, Test: 0.7410
Epoch: 115, Loss: 2.9727, Train: 1.0000, Val: 0.7300, Test: 0.7400
Epoch: 116, Loss: 2.7777, Train: 1.0000, Val: 0.7300, Test: 0.7410
Epoch: 117, Loss: 2.6841, Train: 1.0000, Val: 0.7300, Test: 0.7410
Epoch: 118, Loss: 2.8120, Train: 1.0000, Val: 0.7280, Test: 0.7390
Epoch: 119, Loss: 2.6411, Train: 1.0000, Val: 0.7260, Test: 0.7390
Epoch: 120, Loss: 2.5066, Train: 1.0000, Val: 0.7280, Test: 0.7390
Epoch: 121, Loss: 3.0677, Train: 1.0000, Val: 0.7260, Test: 0.7390
Epoch: 122, Loss: 2.8943, Train: 1.0000, Val: 0.7240, Test: 0.7380
Epoch: 123, Loss: 2.6953, Train: 1.0000, Val: 0.7260, Test: 0.7380
Epoch: 124, Loss: 2.9823, Train: 1.0000, Val: 0.7260, Test: 0.7380
Epoch: 125, Loss: 2.6937, Train: 1.0000, Val: 0.7260, Test: 0.7370
Epoch: 126, Loss: 2.9327, Train: 1.0000, Val: 0.7260, Test: 0.7360
Epoch: 127, Loss: 2.7380, Train: 1.0000, Val: 0.7220, Test: 0.7360
Epoch: 128, Loss: 2.7393, Train: 1.0000, Val: 0.7220, Test: 0.7360
Epoch: 129, Loss: 2.7581, Train: 1.0000, Val: 0.7220, Test: 0.7360
Epoch: 130, Loss: 2.8359, Train: 1.0000, Val: 0.7220, Test: 0.7380
Epoch: 131, Loss: 2.4939, Train: 1.0000, Val: 0.7240, Test: 0.7370
Epoch: 132, Loss: 2.7387, Train: 1.0000, Val: 0.7240, Test: 0.7360
Epoch: 133, Loss: 2.6197, Train: 1.0000, Val: 0.7220, Test: 0.7350
Epoch: 134, Loss: 2.7217, Train: 1.0000, Val: 0.7180, Test: 0.7350
Epoch: 135, Loss: 2.8493, Train: 1.0000, Val: 0.7180, Test: 0.7330
Epoch: 136, Loss: 2.8230, Train: 1.0000, Val: 0.7200, Test: 0.7330
Epoch: 137, Loss: 2.8408, Train: 1.0000, Val: 0.7200, Test: 0.7310
Epoch: 138, Loss: 2.6607, Train: 1.0000, Val: 0.7220, Test: 0.7300
Epoch: 139, Loss: 2.8278, Train: 1.0000, Val: 0.7220, Test: 0.7290
Epoch: 140, Loss: 2.5081, Train: 1.0000, Val: 0.7240, Test: 0.7280
Epoch: 141, Loss: 2.9782, Train: 1.0000, Val: 0.7220, Test: 0.7260
Epoch: 142, Loss: 2.8455, Train: 1.0000, Val: 0.7220, Test: 0.7260
Epoch: 143, Loss: 2.7250, Train: 1.0000, Val: 0.7220, Test: 0.7260
Epoch: 144, Loss: 2.6664, Train: 1.0000, Val: 0.7220, Test: 0.7260
Epoch: 145, Loss: 2.7352, Train: 1.0000, Val: 0.7220, Test: 0.7260
Epoch: 146, Loss: 2.6507, Train: 1.0000, Val: 0.7220, Test: 0.7270
Epoch: 147, Loss: 2.9027, Train: 1.0000, Val: 0.7200, Test: 0.7280
Epoch: 148, Loss: 2.6982, Train: 1.0000, Val: 0.7200, Test: 0.7280
Epoch: 149, Loss: 2.7924, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 150, Loss: 2.4637, Train: 1.0000, Val: 0.7200, Test: 0.7280
Epoch: 151, Loss: 2.5853, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 152, Loss: 2.7482, Train: 1.0000, Val: 0.7240, Test: 0.7280
Epoch: 153, Loss: 2.7038, Train: 1.0000, Val: 0.7220, Test: 0.7250
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 2.6979, Train: 1.0000, Val: 0.7200, Test: 0.7250
Epoch: 155, Loss: 2.5682, Train: 1.0000, Val: 0.7200, Test: 0.7250
Epoch: 156, Loss: 2.6448, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 157, Loss: 2.5823, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 158, Loss: 2.4060, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 159, Loss: 2.8857, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 160, Loss: 2.6730, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 161, Loss: 2.7810, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 162, Loss: 2.5398, Train: 1.0000, Val: 0.7220, Test: 0.7280
Epoch: 163, Loss: 3.0631, Train: 1.0000, Val: 0.7220, Test: 0.7260
Epoch: 164, Loss: 2.7469, Train: 1.0000, Val: 0.7180, Test: 0.7250
Epoch: 165, Loss: 2.7151, Train: 1.0000, Val: 0.7180, Test: 0.7260
Epoch: 166, Loss: 2.8016, Train: 1.0000, Val: 0.7160, Test: 0.7250
Epoch: 167, Loss: 2.5329, Train: 1.0000, Val: 0.7160, Test: 0.7240
Epoch: 168, Loss: 2.6545, Train: 1.0000, Val: 0.7180, Test: 0.7240
Epoch: 169, Loss: 2.3330, Train: 1.0000, Val: 0.7160, Test: 0.7250
Epoch: 170, Loss: 2.9005, Train: 1.0000, Val: 0.7160, Test: 0.7240
Epoch: 171, Loss: 2.4898, Train: 1.0000, Val: 0.7160, Test: 0.7230
Epoch: 172, Loss: 2.2763, Train: 1.0000, Val: 0.7160, Test: 0.7210
Epoch: 173, Loss: 2.5695, Train: 1.0000, Val: 0.7160, Test: 0.7210
Epoch: 174, Loss: 2.6881, Train: 1.0000, Val: 0.7180, Test: 0.7220
Epoch: 175, Loss: 2.3244, Train: 1.0000, Val: 0.7180, Test: 0.7240
Epoch: 176, Loss: 2.8742, Train: 1.0000, Val: 0.7180, Test: 0.7250
Epoch: 177, Loss: 2.3766, Train: 1.0000, Val: 0.7180, Test: 0.7260
Epoch: 178, Loss: 2.5292, Train: 1.0000, Val: 0.7180, Test: 0.7260
Epoch: 179, Loss: 2.3543, Train: 1.0000, Val: 0.7180, Test: 0.7250
Epoch: 180, Loss: 2.4145, Train: 1.0000, Val: 0.7180, Test: 0.7250
Epoch: 181, Loss: 2.8592, Train: 1.0000, Val: 0.7160, Test: 0.7260
Epoch: 182, Loss: 2.6616, Train: 1.0000, Val: 0.7160, Test: 0.7280
Epoch: 183, Loss: 2.8495, Train: 1.0000, Val: 0.7180, Test: 0.7270
Epoch: 184, Loss: 2.3122, Train: 1.0000, Val: 0.7200, Test: 0.7270
Epoch: 185, Loss: 2.4584, Train: 1.0000, Val: 0.7200, Test: 0.7240
Epoch: 186, Loss: 2.6596, Train: 1.0000, Val: 0.7180, Test: 0.7240
Epoch: 187, Loss: 2.3851, Train: 1.0000, Val: 0.7180, Test: 0.7240
Epoch: 188, Loss: 2.2720, Train: 1.0000, Val: 0.7180, Test: 0.7230
Epoch: 189, Loss: 2.8024, Train: 1.0000, Val: 0.7180, Test: 0.7220
Epoch: 190, Loss: 2.6539, Train: 1.0000, Val: 0.7180, Test: 0.7200
Epoch: 191, Loss: 2.7981, Train: 1.0000, Val: 0.7180, Test: 0.7200
Epoch: 192, Loss: 2.5931, Train: 1.0000, Val: 0.7180, Test: 0.7210
Epoch: 193, Loss: 2.5253, Train: 1.0000, Val: 0.7140, Test: 0.7210
Epoch: 194, Loss: 2.6145, Train: 1.0000, Val: 0.7140, Test: 0.7190
Epoch: 195, Loss: 2.4204, Train: 1.0000, Val: 0.7140, Test: 0.7190
Epoch: 196, Loss: 2.6648, Train: 1.0000, Val: 0.7140, Test: 0.7180
Epoch: 197, Loss: 2.3811, Train: 1.0000, Val: 0.7140, Test: 0.7150
Epoch: 198, Loss: 2.8086, Train: 1.0000, Val: 0.7120, Test: 0.7170
Epoch: 199, Loss: 2.5080, Train: 1.0000, Val: 0.7160, Test: 0.7150
Epoch: 200, Loss: 2.5239, Train: 1.0000, Val: 0.7160, Test: 0.7160
MAD:  0.3537
Best Test Accuracy: 0.7620, Val Accuracy: 0.7300, Train Accuracy: 1.0000
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8317, Train: 0.1714, Val: 0.0520, Test: 0.0570
Epoch: 2, Loss: 4.7609, Train: 0.3714, Val: 0.1720, Test: 0.1800
Epoch: 3, Loss: 4.6675, Train: 0.5286, Val: 0.2860, Test: 0.2990
Epoch: 4, Loss: 4.6179, Train: 0.6429, Val: 0.3660, Test: 0.3870
Epoch: 5, Loss: 4.5021, Train: 0.6857, Val: 0.4260, Test: 0.4570
Epoch: 6, Loss: 4.4832, Train: 0.7500, Val: 0.4400, Test: 0.4910
Epoch: 7, Loss: 4.4409, Train: 0.7786, Val: 0.4680, Test: 0.5020
Epoch: 8, Loss: 4.2779, Train: 0.8143, Val: 0.4860, Test: 0.5180
Epoch: 9, Loss: 4.3960, Train: 0.8214, Val: 0.4980, Test: 0.5340
Epoch: 10, Loss: 4.1010, Train: 0.8357, Val: 0.5000, Test: 0.5440
Epoch: 11, Loss: 4.1736, Train: 0.8357, Val: 0.4960, Test: 0.5450
Epoch: 12, Loss: 4.1286, Train: 0.8429, Val: 0.5000, Test: 0.5430
Epoch: 13, Loss: 4.0017, Train: 0.8500, Val: 0.5060, Test: 0.5410
Epoch: 14, Loss: 3.9975, Train: 0.8500, Val: 0.5040, Test: 0.5430
Epoch: 15, Loss: 3.8206, Train: 0.8500, Val: 0.5020, Test: 0.5500
Epoch: 16, Loss: 3.8636, Train: 0.8500, Val: 0.5100, Test: 0.5510
Epoch: 17, Loss: 3.7855, Train: 0.8500, Val: 0.5400, Test: 0.5650
Epoch: 18, Loss: 3.7512, Train: 0.8571, Val: 0.5500, Test: 0.5820
Epoch: 19, Loss: 3.8500, Train: 0.8571, Val: 0.5680, Test: 0.5950
Epoch: 20, Loss: 3.7299, Train: 0.8571, Val: 0.5900, Test: 0.6040
Epoch: 21, Loss: 3.8802, Train: 0.8571, Val: 0.5940, Test: 0.6120
Epoch: 22, Loss: 3.6600, Train: 0.8643, Val: 0.6080, Test: 0.6160
Epoch: 23, Loss: 3.5994, Train: 0.8643, Val: 0.6160, Test: 0.6210
Epoch: 24, Loss: 3.9165, Train: 0.8643, Val: 0.6140, Test: 0.6230
Epoch: 25, Loss: 3.7143, Train: 0.8643, Val: 0.6140, Test: 0.6260
Epoch: 26, Loss: 3.6514, Train: 0.8643, Val: 0.6180, Test: 0.6280
Epoch: 27, Loss: 3.8636, Train: 0.8643, Val: 0.6240, Test: 0.6340
Epoch: 28, Loss: 3.9548, Train: 0.8643, Val: 0.6280, Test: 0.6380
Epoch: 29, Loss: 3.6497, Train: 0.8857, Val: 0.6320, Test: 0.6440
Epoch: 30, Loss: 3.6863, Train: 0.9000, Val: 0.6340, Test: 0.6460
Epoch: 31, Loss: 3.7588, Train: 0.9071, Val: 0.6360, Test: 0.6490
Epoch: 32, Loss: 3.9851, Train: 0.9143, Val: 0.6360, Test: 0.6500
Epoch: 33, Loss: 3.6935, Train: 0.9286, Val: 0.6380, Test: 0.6520
Epoch: 34, Loss: 3.7563, Train: 0.9500, Val: 0.6420, Test: 0.6490
Epoch: 35, Loss: 3.4814, Train: 0.9571, Val: 0.6440, Test: 0.6520
Epoch: 36, Loss: 3.5121, Train: 0.9643, Val: 0.6440, Test: 0.6520
Epoch: 37, Loss: 3.4585, Train: 0.9643, Val: 0.6400, Test: 0.6540
Epoch: 38, Loss: 3.7144, Train: 0.9786, Val: 0.6380, Test: 0.6590
Epoch: 39, Loss: 3.3489, Train: 0.9786, Val: 0.6400, Test: 0.6590
Epoch: 40, Loss: 3.5364, Train: 0.9786, Val: 0.6480, Test: 0.6550
Epoch: 41, Loss: 3.3967, Train: 0.9786, Val: 0.6460, Test: 0.6560
Epoch: 42, Loss: 3.6158, Train: 0.9786, Val: 0.6440, Test: 0.6550
Epoch: 43, Loss: 3.5513, Train: 0.9786, Val: 0.6420, Test: 0.6580
Epoch: 44, Loss: 3.6796, Train: 0.9857, Val: 0.6420, Test: 0.6590
Epoch: 45, Loss: 3.5609, Train: 0.9857, Val: 0.6440, Test: 0.6590
Epoch: 46, Loss: 3.5367, Train: 0.9857, Val: 0.6480, Test: 0.6610
Epoch: 47, Loss: 3.5469, Train: 0.9929, Val: 0.6500, Test: 0.6570
Epoch: 48, Loss: 3.2709, Train: 0.9929, Val: 0.6520, Test: 0.6570
Epoch: 49, Loss: 3.4969, Train: 0.9929, Val: 0.6560, Test: 0.6590
Epoch: 50, Loss: 3.4206, Train: 0.9929, Val: 0.6560, Test: 0.6610
Epoch: 51, Loss: 3.3050, Train: 0.9929, Val: 0.6560, Test: 0.6610
Epoch: 52, Loss: 3.4300, Train: 1.0000, Val: 0.6560, Test: 0.6610
Epoch: 53, Loss: 3.6004, Train: 1.0000, Val: 0.6580, Test: 0.6630
Epoch: 54, Loss: 3.5602, Train: 1.0000, Val: 0.6600, Test: 0.6640
Epoch: 55, Loss: 3.3459, Train: 1.0000, Val: 0.6600, Test: 0.6650
Epoch: 56, Loss: 3.0779, Train: 1.0000, Val: 0.6600, Test: 0.6650
Epoch: 57, Loss: 2.9268, Train: 1.0000, Val: 0.6620, Test: 0.6660
Epoch: 58, Loss: 3.4008, Train: 1.0000, Val: 0.6620, Test: 0.6660
Epoch: 59, Loss: 3.0564, Train: 1.0000, Val: 0.6620, Test: 0.6650
Epoch: 60, Loss: 3.2932, Train: 1.0000, Val: 0.6620, Test: 0.6650
Epoch: 61, Loss: 3.0693, Train: 1.0000, Val: 0.6640, Test: 0.6650
Epoch: 62, Loss: 3.1437, Train: 1.0000, Val: 0.6620, Test: 0.6660
Epoch: 63, Loss: 3.1810, Train: 1.0000, Val: 0.6640, Test: 0.6680
Epoch: 64, Loss: 3.0464, Train: 1.0000, Val: 0.6640, Test: 0.6690
Epoch: 65, Loss: 3.1723, Train: 1.0000, Val: 0.6660, Test: 0.6690
Epoch: 66, Loss: 3.0827, Train: 1.0000, Val: 0.6660, Test: 0.6710
Epoch: 67, Loss: 3.0795, Train: 1.0000, Val: 0.6680, Test: 0.6720
Epoch: 68, Loss: 2.9588, Train: 1.0000, Val: 0.6700, Test: 0.6730
Epoch: 69, Loss: 3.2993, Train: 1.0000, Val: 0.6660, Test: 0.6740
Epoch: 70, Loss: 3.2359, Train: 1.0000, Val: 0.6700, Test: 0.6750
Epoch: 71, Loss: 3.2038, Train: 1.0000, Val: 0.6660, Test: 0.6740
Epoch: 72, Loss: 3.2736, Train: 1.0000, Val: 0.6660, Test: 0.6750
Epoch: 73, Loss: 3.0645, Train: 1.0000, Val: 0.6640, Test: 0.6740
Epoch: 74, Loss: 3.3955, Train: 1.0000, Val: 0.6680, Test: 0.6780
Epoch: 75, Loss: 3.0727, Train: 1.0000, Val: 0.6700, Test: 0.6770
Epoch: 76, Loss: 3.2531, Train: 1.0000, Val: 0.6720, Test: 0.6760
Epoch: 77, Loss: 3.0188, Train: 1.0000, Val: 0.6760, Test: 0.6740
Epoch: 78, Loss: 3.0952, Train: 1.0000, Val: 0.6760, Test: 0.6770
Epoch: 79, Loss: 3.0939, Train: 1.0000, Val: 0.6800, Test: 0.6790
Epoch: 80, Loss: 3.0356, Train: 1.0000, Val: 0.6800, Test: 0.6790
Epoch: 81, Loss: 3.1696, Train: 1.0000, Val: 0.6760, Test: 0.6800
Epoch: 82, Loss: 3.3121, Train: 1.0000, Val: 0.6760, Test: 0.6830
Epoch: 83, Loss: 2.9612, Train: 1.0000, Val: 0.6800, Test: 0.6820
Epoch: 84, Loss: 3.0769, Train: 1.0000, Val: 0.6820, Test: 0.6830
Epoch: 85, Loss: 3.0917, Train: 1.0000, Val: 0.6820, Test: 0.6820
Epoch: 86, Loss: 3.0413, Train: 1.0000, Val: 0.6860, Test: 0.6810
Epoch: 87, Loss: 2.9638, Train: 1.0000, Val: 0.6880, Test: 0.6810
Epoch: 88, Loss: 2.9967, Train: 1.0000, Val: 0.6880, Test: 0.6810
Epoch: 89, Loss: 3.0052, Train: 1.0000, Val: 0.6880, Test: 0.6830
Epoch: 90, Loss: 2.9399, Train: 1.0000, Val: 0.6860, Test: 0.6860
Epoch: 91, Loss: 2.8249, Train: 1.0000, Val: 0.6920, Test: 0.6870
Epoch: 92, Loss: 3.0993, Train: 1.0000, Val: 0.6920, Test: 0.6860
Epoch: 93, Loss: 2.6433, Train: 1.0000, Val: 0.6940, Test: 0.6870
Epoch: 94, Loss: 2.8981, Train: 1.0000, Val: 0.6940, Test: 0.6880
Epoch: 95, Loss: 2.9730, Train: 1.0000, Val: 0.6960, Test: 0.6900
Epoch: 96, Loss: 3.2524, Train: 1.0000, Val: 0.6960, Test: 0.6890
Epoch: 97, Loss: 2.7813, Train: 1.0000, Val: 0.6940, Test: 0.6910
Epoch: 98, Loss: 3.1612, Train: 1.0000, Val: 0.6960, Test: 0.6910
Epoch: 99, Loss: 2.7806, Train: 1.0000, Val: 0.6960, Test: 0.6910
Epoch: 100, Loss: 2.8722, Train: 1.0000, Val: 0.6960, Test: 0.6910
Epoch: 101, Loss: 3.0347, Train: 1.0000, Val: 0.6960, Test: 0.6890
Epoch: 102, Loss: 2.9211, Train: 1.0000, Val: 0.6940, Test: 0.6910
Epoch: 103, Loss: 2.6552, Train: 1.0000, Val: 0.6940, Test: 0.6900
Epoch: 104, Loss: 2.5743, Train: 1.0000, Val: 0.6920, Test: 0.6880
Epoch: 105, Loss: 2.8086, Train: 1.0000, Val: 0.6900, Test: 0.6890
Epoch: 106, Loss: 3.1891, Train: 1.0000, Val: 0.6900, Test: 0.6910
Epoch: 107, Loss: 3.1281, Train: 1.0000, Val: 0.6900, Test: 0.6910
Epoch: 108, Loss: 2.9865, Train: 1.0000, Val: 0.6920, Test: 0.6900
Epoch: 109, Loss: 2.6887, Train: 1.0000, Val: 0.6920, Test: 0.6900
Epoch: 110, Loss: 3.0050, Train: 1.0000, Val: 0.6920, Test: 0.6890
Epoch: 111, Loss: 3.0443, Train: 1.0000, Val: 0.6920, Test: 0.6880
Epoch: 112, Loss: 2.7582, Train: 1.0000, Val: 0.6920, Test: 0.6880
Epoch: 113, Loss: 2.8909, Train: 1.0000, Val: 0.6940, Test: 0.6890
Epoch: 114, Loss: 2.8043, Train: 1.0000, Val: 0.6940, Test: 0.6880
Epoch: 115, Loss: 2.4746, Train: 1.0000, Val: 0.6920, Test: 0.6870
Epoch: 116, Loss: 2.8146, Train: 1.0000, Val: 0.6920, Test: 0.6880
Epoch: 117, Loss: 3.0347, Train: 1.0000, Val: 0.6900, Test: 0.6900
Epoch: 118, Loss: 3.0034, Train: 1.0000, Val: 0.6860, Test: 0.6910
Epoch: 119, Loss: 2.7305, Train: 1.0000, Val: 0.6860, Test: 0.6890
Epoch: 120, Loss: 2.9589, Train: 1.0000, Val: 0.6860, Test: 0.6900
Epoch: 121, Loss: 3.0772, Train: 1.0000, Val: 0.6860, Test: 0.6910
Epoch: 122, Loss: 2.6886, Train: 1.0000, Val: 0.6860, Test: 0.6900
Epoch: 123, Loss: 3.0661, Train: 1.0000, Val: 0.6840, Test: 0.6870
Epoch: 124, Loss: 2.8295, Train: 1.0000, Val: 0.6840, Test: 0.6870
Epoch: 125, Loss: 2.8120, Train: 1.0000, Val: 0.6840, Test: 0.6860
Epoch: 126, Loss: 2.7438, Train: 1.0000, Val: 0.6820, Test: 0.6850
Epoch: 127, Loss: 2.9894, Train: 1.0000, Val: 0.6840, Test: 0.6840
Epoch: 128, Loss: 3.0362, Train: 1.0000, Val: 0.6840, Test: 0.6830
Epoch: 129, Loss: 2.7592, Train: 1.0000, Val: 0.6860, Test: 0.6820
Epoch: 130, Loss: 2.6416, Train: 1.0000, Val: 0.6880, Test: 0.6830
Epoch: 131, Loss: 2.7538, Train: 1.0000, Val: 0.6880, Test: 0.6830
Epoch: 132, Loss: 2.6794, Train: 1.0000, Val: 0.6840, Test: 0.6860
Epoch: 133, Loss: 2.7852, Train: 1.0000, Val: 0.6840, Test: 0.6850
Epoch: 134, Loss: 2.8490, Train: 1.0000, Val: 0.6820, Test: 0.6840
Epoch: 135, Loss: 2.7035, Train: 1.0000, Val: 0.6840, Test: 0.6850
Epoch: 136, Loss: 2.7649, Train: 1.0000, Val: 0.6840, Test: 0.6850
Epoch: 137, Loss: 2.6878, Train: 1.0000, Val: 0.6820, Test: 0.6850
Epoch: 138, Loss: 2.7988, Train: 1.0000, Val: 0.6800, Test: 0.6850
Epoch: 139, Loss: 2.7190, Train: 1.0000, Val: 0.6760, Test: 0.6860
Epoch: 140, Loss: 2.8126, Train: 1.0000, Val: 0.6800, Test: 0.6840
Epoch: 141, Loss: 2.4240, Train: 1.0000, Val: 0.6800, Test: 0.6870
Epoch: 142, Loss: 2.6622, Train: 1.0000, Val: 0.6760, Test: 0.6890
Epoch: 143, Loss: 2.3627, Train: 1.0000, Val: 0.6760, Test: 0.6890
Epoch: 144, Loss: 2.8179, Train: 1.0000, Val: 0.6760, Test: 0.6880
Epoch: 145, Loss: 2.4727, Train: 1.0000, Val: 0.6760, Test: 0.6870
Epoch: 146, Loss: 2.6148, Train: 1.0000, Val: 0.6740, Test: 0.6860
Epoch: 147, Loss: 2.6959, Train: 1.0000, Val: 0.6760, Test: 0.6860
Epoch: 148, Loss: 2.5791, Train: 1.0000, Val: 0.6760, Test: 0.6840
Epoch: 149, Loss: 2.6010, Train: 1.0000, Val: 0.6760, Test: 0.6820
Epoch: 150, Loss: 2.7519, Train: 1.0000, Val: 0.6720, Test: 0.6810
Epoch: 151, Loss: 2.8140, Train: 1.0000, Val: 0.6720, Test: 0.6820
Epoch: 152, Loss: 2.4204, Train: 1.0000, Val: 0.6700, Test: 0.6780
Epoch: 153, Loss: 2.7542, Train: 1.0000, Val: 0.6700, Test: 0.6780
Epoch: 154, Loss: 2.8884, Train: 1.0000, Val: 0.6740, Test: 0.6770
Epoch: 155, Loss: 2.7424, Train: 1.0000, Val: 0.6740, Test: 0.6780
Epoch: 156, Loss: 2.5936, Train: 1.0000, Val: 0.6740, Test: 0.6770
Epoch: 157, Loss: 2.5990, Train: 1.0000, Val: 0.6740, Test: 0.6770
Epoch: 158, Loss: 2.5637, Train: 1.0000, Val: 0.6740, Test: 0.6760
Epoch: 159, Loss: 2.7582, Train: 1.0000, Val: 0.6740, Test: 0.6750
Epoch: 160, Loss: 2.8310, Train: 1.0000, Val: 0.6760, Test: 0.6770
Epoch: 161, Loss: 2.3622, Train: 1.0000, Val: 0.6720, Test: 0.6780
Epoch: 162, Loss: 2.9743, Train: 1.0000, Val: 0.6740, Test: 0.6760
Epoch: 163, Loss: 2.3479, Train: 1.0000, Val: 0.6760, Test: 0.6730
Epoch: 164, Loss: 2.6328, Train: 1.0000, Val: 0.6740, Test: 0.6760
Epoch: 165, Loss: 2.3212, Train: 1.0000, Val: 0.6760, Test: 0.6760
Epoch: 166, Loss: 2.7657, Train: 1.0000, Val: 0.6760, Test: 0.6770
Epoch: 167, Loss: 2.4625, Train: 1.0000, Val: 0.6760, Test: 0.6760
Epoch: 168, Loss: 2.6091, Train: 1.0000, Val: 0.6740, Test: 0.6750
Epoch: 169, Loss: 2.3017, Train: 1.0000, Val: 0.6740, Test: 0.6720
Epoch: 170, Loss: 2.6470, Train: 1.0000, Val: 0.6720, Test: 0.6730
Epoch: 171, Loss: 2.4101, Train: 1.0000, Val: 0.6700, Test: 0.6760
Epoch: 172, Loss: 2.3497, Train: 1.0000, Val: 0.6680, Test: 0.6760
Epoch: 173, Loss: 2.9141, Train: 1.0000, Val: 0.6680, Test: 0.6730
Epoch: 174, Loss: 2.5338, Train: 1.0000, Val: 0.6680, Test: 0.6730
Epoch: 175, Loss: 2.7293, Train: 1.0000, Val: 0.6680, Test: 0.6760
Epoch: 176, Loss: 2.4931, Train: 1.0000, Val: 0.6660, Test: 0.6750
Epoch: 177, Loss: 2.4865, Train: 1.0000, Val: 0.6660, Test: 0.6750
Epoch: 178, Loss: 2.4939, Train: 1.0000, Val: 0.6660, Test: 0.6740
Epoch: 179, Loss: 2.8439, Train: 1.0000, Val: 0.6660, Test: 0.6740
Epoch: 180, Loss: 2.6032, Train: 1.0000, Val: 0.6660, Test: 0.6740
Epoch: 181, Loss: 2.5815, Train: 1.0000, Val: 0.6680, Test: 0.6750
Epoch: 182, Loss: 2.6190, Train: 1.0000, Val: 0.6720, Test: 0.6750
Epoch: 183, Loss: 2.6173, Train: 1.0000, Val: 0.6720, Test: 0.6750
Epoch: 184, Loss: 2.4203, Train: 1.0000, Val: 0.6700, Test: 0.6750
Epoch: 185, Loss: 2.3878, Train: 1.0000, Val: 0.6680, Test: 0.6730
Epoch: 186, Loss: 2.7913, Train: 1.0000, Val: 0.6700, Test: 0.6710
Epoch: 187, Loss: 2.2824, Train: 1.0000, Val: 0.6700, Test: 0.6700
Epoch: 188, Loss: 2.5806, Train: 1.0000, Val: 0.6720, Test: 0.6700
Epoch: 189, Loss: 2.4702, Train: 1.0000, Val: 0.6700, Test: 0.6690
Epoch: 190, Loss: 2.6785, Train: 1.0000, Val: 0.6680, Test: 0.6670
Epoch: 191, Loss: 2.6786, Train: 1.0000, Val: 0.6680, Test: 0.6660
Epoch: 192, Loss: 2.3280, Train: 1.0000, Val: 0.6700, Test: 0.6670
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 2.6313, Train: 1.0000, Val: 0.6680, Test: 0.6650
Epoch: 194, Loss: 2.4488, Train: 1.0000, Val: 0.6640, Test: 0.6660
Epoch: 195, Loss: 2.7046, Train: 1.0000, Val: 0.6640, Test: 0.6670
Epoch: 196, Loss: 2.8219, Train: 1.0000, Val: 0.6640, Test: 0.6690
Epoch: 197, Loss: 2.3947, Train: 1.0000, Val: 0.6680, Test: 0.6700
Epoch: 198, Loss: 2.5004, Train: 1.0000, Val: 0.6680, Test: 0.6700
Epoch: 199, Loss: 2.4683, Train: 1.0000, Val: 0.6700, Test: 0.6700
Epoch: 200, Loss: 2.3897, Train: 1.0000, Val: 0.6660, Test: 0.6710
MAD:  0.1669
Best Test Accuracy: 0.6910, Val Accuracy: 0.6940, Train Accuracy: 1.0000
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8508, Train: 0.1071, Val: 0.0760, Test: 0.0790
Epoch: 2, Loss: 4.8119, Train: 0.2000, Val: 0.1440, Test: 0.1500
Epoch: 3, Loss: 4.6872, Train: 0.2786, Val: 0.1960, Test: 0.1910
Epoch: 4, Loss: 4.7076, Train: 0.4071, Val: 0.2340, Test: 0.2300
Epoch: 5, Loss: 4.6121, Train: 0.4929, Val: 0.2540, Test: 0.2610
Epoch: 6, Loss: 4.4449, Train: 0.5643, Val: 0.2760, Test: 0.2910
Epoch: 7, Loss: 4.3476, Train: 0.5929, Val: 0.3040, Test: 0.3140
Epoch: 8, Loss: 4.4912, Train: 0.6286, Val: 0.3360, Test: 0.3370
Epoch: 9, Loss: 4.3599, Train: 0.6714, Val: 0.3760, Test: 0.3680
Epoch: 10, Loss: 4.3102, Train: 0.6786, Val: 0.4120, Test: 0.3960
Epoch: 11, Loss: 4.1363, Train: 0.7143, Val: 0.4540, Test: 0.4450
Epoch: 12, Loss: 4.0762, Train: 0.7643, Val: 0.5000, Test: 0.4880
Epoch: 13, Loss: 4.0580, Train: 0.8000, Val: 0.5420, Test: 0.5230
Epoch: 14, Loss: 4.1256, Train: 0.8286, Val: 0.5580, Test: 0.5630
Epoch: 15, Loss: 3.8793, Train: 0.8500, Val: 0.5860, Test: 0.5910
Epoch: 16, Loss: 3.7900, Train: 0.8571, Val: 0.6040, Test: 0.6130
Epoch: 17, Loss: 3.5744, Train: 0.8571, Val: 0.6280, Test: 0.6290
Epoch: 18, Loss: 4.0374, Train: 0.8571, Val: 0.6440, Test: 0.6430
Epoch: 19, Loss: 3.7737, Train: 0.8571, Val: 0.6520, Test: 0.6470
Epoch: 20, Loss: 3.9157, Train: 0.8500, Val: 0.6580, Test: 0.6580
Epoch: 21, Loss: 3.8738, Train: 0.8500, Val: 0.6580, Test: 0.6650
Epoch: 22, Loss: 3.7122, Train: 0.8500, Val: 0.6560, Test: 0.6700
Epoch: 23, Loss: 3.7953, Train: 0.8500, Val: 0.6500, Test: 0.6740
Epoch: 24, Loss: 3.8016, Train: 0.8500, Val: 0.6500, Test: 0.6740
Epoch: 25, Loss: 3.9052, Train: 0.8500, Val: 0.6560, Test: 0.6800
Epoch: 26, Loss: 3.7241, Train: 0.8571, Val: 0.6580, Test: 0.6800
Epoch: 27, Loss: 3.6913, Train: 0.8571, Val: 0.6600, Test: 0.6790
Epoch: 28, Loss: 3.3792, Train: 0.8714, Val: 0.6660, Test: 0.6850
Epoch: 29, Loss: 3.5424, Train: 0.8929, Val: 0.6720, Test: 0.6850
Epoch: 30, Loss: 3.6038, Train: 0.9071, Val: 0.6760, Test: 0.6880
Epoch: 31, Loss: 4.0132, Train: 0.9071, Val: 0.6840, Test: 0.6920
Epoch: 32, Loss: 3.5306, Train: 0.9214, Val: 0.6880, Test: 0.7010
Epoch: 33, Loss: 3.9356, Train: 0.9500, Val: 0.6980, Test: 0.7060
Epoch: 34, Loss: 3.5580, Train: 0.9571, Val: 0.7020, Test: 0.7130
Epoch: 35, Loss: 3.6629, Train: 0.9571, Val: 0.6980, Test: 0.7200
Epoch: 36, Loss: 3.6270, Train: 0.9571, Val: 0.6960, Test: 0.7190
Epoch: 37, Loss: 3.6284, Train: 0.9643, Val: 0.7020, Test: 0.7290
Epoch: 38, Loss: 3.4453, Train: 0.9643, Val: 0.7040, Test: 0.7270
Epoch: 39, Loss: 3.6413, Train: 0.9714, Val: 0.7040, Test: 0.7230
Epoch: 40, Loss: 3.3240, Train: 0.9857, Val: 0.7020, Test: 0.7290
Epoch: 41, Loss: 3.5368, Train: 0.9857, Val: 0.7080, Test: 0.7290
Epoch: 42, Loss: 3.6164, Train: 0.9929, Val: 0.7060, Test: 0.7270
Epoch: 43, Loss: 3.3441, Train: 0.9929, Val: 0.7080, Test: 0.7270
Epoch: 44, Loss: 3.4259, Train: 0.9929, Val: 0.7100, Test: 0.7280
Epoch: 45, Loss: 3.1638, Train: 0.9929, Val: 0.7120, Test: 0.7270
Epoch: 46, Loss: 3.3602, Train: 0.9929, Val: 0.7140, Test: 0.7260
Epoch: 47, Loss: 3.3932, Train: 0.9929, Val: 0.7180, Test: 0.7290
Epoch: 48, Loss: 3.4409, Train: 0.9929, Val: 0.7240, Test: 0.7320
Epoch: 49, Loss: 3.4709, Train: 1.0000, Val: 0.7260, Test: 0.7330
Epoch: 50, Loss: 3.5893, Train: 1.0000, Val: 0.7260, Test: 0.7360
Epoch: 51, Loss: 3.3612, Train: 1.0000, Val: 0.7260, Test: 0.7330
Epoch: 52, Loss: 3.3391, Train: 1.0000, Val: 0.7280, Test: 0.7330
Epoch: 53, Loss: 3.4477, Train: 1.0000, Val: 0.7240, Test: 0.7380
Epoch: 54, Loss: 3.2605, Train: 1.0000, Val: 0.7200, Test: 0.7380
Epoch: 55, Loss: 3.3132, Train: 1.0000, Val: 0.7240, Test: 0.7390
Epoch: 56, Loss: 3.0429, Train: 1.0000, Val: 0.7220, Test: 0.7390
Epoch: 57, Loss: 3.1637, Train: 1.0000, Val: 0.7240, Test: 0.7360
Epoch: 58, Loss: 3.6481, Train: 1.0000, Val: 0.7220, Test: 0.7340
Epoch: 59, Loss: 3.4565, Train: 1.0000, Val: 0.7240, Test: 0.7350
Epoch: 60, Loss: 3.3301, Train: 1.0000, Val: 0.7220, Test: 0.7360
Epoch: 61, Loss: 3.2412, Train: 1.0000, Val: 0.7260, Test: 0.7360
Epoch: 62, Loss: 3.3677, Train: 1.0000, Val: 0.7280, Test: 0.7350
Epoch: 63, Loss: 3.2086, Train: 1.0000, Val: 0.7320, Test: 0.7370
Epoch: 64, Loss: 3.3917, Train: 1.0000, Val: 0.7360, Test: 0.7390
Epoch: 65, Loss: 3.2235, Train: 1.0000, Val: 0.7360, Test: 0.7360
Epoch: 66, Loss: 3.1223, Train: 1.0000, Val: 0.7380, Test: 0.7370
Epoch: 67, Loss: 3.0926, Train: 1.0000, Val: 0.7380, Test: 0.7370
Epoch: 68, Loss: 3.2890, Train: 1.0000, Val: 0.7380, Test: 0.7380
Epoch: 69, Loss: 3.1108, Train: 1.0000, Val: 0.7360, Test: 0.7400
Epoch: 70, Loss: 3.1740, Train: 1.0000, Val: 0.7360, Test: 0.7400
Epoch: 71, Loss: 3.0600, Train: 1.0000, Val: 0.7360, Test: 0.7380
Epoch: 72, Loss: 3.1890, Train: 1.0000, Val: 0.7320, Test: 0.7390
Epoch: 73, Loss: 3.3185, Train: 1.0000, Val: 0.7320, Test: 0.7390
Epoch: 74, Loss: 3.1131, Train: 1.0000, Val: 0.7320, Test: 0.7400
Epoch: 75, Loss: 3.1855, Train: 1.0000, Val: 0.7320, Test: 0.7370
Epoch: 76, Loss: 3.2619, Train: 1.0000, Val: 0.7320, Test: 0.7340
Epoch: 77, Loss: 3.2283, Train: 1.0000, Val: 0.7320, Test: 0.7320
Epoch: 78, Loss: 3.1030, Train: 1.0000, Val: 0.7320, Test: 0.7330
Epoch: 79, Loss: 2.8550, Train: 1.0000, Val: 0.7300, Test: 0.7350
Epoch: 80, Loss: 2.6992, Train: 1.0000, Val: 0.7320, Test: 0.7360
Epoch: 81, Loss: 2.8631, Train: 1.0000, Val: 0.7320, Test: 0.7340
Epoch: 82, Loss: 3.4055, Train: 1.0000, Val: 0.7300, Test: 0.7330
Epoch: 83, Loss: 3.1607, Train: 1.0000, Val: 0.7300, Test: 0.7330
Epoch: 84, Loss: 3.1444, Train: 1.0000, Val: 0.7300, Test: 0.7330
Epoch: 85, Loss: 2.9490, Train: 1.0000, Val: 0.7320, Test: 0.7320
Epoch: 86, Loss: 3.2809, Train: 1.0000, Val: 0.7320, Test: 0.7310
Epoch: 87, Loss: 3.1253, Train: 1.0000, Val: 0.7320, Test: 0.7290
Epoch: 88, Loss: 2.9558, Train: 1.0000, Val: 0.7300, Test: 0.7300
Epoch: 89, Loss: 3.3226, Train: 1.0000, Val: 0.7300, Test: 0.7310
Epoch: 90, Loss: 2.8710, Train: 1.0000, Val: 0.7320, Test: 0.7310
Epoch: 91, Loss: 3.0085, Train: 1.0000, Val: 0.7340, Test: 0.7270
Epoch: 92, Loss: 3.0978, Train: 1.0000, Val: 0.7320, Test: 0.7270
Epoch: 93, Loss: 3.0039, Train: 1.0000, Val: 0.7300, Test: 0.7290
Epoch: 94, Loss: 3.0034, Train: 1.0000, Val: 0.7280, Test: 0.7290
Epoch: 95, Loss: 2.8056, Train: 1.0000, Val: 0.7280, Test: 0.7270
Epoch: 96, Loss: 2.7324, Train: 1.0000, Val: 0.7240, Test: 0.7260
Epoch: 97, Loss: 2.7828, Train: 1.0000, Val: 0.7240, Test: 0.7250
Epoch: 98, Loss: 2.6344, Train: 1.0000, Val: 0.7240, Test: 0.7260
Epoch: 99, Loss: 3.2197, Train: 1.0000, Val: 0.7240, Test: 0.7250
Epoch: 100, Loss: 2.8503, Train: 1.0000, Val: 0.7240, Test: 0.7250
Epoch: 101, Loss: 2.8292, Train: 1.0000, Val: 0.7240, Test: 0.7280
Epoch: 102, Loss: 2.9293, Train: 1.0000, Val: 0.7240, Test: 0.7270
Epoch: 103, Loss: 2.9295, Train: 1.0000, Val: 0.7240, Test: 0.7250
Epoch: 104, Loss: 2.8661, Train: 1.0000, Val: 0.7260, Test: 0.7250
Epoch: 105, Loss: 3.0991, Train: 1.0000, Val: 0.7260, Test: 0.7250
Epoch: 106, Loss: 2.7954, Train: 1.0000, Val: 0.7260, Test: 0.7250
Epoch: 107, Loss: 2.7626, Train: 1.0000, Val: 0.7260, Test: 0.7270
Epoch: 108, Loss: 3.0832, Train: 1.0000, Val: 0.7280, Test: 0.7270
Epoch: 109, Loss: 3.1479, Train: 1.0000, Val: 0.7260, Test: 0.7310
Epoch: 110, Loss: 3.0902, Train: 1.0000, Val: 0.7260, Test: 0.7290
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 111, Loss: 2.9642, Train: 1.0000, Val: 0.7240, Test: 0.7260
Epoch: 112, Loss: 2.7352, Train: 1.0000, Val: 0.7260, Test: 0.7260
Epoch: 113, Loss: 3.0087, Train: 1.0000, Val: 0.7260, Test: 0.7250
Epoch: 114, Loss: 3.0284, Train: 1.0000, Val: 0.7260, Test: 0.7250
Epoch: 115, Loss: 2.9787, Train: 1.0000, Val: 0.7260, Test: 0.7220
Epoch: 116, Loss: 2.7859, Train: 1.0000, Val: 0.7260, Test: 0.7220
Epoch: 117, Loss: 2.5596, Train: 1.0000, Val: 0.7240, Test: 0.7220
Epoch: 118, Loss: 2.9797, Train: 1.0000, Val: 0.7240, Test: 0.7220
Epoch: 119, Loss: 2.5435, Train: 1.0000, Val: 0.7260, Test: 0.7200
Epoch: 120, Loss: 2.8649, Train: 1.0000, Val: 0.7260, Test: 0.7190
Epoch: 121, Loss: 2.9410, Train: 1.0000, Val: 0.7240, Test: 0.7180
Epoch: 122, Loss: 2.3720, Train: 1.0000, Val: 0.7240, Test: 0.7210
Epoch: 123, Loss: 2.8771, Train: 1.0000, Val: 0.7280, Test: 0.7180
Epoch: 124, Loss: 2.8635, Train: 1.0000, Val: 0.7280, Test: 0.7190
Epoch: 125, Loss: 2.7267, Train: 1.0000, Val: 0.7280, Test: 0.7190
Epoch: 126, Loss: 2.6196, Train: 1.0000, Val: 0.7280, Test: 0.7200
Epoch: 127, Loss: 2.6427, Train: 1.0000, Val: 0.7280, Test: 0.7190
Epoch: 128, Loss: 2.4195, Train: 1.0000, Val: 0.7280, Test: 0.7190
Epoch: 129, Loss: 2.8871, Train: 1.0000, Val: 0.7260, Test: 0.7160
Epoch: 130, Loss: 2.5971, Train: 1.0000, Val: 0.7240, Test: 0.7160
Epoch: 131, Loss: 2.6840, Train: 1.0000, Val: 0.7240, Test: 0.7150
Epoch: 132, Loss: 2.6016, Train: 1.0000, Val: 0.7240, Test: 0.7150
Epoch: 133, Loss: 2.5622, Train: 1.0000, Val: 0.7240, Test: 0.7160
Epoch: 134, Loss: 2.4003, Train: 1.0000, Val: 0.7220, Test: 0.7170
Epoch: 135, Loss: 2.9682, Train: 1.0000, Val: 0.7200, Test: 0.7160
Epoch: 136, Loss: 3.0034, Train: 1.0000, Val: 0.7200, Test: 0.7160
Epoch: 137, Loss: 2.7034, Train: 1.0000, Val: 0.7200, Test: 0.7130
Epoch: 138, Loss: 2.6503, Train: 1.0000, Val: 0.7200, Test: 0.7100
Epoch: 139, Loss: 2.4908, Train: 1.0000, Val: 0.7200, Test: 0.7120
Epoch: 140, Loss: 2.4980, Train: 1.0000, Val: 0.7180, Test: 0.7130
Epoch: 141, Loss: 2.9247, Train: 1.0000, Val: 0.7160, Test: 0.7110
Epoch: 142, Loss: 2.5829, Train: 1.0000, Val: 0.7160, Test: 0.7050
Epoch: 143, Loss: 2.4437, Train: 1.0000, Val: 0.7160, Test: 0.7060
Epoch: 144, Loss: 2.6382, Train: 1.0000, Val: 0.7100, Test: 0.7040
Epoch: 145, Loss: 2.4924, Train: 1.0000, Val: 0.7100, Test: 0.7030
Epoch: 146, Loss: 2.7477, Train: 1.0000, Val: 0.7100, Test: 0.7000
Epoch: 147, Loss: 2.6544, Train: 1.0000, Val: 0.7080, Test: 0.7010
Epoch: 148, Loss: 2.7002, Train: 1.0000, Val: 0.7000, Test: 0.6980
Epoch: 149, Loss: 2.5951, Train: 1.0000, Val: 0.7000, Test: 0.7000
Epoch: 150, Loss: 2.6805, Train: 1.0000, Val: 0.7020, Test: 0.6950
Epoch: 151, Loss: 2.5226, Train: 1.0000, Val: 0.7000, Test: 0.6950
Epoch: 152, Loss: 2.6092, Train: 1.0000, Val: 0.7000, Test: 0.6960
Epoch: 153, Loss: 2.6597, Train: 1.0000, Val: 0.6960, Test: 0.6990
Epoch: 154, Loss: 2.8360, Train: 1.0000, Val: 0.6980, Test: 0.6970
Epoch: 155, Loss: 2.4841, Train: 1.0000, Val: 0.6980, Test: 0.6970
Epoch: 156, Loss: 2.7249, Train: 1.0000, Val: 0.6980, Test: 0.7000
Epoch: 157, Loss: 2.4668, Train: 1.0000, Val: 0.7000, Test: 0.7000
Epoch: 158, Loss: 2.6866, Train: 1.0000, Val: 0.7000, Test: 0.7000
Epoch: 159, Loss: 2.5345, Train: 1.0000, Val: 0.7000, Test: 0.7030
Epoch: 160, Loss: 2.7879, Train: 1.0000, Val: 0.6980, Test: 0.7050
Epoch: 161, Loss: 2.6949, Train: 1.0000, Val: 0.6960, Test: 0.7030
Epoch: 162, Loss: 2.7502, Train: 1.0000, Val: 0.6980, Test: 0.7020
Epoch: 163, Loss: 2.6873, Train: 1.0000, Val: 0.6980, Test: 0.6980
Epoch: 164, Loss: 2.6208, Train: 1.0000, Val: 0.6920, Test: 0.6970
Epoch: 165, Loss: 2.6361, Train: 1.0000, Val: 0.6920, Test: 0.6960
Epoch: 166, Loss: 2.4277, Train: 1.0000, Val: 0.6940, Test: 0.6970
Epoch: 167, Loss: 2.7524, Train: 1.0000, Val: 0.6920, Test: 0.6970
Epoch: 168, Loss: 2.7632, Train: 1.0000, Val: 0.6940, Test: 0.6980
Epoch: 169, Loss: 2.6817, Train: 1.0000, Val: 0.6940, Test: 0.6960
Epoch: 170, Loss: 2.6514, Train: 1.0000, Val: 0.6980, Test: 0.6990
Epoch: 171, Loss: 2.5137, Train: 1.0000, Val: 0.7000, Test: 0.6990
Epoch: 172, Loss: 2.6868, Train: 1.0000, Val: 0.7020, Test: 0.6990
Epoch: 173, Loss: 2.7388, Train: 1.0000, Val: 0.7020, Test: 0.7010
Epoch: 174, Loss: 2.7985, Train: 1.0000, Val: 0.7020, Test: 0.7010
Epoch: 175, Loss: 2.4968, Train: 1.0000, Val: 0.7020, Test: 0.6980
Epoch: 176, Loss: 2.3514, Train: 1.0000, Val: 0.7000, Test: 0.6950
Epoch: 177, Loss: 2.4283, Train: 1.0000, Val: 0.7000, Test: 0.6920
Epoch: 178, Loss: 2.6515, Train: 1.0000, Val: 0.6960, Test: 0.6930
Epoch: 179, Loss: 2.6715, Train: 1.0000, Val: 0.6940, Test: 0.6910
Epoch: 180, Loss: 2.5001, Train: 1.0000, Val: 0.6920, Test: 0.6890
Epoch: 181, Loss: 2.4626, Train: 1.0000, Val: 0.6920, Test: 0.6880
Epoch: 182, Loss: 2.5678, Train: 1.0000, Val: 0.6920, Test: 0.6890
Epoch: 183, Loss: 2.4301, Train: 1.0000, Val: 0.6920, Test: 0.6900
Epoch: 184, Loss: 2.7623, Train: 1.0000, Val: 0.6920, Test: 0.6910
Epoch: 185, Loss: 2.3794, Train: 1.0000, Val: 0.6960, Test: 0.6920
Epoch: 186, Loss: 2.4021, Train: 1.0000, Val: 0.7000, Test: 0.6940
Epoch: 187, Loss: 2.4786, Train: 1.0000, Val: 0.6980, Test: 0.6960
Epoch: 188, Loss: 2.3904, Train: 1.0000, Val: 0.6980, Test: 0.6980
Epoch: 189, Loss: 2.3447, Train: 1.0000, Val: 0.6980, Test: 0.6980
Epoch: 190, Loss: 2.5150, Train: 1.0000, Val: 0.6980, Test: 0.6970
Epoch: 191, Loss: 2.4452, Train: 1.0000, Val: 0.6980, Test: 0.6950
Epoch: 192, Loss: 2.6530, Train: 1.0000, Val: 0.7000, Test: 0.6920
Epoch: 193, Loss: 2.4668, Train: 1.0000, Val: 0.6940, Test: 0.6930
Epoch: 194, Loss: 2.7111, Train: 1.0000, Val: 0.6880, Test: 0.6910
Epoch: 195, Loss: 2.3294, Train: 1.0000, Val: 0.6860, Test: 0.6890
Epoch: 196, Loss: 2.5745, Train: 1.0000, Val: 0.6880, Test: 0.6860
Epoch: 197, Loss: 2.5329, Train: 1.0000, Val: 0.6900, Test: 0.6840
Epoch: 198, Loss: 2.2823, Train: 1.0000, Val: 0.6900, Test: 0.6840
Epoch: 199, Loss: 2.4675, Train: 1.0000, Val: 0.6880, Test: 0.6860
Epoch: 200, Loss: 2.3008, Train: 1.0000, Val: 0.6900, Test: 0.6880
MAD:  0.2815
Best Test Accuracy: 0.7400, Val Accuracy: 0.7360, Train Accuracy: 1.0000
Training completed.
Average Test Accuracy:  0.755 ± 0.020698899595013382
Average MAD:  0.3349777777777778 ± 0.05150007071791861
