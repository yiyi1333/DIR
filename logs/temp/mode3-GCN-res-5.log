Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8530, Train: 0.2000, Val: 0.1380, Test: 0.1520
Epoch: 2, Loss: 4.8247, Train: 0.2143, Val: 0.1660, Test: 0.1740
Epoch: 3, Loss: 4.8105, Train: 0.2000, Val: 0.1580, Test: 0.1690
Epoch: 4, Loss: 4.7961, Train: 0.2071, Val: 0.1600, Test: 0.1650
Epoch: 5, Loss: 4.7447, Train: 0.2071, Val: 0.1700, Test: 0.1720
Epoch: 6, Loss: 4.7238, Train: 0.2429, Val: 0.1920, Test: 0.1910
Epoch: 7, Loss: 4.6602, Train: 0.2500, Val: 0.1920, Test: 0.1950
Epoch: 8, Loss: 4.6256, Train: 0.2429, Val: 0.1900, Test: 0.1900
Epoch: 9, Loss: 4.5643, Train: 0.2429, Val: 0.1860, Test: 0.1900
Epoch: 10, Loss: 4.4733, Train: 0.2429, Val: 0.1860, Test: 0.1930
Epoch: 11, Loss: 4.3886, Train: 0.2429, Val: 0.1860, Test: 0.1920
Epoch: 12, Loss: 4.3573, Train: 0.2429, Val: 0.1820, Test: 0.1800
Epoch: 13, Loss: 4.1987, Train: 0.2357, Val: 0.1820, Test: 0.1790
Epoch: 14, Loss: 4.1234, Train: 0.2429, Val: 0.1820, Test: 0.1830
Epoch: 15, Loss: 4.1868, Train: 0.2500, Val: 0.1860, Test: 0.1950
Epoch: 16, Loss: 3.9157, Train: 0.3000, Val: 0.2120, Test: 0.2110
Epoch: 17, Loss: 3.7407, Train: 0.3500, Val: 0.2480, Test: 0.2600
Epoch: 18, Loss: 3.7261, Train: 0.4429, Val: 0.3980, Test: 0.4320
Epoch: 19, Loss: 3.7112, Train: 0.6071, Val: 0.5160, Test: 0.5450
Epoch: 20, Loss: 3.7583, Train: 0.7357, Val: 0.6460, Test: 0.6760
Epoch: 21, Loss: 3.7565, Train: 0.7857, Val: 0.6900, Test: 0.7040
Epoch: 22, Loss: 3.7600, Train: 0.7714, Val: 0.6080, Test: 0.6340
Epoch: 23, Loss: 3.5193, Train: 0.7143, Val: 0.5320, Test: 0.5140
Epoch: 24, Loss: 3.6109, Train: 0.7214, Val: 0.5180, Test: 0.5020
Epoch: 25, Loss: 3.6976, Train: 0.7857, Val: 0.5780, Test: 0.5520
Epoch: 26, Loss: 3.5833, Train: 0.8500, Val: 0.6340, Test: 0.6180
Epoch: 27, Loss: 3.4123, Train: 0.8786, Val: 0.6920, Test: 0.6940
Epoch: 28, Loss: 3.6941, Train: 0.8786, Val: 0.7160, Test: 0.7340
Epoch: 29, Loss: 3.4956, Train: 0.9000, Val: 0.6980, Test: 0.7410
Epoch: 30, Loss: 3.1734, Train: 0.8929, Val: 0.6820, Test: 0.7160
Epoch: 31, Loss: 3.3454, Train: 0.8857, Val: 0.6920, Test: 0.7190
Epoch: 32, Loss: 3.4596, Train: 0.9000, Val: 0.6920, Test: 0.7220
Epoch: 33, Loss: 3.4116, Train: 0.8929, Val: 0.6980, Test: 0.7330
Epoch: 34, Loss: 3.3998, Train: 0.8929, Val: 0.7040, Test: 0.7400
Epoch: 35, Loss: 3.2916, Train: 0.9071, Val: 0.7100, Test: 0.7510
Epoch: 36, Loss: 3.5795, Train: 0.9143, Val: 0.7200, Test: 0.7580
Epoch: 37, Loss: 3.2027, Train: 0.9143, Val: 0.7360, Test: 0.7670
Epoch: 38, Loss: 3.1896, Train: 0.9286, Val: 0.7460, Test: 0.7740
Epoch: 39, Loss: 3.2638, Train: 0.9357, Val: 0.7560, Test: 0.7840
Epoch: 40, Loss: 3.4608, Train: 0.9286, Val: 0.7620, Test: 0.7940
Epoch: 41, Loss: 2.7649, Train: 0.9357, Val: 0.7760, Test: 0.8010
Epoch: 42, Loss: 2.9425, Train: 0.9643, Val: 0.7820, Test: 0.8180
Epoch: 43, Loss: 2.7431, Train: 0.9643, Val: 0.7740, Test: 0.8140
Epoch: 44, Loss: 3.1196, Train: 0.9571, Val: 0.7760, Test: 0.8110
Epoch: 45, Loss: 2.9111, Train: 0.9429, Val: 0.7800, Test: 0.8060
Epoch: 46, Loss: 3.1577, Train: 0.9429, Val: 0.7820, Test: 0.8040
Epoch: 47, Loss: 2.8454, Train: 0.9500, Val: 0.7780, Test: 0.8000
Epoch: 48, Loss: 2.9822, Train: 0.9571, Val: 0.7800, Test: 0.7960
Epoch: 49, Loss: 2.8644, Train: 0.9643, Val: 0.7860, Test: 0.7990
Epoch: 50, Loss: 2.9791, Train: 0.9714, Val: 0.7900, Test: 0.8050
Epoch: 51, Loss: 2.7547, Train: 0.9714, Val: 0.7860, Test: 0.8060
Epoch: 52, Loss: 2.9315, Train: 0.9714, Val: 0.7840, Test: 0.8100
Epoch: 53, Loss: 2.5514, Train: 0.9714, Val: 0.7920, Test: 0.8120
Epoch: 54, Loss: 2.8571, Train: 0.9714, Val: 0.7960, Test: 0.8110
Epoch: 55, Loss: 2.8120, Train: 0.9714, Val: 0.7980, Test: 0.8100
Epoch: 56, Loss: 2.8502, Train: 0.9786, Val: 0.7960, Test: 0.8060
Epoch: 57, Loss: 2.8185, Train: 0.9786, Val: 0.7860, Test: 0.8030
Epoch: 58, Loss: 2.8265, Train: 0.9929, Val: 0.7840, Test: 0.8000
Epoch: 59, Loss: 2.9573, Train: 0.9929, Val: 0.7740, Test: 0.7960
Epoch: 60, Loss: 2.7778, Train: 0.9929, Val: 0.7780, Test: 0.7910
Epoch: 61, Loss: 2.9660, Train: 0.9929, Val: 0.7740, Test: 0.7870
Epoch: 62, Loss: 2.5944, Train: 0.9929, Val: 0.7700, Test: 0.7910
Epoch: 63, Loss: 2.4845, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 64, Loss: 2.7351, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 65, Loss: 2.6930, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 66, Loss: 2.3765, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 67, Loss: 2.9199, Train: 0.9929, Val: 0.7880, Test: 0.8100
Epoch: 68, Loss: 2.8620, Train: 0.9929, Val: 0.7880, Test: 0.8110
Epoch: 69, Loss: 2.8462, Train: 0.9929, Val: 0.7900, Test: 0.8110
Epoch: 70, Loss: 2.7417, Train: 0.9929, Val: 0.7880, Test: 0.8050
Epoch: 71, Loss: 2.7490, Train: 0.9929, Val: 0.7820, Test: 0.8010
Epoch: 72, Loss: 2.7701, Train: 0.9929, Val: 0.7840, Test: 0.7940
Epoch: 73, Loss: 2.4351, Train: 0.9929, Val: 0.7820, Test: 0.7940
Epoch: 74, Loss: 2.7281, Train: 0.9929, Val: 0.7740, Test: 0.7930
Epoch: 75, Loss: 2.3824, Train: 0.9929, Val: 0.7700, Test: 0.7940
Epoch: 76, Loss: 2.4881, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 77, Loss: 2.5566, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 78, Loss: 2.4624, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 79, Loss: 2.4133, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 80, Loss: 2.4770, Train: 0.9929, Val: 0.7660, Test: 0.7890
Epoch: 81, Loss: 2.4757, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 82, Loss: 2.7106, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 83, Loss: 2.4984, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 84, Loss: 2.4984, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 85, Loss: 2.4969, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 86, Loss: 2.4959, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 87, Loss: 2.6201, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 88, Loss: 2.4553, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 89, Loss: 2.3734, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 90, Loss: 2.5622, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 91, Loss: 2.4842, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 92, Loss: 2.3505, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 93, Loss: 2.4382, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 94, Loss: 2.3670, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 95, Loss: 2.4880, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 96, Loss: 2.5587, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 97, Loss: 2.7130, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 98, Loss: 2.6769, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 99, Loss: 2.6948, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 100, Loss: 2.5001, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 101, Loss: 2.2715, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 102, Loss: 2.3745, Train: 1.0000, Val: 0.7580, Test: 0.7910
Epoch: 103, Loss: 2.5255, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 104, Loss: 2.1448, Train: 1.0000, Val: 0.7600, Test: 0.7900
Epoch: 105, Loss: 2.6293, Train: 1.0000, Val: 0.7600, Test: 0.7860
Epoch: 106, Loss: 2.3074, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 107, Loss: 2.5481, Train: 1.0000, Val: 0.7600, Test: 0.7870
Epoch: 108, Loss: 2.2130, Train: 1.0000, Val: 0.7600, Test: 0.7860
Epoch: 109, Loss: 2.3241, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 110, Loss: 2.4201, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 111, Loss: 2.5213, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 112, Loss: 2.7307, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 113, Loss: 2.3320, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 114, Loss: 2.3042, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 115, Loss: 2.4363, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 116, Loss: 2.5588, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 117, Loss: 2.4069, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 118, Loss: 2.3613, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 119, Loss: 2.6014, Train: 1.0000, Val: 0.7660, Test: 0.8010
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 2.3230, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 121, Loss: 2.4415, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 122, Loss: 2.2644, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 123, Loss: 2.4542, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 124, Loss: 2.1709, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 125, Loss: 2.6239, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 126, Loss: 2.5350, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 127, Loss: 2.6299, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 128, Loss: 2.6975, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 129, Loss: 2.4900, Train: 1.0000, Val: 0.7600, Test: 0.8040
Epoch: 130, Loss: 2.5092, Train: 1.0000, Val: 0.7560, Test: 0.8020
Epoch: 131, Loss: 2.5063, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 132, Loss: 2.1863, Train: 1.0000, Val: 0.7580, Test: 0.7970
Epoch: 133, Loss: 2.6567, Train: 1.0000, Val: 0.7560, Test: 0.7960
Epoch: 134, Loss: 2.1540, Train: 1.0000, Val: 0.7560, Test: 0.7950
Epoch: 135, Loss: 2.5129, Train: 1.0000, Val: 0.7580, Test: 0.7940
Epoch: 136, Loss: 2.6779, Train: 1.0000, Val: 0.7580, Test: 0.7950
Epoch: 137, Loss: 2.4026, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 138, Loss: 2.1569, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 139, Loss: 2.2078, Train: 1.0000, Val: 0.7580, Test: 0.8000
Epoch: 140, Loss: 2.6295, Train: 1.0000, Val: 0.7580, Test: 0.8000
Epoch: 141, Loss: 2.5912, Train: 1.0000, Val: 0.7580, Test: 0.8000
Epoch: 142, Loss: 2.3584, Train: 1.0000, Val: 0.7600, Test: 0.7980
Epoch: 143, Loss: 2.5796, Train: 1.0000, Val: 0.7580, Test: 0.7980
Epoch: 144, Loss: 2.5970, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 145, Loss: 2.2881, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 146, Loss: 2.4750, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 147, Loss: 2.6974, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 148, Loss: 2.5636, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 149, Loss: 2.0081, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 150, Loss: 2.5578, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 151, Loss: 2.5653, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 152, Loss: 2.5938, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 153, Loss: 2.4214, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 154, Loss: 2.5179, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 155, Loss: 2.3413, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 156, Loss: 2.4623, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 157, Loss: 2.1104, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 158, Loss: 1.9351, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 159, Loss: 2.3000, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 160, Loss: 2.6673, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 161, Loss: 2.6873, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 162, Loss: 2.4289, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 163, Loss: 2.5045, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 164, Loss: 2.6374, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 165, Loss: 2.6923, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 166, Loss: 2.8143, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 167, Loss: 2.2664, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 168, Loss: 2.5603, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 169, Loss: 2.5607, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 170, Loss: 2.6948, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 171, Loss: 2.1494, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 172, Loss: 2.2603, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 173, Loss: 2.7114, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 174, Loss: 2.2174, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 175, Loss: 2.7609, Train: 1.0000, Val: 0.7620, Test: 0.8000
Epoch: 176, Loss: 2.2598, Train: 1.0000, Val: 0.7620, Test: 0.8000
Epoch: 177, Loss: 2.6591, Train: 1.0000, Val: 0.7620, Test: 0.7990
Epoch: 178, Loss: 2.5151, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 179, Loss: 2.5131, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 180, Loss: 2.5217, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 181, Loss: 2.2499, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 182, Loss: 2.4375, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 183, Loss: 2.6626, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 184, Loss: 2.4494, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 185, Loss: 2.5884, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 186, Loss: 1.9275, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 187, Loss: 2.1755, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 188, Loss: 2.9199, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 189, Loss: 2.3603, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 190, Loss: 2.1813, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 191, Loss: 2.8740, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 192, Loss: 2.7281, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 193, Loss: 2.6581, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 194, Loss: 2.6119, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 195, Loss: 2.3929, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 196, Loss: 2.3649, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 197, Loss: 2.2208, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 198, Loss: 2.5438, Train: 1.0000, Val: 0.7600, Test: 0.7980
Epoch: 199, Loss: 2.6170, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 200, Loss: 2.4258, Train: 1.0000, Val: 0.7600, Test: 0.7970
MAD:  0.1164
Best Test Accuracy: 0.8180, Val Accuracy: 0.7820, Train Accuracy: 0.9643
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8540, Train: 0.0357, Val: 0.0360, Test: 0.0320
Epoch: 2, Loss: 4.8397, Train: 0.3357, Val: 0.2360, Test: 0.2470
Epoch: 3, Loss: 4.8282, Train: 0.3500, Val: 0.2640, Test: 0.2590
Epoch: 4, Loss: 4.8050, Train: 0.3857, Val: 0.2720, Test: 0.2790
Epoch: 5, Loss: 4.7719, Train: 0.4071, Val: 0.2820, Test: 0.2840
Epoch: 6, Loss: 4.7264, Train: 0.4071, Val: 0.2780, Test: 0.2780
Epoch: 7, Loss: 4.6924, Train: 0.3929, Val: 0.2760, Test: 0.2680
Epoch: 8, Loss: 4.6248, Train: 0.3714, Val: 0.2640, Test: 0.2620
Epoch: 9, Loss: 4.5631, Train: 0.3429, Val: 0.2560, Test: 0.2480
Epoch: 10, Loss: 4.4816, Train: 0.3286, Val: 0.2460, Test: 0.2400
Epoch: 11, Loss: 4.3487, Train: 0.3071, Val: 0.2360, Test: 0.2350
Epoch: 12, Loss: 4.3865, Train: 0.3000, Val: 0.2300, Test: 0.2300
Epoch: 13, Loss: 4.1643, Train: 0.3000, Val: 0.2300, Test: 0.2280
Epoch: 14, Loss: 4.0386, Train: 0.3000, Val: 0.2240, Test: 0.2210
Epoch: 15, Loss: 4.0284, Train: 0.2929, Val: 0.2240, Test: 0.2190
Epoch: 16, Loss: 3.8031, Train: 0.3071, Val: 0.2280, Test: 0.2250
Epoch: 17, Loss: 4.0093, Train: 0.3071, Val: 0.2320, Test: 0.2330
Epoch: 18, Loss: 3.8093, Train: 0.3857, Val: 0.2700, Test: 0.2750
Epoch: 19, Loss: 3.9435, Train: 0.4571, Val: 0.3160, Test: 0.3220
Epoch: 20, Loss: 3.6660, Train: 0.5214, Val: 0.3580, Test: 0.3520
Epoch: 21, Loss: 3.6086, Train: 0.7357, Val: 0.4420, Test: 0.4610
Epoch: 22, Loss: 4.0890, Train: 0.9071, Val: 0.6860, Test: 0.7040
Epoch: 23, Loss: 3.6055, Train: 0.8571, Val: 0.6840, Test: 0.6960
Epoch: 24, Loss: 3.6776, Train: 0.7643, Val: 0.5980, Test: 0.6010
Epoch: 25, Loss: 3.7442, Train: 0.7500, Val: 0.5440, Test: 0.5580
Epoch: 26, Loss: 4.0024, Train: 0.7143, Val: 0.5120, Test: 0.5290
Epoch: 27, Loss: 3.5494, Train: 0.7286, Val: 0.5180, Test: 0.5270
Epoch: 28, Loss: 3.5340, Train: 0.7357, Val: 0.5260, Test: 0.5390
Epoch: 29, Loss: 3.8396, Train: 0.7786, Val: 0.5700, Test: 0.5800
Epoch: 30, Loss: 3.4445, Train: 0.8643, Val: 0.6300, Test: 0.6430
Epoch: 31, Loss: 3.3592, Train: 0.9000, Val: 0.6780, Test: 0.7030
Epoch: 32, Loss: 3.5585, Train: 0.9357, Val: 0.7140, Test: 0.7260
Epoch: 33, Loss: 3.3188, Train: 0.9214, Val: 0.7340, Test: 0.7410
Epoch: 34, Loss: 3.2253, Train: 0.9286, Val: 0.7500, Test: 0.7480
Epoch: 35, Loss: 3.4144, Train: 0.9286, Val: 0.7500, Test: 0.7560
Epoch: 36, Loss: 3.0904, Train: 0.9071, Val: 0.7580, Test: 0.7490
Epoch: 37, Loss: 3.3097, Train: 0.9214, Val: 0.7540, Test: 0.7470
Epoch: 38, Loss: 3.2045, Train: 0.9429, Val: 0.7560, Test: 0.7490
Epoch: 39, Loss: 3.1491, Train: 0.9429, Val: 0.7540, Test: 0.7510
Epoch: 40, Loss: 2.9269, Train: 0.9429, Val: 0.7560, Test: 0.7550
Epoch: 41, Loss: 3.0786, Train: 0.9500, Val: 0.7680, Test: 0.7580
Epoch: 42, Loss: 3.2098, Train: 0.9571, Val: 0.7800, Test: 0.7710
Epoch: 43, Loss: 3.1119, Train: 0.9571, Val: 0.7820, Test: 0.7790
Epoch: 44, Loss: 3.2879, Train: 0.9571, Val: 0.7840, Test: 0.7860
Epoch: 45, Loss: 3.0662, Train: 0.9571, Val: 0.7920, Test: 0.7880
Epoch: 46, Loss: 3.3482, Train: 0.9500, Val: 0.7860, Test: 0.7870
Epoch: 47, Loss: 2.8336, Train: 0.9643, Val: 0.7840, Test: 0.7910
Epoch: 48, Loss: 3.0896, Train: 0.9643, Val: 0.7860, Test: 0.7930
Epoch: 49, Loss: 2.8998, Train: 0.9643, Val: 0.7880, Test: 0.7840
Epoch: 50, Loss: 2.9953, Train: 0.9643, Val: 0.7820, Test: 0.7860
Epoch: 51, Loss: 2.7603, Train: 0.9643, Val: 0.7840, Test: 0.7880
Epoch: 52, Loss: 3.0123, Train: 0.9643, Val: 0.7840, Test: 0.7930
Epoch: 53, Loss: 3.0992, Train: 0.9714, Val: 0.7880, Test: 0.7950
Epoch: 54, Loss: 3.2803, Train: 0.9714, Val: 0.7880, Test: 0.8000
Epoch: 55, Loss: 3.0591, Train: 0.9714, Val: 0.7900, Test: 0.8030
Epoch: 56, Loss: 3.0197, Train: 0.9714, Val: 0.7920, Test: 0.8010
Epoch: 57, Loss: 3.0422, Train: 0.9786, Val: 0.7900, Test: 0.8050
Epoch: 58, Loss: 2.8938, Train: 0.9786, Val: 0.7880, Test: 0.8030
Epoch: 59, Loss: 2.6702, Train: 0.9714, Val: 0.7840, Test: 0.8040
Epoch: 60, Loss: 2.7649, Train: 0.9714, Val: 0.7840, Test: 0.8020
Epoch: 61, Loss: 2.6733, Train: 0.9714, Val: 0.7860, Test: 0.8030
Epoch: 62, Loss: 2.7250, Train: 0.9786, Val: 0.7840, Test: 0.8030
Epoch: 63, Loss: 2.3870, Train: 0.9786, Val: 0.7840, Test: 0.8010
Epoch: 64, Loss: 2.5738, Train: 0.9786, Val: 0.7840, Test: 0.8040
Epoch: 65, Loss: 2.2148, Train: 0.9857, Val: 0.7840, Test: 0.8070
Epoch: 66, Loss: 2.4541, Train: 0.9857, Val: 0.7880, Test: 0.8050
Epoch: 67, Loss: 2.6082, Train: 0.9857, Val: 0.7840, Test: 0.8070
Epoch: 68, Loss: 2.6549, Train: 0.9929, Val: 0.7800, Test: 0.8110
Epoch: 69, Loss: 2.9412, Train: 0.9929, Val: 0.7800, Test: 0.8090
Epoch: 70, Loss: 2.9132, Train: 0.9929, Val: 0.7820, Test: 0.8080
Epoch: 71, Loss: 2.6919, Train: 0.9929, Val: 0.7860, Test: 0.8050
Epoch: 72, Loss: 2.4719, Train: 0.9929, Val: 0.7820, Test: 0.8050
Epoch: 73, Loss: 2.8126, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 74, Loss: 2.8884, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 75, Loss: 2.7870, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 76, Loss: 2.9203, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 77, Loss: 2.5648, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 78, Loss: 2.7805, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 79, Loss: 2.4805, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 80, Loss: 3.0101, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 81, Loss: 2.5524, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 82, Loss: 2.5969, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 83, Loss: 2.6228, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 84, Loss: 2.5463, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 85, Loss: 2.7097, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 86, Loss: 2.4041, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 87, Loss: 2.3447, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 88, Loss: 2.5735, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 89, Loss: 2.9311, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 90, Loss: 2.6422, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 91, Loss: 2.3153, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 92, Loss: 2.6637, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 93, Loss: 2.3420, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 94, Loss: 2.5120, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 95, Loss: 2.5699, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 96, Loss: 2.3158, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 97, Loss: 2.6344, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 98, Loss: 2.4961, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 99, Loss: 2.9173, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 100, Loss: 2.5021, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 101, Loss: 2.4962, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 102, Loss: 2.3061, Train: 0.9929, Val: 0.7680, Test: 0.7900
Epoch: 103, Loss: 2.5356, Train: 0.9929, Val: 0.7640, Test: 0.7860
Epoch: 104, Loss: 2.5998, Train: 0.9929, Val: 0.7640, Test: 0.7830
Epoch: 105, Loss: 2.2097, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 106, Loss: 2.7176, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 107, Loss: 2.4705, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 108, Loss: 2.4342, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 109, Loss: 2.9178, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 110, Loss: 2.4948, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 111, Loss: 2.5361, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 112, Loss: 2.3529, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 113, Loss: 2.7095, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 114, Loss: 2.4060, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 115, Loss: 2.3492, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 116, Loss: 2.4821, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 117, Loss: 2.4599, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 118, Loss: 2.7571, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 119, Loss: 2.3672, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 120, Loss: 2.2991, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 121, Loss: 2.6255, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 122, Loss: 2.4850, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 123, Loss: 1.9596, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 124, Loss: 2.4836, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 125, Loss: 2.2385, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 126, Loss: 2.3454, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 127, Loss: 2.1413, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 128, Loss: 2.6837, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 129, Loss: 2.2550, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 130, Loss: 2.5622, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 131, Loss: 2.3802, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 132, Loss: 2.6231, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 133, Loss: 2.9028, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 134, Loss: 2.4868, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 135, Loss: 2.4800, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 136, Loss: 2.5789, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 137, Loss: 2.4645, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 138, Loss: 1.9452, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 139, Loss: 2.4930, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 140, Loss: 2.3229, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 141, Loss: 1.9992, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 142, Loss: 2.2985, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 143, Loss: 2.4931, Train: 1.0000, Val: 0.7520, Test: 0.7820
Epoch: 144, Loss: 2.4635, Train: 1.0000, Val: 0.7520, Test: 0.7820
Epoch: 145, Loss: 2.4216, Train: 1.0000, Val: 0.7540, Test: 0.7830
Epoch: 146, Loss: 2.7430, Train: 1.0000, Val: 0.7500, Test: 0.7830
Epoch: 147, Loss: 2.7390, Train: 1.0000, Val: 0.7500, Test: 0.7850
Epoch: 148, Loss: 3.1172, Train: 1.0000, Val: 0.7540, Test: 0.7900
Epoch: 149, Loss: 2.2814, Train: 1.0000, Val: 0.7560, Test: 0.7910
Epoch: 150, Loss: 2.6216, Train: 1.0000, Val: 0.7560, Test: 0.7920
Epoch: 151, Loss: 2.4350, Train: 1.0000, Val: 0.7600, Test: 0.7940
Epoch: 152, Loss: 2.7425, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 153, Loss: 2.3633, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 154, Loss: 2.5963, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 155, Loss: 3.0882, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 156, Loss: 2.5627, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 157, Loss: 2.4937, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 158, Loss: 2.7529, Train: 1.0000, Val: 0.7740, Test: 0.7990
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 159, Loss: 2.6916, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 160, Loss: 2.5731, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 161, Loss: 2.4694, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 162, Loss: 2.3871, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 163, Loss: 2.5281, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 164, Loss: 2.5388, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 165, Loss: 2.8721, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 166, Loss: 2.4481, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 167, Loss: 2.9707, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 168, Loss: 2.5744, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 169, Loss: 2.5441, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 170, Loss: 2.3262, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 171, Loss: 2.4965, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 172, Loss: 2.0992, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 173, Loss: 2.4497, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 174, Loss: 2.3440, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 175, Loss: 2.2588, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 176, Loss: 2.6154, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 177, Loss: 2.5266, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 178, Loss: 2.3144, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 179, Loss: 2.5003, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 180, Loss: 2.4883, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 181, Loss: 2.5205, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 182, Loss: 2.3107, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 183, Loss: 2.3468, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 184, Loss: 2.7005, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 185, Loss: 2.4642, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 186, Loss: 2.4027, Train: 1.0000, Val: 0.7600, Test: 0.7940
Epoch: 187, Loss: 2.3628, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 188, Loss: 2.8728, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 189, Loss: 2.6563, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 190, Loss: 2.0803, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 191, Loss: 2.3424, Train: 1.0000, Val: 0.7600, Test: 0.7960
Epoch: 192, Loss: 2.6565, Train: 1.0000, Val: 0.7600, Test: 0.7960
Epoch: 193, Loss: 2.7723, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 194, Loss: 2.4642, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 195, Loss: 2.1488, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 196, Loss: 2.4013, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 197, Loss: 2.5161, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 198, Loss: 2.5492, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 199, Loss: 2.6974, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 200, Loss: 2.2780, Train: 1.0000, Val: 0.7760, Test: 0.7980
MAD:  0.4722
Best Test Accuracy: 0.8110, Val Accuracy: 0.7800, Train Accuracy: 0.9929
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8558, Train: 0.1929, Val: 0.1580, Test: 0.1500
Epoch: 2, Loss: 4.8401, Train: 0.2714, Val: 0.1800, Test: 0.1890
Epoch: 3, Loss: 4.8186, Train: 0.3071, Val: 0.2080, Test: 0.2180
Epoch: 4, Loss: 4.7957, Train: 0.3286, Val: 0.2220, Test: 0.2390
Epoch: 5, Loss: 4.7909, Train: 0.3500, Val: 0.2760, Test: 0.2810
Epoch: 6, Loss: 4.7635, Train: 0.3571, Val: 0.3380, Test: 0.3170
Epoch: 7, Loss: 4.6566, Train: 0.3714, Val: 0.3520, Test: 0.3330
Epoch: 8, Loss: 4.6322, Train: 0.3929, Val: 0.3600, Test: 0.3430
Epoch: 9, Loss: 4.6361, Train: 0.3929, Val: 0.3760, Test: 0.3570
Epoch: 10, Loss: 4.5175, Train: 0.4000, Val: 0.3880, Test: 0.3730
Epoch: 11, Loss: 4.4272, Train: 0.4071, Val: 0.4020, Test: 0.3910
Epoch: 12, Loss: 4.4007, Train: 0.4143, Val: 0.4180, Test: 0.4130
Epoch: 13, Loss: 4.2504, Train: 0.4214, Val: 0.4260, Test: 0.4370
Epoch: 14, Loss: 4.1265, Train: 0.4214, Val: 0.4220, Test: 0.4340
Epoch: 15, Loss: 4.1486, Train: 0.4143, Val: 0.4260, Test: 0.4350
Epoch: 16, Loss: 3.9595, Train: 0.4071, Val: 0.4140, Test: 0.4310
Epoch: 17, Loss: 4.0750, Train: 0.4143, Val: 0.4020, Test: 0.4160
Epoch: 18, Loss: 3.8538, Train: 0.4357, Val: 0.4160, Test: 0.4290
Epoch: 19, Loss: 3.6278, Train: 0.5786, Val: 0.4840, Test: 0.5000
Epoch: 20, Loss: 3.8105, Train: 0.6571, Val: 0.5160, Test: 0.5460
Epoch: 21, Loss: 3.6038, Train: 0.7500, Val: 0.5720, Test: 0.6060
Epoch: 22, Loss: 3.7691, Train: 0.7143, Val: 0.5340, Test: 0.5720
Epoch: 23, Loss: 3.8896, Train: 0.7143, Val: 0.4760, Test: 0.5090
Epoch: 24, Loss: 3.5620, Train: 0.7643, Val: 0.4800, Test: 0.5160
Epoch: 25, Loss: 3.3975, Train: 0.7929, Val: 0.5380, Test: 0.5580
Epoch: 26, Loss: 3.8420, Train: 0.8357, Val: 0.5820, Test: 0.6060
Epoch: 27, Loss: 3.6524, Train: 0.8429, Val: 0.6300, Test: 0.6470
Epoch: 28, Loss: 3.5936, Train: 0.8786, Val: 0.6860, Test: 0.6730
Epoch: 29, Loss: 3.4820, Train: 0.8857, Val: 0.7040, Test: 0.6960
Epoch: 30, Loss: 3.5277, Train: 0.8786, Val: 0.7080, Test: 0.7070
Epoch: 31, Loss: 3.5766, Train: 0.8857, Val: 0.7320, Test: 0.7200
Epoch: 32, Loss: 3.2308, Train: 0.8929, Val: 0.7480, Test: 0.7410
Epoch: 33, Loss: 3.2972, Train: 0.9071, Val: 0.7500, Test: 0.7490
Epoch: 34, Loss: 3.5975, Train: 0.9286, Val: 0.7580, Test: 0.7660
Epoch: 35, Loss: 3.5645, Train: 0.9214, Val: 0.7700, Test: 0.7820
Epoch: 36, Loss: 3.4163, Train: 0.9357, Val: 0.7820, Test: 0.8030
Epoch: 37, Loss: 3.1656, Train: 0.9357, Val: 0.7960, Test: 0.8050
Epoch: 38, Loss: 3.1593, Train: 0.9357, Val: 0.7940, Test: 0.8010
Epoch: 39, Loss: 3.2104, Train: 0.9571, Val: 0.7920, Test: 0.8070
Epoch: 40, Loss: 3.1012, Train: 0.9643, Val: 0.7940, Test: 0.8030
Epoch: 41, Loss: 3.1688, Train: 0.9571, Val: 0.8000, Test: 0.8030
Epoch: 42, Loss: 3.2053, Train: 0.9643, Val: 0.7940, Test: 0.8030
Epoch: 43, Loss: 3.2433, Train: 0.9643, Val: 0.7940, Test: 0.8010
Epoch: 44, Loss: 2.7411, Train: 0.9714, Val: 0.7880, Test: 0.8040
Epoch: 45, Loss: 3.1641, Train: 0.9714, Val: 0.7820, Test: 0.8000
Epoch: 46, Loss: 2.9155, Train: 0.9643, Val: 0.7780, Test: 0.7940
Epoch: 47, Loss: 3.3870, Train: 0.9643, Val: 0.7800, Test: 0.7870
Epoch: 48, Loss: 2.9212, Train: 0.9643, Val: 0.7820, Test: 0.7860
Epoch: 49, Loss: 3.1097, Train: 0.9643, Val: 0.7860, Test: 0.7880
Epoch: 50, Loss: 2.8474, Train: 0.9714, Val: 0.7860, Test: 0.7900
Epoch: 51, Loss: 2.9468, Train: 0.9714, Val: 0.7940, Test: 0.8000
Epoch: 52, Loss: 3.0007, Train: 0.9786, Val: 0.7920, Test: 0.8020
Epoch: 53, Loss: 3.0324, Train: 0.9786, Val: 0.7920, Test: 0.8000
Epoch: 54, Loss: 2.8433, Train: 0.9786, Val: 0.7860, Test: 0.8010
Epoch: 55, Loss: 3.0938, Train: 0.9857, Val: 0.7820, Test: 0.8030
Epoch: 56, Loss: 2.7318, Train: 0.9857, Val: 0.7780, Test: 0.8020
Epoch: 57, Loss: 2.7941, Train: 0.9857, Val: 0.7760, Test: 0.7970
Epoch: 58, Loss: 2.9610, Train: 0.9857, Val: 0.7800, Test: 0.7990
Epoch: 59, Loss: 2.5719, Train: 0.9857, Val: 0.7840, Test: 0.8000
Epoch: 60, Loss: 2.7326, Train: 0.9857, Val: 0.7860, Test: 0.7960
Epoch: 61, Loss: 2.6855, Train: 0.9857, Val: 0.7780, Test: 0.7960
Epoch: 62, Loss: 2.4999, Train: 0.9857, Val: 0.7800, Test: 0.7920
Epoch: 63, Loss: 2.7746, Train: 0.9857, Val: 0.7940, Test: 0.7930
Epoch: 64, Loss: 2.6159, Train: 0.9857, Val: 0.7960, Test: 0.8000
Epoch: 65, Loss: 2.4880, Train: 0.9857, Val: 0.7960, Test: 0.8000
Epoch: 66, Loss: 2.6725, Train: 0.9857, Val: 0.7900, Test: 0.7990
Epoch: 67, Loss: 2.8570, Train: 0.9786, Val: 0.7920, Test: 0.7980
Epoch: 68, Loss: 2.7081, Train: 0.9786, Val: 0.7960, Test: 0.8030
Epoch: 69, Loss: 3.0055, Train: 0.9857, Val: 0.7960, Test: 0.8010
Epoch: 70, Loss: 2.4928, Train: 0.9857, Val: 0.7940, Test: 0.8000
Epoch: 71, Loss: 2.5338, Train: 0.9929, Val: 0.8000, Test: 0.7980
Epoch: 72, Loss: 2.7115, Train: 1.0000, Val: 0.8000, Test: 0.7990
Epoch: 73, Loss: 2.7472, Train: 1.0000, Val: 0.7960, Test: 0.7960
Epoch: 74, Loss: 2.6129, Train: 0.9929, Val: 0.7980, Test: 0.8010
Epoch: 75, Loss: 2.5255, Train: 1.0000, Val: 0.8060, Test: 0.8050
Epoch: 76, Loss: 2.7200, Train: 1.0000, Val: 0.8060, Test: 0.8040
Epoch: 77, Loss: 2.7405, Train: 1.0000, Val: 0.7940, Test: 0.8020
Epoch: 78, Loss: 2.6404, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 79, Loss: 2.8410, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 80, Loss: 2.4899, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 81, Loss: 2.5233, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 82, Loss: 2.9440, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 83, Loss: 2.5330, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 84, Loss: 2.6196, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 85, Loss: 2.6694, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 86, Loss: 3.1210, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 87, Loss: 2.8806, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 88, Loss: 2.9668, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 89, Loss: 2.3951, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 90, Loss: 2.2806, Train: 1.0000, Val: 0.7960, Test: 0.8120
Epoch: 91, Loss: 2.5490, Train: 1.0000, Val: 0.7980, Test: 0.8160
Epoch: 92, Loss: 2.4026, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 93, Loss: 2.5682, Train: 1.0000, Val: 0.7960, Test: 0.8090
Epoch: 94, Loss: 2.4359, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 95, Loss: 2.7424, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 96, Loss: 2.6770, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 97, Loss: 2.5093, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 98, Loss: 2.6732, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 99, Loss: 2.4486, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 100, Loss: 2.8501, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 101, Loss: 2.4670, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 102, Loss: 2.3995, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 103, Loss: 2.5587, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 104, Loss: 2.6403, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 105, Loss: 2.8626, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 106, Loss: 2.5413, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 107, Loss: 2.6268, Train: 1.0000, Val: 0.7880, Test: 0.7900
Epoch: 108, Loss: 2.6313, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 109, Loss: 2.4977, Train: 1.0000, Val: 0.8000, Test: 0.8010
Epoch: 110, Loss: 2.2067, Train: 1.0000, Val: 0.8040, Test: 0.8060
Epoch: 111, Loss: 2.5486, Train: 1.0000, Val: 0.8040, Test: 0.8080
Epoch: 112, Loss: 2.2007, Train: 1.0000, Val: 0.8080, Test: 0.8130
Epoch: 113, Loss: 2.7725, Train: 1.0000, Val: 0.8060, Test: 0.8200
Epoch: 114, Loss: 2.6851, Train: 1.0000, Val: 0.8020, Test: 0.8180
Epoch: 115, Loss: 2.3923, Train: 1.0000, Val: 0.7880, Test: 0.8140
Epoch: 116, Loss: 2.4606, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 117, Loss: 2.7553, Train: 1.0000, Val: 0.7660, Test: 0.8060
Epoch: 118, Loss: 2.3556, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 119, Loss: 2.1759, Train: 0.9857, Val: 0.7600, Test: 0.7930
Epoch: 120, Loss: 2.1091, Train: 0.9857, Val: 0.7600, Test: 0.7900
Epoch: 121, Loss: 2.4550, Train: 0.9857, Val: 0.7600, Test: 0.7920
Epoch: 122, Loss: 2.6186, Train: 0.9857, Val: 0.7660, Test: 0.7930
Epoch: 123, Loss: 2.5528, Train: 0.9929, Val: 0.7660, Test: 0.7960
Epoch: 124, Loss: 2.6768, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 125, Loss: 2.6823, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 126, Loss: 2.8334, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 127, Loss: 2.3183, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 128, Loss: 2.3702, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 129, Loss: 2.8610, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 130, Loss: 2.5052, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 131, Loss: 2.4358, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 132, Loss: 2.6042, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 133, Loss: 2.2224, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 134, Loss: 2.5934, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 135, Loss: 2.5622, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 136, Loss: 2.5598, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 137, Loss: 2.6017, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 138, Loss: 2.5932, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 139, Loss: 2.4509, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 140, Loss: 2.3278, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 141, Loss: 2.5941, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 142, Loss: 2.6087, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 143, Loss: 2.4738, Train: 1.0000, Val: 0.7620, Test: 0.7990
Epoch: 144, Loss: 2.6506, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 145, Loss: 2.5644, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 146, Loss: 1.9766, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 147, Loss: 2.5897, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 148, Loss: 2.1699, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 149, Loss: 2.4974, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 150, Loss: 2.4611, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 151, Loss: 2.3989, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 152, Loss: 2.8115, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 153, Loss: 2.2351, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 154, Loss: 2.7510, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 155, Loss: 2.9352, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 156, Loss: 1.9760, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 157, Loss: 2.8825, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 158, Loss: 2.8444, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 159, Loss: 2.6763, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 160, Loss: 2.2889, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 161, Loss: 2.1793, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 162, Loss: 2.8619, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 163, Loss: 2.5999, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 164, Loss: 2.4974, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 165, Loss: 2.4856, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 166, Loss: 2.4117, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 167, Loss: 2.7467, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 168, Loss: 2.2317, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 169, Loss: 2.5960, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 170, Loss: 2.3715, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 171, Loss: 2.4304, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 172, Loss: 2.3088, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 173, Loss: 2.4878, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 174, Loss: 2.5835, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 175, Loss: 2.3948, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 176, Loss: 2.4321, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 177, Loss: 2.5886, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 178, Loss: 2.8444, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 179, Loss: 2.1295, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 180, Loss: 2.7268, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 181, Loss: 2.1174, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 182, Loss: 2.3518, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 183, Loss: 2.8939, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 184, Loss: 2.3148, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 185, Loss: 2.1759, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 186, Loss: 2.1712, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 187, Loss: 2.4834, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 188, Loss: 2.3486, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 189, Loss: 2.2008, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 190, Loss: 2.6276, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 191, Loss: 2.6083, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 192, Loss: 2.3567, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 193, Loss: 2.1244, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 194, Loss: 2.7818, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 195, Loss: 2.4860, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 196, Loss: 2.5532, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 197, Loss: 2.6205, Train: 1.0000, Val: 0.7780, Test: 0.8120
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 198, Loss: 2.3786, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 199, Loss: 2.4522, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 200, Loss: 2.1341, Train: 1.0000, Val: 0.7760, Test: 0.8060
MAD:  0.7473
Best Test Accuracy: 0.8200, Val Accuracy: 0.8060, Train Accuracy: 1.0000
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8525, Train: 0.1500, Val: 0.1420, Test: 0.1430
Epoch: 2, Loss: 4.8402, Train: 0.3929, Val: 0.2560, Test: 0.2520
Epoch: 3, Loss: 4.8273, Train: 0.4571, Val: 0.2880, Test: 0.3020
Epoch: 4, Loss: 4.8156, Train: 0.4786, Val: 0.3100, Test: 0.3220
Epoch: 5, Loss: 4.7670, Train: 0.4786, Val: 0.3220, Test: 0.3270
Epoch: 6, Loss: 4.7648, Train: 0.4929, Val: 0.3320, Test: 0.3310
Epoch: 7, Loss: 4.7360, Train: 0.4857, Val: 0.3420, Test: 0.3400
Epoch: 8, Loss: 4.7119, Train: 0.5000, Val: 0.3560, Test: 0.3530
Epoch: 9, Loss: 4.6518, Train: 0.5071, Val: 0.3580, Test: 0.3620
Epoch: 10, Loss: 4.5589, Train: 0.5286, Val: 0.3760, Test: 0.3780
Epoch: 11, Loss: 4.5703, Train: 0.5357, Val: 0.3980, Test: 0.4030
Epoch: 12, Loss: 4.2811, Train: 0.5500, Val: 0.4020, Test: 0.4050
Epoch: 13, Loss: 4.3486, Train: 0.5571, Val: 0.4020, Test: 0.4100
Epoch: 14, Loss: 4.3419, Train: 0.5571, Val: 0.4040, Test: 0.4030
Epoch: 15, Loss: 4.1932, Train: 0.5714, Val: 0.4160, Test: 0.4110
Epoch: 16, Loss: 3.8484, Train: 0.5929, Val: 0.4260, Test: 0.4260
Epoch: 17, Loss: 4.0326, Train: 0.5857, Val: 0.4500, Test: 0.4510
Epoch: 18, Loss: 3.9576, Train: 0.6071, Val: 0.4600, Test: 0.4690
Epoch: 19, Loss: 4.0091, Train: 0.6214, Val: 0.4640, Test: 0.4760
Epoch: 20, Loss: 3.9577, Train: 0.6500, Val: 0.4800, Test: 0.4850
Epoch: 21, Loss: 3.7464, Train: 0.6714, Val: 0.4660, Test: 0.4710
Epoch: 22, Loss: 4.0023, Train: 0.6429, Val: 0.4360, Test: 0.4320
Epoch: 23, Loss: 3.7122, Train: 0.6571, Val: 0.4260, Test: 0.4260
Epoch: 24, Loss: 3.9113, Train: 0.6929, Val: 0.4380, Test: 0.4430
Epoch: 25, Loss: 3.9231, Train: 0.7500, Val: 0.4820, Test: 0.4840
Epoch: 26, Loss: 3.6317, Train: 0.7857, Val: 0.5220, Test: 0.5160
Epoch: 27, Loss: 3.7530, Train: 0.8000, Val: 0.5380, Test: 0.5300
Epoch: 28, Loss: 3.8444, Train: 0.8000, Val: 0.5400, Test: 0.5370
Epoch: 29, Loss: 3.6043, Train: 0.8000, Val: 0.5460, Test: 0.5450
Epoch: 30, Loss: 3.5292, Train: 0.8000, Val: 0.5500, Test: 0.5550
Epoch: 31, Loss: 3.7016, Train: 0.8000, Val: 0.5520, Test: 0.5630
Epoch: 32, Loss: 3.3889, Train: 0.8000, Val: 0.5600, Test: 0.5650
Epoch: 33, Loss: 3.2782, Train: 0.8143, Val: 0.5540, Test: 0.5640
Epoch: 34, Loss: 3.5037, Train: 0.8071, Val: 0.5520, Test: 0.5630
Epoch: 35, Loss: 3.4613, Train: 0.8214, Val: 0.5540, Test: 0.5660
Epoch: 36, Loss: 3.3822, Train: 0.8357, Val: 0.5540, Test: 0.5690
Epoch: 37, Loss: 3.3419, Train: 0.8357, Val: 0.5600, Test: 0.5700
Epoch: 38, Loss: 3.2276, Train: 0.8429, Val: 0.5720, Test: 0.5870
Epoch: 39, Loss: 3.2412, Train: 0.8643, Val: 0.5960, Test: 0.6010
Epoch: 40, Loss: 3.2438, Train: 0.8786, Val: 0.6280, Test: 0.6210
Epoch: 41, Loss: 2.8760, Train: 0.8929, Val: 0.6460, Test: 0.6360
Epoch: 42, Loss: 3.4634, Train: 0.9000, Val: 0.6500, Test: 0.6540
Epoch: 43, Loss: 3.0313, Train: 0.9071, Val: 0.6540, Test: 0.6660
Epoch: 44, Loss: 3.1435, Train: 0.9143, Val: 0.6760, Test: 0.6920
Epoch: 45, Loss: 3.2853, Train: 0.9214, Val: 0.6980, Test: 0.7100
Epoch: 46, Loss: 2.9641, Train: 0.9286, Val: 0.7080, Test: 0.7190
Epoch: 47, Loss: 3.0576, Train: 0.9357, Val: 0.7180, Test: 0.7380
Epoch: 48, Loss: 2.9087, Train: 0.9429, Val: 0.7440, Test: 0.7520
Epoch: 49, Loss: 2.7754, Train: 0.9500, Val: 0.7560, Test: 0.7650
Epoch: 50, Loss: 2.9127, Train: 0.9500, Val: 0.7740, Test: 0.7770
Epoch: 51, Loss: 3.0672, Train: 0.9500, Val: 0.7780, Test: 0.7810
Epoch: 52, Loss: 2.8003, Train: 0.9571, Val: 0.7860, Test: 0.7870
Epoch: 53, Loss: 3.3110, Train: 0.9643, Val: 0.7820, Test: 0.7880
Epoch: 54, Loss: 2.8548, Train: 0.9714, Val: 0.7820, Test: 0.7880
Epoch: 55, Loss: 3.0828, Train: 0.9714, Val: 0.7760, Test: 0.7890
Epoch: 56, Loss: 2.6924, Train: 0.9714, Val: 0.7720, Test: 0.7890
Epoch: 57, Loss: 3.1366, Train: 0.9714, Val: 0.7700, Test: 0.7900
Epoch: 58, Loss: 2.9200, Train: 0.9714, Val: 0.7700, Test: 0.7890
Epoch: 59, Loss: 2.9091, Train: 0.9786, Val: 0.7720, Test: 0.7880
Epoch: 60, Loss: 2.8584, Train: 0.9714, Val: 0.7660, Test: 0.7870
Epoch: 61, Loss: 2.8897, Train: 0.9786, Val: 0.7680, Test: 0.7890
Epoch: 62, Loss: 2.7471, Train: 0.9786, Val: 0.7680, Test: 0.7890
Epoch: 63, Loss: 2.9349, Train: 0.9929, Val: 0.7820, Test: 0.7880
Epoch: 64, Loss: 2.3977, Train: 0.9929, Val: 0.7780, Test: 0.7920
Epoch: 65, Loss: 2.7242, Train: 0.9929, Val: 0.7880, Test: 0.7990
Epoch: 66, Loss: 2.7596, Train: 0.9929, Val: 0.7940, Test: 0.8100
Epoch: 67, Loss: 2.4283, Train: 1.0000, Val: 0.7980, Test: 0.8140
Epoch: 68, Loss: 2.9388, Train: 0.9929, Val: 0.7980, Test: 0.8230
Epoch: 69, Loss: 2.7826, Train: 0.9929, Val: 0.7980, Test: 0.8230
Epoch: 70, Loss: 2.5371, Train: 0.9929, Val: 0.8040, Test: 0.8230
Epoch: 71, Loss: 2.7853, Train: 0.9929, Val: 0.8000, Test: 0.8220
Epoch: 72, Loss: 2.6296, Train: 0.9929, Val: 0.7980, Test: 0.8200
Epoch: 73, Loss: 2.3792, Train: 0.9929, Val: 0.7940, Test: 0.8180
Epoch: 74, Loss: 2.6568, Train: 0.9929, Val: 0.7920, Test: 0.8140
Epoch: 75, Loss: 2.8571, Train: 0.9929, Val: 0.7920, Test: 0.8110
Epoch: 76, Loss: 2.9264, Train: 0.9929, Val: 0.7880, Test: 0.8070
Epoch: 77, Loss: 2.6354, Train: 0.9929, Val: 0.7860, Test: 0.8070
Epoch: 78, Loss: 2.5620, Train: 0.9929, Val: 0.7820, Test: 0.8020
Epoch: 79, Loss: 2.7458, Train: 0.9929, Val: 0.7860, Test: 0.7990
Epoch: 80, Loss: 2.6171, Train: 0.9929, Val: 0.7820, Test: 0.7980
Epoch: 81, Loss: 2.9740, Train: 0.9929, Val: 0.7740, Test: 0.7970
Epoch: 82, Loss: 2.1297, Train: 0.9929, Val: 0.7780, Test: 0.7950
Epoch: 83, Loss: 2.6445, Train: 0.9929, Val: 0.7780, Test: 0.7930
Epoch: 84, Loss: 2.3746, Train: 0.9929, Val: 0.7760, Test: 0.7940
Epoch: 85, Loss: 2.5479, Train: 0.9929, Val: 0.7780, Test: 0.8010
Epoch: 86, Loss: 2.5654, Train: 0.9929, Val: 0.7800, Test: 0.8000
Epoch: 87, Loss: 2.4343, Train: 0.9929, Val: 0.7860, Test: 0.7990
Epoch: 88, Loss: 2.6423, Train: 0.9929, Val: 0.7880, Test: 0.8000
Epoch: 89, Loss: 2.5395, Train: 0.9929, Val: 0.7860, Test: 0.7980
Epoch: 90, Loss: 2.6684, Train: 0.9929, Val: 0.7900, Test: 0.8020
Epoch: 91, Loss: 2.5607, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 92, Loss: 2.6266, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 93, Loss: 2.2163, Train: 0.9929, Val: 0.7880, Test: 0.8080
Epoch: 94, Loss: 2.4378, Train: 0.9929, Val: 0.7840, Test: 0.8080
Epoch: 95, Loss: 2.7805, Train: 0.9929, Val: 0.7840, Test: 0.8070
Epoch: 96, Loss: 2.7707, Train: 0.9929, Val: 0.7900, Test: 0.8090
Epoch: 97, Loss: 2.6740, Train: 0.9929, Val: 0.7880, Test: 0.8100
Epoch: 98, Loss: 2.2165, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 99, Loss: 2.9713, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 100, Loss: 2.4698, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 101, Loss: 2.7053, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 102, Loss: 2.2821, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 103, Loss: 2.6487, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 104, Loss: 2.6104, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 105, Loss: 2.4875, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 106, Loss: 2.3436, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 107, Loss: 2.1349, Train: 1.0000, Val: 0.7860, Test: 0.8160
Epoch: 108, Loss: 2.9309, Train: 1.0000, Val: 0.7860, Test: 0.8170
Epoch: 109, Loss: 2.4878, Train: 1.0000, Val: 0.7860, Test: 0.8170
Epoch: 110, Loss: 2.7913, Train: 1.0000, Val: 0.7920, Test: 0.8150
Epoch: 111, Loss: 2.3442, Train: 1.0000, Val: 0.7940, Test: 0.8110
Epoch: 112, Loss: 2.3064, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 113, Loss: 2.3738, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 114, Loss: 2.9197, Train: 1.0000, Val: 0.7920, Test: 0.8070
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 115, Loss: 2.9672, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 116, Loss: 2.5627, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 117, Loss: 2.2566, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 118, Loss: 2.8218, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 119, Loss: 2.4364, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 120, Loss: 2.3296, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 121, Loss: 2.4028, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 122, Loss: 2.0946, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 123, Loss: 2.1659, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 124, Loss: 2.5830, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 125, Loss: 2.1999, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 126, Loss: 2.7842, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 127, Loss: 2.7917, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 128, Loss: 2.6881, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 129, Loss: 2.4975, Train: 1.0000, Val: 0.8000, Test: 0.8110
Epoch: 130, Loss: 2.7181, Train: 1.0000, Val: 0.8040, Test: 0.8110
Epoch: 131, Loss: 2.4515, Train: 1.0000, Val: 0.8020, Test: 0.8120
Epoch: 132, Loss: 2.7846, Train: 1.0000, Val: 0.8020, Test: 0.8130
Epoch: 133, Loss: 2.8179, Train: 1.0000, Val: 0.7980, Test: 0.8130
Epoch: 134, Loss: 2.5002, Train: 1.0000, Val: 0.8000, Test: 0.8080
Epoch: 135, Loss: 2.4926, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 136, Loss: 2.3456, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 137, Loss: 2.7381, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 138, Loss: 2.3676, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 139, Loss: 2.6274, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 140, Loss: 2.7043, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 141, Loss: 2.3161, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 142, Loss: 2.4415, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 143, Loss: 2.3121, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 144, Loss: 2.5074, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 145, Loss: 2.2890, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 146, Loss: 2.3533, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 147, Loss: 2.3860, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 148, Loss: 2.9805, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 149, Loss: 2.7099, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 150, Loss: 2.4941, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 151, Loss: 2.4848, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 152, Loss: 2.6220, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 153, Loss: 2.4878, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 154, Loss: 2.4823, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 155, Loss: 2.2850, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 156, Loss: 2.4443, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 157, Loss: 1.9180, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 158, Loss: 2.4938, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 159, Loss: 2.7267, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 160, Loss: 2.2743, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 161, Loss: 2.8207, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 162, Loss: 2.3617, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 163, Loss: 2.6744, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 164, Loss: 2.5777, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 165, Loss: 2.4741, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 166, Loss: 2.1817, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 167, Loss: 2.7972, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 168, Loss: 2.0889, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 169, Loss: 2.5498, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 170, Loss: 2.2121, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 171, Loss: 2.2649, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 172, Loss: 2.5188, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 173, Loss: 2.5534, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 174, Loss: 2.4815, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 175, Loss: 2.4650, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 176, Loss: 2.6313, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 177, Loss: 2.4241, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 178, Loss: 2.6142, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 179, Loss: 2.5982, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 180, Loss: 2.6242, Train: 1.0000, Val: 0.7860, Test: 0.8130
Epoch: 181, Loss: 2.6406, Train: 1.0000, Val: 0.7820, Test: 0.8150
Epoch: 182, Loss: 2.4205, Train: 1.0000, Val: 0.7820, Test: 0.8160
Epoch: 183, Loss: 2.5947, Train: 1.0000, Val: 0.7900, Test: 0.8170
Epoch: 184, Loss: 2.4534, Train: 1.0000, Val: 0.7880, Test: 0.8160
Epoch: 185, Loss: 2.4750, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 186, Loss: 2.2863, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 187, Loss: 2.8671, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 188, Loss: 2.6670, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 189, Loss: 2.1328, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 190, Loss: 2.5651, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 191, Loss: 2.4399, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 192, Loss: 2.5365, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 193, Loss: 2.0292, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 194, Loss: 2.3994, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 195, Loss: 2.5167, Train: 1.0000, Val: 0.7760, Test: 0.7850
Epoch: 196, Loss: 2.4120, Train: 1.0000, Val: 0.7780, Test: 0.7870
Epoch: 197, Loss: 2.2666, Train: 1.0000, Val: 0.7800, Test: 0.7880
Epoch: 198, Loss: 2.5545, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 199, Loss: 2.7251, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 200, Loss: 2.5257, Train: 1.0000, Val: 0.7720, Test: 0.7950
MAD:  0.4815
Best Test Accuracy: 0.8230, Val Accuracy: 0.7980, Train Accuracy: 0.9929
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8548, Train: 0.1286, Val: 0.0940, Test: 0.0900
Epoch: 2, Loss: 4.8459, Train: 0.3071, Val: 0.2020, Test: 0.2270
Epoch: 3, Loss: 4.8283, Train: 0.3643, Val: 0.2700, Test: 0.2790
Epoch: 4, Loss: 4.8061, Train: 0.4000, Val: 0.3040, Test: 0.3020
Epoch: 5, Loss: 4.7939, Train: 0.4286, Val: 0.3360, Test: 0.3270
Epoch: 6, Loss: 4.7705, Train: 0.4214, Val: 0.3540, Test: 0.3310
Epoch: 7, Loss: 4.7320, Train: 0.4214, Val: 0.3540, Test: 0.3390
Epoch: 8, Loss: 4.7310, Train: 0.4286, Val: 0.3520, Test: 0.3390
Epoch: 9, Loss: 4.6307, Train: 0.4214, Val: 0.3520, Test: 0.3360
Epoch: 10, Loss: 4.5922, Train: 0.4214, Val: 0.3520, Test: 0.3370
Epoch: 11, Loss: 4.6397, Train: 0.4214, Val: 0.3480, Test: 0.3340
Epoch: 12, Loss: 4.5632, Train: 0.4214, Val: 0.3440, Test: 0.3340
Epoch: 13, Loss: 4.4123, Train: 0.4214, Val: 0.3460, Test: 0.3340
Epoch: 14, Loss: 4.3896, Train: 0.4286, Val: 0.3480, Test: 0.3360
Epoch: 15, Loss: 4.3002, Train: 0.4286, Val: 0.3560, Test: 0.3400
Epoch: 16, Loss: 4.3711, Train: 0.4286, Val: 0.3600, Test: 0.3440
Epoch: 17, Loss: 4.3076, Train: 0.4286, Val: 0.3540, Test: 0.3440
Epoch: 18, Loss: 4.1419, Train: 0.4286, Val: 0.3560, Test: 0.3430
Epoch: 19, Loss: 4.2480, Train: 0.4214, Val: 0.3440, Test: 0.3320
Epoch: 20, Loss: 4.1020, Train: 0.4214, Val: 0.3420, Test: 0.3320
Epoch: 21, Loss: 4.1962, Train: 0.4429, Val: 0.3460, Test: 0.3400
Epoch: 22, Loss: 4.0751, Train: 0.5143, Val: 0.3840, Test: 0.3810
Epoch: 23, Loss: 3.9443, Train: 0.5643, Val: 0.4040, Test: 0.4100
Epoch: 24, Loss: 4.1007, Train: 0.5714, Val: 0.4040, Test: 0.4090
Epoch: 25, Loss: 3.9951, Train: 0.5714, Val: 0.3960, Test: 0.4030
Epoch: 26, Loss: 4.1831, Train: 0.5714, Val: 0.3900, Test: 0.4000
Epoch: 27, Loss: 4.0750, Train: 0.5714, Val: 0.3880, Test: 0.4010
Epoch: 28, Loss: 3.7734, Train: 0.5714, Val: 0.3900, Test: 0.4030
Epoch: 29, Loss: 3.8509, Train: 0.5714, Val: 0.4020, Test: 0.4050
Epoch: 30, Loss: 3.9666, Train: 0.5714, Val: 0.4120, Test: 0.4140
Epoch: 31, Loss: 3.9166, Train: 0.5714, Val: 0.4160, Test: 0.4150
Epoch: 32, Loss: 3.7937, Train: 0.5643, Val: 0.4220, Test: 0.4200
Epoch: 33, Loss: 3.8249, Train: 0.5643, Val: 0.4240, Test: 0.4250
Epoch: 34, Loss: 3.9259, Train: 0.5643, Val: 0.4240, Test: 0.4260
Epoch: 35, Loss: 3.9678, Train: 0.5643, Val: 0.4240, Test: 0.4290
Epoch: 36, Loss: 3.8546, Train: 0.5786, Val: 0.4220, Test: 0.4330
Epoch: 37, Loss: 3.6306, Train: 0.6071, Val: 0.4260, Test: 0.4420
Epoch: 38, Loss: 3.5217, Train: 0.6357, Val: 0.4600, Test: 0.4660
Epoch: 39, Loss: 3.8359, Train: 0.6500, Val: 0.4900, Test: 0.4900
Epoch: 40, Loss: 3.8345, Train: 0.6500, Val: 0.5080, Test: 0.5180
Epoch: 41, Loss: 3.5343, Train: 0.6571, Val: 0.5360, Test: 0.5510
Epoch: 42, Loss: 3.1315, Train: 0.6714, Val: 0.5680, Test: 0.5770
Epoch: 43, Loss: 3.8606, Train: 0.6714, Val: 0.5720, Test: 0.5880
Epoch: 44, Loss: 3.2850, Train: 0.6786, Val: 0.5700, Test: 0.5910
Epoch: 45, Loss: 3.3967, Train: 0.6786, Val: 0.5720, Test: 0.5950
Epoch: 46, Loss: 3.4986, Train: 0.6786, Val: 0.5740, Test: 0.5900
Epoch: 47, Loss: 3.6443, Train: 0.6786, Val: 0.5720, Test: 0.5880
Epoch: 48, Loss: 3.4152, Train: 0.6929, Val: 0.5800, Test: 0.5960
Epoch: 49, Loss: 3.3503, Train: 0.6929, Val: 0.5840, Test: 0.6020
Epoch: 50, Loss: 3.3504, Train: 0.6929, Val: 0.5980, Test: 0.6090
Epoch: 51, Loss: 3.6304, Train: 0.7000, Val: 0.6000, Test: 0.6150
Epoch: 52, Loss: 3.3573, Train: 0.7000, Val: 0.6060, Test: 0.6240
Epoch: 53, Loss: 3.3108, Train: 0.7000, Val: 0.6220, Test: 0.6310
Epoch: 54, Loss: 3.4851, Train: 0.7000, Val: 0.6220, Test: 0.6370
Epoch: 55, Loss: 3.3068, Train: 0.7143, Val: 0.6240, Test: 0.6430
Epoch: 56, Loss: 3.3118, Train: 0.7143, Val: 0.6300, Test: 0.6450
Epoch: 57, Loss: 3.1793, Train: 0.7143, Val: 0.6340, Test: 0.6490
Epoch: 58, Loss: 3.1132, Train: 0.7143, Val: 0.6360, Test: 0.6480
Epoch: 59, Loss: 3.1034, Train: 0.7143, Val: 0.6380, Test: 0.6490
Epoch: 60, Loss: 3.4570, Train: 0.7143, Val: 0.6360, Test: 0.6530
Epoch: 61, Loss: 3.1163, Train: 0.7214, Val: 0.6400, Test: 0.6610
Epoch: 62, Loss: 3.1305, Train: 0.7571, Val: 0.6580, Test: 0.6730
Epoch: 63, Loss: 3.1620, Train: 0.7714, Val: 0.6700, Test: 0.6850
Epoch: 64, Loss: 3.0950, Train: 0.8000, Val: 0.6780, Test: 0.6900
Epoch: 65, Loss: 3.1540, Train: 0.8143, Val: 0.6860, Test: 0.6950
Epoch: 66, Loss: 3.2189, Train: 0.8214, Val: 0.6820, Test: 0.6980
Epoch: 67, Loss: 3.2500, Train: 0.8286, Val: 0.6800, Test: 0.6980
Epoch: 68, Loss: 3.5566, Train: 0.8286, Val: 0.6900, Test: 0.7000
Epoch: 69, Loss: 3.4089, Train: 0.8286, Val: 0.6920, Test: 0.7000
Epoch: 70, Loss: 3.3114, Train: 0.8357, Val: 0.6940, Test: 0.6990
Epoch: 71, Loss: 3.0453, Train: 0.8429, Val: 0.6900, Test: 0.7010
Epoch: 72, Loss: 2.8689, Train: 0.8500, Val: 0.6900, Test: 0.7030
Epoch: 73, Loss: 3.2338, Train: 0.8500, Val: 0.6920, Test: 0.7020
Epoch: 74, Loss: 2.7499, Train: 0.8500, Val: 0.6940, Test: 0.7020
Epoch: 75, Loss: 3.2414, Train: 0.8429, Val: 0.6900, Test: 0.7050
Epoch: 76, Loss: 2.8702, Train: 0.8429, Val: 0.6860, Test: 0.7070
Epoch: 77, Loss: 3.0649, Train: 0.8429, Val: 0.6880, Test: 0.7070
Epoch: 78, Loss: 3.0728, Train: 0.8500, Val: 0.6900, Test: 0.7110
Epoch: 79, Loss: 2.8550, Train: 0.8500, Val: 0.6920, Test: 0.7150
Epoch: 80, Loss: 2.7801, Train: 0.8500, Val: 0.6960, Test: 0.7190
Epoch: 81, Loss: 3.0163, Train: 0.8500, Val: 0.6960, Test: 0.7230
Epoch: 82, Loss: 2.9890, Train: 0.8571, Val: 0.6960, Test: 0.7280
Epoch: 83, Loss: 2.9267, Train: 0.8571, Val: 0.6980, Test: 0.7250
Epoch: 84, Loss: 2.9993, Train: 0.8571, Val: 0.7000, Test: 0.7260
Epoch: 85, Loss: 2.7569, Train: 0.8571, Val: 0.7040, Test: 0.7270
Epoch: 86, Loss: 2.7836, Train: 0.8571, Val: 0.7020, Test: 0.7270
Epoch: 87, Loss: 3.1748, Train: 0.8571, Val: 0.7000, Test: 0.7260
Epoch: 88, Loss: 2.6228, Train: 0.8571, Val: 0.7020, Test: 0.7210
Epoch: 89, Loss: 2.5374, Train: 0.8571, Val: 0.7020, Test: 0.7220
Epoch: 90, Loss: 2.8269, Train: 0.8571, Val: 0.7020, Test: 0.7250
Epoch: 91, Loss: 2.8021, Train: 0.8571, Val: 0.6980, Test: 0.7230
Epoch: 92, Loss: 2.8305, Train: 0.8571, Val: 0.7000, Test: 0.7190
Epoch: 93, Loss: 2.7461, Train: 0.8571, Val: 0.6980, Test: 0.7180
Epoch: 94, Loss: 2.9324, Train: 0.8571, Val: 0.6960, Test: 0.7170
Epoch: 95, Loss: 2.9011, Train: 0.8571, Val: 0.6960, Test: 0.7180
Epoch: 96, Loss: 3.2275, Train: 0.8571, Val: 0.6940, Test: 0.7150
Epoch: 97, Loss: 2.9449, Train: 0.8571, Val: 0.6980, Test: 0.7160
Epoch: 98, Loss: 2.8711, Train: 0.8571, Val: 0.6980, Test: 0.7150
Epoch: 99, Loss: 2.8851, Train: 0.8571, Val: 0.6940, Test: 0.7120
Epoch: 100, Loss: 2.9498, Train: 0.8571, Val: 0.6860, Test: 0.7090
Epoch: 101, Loss: 2.5423, Train: 0.8571, Val: 0.6860, Test: 0.7100
Epoch: 102, Loss: 2.5932, Train: 0.8571, Val: 0.6880, Test: 0.7080
Epoch: 103, Loss: 2.6331, Train: 0.8571, Val: 0.6940, Test: 0.7060
Epoch: 104, Loss: 2.6020, Train: 0.8571, Val: 0.7000, Test: 0.7080
Epoch: 105, Loss: 2.5343, Train: 0.8643, Val: 0.7100, Test: 0.7240
Epoch: 106, Loss: 2.8914, Train: 0.8786, Val: 0.7120, Test: 0.7310
Epoch: 107, Loss: 2.8450, Train: 0.9143, Val: 0.7360, Test: 0.7600
Epoch: 108, Loss: 2.6164, Train: 0.9571, Val: 0.7560, Test: 0.7800
Epoch: 109, Loss: 2.4833, Train: 0.9571, Val: 0.7660, Test: 0.7880
Epoch: 110, Loss: 2.5076, Train: 0.9714, Val: 0.7800, Test: 0.7950
Epoch: 111, Loss: 2.7894, Train: 0.9786, Val: 0.7820, Test: 0.7990
Epoch: 112, Loss: 2.8472, Train: 0.9786, Val: 0.7860, Test: 0.8050
Epoch: 113, Loss: 2.7469, Train: 0.9786, Val: 0.7860, Test: 0.8100
Epoch: 114, Loss: 2.4734, Train: 0.9929, Val: 0.7920, Test: 0.8140
Epoch: 115, Loss: 2.4977, Train: 0.9929, Val: 0.7880, Test: 0.8110
Epoch: 116, Loss: 2.5552, Train: 0.9929, Val: 0.7900, Test: 0.8070
Epoch: 117, Loss: 2.7118, Train: 0.9857, Val: 0.7860, Test: 0.8020
Epoch: 118, Loss: 2.7661, Train: 0.9786, Val: 0.7820, Test: 0.7990
Epoch: 119, Loss: 2.4070, Train: 0.9786, Val: 0.7800, Test: 0.7970
Epoch: 120, Loss: 2.4331, Train: 0.9786, Val: 0.7680, Test: 0.7910
Epoch: 121, Loss: 2.7065, Train: 0.9786, Val: 0.7620, Test: 0.7850
Epoch: 122, Loss: 2.7563, Train: 0.9786, Val: 0.7640, Test: 0.7860
Epoch: 123, Loss: 2.1958, Train: 0.9786, Val: 0.7580, Test: 0.7850
Epoch: 124, Loss: 2.6205, Train: 0.9786, Val: 0.7580, Test: 0.7850
Epoch: 125, Loss: 2.6896, Train: 0.9786, Val: 0.7580, Test: 0.7850
Epoch: 126, Loss: 2.8479, Train: 0.9786, Val: 0.7580, Test: 0.7860
Epoch: 127, Loss: 2.7311, Train: 0.9786, Val: 0.7600, Test: 0.7870
Epoch: 128, Loss: 2.8653, Train: 0.9786, Val: 0.7600, Test: 0.7880
Epoch: 129, Loss: 2.8148, Train: 0.9786, Val: 0.7620, Test: 0.7890
Epoch: 130, Loss: 2.4180, Train: 0.9857, Val: 0.7600, Test: 0.7930
Epoch: 131, Loss: 2.3738, Train: 0.9857, Val: 0.7760, Test: 0.7960
Epoch: 132, Loss: 2.6112, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 133, Loss: 2.7451, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 134, Loss: 2.7230, Train: 1.0000, Val: 0.7980, Test: 0.8030
Epoch: 135, Loss: 2.4791, Train: 1.0000, Val: 0.7940, Test: 0.8040
Epoch: 136, Loss: 2.8312, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 137, Loss: 2.7492, Train: 0.9929, Val: 0.7980, Test: 0.8100
Epoch: 138, Loss: 2.2695, Train: 0.9929, Val: 0.7920, Test: 0.8100
Epoch: 139, Loss: 2.6664, Train: 0.9929, Val: 0.7900, Test: 0.8120
Epoch: 140, Loss: 2.5736, Train: 0.9929, Val: 0.7880, Test: 0.8040
Epoch: 141, Loss: 2.8294, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 142, Loss: 2.2456, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 143, Loss: 2.5175, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 144, Loss: 2.1693, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 145, Loss: 2.4910, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 146, Loss: 2.7259, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 147, Loss: 2.4593, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 148, Loss: 2.8697, Train: 1.0000, Val: 0.7620, Test: 0.7850
Epoch: 149, Loss: 2.7464, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 150, Loss: 2.1823, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 151, Loss: 2.7180, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 152, Loss: 2.4897, Train: 1.0000, Val: 0.7660, Test: 0.7800
Epoch: 153, Loss: 2.2795, Train: 1.0000, Val: 0.7660, Test: 0.7830
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 2.4863, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 155, Loss: 2.7031, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 156, Loss: 2.5748, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 157, Loss: 2.5187, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 158, Loss: 2.2420, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 159, Loss: 2.7798, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 160, Loss: 2.4672, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 161, Loss: 2.5069, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 162, Loss: 2.9863, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 163, Loss: 2.7816, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 164, Loss: 2.6919, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 165, Loss: 2.5597, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 166, Loss: 2.4433, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 167, Loss: 2.6436, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 168, Loss: 2.3685, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 169, Loss: 2.5519, Train: 1.0000, Val: 0.7640, Test: 0.7950
Epoch: 170, Loss: 2.1899, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 171, Loss: 2.2910, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 172, Loss: 2.5241, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 173, Loss: 2.0868, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 174, Loss: 2.2992, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 175, Loss: 2.5673, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 176, Loss: 2.6860, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 177, Loss: 2.5937, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 178, Loss: 2.2598, Train: 1.0000, Val: 0.7620, Test: 0.7980
Epoch: 179, Loss: 2.5338, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 180, Loss: 2.9147, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 181, Loss: 2.3508, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 182, Loss: 2.3646, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 183, Loss: 2.6936, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 184, Loss: 2.8784, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 185, Loss: 2.5792, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 186, Loss: 2.1356, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 187, Loss: 2.7690, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 188, Loss: 2.3300, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 189, Loss: 2.1859, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 190, Loss: 2.3293, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 191, Loss: 2.5135, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 192, Loss: 2.6724, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 193, Loss: 2.2887, Train: 1.0000, Val: 0.7560, Test: 0.7930
Epoch: 194, Loss: 2.3520, Train: 1.0000, Val: 0.7540, Test: 0.7920
Epoch: 195, Loss: 2.8343, Train: 1.0000, Val: 0.7520, Test: 0.7910
Epoch: 196, Loss: 2.6968, Train: 1.0000, Val: 0.7520, Test: 0.7920
Epoch: 197, Loss: 2.5959, Train: 1.0000, Val: 0.7580, Test: 0.7960
Epoch: 198, Loss: 2.5652, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 199, Loss: 2.5608, Train: 1.0000, Val: 0.7580, Test: 0.7990
Epoch: 200, Loss: 2.5817, Train: 1.0000, Val: 0.7620, Test: 0.8000
MAD:  0.6994
Best Test Accuracy: 0.8140, Val Accuracy: 0.7920, Train Accuracy: 0.9929
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8549, Train: 0.2214, Val: 0.2620, Test: 0.2560
Epoch: 2, Loss: 4.8267, Train: 0.3214, Val: 0.3040, Test: 0.3380
Epoch: 3, Loss: 4.8135, Train: 0.3500, Val: 0.2780, Test: 0.3160
Epoch: 4, Loss: 4.7952, Train: 0.3286, Val: 0.2740, Test: 0.2950
Epoch: 5, Loss: 4.7516, Train: 0.3214, Val: 0.2360, Test: 0.2790
Epoch: 6, Loss: 4.7521, Train: 0.3286, Val: 0.2400, Test: 0.2900
Epoch: 7, Loss: 4.6661, Train: 0.3143, Val: 0.2320, Test: 0.2840
Epoch: 8, Loss: 4.6216, Train: 0.3357, Val: 0.2360, Test: 0.2850
Epoch: 9, Loss: 4.5902, Train: 0.3429, Val: 0.2400, Test: 0.2890
Epoch: 10, Loss: 4.5132, Train: 0.3500, Val: 0.2660, Test: 0.3110
Epoch: 11, Loss: 4.4546, Train: 0.3571, Val: 0.2720, Test: 0.3230
Epoch: 12, Loss: 4.3470, Train: 0.3357, Val: 0.2820, Test: 0.3280
Epoch: 13, Loss: 4.1858, Train: 0.3357, Val: 0.2780, Test: 0.3190
Epoch: 14, Loss: 4.1345, Train: 0.3429, Val: 0.2840, Test: 0.3240
Epoch: 15, Loss: 4.1803, Train: 0.3571, Val: 0.2920, Test: 0.3420
Epoch: 16, Loss: 3.9388, Train: 0.3571, Val: 0.3060, Test: 0.3510
Epoch: 17, Loss: 3.7962, Train: 0.4071, Val: 0.3100, Test: 0.3650
Epoch: 18, Loss: 4.1625, Train: 0.4786, Val: 0.3240, Test: 0.3650
Epoch: 19, Loss: 4.1827, Train: 0.6286, Val: 0.4160, Test: 0.4660
Epoch: 20, Loss: 3.8445, Train: 0.7357, Val: 0.5880, Test: 0.6070
Epoch: 21, Loss: 3.7889, Train: 0.7857, Val: 0.6520, Test: 0.6770
Epoch: 22, Loss: 3.8875, Train: 0.7500, Val: 0.6040, Test: 0.6210
Epoch: 23, Loss: 3.8450, Train: 0.7000, Val: 0.5680, Test: 0.5630
Epoch: 24, Loss: 3.9625, Train: 0.6357, Val: 0.5420, Test: 0.5320
Epoch: 25, Loss: 3.6180, Train: 0.6929, Val: 0.5900, Test: 0.5820
Epoch: 26, Loss: 3.9626, Train: 0.7429, Val: 0.6280, Test: 0.6280
Epoch: 27, Loss: 3.7641, Train: 0.7857, Val: 0.6480, Test: 0.6760
Epoch: 28, Loss: 3.7295, Train: 0.8071, Val: 0.6820, Test: 0.7280
Epoch: 29, Loss: 3.7425, Train: 0.8071, Val: 0.7180, Test: 0.7480
Epoch: 30, Loss: 3.3724, Train: 0.7929, Val: 0.7200, Test: 0.7580
Epoch: 31, Loss: 3.5880, Train: 0.7786, Val: 0.7180, Test: 0.7550
Epoch: 32, Loss: 3.2800, Train: 0.7714, Val: 0.7120, Test: 0.7440
Epoch: 33, Loss: 3.4166, Train: 0.7714, Val: 0.7100, Test: 0.7380
Epoch: 34, Loss: 3.5575, Train: 0.7714, Val: 0.7120, Test: 0.7410
Epoch: 35, Loss: 3.5433, Train: 0.7929, Val: 0.7120, Test: 0.7480
Epoch: 36, Loss: 3.4743, Train: 0.7929, Val: 0.7120, Test: 0.7500
Epoch: 37, Loss: 3.4497, Train: 0.8071, Val: 0.7060, Test: 0.7540
Epoch: 38, Loss: 3.1728, Train: 0.8143, Val: 0.7080, Test: 0.7510
Epoch: 39, Loss: 3.6637, Train: 0.8214, Val: 0.7020, Test: 0.7470
Epoch: 40, Loss: 3.2778, Train: 0.8286, Val: 0.6900, Test: 0.7450
Epoch: 41, Loss: 3.3605, Train: 0.8286, Val: 0.6960, Test: 0.7420
Epoch: 42, Loss: 3.1526, Train: 0.8286, Val: 0.6940, Test: 0.7410
Epoch: 43, Loss: 3.2469, Train: 0.8357, Val: 0.6920, Test: 0.7380
Epoch: 44, Loss: 3.3225, Train: 0.8357, Val: 0.6960, Test: 0.7420
Epoch: 45, Loss: 3.0077, Train: 0.8357, Val: 0.7080, Test: 0.7500
Epoch: 46, Loss: 2.9568, Train: 0.8286, Val: 0.7200, Test: 0.7500
Epoch: 47, Loss: 2.8460, Train: 0.8357, Val: 0.7260, Test: 0.7660
Epoch: 48, Loss: 3.1889, Train: 0.8643, Val: 0.7440, Test: 0.7810
Epoch: 49, Loss: 3.2910, Train: 0.9286, Val: 0.7600, Test: 0.8070
Epoch: 50, Loss: 3.1250, Train: 0.9429, Val: 0.7700, Test: 0.8130
Epoch: 51, Loss: 3.0469, Train: 0.9500, Val: 0.7880, Test: 0.8190
Epoch: 52, Loss: 3.1321, Train: 0.9500, Val: 0.7840, Test: 0.8170
Epoch: 53, Loss: 3.3345, Train: 0.9571, Val: 0.7820, Test: 0.8210
Epoch: 54, Loss: 2.8845, Train: 0.9714, Val: 0.7820, Test: 0.8130
Epoch: 55, Loss: 2.9529, Train: 0.9714, Val: 0.7760, Test: 0.8080
Epoch: 56, Loss: 2.8743, Train: 0.9786, Val: 0.7740, Test: 0.8080
Epoch: 57, Loss: 2.8176, Train: 0.9857, Val: 0.7680, Test: 0.8030
Epoch: 58, Loss: 2.8863, Train: 0.9857, Val: 0.7680, Test: 0.8050
Epoch: 59, Loss: 3.3419, Train: 0.9857, Val: 0.7660, Test: 0.8060
Epoch: 60, Loss: 3.1319, Train: 0.9857, Val: 0.7700, Test: 0.8080
Epoch: 61, Loss: 2.9301, Train: 0.9857, Val: 0.7720, Test: 0.8110
Epoch: 62, Loss: 3.1503, Train: 0.9857, Val: 0.7760, Test: 0.8170
Epoch: 63, Loss: 2.9977, Train: 0.9857, Val: 0.7800, Test: 0.8210
Epoch: 64, Loss: 2.9101, Train: 0.9857, Val: 0.7820, Test: 0.8210
Epoch: 65, Loss: 2.7139, Train: 0.9857, Val: 0.7720, Test: 0.8180
Epoch: 66, Loss: 2.5878, Train: 0.9857, Val: 0.7720, Test: 0.8160
Epoch: 67, Loss: 2.4599, Train: 0.9857, Val: 0.7800, Test: 0.8120
Epoch: 68, Loss: 2.8142, Train: 0.9857, Val: 0.7820, Test: 0.8150
Epoch: 69, Loss: 2.9256, Train: 0.9857, Val: 0.7800, Test: 0.8170
Epoch: 70, Loss: 2.5766, Train: 0.9786, Val: 0.7800, Test: 0.8110
Epoch: 71, Loss: 2.7133, Train: 0.9786, Val: 0.7780, Test: 0.8080
Epoch: 72, Loss: 2.5731, Train: 0.9786, Val: 0.7740, Test: 0.8080
Epoch: 73, Loss: 3.1871, Train: 0.9786, Val: 0.7700, Test: 0.8050
Epoch: 74, Loss: 2.6598, Train: 0.9857, Val: 0.7740, Test: 0.7960
Epoch: 75, Loss: 2.7773, Train: 0.9786, Val: 0.7740, Test: 0.7960
Epoch: 76, Loss: 2.8254, Train: 0.9929, Val: 0.7780, Test: 0.8000
Epoch: 77, Loss: 2.7633, Train: 0.9929, Val: 0.7780, Test: 0.8050
Epoch: 78, Loss: 2.4788, Train: 0.9929, Val: 0.7860, Test: 0.8110
Epoch: 79, Loss: 2.8286, Train: 0.9929, Val: 0.7860, Test: 0.8160
Epoch: 80, Loss: 2.7411, Train: 0.9929, Val: 0.7880, Test: 0.8220
Epoch: 81, Loss: 2.9054, Train: 0.9929, Val: 0.7920, Test: 0.8190
Epoch: 82, Loss: 2.8277, Train: 0.9929, Val: 0.7960, Test: 0.8180
Epoch: 83, Loss: 2.7927, Train: 0.9929, Val: 0.7960, Test: 0.8200
Epoch: 84, Loss: 2.2982, Train: 0.9929, Val: 0.7900, Test: 0.8180
Epoch: 85, Loss: 2.4481, Train: 0.9929, Val: 0.7860, Test: 0.8130
Epoch: 86, Loss: 2.5534, Train: 0.9929, Val: 0.7840, Test: 0.8100
Epoch: 87, Loss: 2.7766, Train: 0.9929, Val: 0.7740, Test: 0.8050
Epoch: 88, Loss: 2.4417, Train: 0.9929, Val: 0.7700, Test: 0.8060
Epoch: 89, Loss: 2.9022, Train: 0.9929, Val: 0.7740, Test: 0.8040
Epoch: 90, Loss: 2.4292, Train: 0.9929, Val: 0.7760, Test: 0.8040
Epoch: 91, Loss: 2.6044, Train: 0.9929, Val: 0.7760, Test: 0.8050
Epoch: 92, Loss: 2.7416, Train: 0.9929, Val: 0.7780, Test: 0.8010
Epoch: 93, Loss: 2.5938, Train: 0.9929, Val: 0.7780, Test: 0.8030
Epoch: 94, Loss: 2.8190, Train: 0.9929, Val: 0.7800, Test: 0.8020
Epoch: 95, Loss: 2.3704, Train: 0.9929, Val: 0.7820, Test: 0.8000
Epoch: 96, Loss: 2.6316, Train: 0.9929, Val: 0.7800, Test: 0.8010
Epoch: 97, Loss: 2.5853, Train: 0.9929, Val: 0.7860, Test: 0.8040
Epoch: 98, Loss: 2.8816, Train: 0.9929, Val: 0.7860, Test: 0.8110
Epoch: 99, Loss: 2.7989, Train: 0.9929, Val: 0.7860, Test: 0.8100
Epoch: 100, Loss: 2.3678, Train: 0.9929, Val: 0.7860, Test: 0.8100
Epoch: 101, Loss: 2.6237, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 102, Loss: 2.7688, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 103, Loss: 2.6312, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 104, Loss: 2.6234, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 105, Loss: 2.1721, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 106, Loss: 2.0558, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 107, Loss: 2.5884, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 108, Loss: 2.5277, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 109, Loss: 2.4372, Train: 1.0000, Val: 0.7660, Test: 0.7820
Epoch: 110, Loss: 2.3396, Train: 1.0000, Val: 0.7680, Test: 0.7820
Epoch: 111, Loss: 2.5801, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 112, Loss: 3.0539, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 113, Loss: 2.6532, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 114, Loss: 2.8189, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 115, Loss: 1.8683, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 116, Loss: 2.6714, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 117, Loss: 2.7024, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 118, Loss: 2.4847, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 119, Loss: 2.5123, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 120, Loss: 2.1058, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 121, Loss: 2.7367, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 122, Loss: 2.3529, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 123, Loss: 2.5203, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 124, Loss: 2.7578, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 125, Loss: 2.8492, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 126, Loss: 2.7462, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 127, Loss: 2.3486, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 128, Loss: 2.3562, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 129, Loss: 2.7527, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 130, Loss: 2.6569, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 131, Loss: 2.7352, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 132, Loss: 2.5502, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 133, Loss: 2.5172, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 134, Loss: 2.4857, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 135, Loss: 2.7919, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 136, Loss: 2.3624, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 137, Loss: 2.3581, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 138, Loss: 2.5558, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 139, Loss: 2.2465, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 140, Loss: 2.5144, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 141, Loss: 2.5416, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 142, Loss: 2.4777, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 143, Loss: 2.1636, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 144, Loss: 2.2532, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 145, Loss: 2.4879, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 146, Loss: 2.6321, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 147, Loss: 2.5944, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 148, Loss: 2.1243, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 149, Loss: 2.5773, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 150, Loss: 2.7930, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 151, Loss: 2.3688, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 152, Loss: 2.2154, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 153, Loss: 2.4271, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 154, Loss: 2.6542, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 155, Loss: 2.5119, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 156, Loss: 2.4800, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 157, Loss: 2.0856, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 158, Loss: 2.1343, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 159, Loss: 2.3404, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 160, Loss: 2.6639, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 161, Loss: 2.4612, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 162, Loss: 2.8510, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 163, Loss: 2.1813, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 164, Loss: 2.5564, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 165, Loss: 2.5515, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 166, Loss: 2.3437, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 167, Loss: 2.6262, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 168, Loss: 2.4651, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 169, Loss: 3.0850, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 170, Loss: 2.5139, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 171, Loss: 2.6363, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 172, Loss: 2.5185, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 173, Loss: 2.4566, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 174, Loss: 2.2402, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 175, Loss: 2.2686, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 176, Loss: 2.3512, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 177, Loss: 2.1336, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 178, Loss: 2.5313, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 179, Loss: 2.4630, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 180, Loss: 2.7084, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 181, Loss: 2.5297, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 182, Loss: 2.6694, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 183, Loss: 2.8391, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 184, Loss: 2.3802, Train: 1.0000, Val: 0.7560, Test: 0.7830
Epoch: 185, Loss: 2.4803, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 186, Loss: 2.5341, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 187, Loss: 2.4827, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 188, Loss: 2.6197, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 189, Loss: 2.6944, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 190, Loss: 2.8153, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 191, Loss: 2.4206, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 192, Loss: 2.3527, Train: 1.0000, Val: 0.7600, Test: 0.7850
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 2.0003, Train: 1.0000, Val: 0.7600, Test: 0.7870
Epoch: 194, Loss: 2.2018, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 195, Loss: 2.4563, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 196, Loss: 2.7298, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 197, Loss: 2.0746, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 198, Loss: 2.3239, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 199, Loss: 2.8286, Train: 1.0000, Val: 0.7600, Test: 0.7910
Epoch: 200, Loss: 2.2775, Train: 1.0000, Val: 0.7600, Test: 0.7900
MAD:  0.6145
Best Test Accuracy: 0.8220, Val Accuracy: 0.7880, Train Accuracy: 0.9929
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8556, Train: 0.1929, Val: 0.1240, Test: 0.1090
Epoch: 2, Loss: 4.8414, Train: 0.2929, Val: 0.1740, Test: 0.1760
Epoch: 3, Loss: 4.8259, Train: 0.3286, Val: 0.2180, Test: 0.2130
Epoch: 4, Loss: 4.8159, Train: 0.3357, Val: 0.2280, Test: 0.2280
Epoch: 5, Loss: 4.7883, Train: 0.3286, Val: 0.2200, Test: 0.2290
Epoch: 6, Loss: 4.7482, Train: 0.3214, Val: 0.2080, Test: 0.2250
Epoch: 7, Loss: 4.7619, Train: 0.3214, Val: 0.2060, Test: 0.2180
Epoch: 8, Loss: 4.7045, Train: 0.2929, Val: 0.2020, Test: 0.2110
Epoch: 9, Loss: 4.6704, Train: 0.2929, Val: 0.2020, Test: 0.2070
Epoch: 10, Loss: 4.5695, Train: 0.2714, Val: 0.1900, Test: 0.1910
Epoch: 11, Loss: 4.5200, Train: 0.2429, Val: 0.1720, Test: 0.1780
Epoch: 12, Loss: 4.5605, Train: 0.2357, Val: 0.1680, Test: 0.1760
Epoch: 13, Loss: 4.3772, Train: 0.2357, Val: 0.1680, Test: 0.1740
Epoch: 14, Loss: 4.3461, Train: 0.2286, Val: 0.1620, Test: 0.1630
Epoch: 15, Loss: 4.1025, Train: 0.2286, Val: 0.1600, Test: 0.1620
Epoch: 16, Loss: 4.2356, Train: 0.2357, Val: 0.1680, Test: 0.1760
Epoch: 17, Loss: 4.0089, Train: 0.2786, Val: 0.1860, Test: 0.1920
Epoch: 18, Loss: 4.1861, Train: 0.3071, Val: 0.2060, Test: 0.2130
Epoch: 19, Loss: 4.0303, Train: 0.3643, Val: 0.2200, Test: 0.2320
Epoch: 20, Loss: 4.0519, Train: 0.4000, Val: 0.2540, Test: 0.2600
Epoch: 21, Loss: 3.7991, Train: 0.4500, Val: 0.2700, Test: 0.2830
Epoch: 22, Loss: 3.8452, Train: 0.4857, Val: 0.2900, Test: 0.3000
Epoch: 23, Loss: 3.7869, Train: 0.6071, Val: 0.3340, Test: 0.3710
Epoch: 24, Loss: 3.9670, Train: 0.6714, Val: 0.4920, Test: 0.5120
Epoch: 25, Loss: 3.6500, Train: 0.7714, Val: 0.5860, Test: 0.6110
Epoch: 26, Loss: 3.7935, Train: 0.7929, Val: 0.6260, Test: 0.6790
Epoch: 27, Loss: 3.7594, Train: 0.7929, Val: 0.6420, Test: 0.6820
Epoch: 28, Loss: 3.6393, Train: 0.7929, Val: 0.6460, Test: 0.6680
Epoch: 29, Loss: 3.6512, Train: 0.7929, Val: 0.6200, Test: 0.6510
Epoch: 30, Loss: 3.6358, Train: 0.8000, Val: 0.6280, Test: 0.6610
Epoch: 31, Loss: 3.6799, Train: 0.8571, Val: 0.6620, Test: 0.6740
Epoch: 32, Loss: 3.3486, Train: 0.9000, Val: 0.6920, Test: 0.7130
Epoch: 33, Loss: 3.5292, Train: 0.9071, Val: 0.7340, Test: 0.7460
Epoch: 34, Loss: 3.1409, Train: 0.9214, Val: 0.7560, Test: 0.7630
Epoch: 35, Loss: 3.4285, Train: 0.9357, Val: 0.7700, Test: 0.7690
Epoch: 36, Loss: 3.2270, Train: 0.9357, Val: 0.7680, Test: 0.7710
Epoch: 37, Loss: 3.7085, Train: 0.9429, Val: 0.7680, Test: 0.7660
Epoch: 38, Loss: 3.3497, Train: 0.9357, Val: 0.7680, Test: 0.7630
Epoch: 39, Loss: 3.6593, Train: 0.9357, Val: 0.7640, Test: 0.7620
Epoch: 40, Loss: 3.3328, Train: 0.9214, Val: 0.7560, Test: 0.7620
Epoch: 41, Loss: 2.8718, Train: 0.9214, Val: 0.7520, Test: 0.7660
Epoch: 42, Loss: 3.1652, Train: 0.9143, Val: 0.7440, Test: 0.7570
Epoch: 43, Loss: 2.7316, Train: 0.9143, Val: 0.7480, Test: 0.7580
Epoch: 44, Loss: 3.1095, Train: 0.9214, Val: 0.7500, Test: 0.7540
Epoch: 45, Loss: 3.0507, Train: 0.9143, Val: 0.7520, Test: 0.7550
Epoch: 46, Loss: 3.3747, Train: 0.9286, Val: 0.7420, Test: 0.7580
Epoch: 47, Loss: 2.8300, Train: 0.9357, Val: 0.7420, Test: 0.7590
Epoch: 48, Loss: 2.6267, Train: 0.9429, Val: 0.7500, Test: 0.7610
Epoch: 49, Loss: 3.1318, Train: 0.9429, Val: 0.7620, Test: 0.7640
Epoch: 50, Loss: 3.0141, Train: 0.9500, Val: 0.7680, Test: 0.7700
Epoch: 51, Loss: 2.8504, Train: 0.9500, Val: 0.7680, Test: 0.7800
Epoch: 52, Loss: 2.5969, Train: 0.9643, Val: 0.7740, Test: 0.7830
Epoch: 53, Loss: 2.9451, Train: 0.9643, Val: 0.7800, Test: 0.7890
Epoch: 54, Loss: 2.7001, Train: 0.9714, Val: 0.7800, Test: 0.7970
Epoch: 55, Loss: 2.7557, Train: 0.9714, Val: 0.7760, Test: 0.7960
Epoch: 56, Loss: 3.1853, Train: 0.9786, Val: 0.7800, Test: 0.8010
Epoch: 57, Loss: 2.6712, Train: 0.9786, Val: 0.7860, Test: 0.8020
Epoch: 58, Loss: 2.4017, Train: 0.9786, Val: 0.7920, Test: 0.8010
Epoch: 59, Loss: 2.7032, Train: 0.9786, Val: 0.7900, Test: 0.7970
Epoch: 60, Loss: 2.6153, Train: 0.9786, Val: 0.7900, Test: 0.7990
Epoch: 61, Loss: 2.2331, Train: 0.9786, Val: 0.7960, Test: 0.8040
Epoch: 62, Loss: 2.5446, Train: 0.9786, Val: 0.7920, Test: 0.8060
Epoch: 63, Loss: 2.5838, Train: 0.9786, Val: 0.7880, Test: 0.8040
Epoch: 64, Loss: 2.8632, Train: 0.9786, Val: 0.7800, Test: 0.8030
Epoch: 65, Loss: 2.5664, Train: 0.9857, Val: 0.7800, Test: 0.8040
Epoch: 66, Loss: 2.7706, Train: 0.9857, Val: 0.7800, Test: 0.8040
Epoch: 67, Loss: 2.6225, Train: 0.9857, Val: 0.7840, Test: 0.8050
Epoch: 68, Loss: 2.3998, Train: 0.9857, Val: 0.7840, Test: 0.8050
Epoch: 69, Loss: 2.7896, Train: 0.9857, Val: 0.7860, Test: 0.8060
Epoch: 70, Loss: 2.5638, Train: 0.9857, Val: 0.7880, Test: 0.8010
Epoch: 71, Loss: 3.1880, Train: 0.9857, Val: 0.7880, Test: 0.8030
Epoch: 72, Loss: 2.7707, Train: 0.9857, Val: 0.7840, Test: 0.8060
Epoch: 73, Loss: 2.6045, Train: 0.9929, Val: 0.7840, Test: 0.8010
Epoch: 74, Loss: 2.5612, Train: 0.9929, Val: 0.7840, Test: 0.7990
Epoch: 75, Loss: 2.6663, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 76, Loss: 2.4996, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 77, Loss: 2.6666, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 78, Loss: 2.5540, Train: 0.9929, Val: 0.7820, Test: 0.7930
Epoch: 79, Loss: 2.4075, Train: 0.9929, Val: 0.7820, Test: 0.7860
Epoch: 80, Loss: 2.7057, Train: 0.9929, Val: 0.7780, Test: 0.7860
Epoch: 81, Loss: 2.4364, Train: 0.9929, Val: 0.7780, Test: 0.7870
Epoch: 82, Loss: 2.6889, Train: 0.9929, Val: 0.7740, Test: 0.7900
Epoch: 83, Loss: 2.6277, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 84, Loss: 2.5428, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 85, Loss: 2.5112, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 86, Loss: 2.6004, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 87, Loss: 2.8867, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 88, Loss: 2.8973, Train: 0.9929, Val: 0.7800, Test: 0.8060
Epoch: 89, Loss: 2.4556, Train: 0.9929, Val: 0.7780, Test: 0.8030
Epoch: 90, Loss: 2.7542, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 91, Loss: 2.3088, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 92, Loss: 2.9880, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 93, Loss: 2.7987, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 94, Loss: 2.1294, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 95, Loss: 2.4262, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 96, Loss: 2.6327, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 97, Loss: 2.5783, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 98, Loss: 2.3722, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 99, Loss: 2.4973, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 100, Loss: 2.5901, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 101, Loss: 2.2720, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 102, Loss: 2.7723, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 103, Loss: 2.2990, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 104, Loss: 2.2622, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 105, Loss: 2.2597, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 106, Loss: 2.5873, Train: 1.0000, Val: 0.7600, Test: 0.7940
Epoch: 107, Loss: 2.2219, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 108, Loss: 2.8161, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 109, Loss: 2.4272, Train: 1.0000, Val: 0.7700, Test: 0.7890
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 110, Loss: 2.5962, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 111, Loss: 2.3703, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 112, Loss: 2.0540, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 113, Loss: 2.4397, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 114, Loss: 2.3397, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 115, Loss: 2.6612, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 116, Loss: 2.6411, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 117, Loss: 2.5947, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 118, Loss: 2.2553, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 119, Loss: 2.5974, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 120, Loss: 2.2402, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 121, Loss: 2.5344, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 122, Loss: 2.0722, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 123, Loss: 2.3708, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 124, Loss: 2.1865, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 125, Loss: 2.3883, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 126, Loss: 2.2693, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 127, Loss: 2.2634, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 128, Loss: 2.2577, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 129, Loss: 2.2404, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 130, Loss: 2.4937, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 131, Loss: 2.4700, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 132, Loss: 2.5006, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 133, Loss: 2.4015, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 134, Loss: 2.1926, Train: 1.0000, Val: 0.7760, Test: 0.7800
Epoch: 135, Loss: 2.4725, Train: 1.0000, Val: 0.7820, Test: 0.7820
Epoch: 136, Loss: 2.4379, Train: 1.0000, Val: 0.7840, Test: 0.7880
Epoch: 137, Loss: 2.5817, Train: 1.0000, Val: 0.7840, Test: 0.7870
Epoch: 138, Loss: 2.2238, Train: 1.0000, Val: 0.7880, Test: 0.7890
Epoch: 139, Loss: 2.5741, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 140, Loss: 2.6113, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 141, Loss: 1.9882, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 142, Loss: 2.8017, Train: 1.0000, Val: 0.7900, Test: 0.8020
Epoch: 143, Loss: 2.4498, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 144, Loss: 2.5061, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 145, Loss: 2.1411, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 146, Loss: 2.3425, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 147, Loss: 2.5986, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 148, Loss: 2.2790, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 149, Loss: 2.5520, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 150, Loss: 2.7169, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 151, Loss: 2.3668, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 152, Loss: 2.5760, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 153, Loss: 2.5095, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 154, Loss: 2.5301, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 155, Loss: 2.2990, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 156, Loss: 2.4261, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 157, Loss: 2.2513, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 158, Loss: 2.6747, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 159, Loss: 2.9536, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 160, Loss: 2.5653, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 161, Loss: 2.8201, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 162, Loss: 2.3213, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 163, Loss: 2.6368, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 164, Loss: 2.1982, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 165, Loss: 2.2971, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 166, Loss: 2.4008, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 167, Loss: 2.5360, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 168, Loss: 2.4140, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 169, Loss: 2.6696, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 170, Loss: 2.5954, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 171, Loss: 2.7623, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 172, Loss: 2.4936, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 173, Loss: 2.5825, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 174, Loss: 2.5942, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 175, Loss: 2.4118, Train: 1.0000, Val: 0.7680, Test: 0.7820
Epoch: 176, Loss: 2.5533, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 177, Loss: 2.7028, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 178, Loss: 2.7634, Train: 1.0000, Val: 0.7660, Test: 0.7800
Epoch: 179, Loss: 2.4559, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 180, Loss: 2.4524, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 181, Loss: 2.6841, Train: 1.0000, Val: 0.7600, Test: 0.7810
Epoch: 182, Loss: 2.7362, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 183, Loss: 2.7340, Train: 1.0000, Val: 0.7580, Test: 0.7830
Epoch: 184, Loss: 2.4763, Train: 1.0000, Val: 0.7580, Test: 0.7830
Epoch: 185, Loss: 2.4554, Train: 1.0000, Val: 0.7580, Test: 0.7830
Epoch: 186, Loss: 2.3407, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 187, Loss: 2.6922, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 188, Loss: 2.3202, Train: 1.0000, Val: 0.7660, Test: 0.7800
Epoch: 189, Loss: 2.3280, Train: 1.0000, Val: 0.7680, Test: 0.7820
Epoch: 190, Loss: 2.2924, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 191, Loss: 2.5169, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 192, Loss: 2.6319, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 193, Loss: 2.1055, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 194, Loss: 2.2305, Train: 1.0000, Val: 0.7760, Test: 0.7850
Epoch: 195, Loss: 2.3384, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 196, Loss: 2.4793, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 197, Loss: 2.4194, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 198, Loss: 2.7259, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 199, Loss: 2.3133, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 200, Loss: 2.0719, Train: 1.0000, Val: 0.7780, Test: 0.7950
MAD:  0.7723
Best Test Accuracy: 0.8080, Val Accuracy: 0.7900, Train Accuracy: 1.0000
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8477, Train: 0.1500, Val: 0.3160, Test: 0.3120
Epoch: 2, Loss: 4.8343, Train: 0.1929, Val: 0.3240, Test: 0.3240
Epoch: 3, Loss: 4.8093, Train: 0.2214, Val: 0.3300, Test: 0.3300
Epoch: 4, Loss: 4.7797, Train: 0.2286, Val: 0.3300, Test: 0.3290
Epoch: 5, Loss: 4.7375, Train: 0.2286, Val: 0.3280, Test: 0.3280
Epoch: 6, Loss: 4.7020, Train: 0.2143, Val: 0.3240, Test: 0.3280
Epoch: 7, Loss: 4.6522, Train: 0.1857, Val: 0.3200, Test: 0.3240
Epoch: 8, Loss: 4.6356, Train: 0.1857, Val: 0.3160, Test: 0.3230
Epoch: 9, Loss: 4.5861, Train: 0.1857, Val: 0.3160, Test: 0.3230
Epoch: 10, Loss: 4.5321, Train: 0.1786, Val: 0.3160, Test: 0.3220
Epoch: 11, Loss: 4.3734, Train: 0.1786, Val: 0.3160, Test: 0.3220
Epoch: 12, Loss: 4.4121, Train: 0.1786, Val: 0.3160, Test: 0.3220
Epoch: 13, Loss: 4.3105, Train: 0.1786, Val: 0.3160, Test: 0.3220
Epoch: 14, Loss: 4.2421, Train: 0.1786, Val: 0.3160, Test: 0.3220
Epoch: 15, Loss: 4.2307, Train: 0.1786, Val: 0.3160, Test: 0.3220
Epoch: 16, Loss: 4.0441, Train: 0.1786, Val: 0.3160, Test: 0.3230
Epoch: 17, Loss: 4.0394, Train: 0.1929, Val: 0.3180, Test: 0.3260
Epoch: 18, Loss: 3.8600, Train: 0.2286, Val: 0.3300, Test: 0.3290
Epoch: 19, Loss: 3.9360, Train: 0.3429, Val: 0.3580, Test: 0.3650
Epoch: 20, Loss: 4.2564, Train: 0.6714, Val: 0.4880, Test: 0.5490
Epoch: 21, Loss: 3.8724, Train: 0.7500, Val: 0.5580, Test: 0.6030
Epoch: 22, Loss: 3.6469, Train: 0.7357, Val: 0.4720, Test: 0.5020
Epoch: 23, Loss: 3.9830, Train: 0.6857, Val: 0.4100, Test: 0.4490
Epoch: 24, Loss: 3.5321, Train: 0.6714, Val: 0.3980, Test: 0.4390
Epoch: 25, Loss: 3.6171, Train: 0.6714, Val: 0.4060, Test: 0.4350
Epoch: 26, Loss: 3.7630, Train: 0.6714, Val: 0.4040, Test: 0.4360
Epoch: 27, Loss: 3.5428, Train: 0.6786, Val: 0.4080, Test: 0.4480
Epoch: 28, Loss: 3.4373, Train: 0.6929, Val: 0.4180, Test: 0.4590
Epoch: 29, Loss: 3.5968, Train: 0.7143, Val: 0.4420, Test: 0.4640
Epoch: 30, Loss: 3.7200, Train: 0.7286, Val: 0.4660, Test: 0.5080
Epoch: 31, Loss: 3.6242, Train: 0.7643, Val: 0.5200, Test: 0.5570
Epoch: 32, Loss: 3.4252, Train: 0.7643, Val: 0.5560, Test: 0.5850
Epoch: 33, Loss: 3.5612, Train: 0.7857, Val: 0.5840, Test: 0.6020
Epoch: 34, Loss: 3.3215, Train: 0.8000, Val: 0.6120, Test: 0.6260
Epoch: 35, Loss: 3.3638, Train: 0.8286, Val: 0.6680, Test: 0.6750
Epoch: 36, Loss: 3.4775, Train: 0.8786, Val: 0.7100, Test: 0.7260
Epoch: 37, Loss: 3.3489, Train: 0.9143, Val: 0.7440, Test: 0.7590
Epoch: 38, Loss: 3.3634, Train: 0.9357, Val: 0.7440, Test: 0.7800
Epoch: 39, Loss: 3.3170, Train: 0.9357, Val: 0.7520, Test: 0.7900
Epoch: 40, Loss: 3.3667, Train: 0.9429, Val: 0.7580, Test: 0.7970
Epoch: 41, Loss: 3.3997, Train: 0.9429, Val: 0.7560, Test: 0.7930
Epoch: 42, Loss: 3.1614, Train: 0.9429, Val: 0.7500, Test: 0.7950
Epoch: 43, Loss: 3.4723, Train: 0.9429, Val: 0.7520, Test: 0.8000
Epoch: 44, Loss: 3.0964, Train: 0.9500, Val: 0.7460, Test: 0.7980
Epoch: 45, Loss: 3.1932, Train: 0.9571, Val: 0.7460, Test: 0.7970
Epoch: 46, Loss: 3.1270, Train: 0.9571, Val: 0.7520, Test: 0.7920
Epoch: 47, Loss: 2.9864, Train: 0.9571, Val: 0.7500, Test: 0.7920
Epoch: 48, Loss: 2.6139, Train: 0.9643, Val: 0.7580, Test: 0.7920
Epoch: 49, Loss: 2.7621, Train: 0.9571, Val: 0.7700, Test: 0.7930
Epoch: 50, Loss: 2.8956, Train: 0.9500, Val: 0.7720, Test: 0.7950
Epoch: 51, Loss: 3.2991, Train: 0.9500, Val: 0.7780, Test: 0.8000
Epoch: 52, Loss: 3.1024, Train: 0.9571, Val: 0.7780, Test: 0.8030
Epoch: 53, Loss: 3.1918, Train: 0.9643, Val: 0.7780, Test: 0.8040
Epoch: 54, Loss: 3.0091, Train: 0.9786, Val: 0.7820, Test: 0.8040
Epoch: 55, Loss: 3.0652, Train: 0.9786, Val: 0.7840, Test: 0.8040
Epoch: 56, Loss: 2.5626, Train: 0.9786, Val: 0.7880, Test: 0.8020
Epoch: 57, Loss: 2.8871, Train: 0.9786, Val: 0.7820, Test: 0.8050
Epoch: 58, Loss: 2.9611, Train: 0.9714, Val: 0.7760, Test: 0.7990
Epoch: 59, Loss: 2.7814, Train: 0.9786, Val: 0.7640, Test: 0.7930
Epoch: 60, Loss: 2.5689, Train: 0.9857, Val: 0.7680, Test: 0.7930
Epoch: 61, Loss: 2.8461, Train: 0.9857, Val: 0.7680, Test: 0.7920
Epoch: 62, Loss: 2.6177, Train: 0.9857, Val: 0.7680, Test: 0.7910
Epoch: 63, Loss: 2.7928, Train: 0.9857, Val: 0.7740, Test: 0.7920
Epoch: 64, Loss: 2.9023, Train: 0.9929, Val: 0.7760, Test: 0.7940
Epoch: 65, Loss: 2.6864, Train: 0.9857, Val: 0.7760, Test: 0.7960
Epoch: 66, Loss: 2.8565, Train: 0.9857, Val: 0.7760, Test: 0.7970
Epoch: 67, Loss: 2.7696, Train: 0.9857, Val: 0.7760, Test: 0.8000
Epoch: 68, Loss: 3.0707, Train: 0.9857, Val: 0.7800, Test: 0.7940
Epoch: 69, Loss: 2.4045, Train: 0.9857, Val: 0.7840, Test: 0.7980
Epoch: 70, Loss: 2.3783, Train: 0.9857, Val: 0.7880, Test: 0.8000
Epoch: 71, Loss: 2.7243, Train: 0.9857, Val: 0.7880, Test: 0.7980
Epoch: 72, Loss: 2.4621, Train: 0.9929, Val: 0.7880, Test: 0.7980
Epoch: 73, Loss: 2.8921, Train: 0.9929, Val: 0.7860, Test: 0.8000
Epoch: 74, Loss: 2.6034, Train: 0.9929, Val: 0.7800, Test: 0.7990
Epoch: 75, Loss: 2.4985, Train: 0.9929, Val: 0.7760, Test: 0.7990
Epoch: 76, Loss: 2.8877, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 77, Loss: 3.0377, Train: 1.0000, Val: 0.7600, Test: 0.7910
Epoch: 78, Loss: 2.5227, Train: 1.0000, Val: 0.7580, Test: 0.7900
Epoch: 79, Loss: 2.8594, Train: 1.0000, Val: 0.7580, Test: 0.7880
Epoch: 80, Loss: 2.6916, Train: 1.0000, Val: 0.7600, Test: 0.7900
Epoch: 81, Loss: 2.8539, Train: 1.0000, Val: 0.7580, Test: 0.7890
Epoch: 82, Loss: 2.1645, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 83, Loss: 2.5584, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 84, Loss: 2.7077, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 85, Loss: 2.6004, Train: 1.0000, Val: 0.7600, Test: 0.7860
Epoch: 86, Loss: 3.0205, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 87, Loss: 2.5446, Train: 1.0000, Val: 0.7580, Test: 0.7870
Epoch: 88, Loss: 2.8518, Train: 1.0000, Val: 0.7600, Test: 0.7880
Epoch: 89, Loss: 2.2060, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 90, Loss: 2.7758, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 91, Loss: 2.6186, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 92, Loss: 2.3263, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 93, Loss: 2.5412, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 94, Loss: 2.7776, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 95, Loss: 2.5287, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 96, Loss: 2.2851, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 97, Loss: 2.5764, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 98, Loss: 2.4700, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 99, Loss: 2.7001, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 100, Loss: 2.4279, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 101, Loss: 2.5533, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 102, Loss: 2.5731, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 103, Loss: 2.4732, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 104, Loss: 2.4588, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 105, Loss: 2.8666, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 106, Loss: 2.3931, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 107, Loss: 2.8292, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 108, Loss: 2.4652, Train: 1.0000, Val: 0.7600, Test: 0.7940
Epoch: 109, Loss: 2.5679, Train: 1.0000, Val: 0.7600, Test: 0.7970
Epoch: 110, Loss: 2.2080, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 111, Loss: 2.5086, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 112, Loss: 2.6618, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 113, Loss: 2.6771, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 114, Loss: 2.4365, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 115, Loss: 2.6190, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 116, Loss: 2.4627, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 117, Loss: 2.4009, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 118, Loss: 2.5132, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 119, Loss: 2.0196, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 120, Loss: 2.5170, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 121, Loss: 2.6501, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 122, Loss: 2.4422, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 123, Loss: 2.6590, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 124, Loss: 2.7662, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 125, Loss: 2.7719, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 126, Loss: 2.9740, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 127, Loss: 2.4441, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 128, Loss: 2.7499, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 129, Loss: 2.6678, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 130, Loss: 2.6352, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 131, Loss: 2.6848, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 132, Loss: 2.6156, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 133, Loss: 2.1500, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 134, Loss: 2.5156, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 135, Loss: 2.5686, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 136, Loss: 2.2173, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 137, Loss: 2.6360, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 138, Loss: 2.3874, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 139, Loss: 2.4750, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 140, Loss: 2.4264, Train: 1.0000, Val: 0.7820, Test: 0.7910
Epoch: 141, Loss: 2.7885, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 142, Loss: 2.1968, Train: 1.0000, Val: 0.7840, Test: 0.7900
Epoch: 143, Loss: 3.2316, Train: 1.0000, Val: 0.7840, Test: 0.7890
Epoch: 144, Loss: 2.2146, Train: 1.0000, Val: 0.7800, Test: 0.7860
Epoch: 145, Loss: 2.4545, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 146, Loss: 2.7681, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 147, Loss: 2.2261, Train: 1.0000, Val: 0.7720, Test: 0.7860
Epoch: 148, Loss: 2.6466, Train: 1.0000, Val: 0.7740, Test: 0.7870
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 149, Loss: 2.5403, Train: 1.0000, Val: 0.7780, Test: 0.7880
Epoch: 150, Loss: 2.5424, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 151, Loss: 2.5864, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 152, Loss: 2.8105, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 153, Loss: 2.3960, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 154, Loss: 2.1254, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 155, Loss: 2.2879, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 156, Loss: 2.5360, Train: 1.0000, Val: 0.7880, Test: 0.7960
Epoch: 157, Loss: 2.4814, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 158, Loss: 2.6597, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 159, Loss: 2.7746, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 160, Loss: 2.3214, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 161, Loss: 2.2883, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 162, Loss: 2.1117, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 163, Loss: 2.6655, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 164, Loss: 2.1241, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 165, Loss: 2.8154, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 166, Loss: 2.8579, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 167, Loss: 2.7440, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 168, Loss: 2.5343, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 169, Loss: 2.3576, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 170, Loss: 2.7991, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 171, Loss: 2.4728, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 172, Loss: 2.3323, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 173, Loss: 2.5882, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 174, Loss: 2.5381, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 175, Loss: 2.7359, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 176, Loss: 2.6150, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 177, Loss: 2.6435, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 178, Loss: 2.1332, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 179, Loss: 2.8295, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 180, Loss: 2.2893, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 181, Loss: 2.7071, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 182, Loss: 2.1831, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 183, Loss: 2.9471, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 184, Loss: 2.2837, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 185, Loss: 2.2886, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 186, Loss: 2.6311, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 187, Loss: 2.5525, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 188, Loss: 2.4457, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 189, Loss: 2.0436, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 190, Loss: 2.3062, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 191, Loss: 2.9183, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 192, Loss: 2.8714, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 193, Loss: 2.9333, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 194, Loss: 2.2212, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 195, Loss: 2.2924, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 196, Loss: 2.3079, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 197, Loss: 2.5227, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 198, Loss: 2.5365, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 199, Loss: 2.4156, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 200, Loss: 2.3915, Train: 1.0000, Val: 0.7720, Test: 0.7920
MAD:  0.6952
Best Test Accuracy: 0.8100, Val Accuracy: 0.7720, Train Accuracy: 1.0000
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8510, Train: 0.2214, Val: 0.1980, Test: 0.2350
Epoch: 2, Loss: 4.8309, Train: 0.3929, Val: 0.4120, Test: 0.4500
Epoch: 3, Loss: 4.8000, Train: 0.4929, Val: 0.4860, Test: 0.5100
Epoch: 4, Loss: 4.7749, Train: 0.5286, Val: 0.5240, Test: 0.5560
Epoch: 5, Loss: 4.7338, Train: 0.5857, Val: 0.5600, Test: 0.5730
Epoch: 6, Loss: 4.6795, Train: 0.6071, Val: 0.5700, Test: 0.5840
Epoch: 7, Loss: 4.6501, Train: 0.6143, Val: 0.5540, Test: 0.5670
Epoch: 8, Loss: 4.5616, Train: 0.6000, Val: 0.5320, Test: 0.5490
Epoch: 9, Loss: 4.4073, Train: 0.5857, Val: 0.5120, Test: 0.5200
Epoch: 10, Loss: 4.4247, Train: 0.5500, Val: 0.4860, Test: 0.4870
Epoch: 11, Loss: 4.4479, Train: 0.5286, Val: 0.4560, Test: 0.4470
Epoch: 12, Loss: 4.2364, Train: 0.4857, Val: 0.4080, Test: 0.4060
Epoch: 13, Loss: 4.1981, Train: 0.4429, Val: 0.3520, Test: 0.3340
Epoch: 14, Loss: 3.9512, Train: 0.4000, Val: 0.3060, Test: 0.2930
Epoch: 15, Loss: 3.9099, Train: 0.3643, Val: 0.2640, Test: 0.2690
Epoch: 16, Loss: 4.0023, Train: 0.3857, Val: 0.2580, Test: 0.2760
Epoch: 17, Loss: 3.9748, Train: 0.4500, Val: 0.3040, Test: 0.3220
Epoch: 18, Loss: 3.9779, Train: 0.6286, Val: 0.4200, Test: 0.4450
Epoch: 19, Loss: 3.4836, Train: 0.7714, Val: 0.5340, Test: 0.5680
Epoch: 20, Loss: 3.5681, Train: 0.7929, Val: 0.5780, Test: 0.6040
Epoch: 21, Loss: 3.7636, Train: 0.8286, Val: 0.5860, Test: 0.6090
Epoch: 22, Loss: 3.6880, Train: 0.8214, Val: 0.5820, Test: 0.6090
Epoch: 23, Loss: 3.6877, Train: 0.8214, Val: 0.5820, Test: 0.5940
Epoch: 24, Loss: 3.8956, Train: 0.8143, Val: 0.5800, Test: 0.5980
Epoch: 25, Loss: 3.4413, Train: 0.8286, Val: 0.5960, Test: 0.6210
Epoch: 26, Loss: 3.6122, Train: 0.8286, Val: 0.6220, Test: 0.6400
Epoch: 27, Loss: 3.4927, Train: 0.8571, Val: 0.6400, Test: 0.6540
Epoch: 28, Loss: 3.5767, Train: 0.8571, Val: 0.6500, Test: 0.6740
Epoch: 29, Loss: 3.3274, Train: 0.8643, Val: 0.6740, Test: 0.6970
Epoch: 30, Loss: 3.4191, Train: 0.9071, Val: 0.6900, Test: 0.7330
Epoch: 31, Loss: 3.3485, Train: 0.9357, Val: 0.7160, Test: 0.7560
Epoch: 32, Loss: 3.2369, Train: 0.9500, Val: 0.7300, Test: 0.7760
Epoch: 33, Loss: 3.3337, Train: 0.9571, Val: 0.7460, Test: 0.7840
Epoch: 34, Loss: 3.3762, Train: 0.9500, Val: 0.7640, Test: 0.7950
Epoch: 35, Loss: 3.5582, Train: 0.9429, Val: 0.7600, Test: 0.7950
Epoch: 36, Loss: 3.1272, Train: 0.9429, Val: 0.7660, Test: 0.7990
Epoch: 37, Loss: 2.9423, Train: 0.9429, Val: 0.7620, Test: 0.7950
Epoch: 38, Loss: 3.2982, Train: 0.9286, Val: 0.7620, Test: 0.7990
Epoch: 39, Loss: 3.2451, Train: 0.9286, Val: 0.7620, Test: 0.8020
Epoch: 40, Loss: 2.9812, Train: 0.9429, Val: 0.7560, Test: 0.7950
Epoch: 41, Loss: 3.0408, Train: 0.9429, Val: 0.7560, Test: 0.7850
Epoch: 42, Loss: 3.0712, Train: 0.9429, Val: 0.7500, Test: 0.7850
Epoch: 43, Loss: 3.3167, Train: 0.9429, Val: 0.7480, Test: 0.7840
Epoch: 44, Loss: 3.2383, Train: 0.9500, Val: 0.7480, Test: 0.7830
Epoch: 45, Loss: 2.8117, Train: 0.9500, Val: 0.7520, Test: 0.7840
Epoch: 46, Loss: 2.8487, Train: 0.9643, Val: 0.7580, Test: 0.7770
Epoch: 47, Loss: 2.8589, Train: 0.9571, Val: 0.7520, Test: 0.7810
Epoch: 48, Loss: 3.2641, Train: 0.9643, Val: 0.7580, Test: 0.7900
Epoch: 49, Loss: 3.1650, Train: 0.9643, Val: 0.7620, Test: 0.7950
Epoch: 50, Loss: 2.9974, Train: 0.9643, Val: 0.7600, Test: 0.8030
Epoch: 51, Loss: 2.7525, Train: 0.9643, Val: 0.7660, Test: 0.8110
Epoch: 52, Loss: 2.9153, Train: 0.9786, Val: 0.7740, Test: 0.8120
Epoch: 53, Loss: 2.8646, Train: 0.9786, Val: 0.7740, Test: 0.8090
Epoch: 54, Loss: 2.8983, Train: 0.9786, Val: 0.7760, Test: 0.8060
Epoch: 55, Loss: 3.0227, Train: 0.9786, Val: 0.7760, Test: 0.8050
Epoch: 56, Loss: 3.0499, Train: 0.9786, Val: 0.7840, Test: 0.8090
Epoch: 57, Loss: 2.7919, Train: 0.9786, Val: 0.7860, Test: 0.8130
Epoch: 58, Loss: 2.5861, Train: 0.9786, Val: 0.7820, Test: 0.8130
Epoch: 59, Loss: 2.5670, Train: 0.9786, Val: 0.7820, Test: 0.8150
Epoch: 60, Loss: 2.8279, Train: 0.9786, Val: 0.7820, Test: 0.8160
Epoch: 61, Loss: 2.9374, Train: 0.9786, Val: 0.7780, Test: 0.8120
Epoch: 62, Loss: 2.9200, Train: 0.9786, Val: 0.7780, Test: 0.8120
Epoch: 63, Loss: 2.7832, Train: 0.9786, Val: 0.7740, Test: 0.8080
Epoch: 64, Loss: 3.0540, Train: 0.9786, Val: 0.7700, Test: 0.8020
Epoch: 65, Loss: 2.5207, Train: 0.9786, Val: 0.7680, Test: 0.8020
Epoch: 66, Loss: 2.4671, Train: 0.9786, Val: 0.7700, Test: 0.7980
Epoch: 67, Loss: 2.5197, Train: 0.9857, Val: 0.7720, Test: 0.8010
Epoch: 68, Loss: 2.8315, Train: 0.9857, Val: 0.7680, Test: 0.7960
Epoch: 69, Loss: 2.6516, Train: 0.9786, Val: 0.7680, Test: 0.7980
Epoch: 70, Loss: 2.9443, Train: 0.9786, Val: 0.7700, Test: 0.7960
Epoch: 71, Loss: 3.0119, Train: 0.9786, Val: 0.7640, Test: 0.7900
Epoch: 72, Loss: 2.7232, Train: 0.9857, Val: 0.7700, Test: 0.7930
Epoch: 73, Loss: 2.4652, Train: 0.9857, Val: 0.7640, Test: 0.7940
Epoch: 74, Loss: 2.5796, Train: 0.9857, Val: 0.7640, Test: 0.7940
Epoch: 75, Loss: 3.1486, Train: 0.9857, Val: 0.7640, Test: 0.7910
Epoch: 76, Loss: 2.7667, Train: 0.9857, Val: 0.7640, Test: 0.7910
Epoch: 77, Loss: 2.6158, Train: 0.9929, Val: 0.7680, Test: 0.7900
Epoch: 78, Loss: 2.8413, Train: 0.9929, Val: 0.7680, Test: 0.7940
Epoch: 79, Loss: 2.3137, Train: 0.9929, Val: 0.7660, Test: 0.7950
Epoch: 80, Loss: 2.4652, Train: 0.9929, Val: 0.7660, Test: 0.7960
Epoch: 81, Loss: 2.6593, Train: 0.9929, Val: 0.7680, Test: 0.7950
Epoch: 82, Loss: 2.4211, Train: 0.9929, Val: 0.7700, Test: 0.7960
Epoch: 83, Loss: 2.8000, Train: 0.9929, Val: 0.7680, Test: 0.7980
Epoch: 84, Loss: 2.6280, Train: 0.9929, Val: 0.7620, Test: 0.7960
Epoch: 85, Loss: 2.7184, Train: 0.9929, Val: 0.7660, Test: 0.8000
Epoch: 86, Loss: 2.6396, Train: 1.0000, Val: 0.7580, Test: 0.7980
Epoch: 87, Loss: 2.4789, Train: 1.0000, Val: 0.7580, Test: 0.7980
Epoch: 88, Loss: 2.5717, Train: 1.0000, Val: 0.7580, Test: 0.7990
Epoch: 89, Loss: 2.5693, Train: 1.0000, Val: 0.7620, Test: 0.8000
Epoch: 90, Loss: 2.7409, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 91, Loss: 2.5316, Train: 1.0000, Val: 0.7620, Test: 0.8010
Epoch: 92, Loss: 2.3980, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 93, Loss: 2.5958, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 94, Loss: 2.2456, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 95, Loss: 2.5840, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 96, Loss: 2.5617, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 97, Loss: 2.6979, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 98, Loss: 2.9810, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 99, Loss: 2.4496, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 100, Loss: 2.2354, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 101, Loss: 2.4390, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 102, Loss: 2.9933, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 103, Loss: 2.3390, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 104, Loss: 2.3760, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 105, Loss: 2.6521, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 106, Loss: 2.3502, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 107, Loss: 2.6400, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 108, Loss: 2.3276, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 109, Loss: 2.5758, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 110, Loss: 2.3004, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 111, Loss: 2.5776, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 112, Loss: 2.4639, Train: 1.0000, Val: 0.7620, Test: 0.7980
Epoch: 113, Loss: 2.5563, Train: 1.0000, Val: 0.7640, Test: 0.7950
Epoch: 114, Loss: 2.3220, Train: 1.0000, Val: 0.7560, Test: 0.7960
Epoch: 115, Loss: 2.4842, Train: 1.0000, Val: 0.7540, Test: 0.7960
Epoch: 116, Loss: 2.6069, Train: 1.0000, Val: 0.7540, Test: 0.7950
Epoch: 117, Loss: 2.2366, Train: 1.0000, Val: 0.7540, Test: 0.7920
Epoch: 118, Loss: 2.1953, Train: 1.0000, Val: 0.7540, Test: 0.7910
Epoch: 119, Loss: 2.6288, Train: 1.0000, Val: 0.7580, Test: 0.7920
Epoch: 120, Loss: 2.6120, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 121, Loss: 2.2055, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 122, Loss: 2.5271, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 123, Loss: 2.2123, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 124, Loss: 2.5296, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 125, Loss: 2.2249, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 126, Loss: 2.6034, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 127, Loss: 2.5652, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 128, Loss: 2.9866, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 129, Loss: 2.3443, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 130, Loss: 2.5409, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 131, Loss: 2.3459, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 132, Loss: 2.4003, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 133, Loss: 2.0315, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 134, Loss: 2.4636, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 135, Loss: 2.4804, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 136, Loss: 2.4697, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 137, Loss: 2.4554, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 138, Loss: 2.5287, Train: 1.0000, Val: 0.7600, Test: 0.7900
Epoch: 139, Loss: 2.1697, Train: 1.0000, Val: 0.7560, Test: 0.7960
Epoch: 140, Loss: 2.5102, Train: 1.0000, Val: 0.7500, Test: 0.7960
Epoch: 141, Loss: 2.6940, Train: 1.0000, Val: 0.7520, Test: 0.7940
Epoch: 142, Loss: 2.9228, Train: 1.0000, Val: 0.7540, Test: 0.7890
Epoch: 143, Loss: 2.5759, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 144, Loss: 2.2882, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 145, Loss: 2.4023, Train: 1.0000, Val: 0.7560, Test: 0.7920
Epoch: 146, Loss: 2.1634, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 147, Loss: 2.5249, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 148, Loss: 2.5790, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 149, Loss: 2.6972, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 150, Loss: 2.3456, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 151, Loss: 2.4913, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 152, Loss: 2.4236, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 153, Loss: 2.5966, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 154, Loss: 2.4649, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 155, Loss: 2.3769, Train: 1.0000, Val: 0.7660, Test: 0.7980
Epoch: 156, Loss: 2.4357, Train: 1.0000, Val: 0.7640, Test: 0.7980
Epoch: 157, Loss: 2.8157, Train: 1.0000, Val: 0.7600, Test: 0.7970
Epoch: 158, Loss: 2.6268, Train: 1.0000, Val: 0.7600, Test: 0.7960
Epoch: 159, Loss: 2.0970, Train: 1.0000, Val: 0.7560, Test: 0.7960
Epoch: 160, Loss: 2.2460, Train: 1.0000, Val: 0.7580, Test: 0.7920
Epoch: 161, Loss: 2.3065, Train: 1.0000, Val: 0.7540, Test: 0.7910
Epoch: 162, Loss: 2.1463, Train: 1.0000, Val: 0.7520, Test: 0.7880
Epoch: 163, Loss: 2.4748, Train: 1.0000, Val: 0.7520, Test: 0.7880
Epoch: 164, Loss: 2.4487, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 165, Loss: 2.2259, Train: 1.0000, Val: 0.7580, Test: 0.7830
Epoch: 166, Loss: 2.3897, Train: 1.0000, Val: 0.7580, Test: 0.7830
Epoch: 167, Loss: 2.5772, Train: 1.0000, Val: 0.7560, Test: 0.7810
Epoch: 168, Loss: 2.6478, Train: 1.0000, Val: 0.7580, Test: 0.7820
Epoch: 169, Loss: 2.1802, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 170, Loss: 2.2564, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 171, Loss: 2.6004, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 172, Loss: 2.3020, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 173, Loss: 2.5421, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 174, Loss: 2.6978, Train: 1.0000, Val: 0.7660, Test: 0.7820
Epoch: 175, Loss: 2.5083, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 176, Loss: 2.5375, Train: 1.0000, Val: 0.7620, Test: 0.7810
Epoch: 177, Loss: 2.6993, Train: 1.0000, Val: 0.7640, Test: 0.7800
Epoch: 178, Loss: 2.7177, Train: 1.0000, Val: 0.7560, Test: 0.7840
Epoch: 179, Loss: 2.4584, Train: 1.0000, Val: 0.7540, Test: 0.7800
Epoch: 180, Loss: 2.7617, Train: 1.0000, Val: 0.7520, Test: 0.7820
Epoch: 181, Loss: 2.2191, Train: 1.0000, Val: 0.7500, Test: 0.7840
Epoch: 182, Loss: 2.4189, Train: 1.0000, Val: 0.7500, Test: 0.7880
Epoch: 183, Loss: 2.2067, Train: 1.0000, Val: 0.7500, Test: 0.7900
Epoch: 184, Loss: 2.5809, Train: 1.0000, Val: 0.7500, Test: 0.7910
Epoch: 185, Loss: 2.0673, Train: 1.0000, Val: 0.7500, Test: 0.7910
Epoch: 186, Loss: 2.4576, Train: 1.0000, Val: 0.7520, Test: 0.7950
Epoch: 187, Loss: 2.5939, Train: 1.0000, Val: 0.7560, Test: 0.7970
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 188, Loss: 2.6872, Train: 1.0000, Val: 0.7560, Test: 0.7990
Epoch: 189, Loss: 2.3130, Train: 1.0000, Val: 0.7540, Test: 0.7970
Epoch: 190, Loss: 2.4869, Train: 1.0000, Val: 0.7500, Test: 0.7970
Epoch: 191, Loss: 2.4789, Train: 1.0000, Val: 0.7500, Test: 0.7990
Epoch: 192, Loss: 2.3783, Train: 1.0000, Val: 0.7520, Test: 0.8000
Epoch: 193, Loss: 2.2719, Train: 1.0000, Val: 0.7580, Test: 0.7990
Epoch: 194, Loss: 2.4308, Train: 1.0000, Val: 0.7580, Test: 0.8030
Epoch: 195, Loss: 2.8649, Train: 1.0000, Val: 0.7600, Test: 0.8040
Epoch: 196, Loss: 2.2521, Train: 1.0000, Val: 0.7580, Test: 0.8000
Epoch: 197, Loss: 2.4778, Train: 1.0000, Val: 0.7540, Test: 0.7970
Epoch: 198, Loss: 2.7614, Train: 1.0000, Val: 0.7540, Test: 0.7960
Epoch: 199, Loss: 2.4833, Train: 1.0000, Val: 0.7580, Test: 0.7950
Epoch: 200, Loss: 2.1990, Train: 1.0000, Val: 0.7580, Test: 0.7950
MAD:  0.38
Best Test Accuracy: 0.8160, Val Accuracy: 0.7820, Train Accuracy: 0.9786
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8565, Train: 0.0643, Val: 0.0120, Test: 0.0190
Epoch: 2, Loss: 4.8459, Train: 0.2286, Val: 0.0560, Test: 0.0900
Epoch: 3, Loss: 4.8386, Train: 0.3357, Val: 0.1440, Test: 0.1810
Epoch: 4, Loss: 4.8280, Train: 0.4786, Val: 0.2520, Test: 0.2780
Epoch: 5, Loss: 4.8175, Train: 0.4929, Val: 0.3180, Test: 0.3210
Epoch: 6, Loss: 4.7808, Train: 0.5357, Val: 0.3380, Test: 0.3330
Epoch: 7, Loss: 4.7443, Train: 0.5357, Val: 0.3400, Test: 0.3240
Epoch: 8, Loss: 4.7543, Train: 0.5143, Val: 0.3180, Test: 0.3160
Epoch: 9, Loss: 4.7009, Train: 0.5071, Val: 0.3040, Test: 0.3070
Epoch: 10, Loss: 4.7307, Train: 0.5286, Val: 0.3060, Test: 0.2990
Epoch: 11, Loss: 4.6168, Train: 0.5357, Val: 0.3180, Test: 0.3090
Epoch: 12, Loss: 4.5925, Train: 0.5357, Val: 0.3260, Test: 0.3120
Epoch: 13, Loss: 4.5515, Train: 0.5571, Val: 0.3400, Test: 0.3310
Epoch: 14, Loss: 4.4574, Train: 0.5714, Val: 0.3540, Test: 0.3480
Epoch: 15, Loss: 4.2744, Train: 0.5929, Val: 0.3580, Test: 0.3630
Epoch: 16, Loss: 4.2661, Train: 0.6214, Val: 0.3860, Test: 0.3990
Epoch: 17, Loss: 4.2431, Train: 0.6357, Val: 0.4060, Test: 0.4120
Epoch: 18, Loss: 3.9927, Train: 0.6429, Val: 0.4220, Test: 0.4230
Epoch: 19, Loss: 3.7984, Train: 0.6429, Val: 0.4260, Test: 0.4230
Epoch: 20, Loss: 3.9747, Train: 0.6429, Val: 0.4240, Test: 0.4260
Epoch: 21, Loss: 3.8314, Train: 0.6429, Val: 0.4200, Test: 0.4320
Epoch: 22, Loss: 3.8786, Train: 0.6429, Val: 0.4260, Test: 0.4330
Epoch: 23, Loss: 3.7785, Train: 0.6571, Val: 0.4260, Test: 0.4320
Epoch: 24, Loss: 3.6265, Train: 0.6714, Val: 0.4260, Test: 0.4400
Epoch: 25, Loss: 3.7137, Train: 0.6857, Val: 0.4300, Test: 0.4490
Epoch: 26, Loss: 3.9266, Train: 0.7000, Val: 0.4560, Test: 0.4820
Epoch: 27, Loss: 3.6855, Train: 0.8929, Val: 0.6420, Test: 0.6780
Epoch: 28, Loss: 3.5004, Train: 0.9143, Val: 0.7620, Test: 0.7960
Epoch: 29, Loss: 3.4522, Train: 0.9214, Val: 0.7860, Test: 0.8160
Epoch: 30, Loss: 3.2909, Train: 0.8714, Val: 0.7620, Test: 0.7930
Epoch: 31, Loss: 3.6032, Train: 0.8714, Val: 0.7500, Test: 0.7760
Epoch: 32, Loss: 3.1236, Train: 0.8500, Val: 0.7540, Test: 0.7550
Epoch: 33, Loss: 3.6338, Train: 0.8643, Val: 0.7400, Test: 0.7540
Epoch: 34, Loss: 3.4290, Train: 0.8929, Val: 0.7340, Test: 0.7580
Epoch: 35, Loss: 3.3260, Train: 0.9071, Val: 0.7380, Test: 0.7670
Epoch: 36, Loss: 3.0758, Train: 0.9071, Val: 0.7460, Test: 0.7790
Epoch: 37, Loss: 3.4161, Train: 0.9429, Val: 0.7720, Test: 0.7900
Epoch: 38, Loss: 2.9612, Train: 0.9429, Val: 0.7700, Test: 0.7920
Epoch: 39, Loss: 3.0819, Train: 0.9357, Val: 0.7820, Test: 0.7960
Epoch: 40, Loss: 3.1251, Train: 0.9286, Val: 0.7760, Test: 0.7960
Epoch: 41, Loss: 3.0586, Train: 0.9214, Val: 0.7700, Test: 0.7920
Epoch: 42, Loss: 3.3984, Train: 0.9286, Val: 0.7600, Test: 0.7840
Epoch: 43, Loss: 3.2889, Train: 0.9357, Val: 0.7480, Test: 0.7810
Epoch: 44, Loss: 3.3984, Train: 0.9214, Val: 0.7420, Test: 0.7730
Epoch: 45, Loss: 3.0333, Train: 0.9286, Val: 0.7420, Test: 0.7730
Epoch: 46, Loss: 3.1544, Train: 0.9429, Val: 0.7480, Test: 0.7760
Epoch: 47, Loss: 2.7671, Train: 0.9429, Val: 0.7440, Test: 0.7770
Epoch: 48, Loss: 3.1304, Train: 0.9500, Val: 0.7500, Test: 0.7760
Epoch: 49, Loss: 2.9494, Train: 0.9643, Val: 0.7580, Test: 0.7770
Epoch: 50, Loss: 2.8877, Train: 0.9643, Val: 0.7620, Test: 0.7740
Epoch: 51, Loss: 2.5469, Train: 0.9643, Val: 0.7640, Test: 0.7770
Epoch: 52, Loss: 2.7251, Train: 0.9643, Val: 0.7660, Test: 0.7860
Epoch: 53, Loss: 2.9045, Train: 0.9786, Val: 0.7740, Test: 0.7910
Epoch: 54, Loss: 3.2947, Train: 0.9786, Val: 0.7720, Test: 0.7890
Epoch: 55, Loss: 2.5314, Train: 0.9786, Val: 0.7680, Test: 0.7940
Epoch: 56, Loss: 2.6017, Train: 0.9857, Val: 0.7660, Test: 0.7990
Epoch: 57, Loss: 3.0828, Train: 0.9857, Val: 0.7680, Test: 0.8020
Epoch: 58, Loss: 2.7252, Train: 0.9857, Val: 0.7660, Test: 0.7970
Epoch: 59, Loss: 3.1442, Train: 0.9857, Val: 0.7640, Test: 0.8000
Epoch: 60, Loss: 2.8580, Train: 0.9857, Val: 0.7640, Test: 0.7970
Epoch: 61, Loss: 2.6861, Train: 0.9857, Val: 0.7680, Test: 0.7950
Epoch: 62, Loss: 2.5014, Train: 0.9857, Val: 0.7680, Test: 0.7960
Epoch: 63, Loss: 2.8122, Train: 0.9857, Val: 0.7800, Test: 0.7970
Epoch: 64, Loss: 2.9326, Train: 0.9857, Val: 0.7840, Test: 0.7990
Epoch: 65, Loss: 2.7769, Train: 0.9857, Val: 0.7820, Test: 0.7960
Epoch: 66, Loss: 2.7437, Train: 0.9857, Val: 0.7780, Test: 0.7950
Epoch: 67, Loss: 2.7697, Train: 0.9857, Val: 0.7800, Test: 0.7990
Epoch: 68, Loss: 2.7309, Train: 0.9857, Val: 0.7820, Test: 0.8030
Epoch: 69, Loss: 2.7666, Train: 0.9857, Val: 0.7780, Test: 0.8050
Epoch: 70, Loss: 2.5256, Train: 0.9929, Val: 0.7780, Test: 0.8070
Epoch: 71, Loss: 2.7414, Train: 0.9929, Val: 0.7800, Test: 0.8060
Epoch: 72, Loss: 2.5552, Train: 0.9929, Val: 0.7780, Test: 0.8060
Epoch: 73, Loss: 2.6247, Train: 0.9929, Val: 0.7720, Test: 0.8020
Epoch: 74, Loss: 2.4920, Train: 0.9929, Val: 0.7700, Test: 0.8030
Epoch: 75, Loss: 2.9450, Train: 0.9929, Val: 0.7700, Test: 0.8020
Epoch: 76, Loss: 2.6085, Train: 0.9929, Val: 0.7640, Test: 0.7950
Epoch: 77, Loss: 2.1949, Train: 0.9929, Val: 0.7640, Test: 0.7940
Epoch: 78, Loss: 2.4010, Train: 0.9929, Val: 0.7640, Test: 0.7920
Epoch: 79, Loss: 2.8160, Train: 0.9929, Val: 0.7640, Test: 0.7900
Epoch: 80, Loss: 2.4100, Train: 0.9929, Val: 0.7660, Test: 0.7920
Epoch: 81, Loss: 2.3168, Train: 0.9929, Val: 0.7660, Test: 0.7990
Epoch: 82, Loss: 2.4321, Train: 0.9929, Val: 0.7700, Test: 0.8030
Epoch: 83, Loss: 2.7678, Train: 0.9929, Val: 0.7760, Test: 0.8060
Epoch: 84, Loss: 2.7015, Train: 0.9929, Val: 0.7780, Test: 0.8060
Epoch: 85, Loss: 2.6558, Train: 0.9929, Val: 0.7800, Test: 0.8080
Epoch: 86, Loss: 2.0928, Train: 0.9929, Val: 0.7800, Test: 0.8040
Epoch: 87, Loss: 2.6375, Train: 0.9929, Val: 0.7780, Test: 0.8070
Epoch: 88, Loss: 2.7848, Train: 0.9929, Val: 0.7760, Test: 0.8060
Epoch: 89, Loss: 2.5198, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 90, Loss: 2.2494, Train: 1.0000, Val: 0.7660, Test: 0.8000
Epoch: 91, Loss: 2.6378, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 92, Loss: 2.3914, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 93, Loss: 2.6339, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 94, Loss: 2.5635, Train: 1.0000, Val: 0.7600, Test: 0.7960
Epoch: 95, Loss: 2.6847, Train: 1.0000, Val: 0.7600, Test: 0.7960
Epoch: 96, Loss: 2.3781, Train: 1.0000, Val: 0.7600, Test: 0.7940
Epoch: 97, Loss: 2.4911, Train: 1.0000, Val: 0.7560, Test: 0.7930
Epoch: 98, Loss: 2.3802, Train: 1.0000, Val: 0.7580, Test: 0.7920
Epoch: 99, Loss: 2.6447, Train: 1.0000, Val: 0.7580, Test: 0.7940
Epoch: 100, Loss: 2.3890, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 101, Loss: 2.4702, Train: 1.0000, Val: 0.7640, Test: 0.7950
Epoch: 102, Loss: 2.6616, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 103, Loss: 2.6504, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 104, Loss: 2.3691, Train: 1.0000, Val: 0.7660, Test: 0.7910
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 105, Loss: 2.5476, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 106, Loss: 2.6769, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 107, Loss: 2.4463, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 108, Loss: 2.3406, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 109, Loss: 2.2041, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 110, Loss: 2.5554, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 111, Loss: 2.3955, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 112, Loss: 2.6626, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 113, Loss: 2.3429, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 114, Loss: 2.4428, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 115, Loss: 2.3690, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 116, Loss: 2.8012, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 117, Loss: 2.3940, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 118, Loss: 2.3591, Train: 1.0000, Val: 0.7580, Test: 0.7940
Epoch: 119, Loss: 2.9276, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 120, Loss: 2.7684, Train: 1.0000, Val: 0.7620, Test: 0.7980
Epoch: 121, Loss: 2.5845, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 122, Loss: 2.3517, Train: 1.0000, Val: 0.7660, Test: 0.8020
Epoch: 123, Loss: 2.5217, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 124, Loss: 2.7792, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 125, Loss: 2.5280, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 126, Loss: 2.1851, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 127, Loss: 2.4751, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 128, Loss: 2.3126, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 129, Loss: 2.5782, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 130, Loss: 2.4514, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 131, Loss: 2.8455, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 132, Loss: 2.2193, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 133, Loss: 2.2821, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 134, Loss: 2.5120, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 135, Loss: 2.5584, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 136, Loss: 2.5035, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 137, Loss: 2.4071, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 138, Loss: 2.3986, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 139, Loss: 2.4173, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 140, Loss: 2.5001, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 141, Loss: 2.0845, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 142, Loss: 2.5819, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 143, Loss: 2.2434, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 144, Loss: 2.6091, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 145, Loss: 2.5982, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 146, Loss: 2.0330, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 147, Loss: 2.2846, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 148, Loss: 2.8802, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 149, Loss: 2.5656, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 150, Loss: 2.4784, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 151, Loss: 2.6678, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 152, Loss: 2.9594, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 153, Loss: 2.4906, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 154, Loss: 2.2406, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 155, Loss: 2.2647, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 156, Loss: 1.9948, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 157, Loss: 2.3283, Train: 1.0000, Val: 0.7640, Test: 0.7980
Epoch: 158, Loss: 2.7469, Train: 1.0000, Val: 0.7640, Test: 0.7990
Epoch: 159, Loss: 2.7842, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 160, Loss: 2.4005, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 161, Loss: 2.2174, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 162, Loss: 2.3370, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 163, Loss: 2.0064, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 164, Loss: 2.2498, Train: 1.0000, Val: 0.7660, Test: 0.8070
Epoch: 165, Loss: 2.1674, Train: 1.0000, Val: 0.7660, Test: 0.8060
Epoch: 166, Loss: 2.6449, Train: 1.0000, Val: 0.7620, Test: 0.8070
Epoch: 167, Loss: 2.3450, Train: 1.0000, Val: 0.7620, Test: 0.8050
Epoch: 168, Loss: 2.2530, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 169, Loss: 2.3797, Train: 1.0000, Val: 0.7660, Test: 0.8060
Epoch: 170, Loss: 2.5310, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 171, Loss: 2.6037, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 172, Loss: 2.5452, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 173, Loss: 2.4685, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 174, Loss: 2.5540, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 175, Loss: 2.4624, Train: 1.0000, Val: 0.7580, Test: 0.7930
Epoch: 176, Loss: 2.3120, Train: 1.0000, Val: 0.7560, Test: 0.7880
Epoch: 177, Loss: 2.1857, Train: 1.0000, Val: 0.7560, Test: 0.7880
Epoch: 178, Loss: 2.5162, Train: 1.0000, Val: 0.7540, Test: 0.7860
Epoch: 179, Loss: 2.8421, Train: 1.0000, Val: 0.7560, Test: 0.7890
Epoch: 180, Loss: 2.3410, Train: 1.0000, Val: 0.7540, Test: 0.7910
Epoch: 181, Loss: 2.3153, Train: 1.0000, Val: 0.7540, Test: 0.7960
Epoch: 182, Loss: 2.3753, Train: 1.0000, Val: 0.7600, Test: 0.8020
Epoch: 183, Loss: 2.5149, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 184, Loss: 2.6581, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 185, Loss: 2.6306, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 186, Loss: 2.6330, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 187, Loss: 2.6260, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 188, Loss: 2.2044, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 189, Loss: 2.4939, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 190, Loss: 2.6694, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 191, Loss: 2.6640, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 192, Loss: 2.5431, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 193, Loss: 2.6514, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 194, Loss: 2.2263, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 195, Loss: 2.7024, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 196, Loss: 2.3639, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 197, Loss: 2.4186, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 198, Loss: 2.4541, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 199, Loss: 2.2763, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 200, Loss: 2.1790, Train: 1.0000, Val: 0.7620, Test: 0.7890
MAD:  0.0403
Best Test Accuracy: 0.8160, Val Accuracy: 0.7860, Train Accuracy: 0.9214
Training completed.
Average Test Accuracy:  0.8158 ± 0.00483321838943779
Average MAD:  0.50191 ± 0.24499589567990726
