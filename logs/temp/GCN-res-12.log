Seed:  0
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 12.7678, Train: 0.1429, Val: 0.2960, Test: 0.2950
Epoch: 2, Loss: 8.6928, Train: 0.1357, Val: 0.2760, Test: 0.2690
Epoch: 3, Loss: 5.7546, Train: 0.1714, Val: 0.1740, Test: 0.2000
Epoch: 4, Loss: 5.6585, Train: 0.1357, Val: 0.1260, Test: 0.1490
Epoch: 5, Loss: 4.0119, Train: 0.1357, Val: 0.0900, Test: 0.1210
Epoch: 6, Loss: 3.5444, Train: 0.1571, Val: 0.0660, Test: 0.0840
Epoch: 7, Loss: 3.2170, Train: 0.1214, Val: 0.0660, Test: 0.0850
Epoch: 8, Loss: 4.0067, Train: 0.1571, Val: 0.0900, Test: 0.1020
Epoch: 9, Loss: 3.0322, Train: 0.1643, Val: 0.1060, Test: 0.1170
Epoch: 10, Loss: 2.9082, Train: 0.1571, Val: 0.1440, Test: 0.1260
Epoch: 11, Loss: 2.9453, Train: 0.1786, Val: 0.1600, Test: 0.1560
Epoch: 12, Loss: 2.7176, Train: 0.2000, Val: 0.1580, Test: 0.1570
Epoch: 13, Loss: 3.3574, Train: 0.1714, Val: 0.1600, Test: 0.1450
Epoch: 14, Loss: 2.5599, Train: 0.1643, Val: 0.1560, Test: 0.1460
Epoch: 15, Loss: 2.6810, Train: 0.1643, Val: 0.1620, Test: 0.1470
Epoch: 16, Loss: 2.0577, Train: 0.1571, Val: 0.1540, Test: 0.1400
Epoch: 17, Loss: 2.1731, Train: 0.1500, Val: 0.1600, Test: 0.1420
Epoch: 18, Loss: 2.2741, Train: 0.1571, Val: 0.1680, Test: 0.1480
Epoch: 19, Loss: 2.3818, Train: 0.1571, Val: 0.1680, Test: 0.1490
Epoch: 20, Loss: 2.2492, Train: 0.1571, Val: 0.1660, Test: 0.1500
Epoch: 21, Loss: 2.1821, Train: 0.1500, Val: 0.1620, Test: 0.1490
Epoch: 22, Loss: 2.1563, Train: 0.1500, Val: 0.1620, Test: 0.1490
Epoch: 23, Loss: 2.1010, Train: 0.1500, Val: 0.1620, Test: 0.1510
Epoch: 24, Loss: 2.2210, Train: 0.1500, Val: 0.1600, Test: 0.1540
Epoch: 25, Loss: 2.1560, Train: 0.1500, Val: 0.1580, Test: 0.1530
Epoch: 26, Loss: 1.9866, Train: 0.1500, Val: 0.1580, Test: 0.1560
Epoch: 27, Loss: 2.0181, Train: 0.1500, Val: 0.1620, Test: 0.1580
Epoch: 28, Loss: 1.9913, Train: 0.1500, Val: 0.1620, Test: 0.1590
Epoch: 29, Loss: 2.0143, Train: 0.1500, Val: 0.1620, Test: 0.1600
Epoch: 30, Loss: 2.0231, Train: 0.1571, Val: 0.1580, Test: 0.1600
Epoch: 31, Loss: 2.0011, Train: 0.1643, Val: 0.1580, Test: 0.1590
Epoch: 32, Loss: 2.2283, Train: 0.1643, Val: 0.1580, Test: 0.1590
Epoch: 33, Loss: 2.0414, Train: 0.1571, Val: 0.1600, Test: 0.1550
Epoch: 34, Loss: 2.0441, Train: 0.1571, Val: 0.1600, Test: 0.1520
Epoch: 35, Loss: 2.0174, Train: 0.1571, Val: 0.1600, Test: 0.1510
Epoch: 36, Loss: 2.3380, Train: 0.1500, Val: 0.1600, Test: 0.1480
Epoch: 37, Loss: 2.1084, Train: 0.1500, Val: 0.1600, Test: 0.1490
Epoch: 38, Loss: 2.1435, Train: 0.1500, Val: 0.1580, Test: 0.1490
Epoch: 39, Loss: 2.0845, Train: 0.1500, Val: 0.1600, Test: 0.1480
Epoch: 40, Loss: 1.9771, Train: 0.1429, Val: 0.1600, Test: 0.1480
Epoch: 41, Loss: 2.2122, Train: 0.1429, Val: 0.1600, Test: 0.1480
Epoch: 42, Loss: 2.1111, Train: 0.1429, Val: 0.1600, Test: 0.1480
Epoch: 43, Loss: 1.9510, Train: 0.1500, Val: 0.1600, Test: 0.1470
Epoch: 44, Loss: 1.9493, Train: 0.1429, Val: 0.1580, Test: 0.1460
Epoch: 45, Loss: 2.0692, Train: 0.1429, Val: 0.1600, Test: 0.1480
Epoch: 46, Loss: 1.9518, Train: 0.1500, Val: 0.1580, Test: 0.1490
Epoch: 47, Loss: 1.9688, Train: 0.1500, Val: 0.1560, Test: 0.1490
Epoch: 48, Loss: 2.0721, Train: 0.1500, Val: 0.1560, Test: 0.1490
Epoch: 49, Loss: 2.0418, Train: 0.1500, Val: 0.1560, Test: 0.1490
Epoch: 50, Loss: 2.0565, Train: 0.1500, Val: 0.1540, Test: 0.1470
Epoch: 51, Loss: 2.0811, Train: 0.1500, Val: 0.1560, Test: 0.1490
Epoch: 52, Loss: 2.0849, Train: 0.1429, Val: 0.1580, Test: 0.1510
Epoch: 53, Loss: 1.9322, Train: 0.1571, Val: 0.1580, Test: 0.1480
Epoch: 54, Loss: 1.9495, Train: 0.1571, Val: 0.1560, Test: 0.1480
Epoch: 55, Loss: 1.9971, Train: 0.1571, Val: 0.1600, Test: 0.1510
Epoch: 56, Loss: 1.9475, Train: 0.1500, Val: 0.1620, Test: 0.1490
Epoch: 57, Loss: 1.8716, Train: 0.1500, Val: 0.1640, Test: 0.1490
Epoch: 58, Loss: 2.0737, Train: 0.1500, Val: 0.1680, Test: 0.1490
Epoch: 59, Loss: 1.9415, Train: 0.1500, Val: 0.1660, Test: 0.1520
Epoch: 60, Loss: 2.0218, Train: 0.1500, Val: 0.1680, Test: 0.1530
Epoch: 61, Loss: 1.9299, Train: 0.1500, Val: 0.1680, Test: 0.1530
Epoch: 62, Loss: 1.9138, Train: 0.1500, Val: 0.1720, Test: 0.1550
Epoch: 63, Loss: 1.9108, Train: 0.1429, Val: 0.1720, Test: 0.1530
Epoch: 64, Loss: 1.9399, Train: 0.1357, Val: 0.1720, Test: 0.1540
Epoch: 65, Loss: 2.0703, Train: 0.1286, Val: 0.1700, Test: 0.1540
Epoch: 66, Loss: 2.4595, Train: 0.1214, Val: 0.1620, Test: 0.1560
Epoch: 67, Loss: 1.9776, Train: 0.1214, Val: 0.1600, Test: 0.1540
Epoch: 68, Loss: 1.9457, Train: 0.1286, Val: 0.1500, Test: 0.1520
Epoch: 69, Loss: 1.8258, Train: 0.1357, Val: 0.1480, Test: 0.1520
Epoch: 70, Loss: 1.9523, Train: 0.1357, Val: 0.1500, Test: 0.1510
Epoch: 71, Loss: 1.9031, Train: 0.1500, Val: 0.1520, Test: 0.1470
Epoch: 72, Loss: 1.9434, Train: 0.1500, Val: 0.1480, Test: 0.1490
Epoch: 73, Loss: 1.9361, Train: 0.1500, Val: 0.1480, Test: 0.1490
Epoch: 74, Loss: 1.8767, Train: 0.1571, Val: 0.1520, Test: 0.1500
Epoch: 75, Loss: 1.9144, Train: 0.1571, Val: 0.1520, Test: 0.1480
Epoch: 76, Loss: 1.9468, Train: 0.1571, Val: 0.1520, Test: 0.1480
Epoch: 77, Loss: 1.8521, Train: 0.1786, Val: 0.1560, Test: 0.1520
Epoch: 78, Loss: 1.8388, Train: 0.1857, Val: 0.1540, Test: 0.1530
Epoch: 79, Loss: 1.9218, Train: 0.1857, Val: 0.1540, Test: 0.1540
Epoch: 80, Loss: 1.9201, Train: 0.2000, Val: 0.1560, Test: 0.1570
Epoch: 81, Loss: 1.8405, Train: 0.2000, Val: 0.1600, Test: 0.1530
Epoch: 82, Loss: 1.8768, Train: 0.1857, Val: 0.1660, Test: 0.1510
Epoch: 83, Loss: 1.9510, Train: 0.1786, Val: 0.1680, Test: 0.1520
Epoch: 84, Loss: 1.8795, Train: 0.1857, Val: 0.1680, Test: 0.1520
Epoch: 85, Loss: 1.8222, Train: 0.1929, Val: 0.1720, Test: 0.1560
Epoch: 86, Loss: 1.8996, Train: 0.1929, Val: 0.1700, Test: 0.1570
Epoch: 87, Loss: 1.9687, Train: 0.1929, Val: 0.1720, Test: 0.1600
Epoch: 88, Loss: 1.8623, Train: 0.1929, Val: 0.1640, Test: 0.1600
Epoch: 89, Loss: 1.9635, Train: 0.2000, Val: 0.1620, Test: 0.1600
Epoch: 90, Loss: 2.3023, Train: 0.2000, Val: 0.1660, Test: 0.1600
Epoch: 91, Loss: 1.9041, Train: 0.2000, Val: 0.1700, Test: 0.1620
Epoch: 92, Loss: 1.8430, Train: 0.2071, Val: 0.1640, Test: 0.1650
Epoch: 93, Loss: 1.7997, Train: 0.2071, Val: 0.1640, Test: 0.1640
Epoch: 94, Loss: 1.8067, Train: 0.1929, Val: 0.1640, Test: 0.1620
Epoch: 95, Loss: 1.7731, Train: 0.2000, Val: 0.1640, Test: 0.1620
Epoch: 96, Loss: 1.7629, Train: 0.2000, Val: 0.1620, Test: 0.1620
Epoch: 97, Loss: 1.8051, Train: 0.2000, Val: 0.1620, Test: 0.1620
Epoch: 98, Loss: 1.8265, Train: 0.2000, Val: 0.1640, Test: 0.1620
Epoch: 99, Loss: 1.8110, Train: 0.2000, Val: 0.1640, Test: 0.1620
Epoch: 100, Loss: 1.8290, Train: 0.2000, Val: 0.1640, Test: 0.1620
Epoch: 101, Loss: 1.8498, Train: 0.2000, Val: 0.1640, Test: 0.1620
Epoch: 102, Loss: 1.8173, Train: 0.2071, Val: 0.1640, Test: 0.1620
Epoch: 103, Loss: 1.8206, Train: 0.2071, Val: 0.1660, Test: 0.1620
Epoch: 104, Loss: 1.7955, Train: 0.2071, Val: 0.1660, Test: 0.1620
Epoch: 105, Loss: 1.8111, Train: 0.2071, Val: 0.1660, Test: 0.1620
Epoch: 106, Loss: 1.7793, Train: 0.2071, Val: 0.1660, Test: 0.1620
Epoch: 107, Loss: 1.7904, Train: 0.2071, Val: 0.1660, Test: 0.1620
Epoch: 108, Loss: 1.8374, Train: 0.2143, Val: 0.1660, Test: 0.1630
Epoch: 109, Loss: 1.7687, Train: 0.2143, Val: 0.1660, Test: 0.1630
Epoch: 110, Loss: 1.7815, Train: 0.2214, Val: 0.1660, Test: 0.1630
Epoch: 111, Loss: 2.6425, Train: 0.2214, Val: 0.1660, Test: 0.1630
Epoch: 112, Loss: 1.7521, Train: 0.2214, Val: 0.1660, Test: 0.1630
Epoch: 113, Loss: 1.7736, Train: 0.2214, Val: 0.1660, Test: 0.1630
Epoch: 114, Loss: 1.7287, Train: 0.2214, Val: 0.1680, Test: 0.1630
Epoch: 115, Loss: 1.7190, Train: 0.2214, Val: 0.1680, Test: 0.1640
Epoch: 116, Loss: 1.8102, Train: 0.2214, Val: 0.1700, Test: 0.1640
Epoch: 117, Loss: 1.8098, Train: 0.2214, Val: 0.1700, Test: 0.1650
Epoch: 118, Loss: 1.7257, Train: 0.2286, Val: 0.1700, Test: 0.1660
Epoch: 119, Loss: 1.7082, Train: 0.2286, Val: 0.1700, Test: 0.1660
Epoch: 120, Loss: 1.7493, Train: 0.2286, Val: 0.1720, Test: 0.1660
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 121, Loss: 1.6956, Train: 0.2286, Val: 0.1720, Test: 0.1660
Epoch: 122, Loss: 1.7754, Train: 0.2357, Val: 0.1720, Test: 0.1660
Epoch: 123, Loss: 1.7319, Train: 0.2357, Val: 0.1740, Test: 0.1660
Epoch: 124, Loss: 1.6720, Train: 0.2357, Val: 0.1780, Test: 0.1660
Epoch: 125, Loss: 1.9273, Train: 0.2357, Val: 0.1780, Test: 0.1660
Epoch: 126, Loss: 1.6931, Train: 0.2357, Val: 0.1840, Test: 0.1660
Epoch: 127, Loss: 1.7352, Train: 0.2357, Val: 0.1840, Test: 0.1660
Epoch: 128, Loss: 1.7523, Train: 0.2357, Val: 0.1840, Test: 0.1660
Epoch: 129, Loss: 1.7216, Train: 0.2357, Val: 0.1820, Test: 0.1680
Epoch: 130, Loss: 1.6801, Train: 0.2357, Val: 0.1820, Test: 0.1680
Epoch: 131, Loss: 1.7334, Train: 0.2429, Val: 0.1820, Test: 0.1690
Epoch: 132, Loss: 1.6606, Train: 0.2429, Val: 0.1820, Test: 0.1690
Epoch: 133, Loss: 1.7155, Train: 0.2429, Val: 0.1820, Test: 0.1700
Epoch: 134, Loss: 1.6430, Train: 0.2429, Val: 0.1820, Test: 0.1690
Epoch: 135, Loss: 1.6898, Train: 0.2500, Val: 0.1800, Test: 0.1680
Epoch: 136, Loss: 1.6589, Train: 0.2571, Val: 0.1820, Test: 0.1690
Epoch: 137, Loss: 1.7026, Train: 0.2571, Val: 0.1820, Test: 0.1700
Epoch: 138, Loss: 1.6995, Train: 0.2571, Val: 0.1840, Test: 0.1710
Epoch: 139, Loss: 1.6611, Train: 0.2571, Val: 0.1860, Test: 0.1710
Epoch: 140, Loss: 1.6975, Train: 0.2571, Val: 0.1860, Test: 0.1710
Epoch: 141, Loss: 1.7047, Train: 0.2571, Val: 0.1860, Test: 0.1730
Epoch: 142, Loss: 1.6346, Train: 0.2571, Val: 0.1860, Test: 0.1750
Epoch: 143, Loss: 1.6856, Train: 0.2643, Val: 0.1900, Test: 0.1750
Epoch: 144, Loss: 1.6476, Train: 0.2643, Val: 0.1900, Test: 0.1750
Epoch: 145, Loss: 1.6418, Train: 0.2643, Val: 0.1900, Test: 0.1760
Epoch: 146, Loss: 1.6376, Train: 0.2643, Val: 0.1900, Test: 0.1770
Epoch: 147, Loss: 1.8797, Train: 0.2643, Val: 0.1900, Test: 0.1770
Epoch: 148, Loss: 1.6968, Train: 0.2643, Val: 0.1900, Test: 0.1770
Epoch: 149, Loss: 1.6502, Train: 0.2643, Val: 0.1900, Test: 0.1760
Epoch: 150, Loss: 1.6584, Train: 0.2643, Val: 0.1900, Test: 0.1750
Epoch: 151, Loss: 1.6566, Train: 0.2643, Val: 0.1900, Test: 0.1750
Epoch: 152, Loss: 1.6428, Train: 0.2643, Val: 0.1900, Test: 0.1750
Epoch: 153, Loss: 1.6181, Train: 0.2643, Val: 0.1900, Test: 0.1760
Epoch: 154, Loss: 1.6242, Train: 0.2643, Val: 0.1900, Test: 0.1770
Epoch: 155, Loss: 1.7897, Train: 0.2643, Val: 0.1920, Test: 0.1770
Epoch: 156, Loss: 1.6502, Train: 0.2714, Val: 0.1920, Test: 0.1770
Epoch: 157, Loss: 1.6602, Train: 0.2714, Val: 0.1920, Test: 0.1780
Epoch: 158, Loss: 1.6421, Train: 0.2714, Val: 0.1920, Test: 0.1770
Epoch: 159, Loss: 1.6151, Train: 0.2714, Val: 0.1920, Test: 0.1770
Epoch: 160, Loss: 1.5998, Train: 0.2714, Val: 0.1920, Test: 0.1790
Epoch: 161, Loss: 1.6115, Train: 0.2714, Val: 0.1940, Test: 0.1790
Epoch: 162, Loss: 1.6371, Train: 0.2714, Val: 0.1940, Test: 0.1800
Epoch: 163, Loss: 1.5894, Train: 0.2714, Val: 0.1940, Test: 0.1800
Epoch: 164, Loss: 1.5980, Train: 0.2714, Val: 0.1940, Test: 0.1810
Epoch: 165, Loss: 1.6371, Train: 0.2714, Val: 0.1940, Test: 0.1820
Epoch: 166, Loss: 1.6448, Train: 0.2714, Val: 0.1940, Test: 0.1820
Epoch: 167, Loss: 1.6138, Train: 0.2714, Val: 0.1940, Test: 0.1820
Epoch: 168, Loss: 1.7049, Train: 0.2714, Val: 0.1940, Test: 0.1840
Epoch: 169, Loss: 1.6628, Train: 0.2714, Val: 0.1940, Test: 0.1850
Epoch: 170, Loss: 1.7419, Train: 0.2714, Val: 0.1940, Test: 0.1860
Epoch: 171, Loss: 1.5890, Train: 0.2714, Val: 0.1940, Test: 0.1860
Epoch: 172, Loss: 1.5929, Train: 0.2714, Val: 0.1940, Test: 0.1860
Epoch: 173, Loss: 1.5958, Train: 0.2714, Val: 0.1940, Test: 0.1860
Epoch: 174, Loss: 1.6072, Train: 0.2786, Val: 0.1940, Test: 0.1860
Epoch: 175, Loss: 1.5828, Train: 0.2786, Val: 0.1940, Test: 0.1860
Epoch: 176, Loss: 1.6206, Train: 0.2786, Val: 0.1940, Test: 0.1860
Epoch: 177, Loss: 1.5911, Train: 0.2786, Val: 0.1940, Test: 0.1860
Epoch: 178, Loss: 1.6581, Train: 0.2786, Val: 0.1940, Test: 0.1880
Epoch: 179, Loss: 1.6027, Train: 0.2786, Val: 0.1940, Test: 0.1880
Epoch: 180, Loss: 1.6553, Train: 0.2786, Val: 0.1940, Test: 0.1900
Epoch: 181, Loss: 1.6395, Train: 0.2786, Val: 0.1940, Test: 0.1900
Epoch: 182, Loss: 1.5958, Train: 0.2786, Val: 0.1920, Test: 0.1930
Epoch: 183, Loss: 1.5659, Train: 0.2786, Val: 0.1940, Test: 0.1930
Epoch: 184, Loss: 1.5785, Train: 0.2786, Val: 0.1940, Test: 0.1950
Epoch: 185, Loss: 1.6751, Train: 0.2786, Val: 0.1940, Test: 0.1950
Epoch: 186, Loss: 1.5685, Train: 0.2786, Val: 0.1940, Test: 0.1960
Epoch: 187, Loss: 1.6406, Train: 0.2786, Val: 0.1940, Test: 0.1960
Epoch: 188, Loss: 1.5585, Train: 0.2786, Val: 0.1940, Test: 0.1960
Epoch: 189, Loss: 1.8614, Train: 0.2786, Val: 0.1940, Test: 0.1960
Epoch: 190, Loss: 1.6572, Train: 0.2786, Val: 0.1940, Test: 0.1960
Epoch: 191, Loss: 1.6485, Train: 0.2786, Val: 0.1940, Test: 0.1950
Epoch: 192, Loss: 1.6511, Train: 0.2714, Val: 0.1940, Test: 0.1940
Epoch: 193, Loss: 1.5825, Train: 0.2714, Val: 0.1940, Test: 0.1930
Epoch: 194, Loss: 1.5510, Train: 0.2714, Val: 0.1940, Test: 0.1930
Epoch: 195, Loss: 1.5511, Train: 0.2714, Val: 0.1940, Test: 0.1930
Epoch: 196, Loss: 1.5445, Train: 0.2714, Val: 0.1960, Test: 0.1930
Epoch: 197, Loss: 1.5399, Train: 0.2714, Val: 0.1960, Test: 0.1930
Epoch: 198, Loss: 1.6109, Train: 0.2714, Val: 0.1960, Test: 0.1930
Epoch: 199, Loss: 1.5852, Train: 0.2714, Val: 0.1960, Test: 0.1930
Epoch: 200, Loss: 1.5327, Train: 0.2714, Val: 0.1980, Test: 0.1930
MAD:  0.119
Best Test Accuracy: 0.2950, Val Accuracy: 0.2960, Train Accuracy: 0.1429
Training completed.
Seed:  1
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 12.4451, Train: 0.1429, Val: 0.1200, Test: 0.1320
Epoch: 2, Loss: 7.3004, Train: 0.1643, Val: 0.1300, Test: 0.1290
Epoch: 3, Loss: 6.8859, Train: 0.1357, Val: 0.1100, Test: 0.0900
Epoch: 4, Loss: 5.5135, Train: 0.1286, Val: 0.0920, Test: 0.0950
Epoch: 5, Loss: 4.0906, Train: 0.1571, Val: 0.1540, Test: 0.1650
Epoch: 6, Loss: 4.2096, Train: 0.1857, Val: 0.2540, Test: 0.2610
Epoch: 7, Loss: 3.6884, Train: 0.2000, Val: 0.2760, Test: 0.2880
Epoch: 8, Loss: 2.9313, Train: 0.1929, Val: 0.2900, Test: 0.3000
Epoch: 9, Loss: 2.9158, Train: 0.1786, Val: 0.2880, Test: 0.3030
Epoch: 10, Loss: 2.8805, Train: 0.1714, Val: 0.2940, Test: 0.3000
Epoch: 11, Loss: 2.4395, Train: 0.1643, Val: 0.2940, Test: 0.3000
Epoch: 12, Loss: 2.8616, Train: 0.1357, Val: 0.2880, Test: 0.3000
Epoch: 13, Loss: 2.6391, Train: 0.1214, Val: 0.2880, Test: 0.2950
Epoch: 14, Loss: 2.3664, Train: 0.1429, Val: 0.2860, Test: 0.2870
Epoch: 15, Loss: 2.3266, Train: 0.1857, Val: 0.2380, Test: 0.2390
Epoch: 16, Loss: 2.4954, Train: 0.1929, Val: 0.1680, Test: 0.1870
Epoch: 17, Loss: 2.2839, Train: 0.1786, Val: 0.1340, Test: 0.1400
Epoch: 18, Loss: 2.2483, Train: 0.1643, Val: 0.0900, Test: 0.1210
Epoch: 19, Loss: 2.6559, Train: 0.1643, Val: 0.0780, Test: 0.1100
Epoch: 20, Loss: 2.7613, Train: 0.1643, Val: 0.0760, Test: 0.1040
Epoch: 21, Loss: 2.5540, Train: 0.1714, Val: 0.0780, Test: 0.0990
Epoch: 22, Loss: 2.2196, Train: 0.1714, Val: 0.0760, Test: 0.0980
Epoch: 23, Loss: 2.6588, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 24, Loss: 1.9514, Train: 0.1500, Val: 0.0760, Test: 0.0930
Epoch: 25, Loss: 2.0318, Train: 0.1429, Val: 0.0720, Test: 0.0920
Epoch: 26, Loss: 2.0379, Train: 0.1500, Val: 0.0720, Test: 0.0920
Epoch: 27, Loss: 2.0931, Train: 0.1500, Val: 0.0720, Test: 0.0920
Epoch: 28, Loss: 1.9551, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 29, Loss: 2.0977, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 30, Loss: 2.0207, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 31, Loss: 2.1376, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 32, Loss: 2.1881, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 33, Loss: 2.1042, Train: 0.1357, Val: 0.0720, Test: 0.0910
Epoch: 34, Loss: 2.2234, Train: 0.1357, Val: 0.0720, Test: 0.0910
Epoch: 35, Loss: 2.0030, Train: 0.1357, Val: 0.0720, Test: 0.0910
Epoch: 36, Loss: 2.0976, Train: 0.1357, Val: 0.0720, Test: 0.0900
Epoch: 37, Loss: 2.0283, Train: 0.1357, Val: 0.0720, Test: 0.0900
Epoch: 38, Loss: 2.1072, Train: 0.1357, Val: 0.0720, Test: 0.0900
Epoch: 39, Loss: 1.9946, Train: 0.1357, Val: 0.0720, Test: 0.0910
Epoch: 40, Loss: 2.0079, Train: 0.1357, Val: 0.0720, Test: 0.0910
Epoch: 41, Loss: 1.9427, Train: 0.1357, Val: 0.0720, Test: 0.0910
Epoch: 42, Loss: 1.9833, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 43, Loss: 2.0269, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 44, Loss: 2.1577, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 45, Loss: 2.0335, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 46, Loss: 1.9374, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 47, Loss: 2.1390, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 48, Loss: 1.9652, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 49, Loss: 2.0283, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 50, Loss: 1.9438, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 51, Loss: 1.9355, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 52, Loss: 1.9842, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 53, Loss: 2.0218, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 54, Loss: 1.9206, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 55, Loss: 1.9337, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 56, Loss: 1.9928, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 57, Loss: 1.9805, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 58, Loss: 1.9401, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 59, Loss: 1.9896, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 60, Loss: 1.9169, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 61, Loss: 1.9166, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 62, Loss: 1.9571, Train: 0.1429, Val: 0.0720, Test: 0.0920
Epoch: 63, Loss: 1.9094, Train: 0.1571, Val: 0.0720, Test: 0.0920
Epoch: 64, Loss: 1.9096, Train: 0.1714, Val: 0.0720, Test: 0.0930
Epoch: 65, Loss: 1.8496, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 66, Loss: 1.9953, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 67, Loss: 1.8779, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 68, Loss: 1.9173, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 69, Loss: 1.8386, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 70, Loss: 1.8242, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 71, Loss: 1.9034, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 72, Loss: 2.0701, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 73, Loss: 1.9293, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 74, Loss: 1.8868, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 75, Loss: 1.8758, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 76, Loss: 1.9337, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 77, Loss: 1.8267, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 78, Loss: 1.8599, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 79, Loss: 1.9320, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 80, Loss: 1.8604, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 81, Loss: 1.9843, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 82, Loss: 1.9574, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 83, Loss: 1.8389, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 84, Loss: 1.8548, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 85, Loss: 1.9005, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 86, Loss: 2.0755, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 87, Loss: 1.8525, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 88, Loss: 1.7985, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 89, Loss: 2.0799, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 90, Loss: 1.8937, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 91, Loss: 1.7583, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 92, Loss: 1.8231, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 93, Loss: 1.9995, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 94, Loss: 1.8267, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 95, Loss: 1.8293, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 96, Loss: 1.8110, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 97, Loss: 1.8464, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 98, Loss: 1.7616, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 99, Loss: 1.7673, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 100, Loss: 1.8020, Train: 0.1786, Val: 0.0720, Test: 0.0950
Epoch: 101, Loss: 1.8346, Train: 0.1786, Val: 0.0720, Test: 0.0960
Epoch: 102, Loss: 1.7501, Train: 0.1786, Val: 0.0720, Test: 0.0960
Epoch: 103, Loss: 1.7273, Train: 0.1857, Val: 0.0720, Test: 0.0970
Epoch: 104, Loss: 1.7719, Train: 0.1929, Val: 0.0740, Test: 0.0980
Epoch: 105, Loss: 1.7544, Train: 0.2071, Val: 0.0740, Test: 0.0990
Epoch: 106, Loss: 1.7313, Train: 0.2143, Val: 0.0740, Test: 0.0990
Epoch: 107, Loss: 1.7653, Train: 0.2143, Val: 0.0740, Test: 0.0990
Epoch: 108, Loss: 1.7462, Train: 0.2143, Val: 0.0740, Test: 0.0990
Epoch: 109, Loss: 1.7634, Train: 0.2143, Val: 0.0740, Test: 0.0990
Epoch: 110, Loss: 1.7534, Train: 0.2143, Val: 0.0740, Test: 0.0990
Epoch: 111, Loss: 1.7277, Train: 0.2143, Val: 0.0720, Test: 0.1010
Epoch: 112, Loss: 1.8054, Train: 0.2143, Val: 0.0740, Test: 0.1020
Epoch: 113, Loss: 1.8027, Train: 0.2143, Val: 0.0740, Test: 0.1030
Epoch: 114, Loss: 1.7115, Train: 0.2143, Val: 0.0740, Test: 0.1030
Epoch: 115, Loss: 1.7070, Train: 0.2143, Val: 0.0760, Test: 0.1060
Epoch: 116, Loss: 1.9004, Train: 0.2143, Val: 0.0760, Test: 0.1060
Epoch: 117, Loss: 1.7287, Train: 0.2214, Val: 0.0740, Test: 0.1060
Epoch: 118, Loss: 1.8401, Train: 0.2214, Val: 0.0740, Test: 0.1060
Epoch: 119, Loss: 1.7101, Train: 0.2214, Val: 0.0740, Test: 0.1060
Epoch: 120, Loss: 1.8149, Train: 0.2214, Val: 0.0740, Test: 0.1080
Epoch: 121, Loss: 1.7797, Train: 0.2214, Val: 0.0740, Test: 0.1080
Epoch: 122, Loss: 1.7012, Train: 0.2214, Val: 0.0740, Test: 0.1080
Epoch: 123, Loss: 1.6944, Train: 0.2214, Val: 0.0740, Test: 0.1080
Epoch: 124, Loss: 1.6756, Train: 0.2214, Val: 0.0740, Test: 0.1090
Epoch: 125, Loss: 1.7370, Train: 0.2214, Val: 0.0760, Test: 0.1100
Epoch: 126, Loss: 1.6773, Train: 0.2214, Val: 0.0780, Test: 0.1100
Epoch: 127, Loss: 1.6938, Train: 0.2214, Val: 0.0800, Test: 0.1100
Epoch: 128, Loss: 1.6717, Train: 0.2214, Val: 0.0820, Test: 0.1100
Epoch: 129, Loss: 1.7391, Train: 0.2214, Val: 0.0820, Test: 0.1110
Epoch: 130, Loss: 1.6824, Train: 0.2214, Val: 0.0840, Test: 0.1110
Epoch: 131, Loss: 1.7849, Train: 0.2214, Val: 0.0840, Test: 0.1110
Epoch: 132, Loss: 1.6766, Train: 0.2286, Val: 0.0840, Test: 0.1110
Epoch: 133, Loss: 1.7311, Train: 0.2286, Val: 0.0840, Test: 0.1110
Epoch: 134, Loss: 1.6411, Train: 0.2286, Val: 0.0840, Test: 0.1110
Epoch: 135, Loss: 1.7739, Train: 0.2286, Val: 0.0840, Test: 0.1110
Epoch: 136, Loss: 1.6941, Train: 0.2286, Val: 0.0860, Test: 0.1110
Epoch: 137, Loss: 1.7493, Train: 0.2357, Val: 0.0860, Test: 0.1110
Epoch: 138, Loss: 1.6293, Train: 0.2357, Val: 0.0860, Test: 0.1110
Epoch: 139, Loss: 1.6200, Train: 0.2357, Val: 0.0860, Test: 0.1110
Epoch: 140, Loss: 1.6229, Train: 0.2357, Val: 0.0880, Test: 0.1120
Epoch: 141, Loss: 1.7768, Train: 0.2357, Val: 0.0880, Test: 0.1120
Epoch: 142, Loss: 1.6675, Train: 0.2429, Val: 0.0880, Test: 0.1120
Epoch: 143, Loss: 1.6511, Train: 0.2500, Val: 0.0880, Test: 0.1120
Epoch: 144, Loss: 1.6705, Train: 0.2500, Val: 0.0860, Test: 0.1110
Epoch: 145, Loss: 1.6929, Train: 0.2500, Val: 0.0840, Test: 0.1130
Epoch: 146, Loss: 1.6527, Train: 0.2500, Val: 0.0840, Test: 0.1140
Epoch: 147, Loss: 2.1347, Train: 0.2500, Val: 0.0860, Test: 0.1150
Epoch: 148, Loss: 1.6356, Train: 0.2500, Val: 0.0880, Test: 0.1140
Epoch: 149, Loss: 1.6085, Train: 0.2500, Val: 0.0880, Test: 0.1140
Epoch: 150, Loss: 1.6196, Train: 0.2500, Val: 0.0880, Test: 0.1150
Epoch: 151, Loss: 1.6662, Train: 0.2500, Val: 0.0880, Test: 0.1150
Epoch: 152, Loss: 1.6056, Train: 0.2500, Val: 0.0900, Test: 0.1150
Epoch: 153, Loss: 1.6059, Train: 0.2500, Val: 0.0900, Test: 0.1150
Epoch: 154, Loss: 1.5948, Train: 0.2500, Val: 0.0900, Test: 0.1150
Epoch: 155, Loss: 1.6072, Train: 0.2500, Val: 0.0900, Test: 0.1160
Epoch: 156, Loss: 1.8641, Train: 0.2500, Val: 0.0900, Test: 0.1160
Epoch: 157, Loss: 1.6210, Train: 0.2500, Val: 0.0920, Test: 0.1160
Epoch: 158, Loss: 1.6356, Train: 0.2571, Val: 0.0920, Test: 0.1160
Epoch: 159, Loss: 1.5709, Train: 0.2571, Val: 0.0920, Test: 0.1160
Epoch: 160, Loss: 1.5917, Train: 0.2571, Val: 0.0920, Test: 0.1160
Epoch: 161, Loss: 1.6140, Train: 0.2571, Val: 0.0940, Test: 0.1170
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 162, Loss: 1.5993, Train: 0.2571, Val: 0.0940, Test: 0.1190
Epoch: 163, Loss: 1.6143, Train: 0.2571, Val: 0.0980, Test: 0.1190
Epoch: 164, Loss: 1.5896, Train: 0.2571, Val: 0.0980, Test: 0.1200
Epoch: 165, Loss: 1.6433, Train: 0.2571, Val: 0.0980, Test: 0.1200
Epoch: 166, Loss: 1.9022, Train: 0.2571, Val: 0.0940, Test: 0.1210
Epoch: 167, Loss: 1.5731, Train: 0.2571, Val: 0.0940, Test: 0.1220
Epoch: 168, Loss: 1.6128, Train: 0.2643, Val: 0.0940, Test: 0.1240
Epoch: 169, Loss: 1.5772, Train: 0.2643, Val: 0.0940, Test: 0.1240
Epoch: 170, Loss: 1.5568, Train: 0.2643, Val: 0.0940, Test: 0.1240
Epoch: 171, Loss: 1.5855, Train: 0.2643, Val: 0.0980, Test: 0.1230
Epoch: 172, Loss: 2.4145, Train: 0.2643, Val: 0.1000, Test: 0.1230
Epoch: 173, Loss: 1.5645, Train: 0.2643, Val: 0.1000, Test: 0.1230
Epoch: 174, Loss: 1.5605, Train: 0.2643, Val: 0.1020, Test: 0.1240
Epoch: 175, Loss: 1.5517, Train: 0.2643, Val: 0.1020, Test: 0.1270
Epoch: 176, Loss: 1.5575, Train: 0.2643, Val: 0.1040, Test: 0.1290
Epoch: 177, Loss: 1.5518, Train: 0.2643, Val: 0.1060, Test: 0.1320
Epoch: 178, Loss: 1.6883, Train: 0.2643, Val: 0.1080, Test: 0.1340
Epoch: 179, Loss: 1.5107, Train: 0.2643, Val: 0.1120, Test: 0.1350
Epoch: 180, Loss: 1.5461, Train: 0.2714, Val: 0.1140, Test: 0.1380
Epoch: 181, Loss: 1.5894, Train: 0.2786, Val: 0.1120, Test: 0.1430
Epoch: 182, Loss: 1.5895, Train: 0.2786, Val: 0.1160, Test: 0.1440
Epoch: 183, Loss: 1.5341, Train: 0.2786, Val: 0.1180, Test: 0.1450
Epoch: 184, Loss: 1.5462, Train: 0.2643, Val: 0.1180, Test: 0.1410
Epoch: 185, Loss: 1.5607, Train: 0.2643, Val: 0.1140, Test: 0.1370
Epoch: 186, Loss: 1.5519, Train: 0.2643, Val: 0.1140, Test: 0.1360
Epoch: 187, Loss: 1.7579, Train: 0.2643, Val: 0.1120, Test: 0.1350
Epoch: 188, Loss: 1.5175, Train: 0.2643, Val: 0.1120, Test: 0.1360
Epoch: 189, Loss: 1.5563, Train: 0.2643, Val: 0.1160, Test: 0.1390
Epoch: 190, Loss: 1.5503, Train: 0.2643, Val: 0.1160, Test: 0.1410
Epoch: 191, Loss: 1.5493, Train: 0.2714, Val: 0.1160, Test: 0.1430
Epoch: 192, Loss: 1.5367, Train: 0.2714, Val: 0.1180, Test: 0.1480
Epoch: 193, Loss: 1.5253, Train: 0.2714, Val: 0.1140, Test: 0.1470
Epoch: 194, Loss: 1.5580, Train: 0.2714, Val: 0.1180, Test: 0.1480
Epoch: 195, Loss: 1.5522, Train: 0.2714, Val: 0.1160, Test: 0.1470
Epoch: 196, Loss: 1.5196, Train: 0.2714, Val: 0.1120, Test: 0.1470
Epoch: 197, Loss: 1.5022, Train: 0.2786, Val: 0.1160, Test: 0.1540
Epoch: 198, Loss: 1.6833, Train: 0.2786, Val: 0.1240, Test: 0.1580
Epoch: 199, Loss: 1.5100, Train: 0.2929, Val: 0.1300, Test: 0.1620
Epoch: 200, Loss: 1.4741, Train: 0.3000, Val: 0.1360, Test: 0.1680
MAD:  0.0571
Best Test Accuracy: 0.3030, Val Accuracy: 0.2880, Train Accuracy: 0.1786
Training completed.
Seed:  2
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 14.7876, Train: 0.1286, Val: 0.1560, Test: 0.1460
Epoch: 2, Loss: 8.8883, Train: 0.1357, Val: 0.1300, Test: 0.1600
Epoch: 3, Loss: 5.3081, Train: 0.1286, Val: 0.1460, Test: 0.1440
Epoch: 4, Loss: 4.6056, Train: 0.1357, Val: 0.1560, Test: 0.1520
Epoch: 5, Loss: 3.8263, Train: 0.1500, Val: 0.1580, Test: 0.1560
Epoch: 6, Loss: 3.7220, Train: 0.1571, Val: 0.1500, Test: 0.1570
Epoch: 7, Loss: 3.0844, Train: 0.1500, Val: 0.1460, Test: 0.1470
Epoch: 8, Loss: 3.5980, Train: 0.1500, Val: 0.1460, Test: 0.1430
Epoch: 9, Loss: 3.1020, Train: 0.1500, Val: 0.1500, Test: 0.1550
Epoch: 10, Loss: 2.9866, Train: 0.1643, Val: 0.1560, Test: 0.1570
Epoch: 11, Loss: 2.9875, Train: 0.1643, Val: 0.1600, Test: 0.1620
Epoch: 12, Loss: 2.9331, Train: 0.1643, Val: 0.1640, Test: 0.1610
Epoch: 13, Loss: 2.6648, Train: 0.2071, Val: 0.1600, Test: 0.1590
Epoch: 14, Loss: 2.3541, Train: 0.1929, Val: 0.1620, Test: 0.1560
Epoch: 15, Loss: 2.8402, Train: 0.2000, Val: 0.1360, Test: 0.1410
Epoch: 16, Loss: 2.2568, Train: 0.1714, Val: 0.1260, Test: 0.1360
Epoch: 17, Loss: 2.5432, Train: 0.1643, Val: 0.1180, Test: 0.1270
Epoch: 18, Loss: 2.3279, Train: 0.1571, Val: 0.1140, Test: 0.1190
Epoch: 19, Loss: 2.0470, Train: 0.1500, Val: 0.1080, Test: 0.1130
Epoch: 20, Loss: 2.3326, Train: 0.1429, Val: 0.0960, Test: 0.1090
Epoch: 21, Loss: 2.3685, Train: 0.1429, Val: 0.0940, Test: 0.1090
Epoch: 22, Loss: 2.1653, Train: 0.1429, Val: 0.1000, Test: 0.1050
Epoch: 23, Loss: 2.2059, Train: 0.1429, Val: 0.0920, Test: 0.1060
Epoch: 24, Loss: 2.0203, Train: 0.1357, Val: 0.0900, Test: 0.1090
Epoch: 25, Loss: 2.3095, Train: 0.1357, Val: 0.0860, Test: 0.1070
Epoch: 26, Loss: 2.5378, Train: 0.1429, Val: 0.0820, Test: 0.1100
Epoch: 27, Loss: 2.0853, Train: 0.1286, Val: 0.0780, Test: 0.1110
Epoch: 28, Loss: 2.1266, Train: 0.1286, Val: 0.0760, Test: 0.1070
Epoch: 29, Loss: 2.2578, Train: 0.1500, Val: 0.0800, Test: 0.1100
Epoch: 30, Loss: 2.1762, Train: 0.1500, Val: 0.0820, Test: 0.1070
Epoch: 31, Loss: 1.9448, Train: 0.1714, Val: 0.0880, Test: 0.1070
Epoch: 32, Loss: 2.0106, Train: 0.1643, Val: 0.0860, Test: 0.1060
Epoch: 33, Loss: 2.0151, Train: 0.1786, Val: 0.0860, Test: 0.1120
Epoch: 34, Loss: 2.1342, Train: 0.1714, Val: 0.0820, Test: 0.1120
Epoch: 35, Loss: 1.9642, Train: 0.1786, Val: 0.0840, Test: 0.1070
Epoch: 36, Loss: 2.0936, Train: 0.1429, Val: 0.0820, Test: 0.1100
Epoch: 37, Loss: 1.9921, Train: 0.1571, Val: 0.1060, Test: 0.1330
Epoch: 38, Loss: 2.0392, Train: 0.2214, Val: 0.1280, Test: 0.1600
Epoch: 39, Loss: 1.9627, Train: 0.1929, Val: 0.1640, Test: 0.1710
Epoch: 40, Loss: 2.0403, Train: 0.1714, Val: 0.1660, Test: 0.1660
Epoch: 41, Loss: 2.1154, Train: 0.1571, Val: 0.1680, Test: 0.1630
Epoch: 42, Loss: 1.9243, Train: 0.1500, Val: 0.1660, Test: 0.1620
Epoch: 43, Loss: 2.0743, Train: 0.1429, Val: 0.1640, Test: 0.1560
Epoch: 44, Loss: 1.9121, Train: 0.1429, Val: 0.1640, Test: 0.1540
Epoch: 45, Loss: 1.9970, Train: 0.1429, Val: 0.1620, Test: 0.1510
Epoch: 46, Loss: 1.9556, Train: 0.1429, Val: 0.1620, Test: 0.1510
Epoch: 47, Loss: 2.0104, Train: 0.1429, Val: 0.1620, Test: 0.1480
Epoch: 48, Loss: 1.8962, Train: 0.1429, Val: 0.1620, Test: 0.1480
Epoch: 49, Loss: 1.9689, Train: 0.1429, Val: 0.1620, Test: 0.1480
Epoch: 50, Loss: 2.0000, Train: 0.1429, Val: 0.1620, Test: 0.1480
Epoch: 51, Loss: 1.9492, Train: 0.1429, Val: 0.1620, Test: 0.1480
Epoch: 52, Loss: 1.9744, Train: 0.1429, Val: 0.1620, Test: 0.1480
Epoch: 53, Loss: 1.9888, Train: 0.1429, Val: 0.1620, Test: 0.1470
Epoch: 54, Loss: 2.1191, Train: 0.1429, Val: 0.1620, Test: 0.1470
Epoch: 55, Loss: 2.0076, Train: 0.1429, Val: 0.1620, Test: 0.1480
Epoch: 56, Loss: 1.9637, Train: 0.1429, Val: 0.1620, Test: 0.1490
Epoch: 57, Loss: 1.9417, Train: 0.1429, Val: 0.1620, Test: 0.1500
Epoch: 58, Loss: 1.9326, Train: 0.1500, Val: 0.1620, Test: 0.1540
Epoch: 59, Loss: 1.8977, Train: 0.1500, Val: 0.1620, Test: 0.1540
Epoch: 60, Loss: 1.9894, Train: 0.1500, Val: 0.1620, Test: 0.1540
Epoch: 61, Loss: 1.9325, Train: 0.1714, Val: 0.1620, Test: 0.1540
Epoch: 62, Loss: 2.0756, Train: 0.1714, Val: 0.1620, Test: 0.1550
Epoch: 63, Loss: 2.0070, Train: 0.1714, Val: 0.1640, Test: 0.1550
Epoch: 64, Loss: 2.0035, Train: 0.1786, Val: 0.1640, Test: 0.1540
Epoch: 65, Loss: 1.9354, Train: 0.1786, Val: 0.1640, Test: 0.1540
Epoch: 66, Loss: 2.0060, Train: 0.1786, Val: 0.1660, Test: 0.1530
Epoch: 67, Loss: 1.8875, Train: 0.1786, Val: 0.1660, Test: 0.1540
Epoch: 68, Loss: 1.8544, Train: 0.1786, Val: 0.1660, Test: 0.1550
Epoch: 69, Loss: 2.0198, Train: 0.1714, Val: 0.1660, Test: 0.1540
Epoch: 70, Loss: 1.8680, Train: 0.1643, Val: 0.1660, Test: 0.1540
Epoch: 71, Loss: 2.0142, Train: 0.1643, Val: 0.1660, Test: 0.1540
Epoch: 72, Loss: 1.9679, Train: 0.1643, Val: 0.1660, Test: 0.1540
Epoch: 73, Loss: 2.0378, Train: 0.1643, Val: 0.1660, Test: 0.1540
Epoch: 74, Loss: 1.8639, Train: 0.1643, Val: 0.1660, Test: 0.1540
Epoch: 75, Loss: 1.8517, Train: 0.1643, Val: 0.1660, Test: 0.1540
Epoch: 76, Loss: 1.8167, Train: 0.1643, Val: 0.1660, Test: 0.1540
Epoch: 77, Loss: 1.8933, Train: 0.1714, Val: 0.1660, Test: 0.1550
Epoch: 78, Loss: 1.8819, Train: 0.1714, Val: 0.1660, Test: 0.1550
Epoch: 79, Loss: 1.9537, Train: 0.1714, Val: 0.1660, Test: 0.1550
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 80, Loss: 1.8861, Train: 0.1714, Val: 0.1660, Test: 0.1550
Epoch: 81, Loss: 1.8445, Train: 0.1714, Val: 0.1660, Test: 0.1560
Epoch: 82, Loss: 1.8960, Train: 0.1714, Val: 0.1660, Test: 0.1570
Epoch: 83, Loss: 1.8183, Train: 0.1714, Val: 0.1660, Test: 0.1560
Epoch: 84, Loss: 1.8273, Train: 0.1714, Val: 0.1660, Test: 0.1580
Epoch: 85, Loss: 1.8524, Train: 0.1643, Val: 0.1660, Test: 0.1550
Epoch: 86, Loss: 1.8711, Train: 0.1643, Val: 0.1640, Test: 0.1530
Epoch: 87, Loss: 1.8234, Train: 0.1857, Val: 0.1620, Test: 0.1520
Epoch: 88, Loss: 1.9325, Train: 0.1929, Val: 0.1580, Test: 0.1490
Epoch: 89, Loss: 2.2265, Train: 0.2143, Val: 0.1680, Test: 0.1500
Epoch: 90, Loss: 1.8283, Train: 0.2357, Val: 0.1640, Test: 0.1510
Epoch: 91, Loss: 1.8663, Train: 0.2143, Val: 0.1460, Test: 0.1480
Epoch: 92, Loss: 1.8023, Train: 0.1929, Val: 0.1060, Test: 0.1300
Epoch: 93, Loss: 1.9330, Train: 0.1857, Val: 0.0840, Test: 0.1110
Epoch: 94, Loss: 1.8078, Train: 0.1929, Val: 0.0780, Test: 0.1060
Epoch: 95, Loss: 1.9159, Train: 0.1929, Val: 0.0780, Test: 0.1060
Epoch: 96, Loss: 1.8637, Train: 0.1929, Val: 0.0780, Test: 0.1040
Epoch: 97, Loss: 1.8294, Train: 0.1929, Val: 0.0780, Test: 0.1040
Epoch: 98, Loss: 1.8700, Train: 0.1929, Val: 0.0800, Test: 0.1030
Epoch: 99, Loss: 1.8118, Train: 0.1929, Val: 0.0800, Test: 0.1030
Epoch: 100, Loss: 1.7421, Train: 0.1929, Val: 0.0800, Test: 0.1030
Epoch: 101, Loss: 1.8443, Train: 0.1929, Val: 0.0780, Test: 0.1030
Epoch: 102, Loss: 1.8095, Train: 0.1929, Val: 0.0780, Test: 0.1020
Epoch: 103, Loss: 1.8259, Train: 0.1929, Val: 0.0780, Test: 0.1020
Epoch: 104, Loss: 1.8747, Train: 0.1929, Val: 0.0780, Test: 0.1020
Epoch: 105, Loss: 1.8220, Train: 0.1929, Val: 0.0780, Test: 0.1020
Epoch: 106, Loss: 1.8084, Train: 0.2000, Val: 0.0780, Test: 0.1040
Epoch: 107, Loss: 1.7308, Train: 0.2143, Val: 0.0780, Test: 0.1050
Epoch: 108, Loss: 1.7332, Train: 0.2143, Val: 0.0800, Test: 0.1050
Epoch: 109, Loss: 1.7659, Train: 0.2214, Val: 0.0800, Test: 0.1050
Epoch: 110, Loss: 1.7812, Train: 0.2214, Val: 0.0800, Test: 0.1050
Epoch: 111, Loss: 1.7369, Train: 0.2214, Val: 0.0800, Test: 0.1070
Epoch: 112, Loss: 1.7530, Train: 0.2214, Val: 0.0800, Test: 0.1070
Epoch: 113, Loss: 1.7697, Train: 0.2214, Val: 0.0800, Test: 0.1070
Epoch: 114, Loss: 1.7905, Train: 0.2214, Val: 0.0780, Test: 0.1070
Epoch: 115, Loss: 1.7123, Train: 0.2214, Val: 0.0780, Test: 0.1070
Epoch: 116, Loss: 1.7056, Train: 0.2214, Val: 0.0800, Test: 0.1070
Epoch: 117, Loss: 1.7382, Train: 0.2214, Val: 0.0800, Test: 0.1070
Epoch: 118, Loss: 1.8114, Train: 0.2214, Val: 0.0800, Test: 0.1070
Epoch: 119, Loss: 1.8225, Train: 0.2214, Val: 0.0800, Test: 0.1070
Epoch: 120, Loss: 1.7289, Train: 0.2214, Val: 0.0800, Test: 0.1070
Epoch: 121, Loss: 1.7314, Train: 0.2286, Val: 0.0800, Test: 0.1070
Epoch: 122, Loss: 1.7011, Train: 0.2286, Val: 0.0800, Test: 0.1070
Epoch: 123, Loss: 1.6930, Train: 0.2286, Val: 0.0820, Test: 0.1080
Epoch: 124, Loss: 1.7020, Train: 0.2286, Val: 0.0820, Test: 0.1080
Epoch: 125, Loss: 1.6365, Train: 0.2286, Val: 0.0800, Test: 0.1080
Epoch: 126, Loss: 1.8487, Train: 0.2286, Val: 0.0820, Test: 0.1080
Epoch: 127, Loss: 1.6667, Train: 0.2357, Val: 0.0820, Test: 0.1100
Epoch: 128, Loss: 1.7547, Train: 0.2357, Val: 0.0860, Test: 0.1100
Epoch: 129, Loss: 1.6318, Train: 0.2357, Val: 0.0840, Test: 0.1090
Epoch: 130, Loss: 1.6774, Train: 0.2357, Val: 0.0840, Test: 0.1100
Epoch: 131, Loss: 1.7227, Train: 0.2429, Val: 0.0840, Test: 0.1130
Epoch: 132, Loss: 1.6459, Train: 0.2429, Val: 0.0840, Test: 0.1130
Epoch: 133, Loss: 1.6375, Train: 0.2429, Val: 0.0840, Test: 0.1130
Epoch: 134, Loss: 1.7420, Train: 0.2429, Val: 0.0840, Test: 0.1130
Epoch: 135, Loss: 1.6784, Train: 0.2429, Val: 0.0840, Test: 0.1130
Epoch: 136, Loss: 1.6301, Train: 0.2429, Val: 0.0860, Test: 0.1130
Epoch: 137, Loss: 1.7087, Train: 0.2429, Val: 0.0880, Test: 0.1140
Epoch: 138, Loss: 1.7082, Train: 0.2429, Val: 0.0900, Test: 0.1150
Epoch: 139, Loss: 1.7270, Train: 0.2429, Val: 0.0920, Test: 0.1150
Epoch: 140, Loss: 1.5896, Train: 0.2429, Val: 0.0960, Test: 0.1140
Epoch: 141, Loss: 1.7409, Train: 0.2429, Val: 0.0980, Test: 0.1160
Epoch: 142, Loss: 1.5896, Train: 0.2429, Val: 0.0960, Test: 0.1160
Epoch: 143, Loss: 1.6276, Train: 0.2429, Val: 0.0960, Test: 0.1150
Epoch: 144, Loss: 1.6314, Train: 0.2429, Val: 0.0980, Test: 0.1160
Epoch: 145, Loss: 1.5895, Train: 0.2500, Val: 0.1020, Test: 0.1160
Epoch: 146, Loss: 1.6472, Train: 0.2500, Val: 0.1040, Test: 0.1170
Epoch: 147, Loss: 1.5759, Train: 0.2500, Val: 0.1020, Test: 0.1170
Epoch: 148, Loss: 1.6274, Train: 0.2500, Val: 0.1040, Test: 0.1180
Epoch: 149, Loss: 1.5966, Train: 0.2500, Val: 0.1040, Test: 0.1190
Epoch: 150, Loss: 1.6099, Train: 0.2500, Val: 0.1040, Test: 0.1180
Epoch: 151, Loss: 1.6583, Train: 0.2500, Val: 0.1060, Test: 0.1190
Epoch: 152, Loss: 1.6303, Train: 0.2500, Val: 0.1080, Test: 0.1200
Epoch: 153, Loss: 1.6327, Train: 0.2500, Val: 0.1080, Test: 0.1200
Epoch: 154, Loss: 1.6189, Train: 0.2500, Val: 0.1060, Test: 0.1210
Epoch: 155, Loss: 1.5542, Train: 0.2500, Val: 0.1080, Test: 0.1230
Epoch: 156, Loss: 1.6417, Train: 0.2500, Val: 0.1140, Test: 0.1260
Epoch: 157, Loss: 1.5404, Train: 0.2500, Val: 0.1160, Test: 0.1310
Epoch: 158, Loss: 1.6604, Train: 0.2571, Val: 0.1160, Test: 0.1330
Epoch: 159, Loss: 1.6501, Train: 0.2571, Val: 0.1180, Test: 0.1330
Epoch: 160, Loss: 1.5824, Train: 0.2571, Val: 0.1180, Test: 0.1350
Epoch: 161, Loss: 1.5296, Train: 0.2643, Val: 0.1180, Test: 0.1370
Epoch: 162, Loss: 1.5696, Train: 0.2643, Val: 0.1200, Test: 0.1430
Epoch: 163, Loss: 1.6159, Train: 0.2643, Val: 0.1180, Test: 0.1450
Epoch: 164, Loss: 1.6123, Train: 0.2643, Val: 0.1200, Test: 0.1460
Epoch: 165, Loss: 1.6269, Train: 0.2643, Val: 0.1240, Test: 0.1460
Epoch: 166, Loss: 1.5499, Train: 0.2643, Val: 0.1240, Test: 0.1450
Epoch: 167, Loss: 1.5432, Train: 0.2643, Val: 0.1220, Test: 0.1450
Epoch: 168, Loss: 1.5680, Train: 0.2643, Val: 0.1180, Test: 0.1450
Epoch: 169, Loss: 1.5716, Train: 0.2643, Val: 0.1180, Test: 0.1430
Epoch: 170, Loss: 1.5469, Train: 0.2643, Val: 0.1200, Test: 0.1460
Epoch: 171, Loss: 1.5762, Train: 0.2643, Val: 0.1220, Test: 0.1480
Epoch: 172, Loss: 1.5232, Train: 0.2643, Val: 0.1240, Test: 0.1540
Epoch: 173, Loss: 1.5009, Train: 0.2786, Val: 0.1240, Test: 0.1560
Epoch: 174, Loss: 1.5134, Train: 0.2786, Val: 0.1240, Test: 0.1550
Epoch: 175, Loss: 1.5504, Train: 0.2786, Val: 0.1220, Test: 0.1530
Epoch: 176, Loss: 1.4691, Train: 0.2857, Val: 0.1240, Test: 0.1550
Epoch: 177, Loss: 1.5282, Train: 0.2857, Val: 0.1260, Test: 0.1590
Epoch: 178, Loss: 1.5123, Train: 0.2857, Val: 0.1260, Test: 0.1620
Epoch: 179, Loss: 1.5289, Train: 0.2929, Val: 0.1340, Test: 0.1740
Epoch: 180, Loss: 1.4832, Train: 0.2929, Val: 0.1440, Test: 0.1830
Epoch: 181, Loss: 1.5038, Train: 0.2929, Val: 0.1500, Test: 0.1860
Epoch: 182, Loss: 1.7350, Train: 0.2929, Val: 0.1480, Test: 0.1800
Epoch: 183, Loss: 1.4669, Train: 0.2929, Val: 0.1440, Test: 0.1750
Epoch: 184, Loss: 1.5017, Train: 0.2929, Val: 0.1400, Test: 0.1750
Epoch: 185, Loss: 1.5185, Train: 0.2714, Val: 0.1360, Test: 0.1710
Epoch: 186, Loss: 1.4461, Train: 0.2714, Val: 0.1340, Test: 0.1700
Epoch: 187, Loss: 1.4687, Train: 0.2857, Val: 0.1360, Test: 0.1730
Epoch: 188, Loss: 1.5036, Train: 0.2786, Val: 0.1340, Test: 0.1700
Epoch: 189, Loss: 1.5345, Train: 0.2786, Val: 0.1320, Test: 0.1660
Epoch: 190, Loss: 1.5267, Train: 0.2786, Val: 0.1240, Test: 0.1580
Epoch: 191, Loss: 1.4304, Train: 0.2786, Val: 0.1260, Test: 0.1580
Epoch: 192, Loss: 1.4923, Train: 0.2786, Val: 0.1340, Test: 0.1650
Epoch: 193, Loss: 1.5273, Train: 0.2857, Val: 0.1340, Test: 0.1690
Epoch: 194, Loss: 1.5821, Train: 0.2929, Val: 0.1380, Test: 0.1750
Epoch: 195, Loss: 1.4975, Train: 0.2929, Val: 0.1440, Test: 0.1760
Epoch: 196, Loss: 1.6827, Train: 0.2929, Val: 0.1440, Test: 0.1790
Epoch: 197, Loss: 1.4957, Train: 0.2929, Val: 0.1440, Test: 0.1780
Epoch: 198, Loss: 1.4771, Train: 0.2857, Val: 0.1360, Test: 0.1690
Epoch: 199, Loss: 1.4087, Train: 0.2786, Val: 0.1300, Test: 0.1670
Epoch: 200, Loss: 1.5371, Train: 0.2786, Val: 0.1300, Test: 0.1560
MAD:  0.4096
Best Test Accuracy: 0.1860, Val Accuracy: 0.1500, Train Accuracy: 0.2929
Training completed.
Seed:  3
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 13.1891, Train: 0.1429, Val: 0.1220, Test: 0.1310
Epoch: 2, Loss: 8.4700, Train: 0.1286, Val: 0.1380, Test: 0.1320
Epoch: 3, Loss: 6.1545, Train: 0.1429, Val: 0.2260, Test: 0.2500
Epoch: 4, Loss: 4.7621, Train: 0.1429, Val: 0.2540, Test: 0.2810
Epoch: 5, Loss: 4.5785, Train: 0.1500, Val: 0.2940, Test: 0.2880
Epoch: 6, Loss: 3.7691, Train: 0.1500, Val: 0.2860, Test: 0.2900
Epoch: 7, Loss: 4.0962, Train: 0.2000, Val: 0.3160, Test: 0.3050
Epoch: 8, Loss: 2.9377, Train: 0.2286, Val: 0.2980, Test: 0.2890
Epoch: 9, Loss: 3.2538, Train: 0.2214, Val: 0.2680, Test: 0.2730
Epoch: 10, Loss: 2.8784, Train: 0.2214, Val: 0.2380, Test: 0.2500
Epoch: 11, Loss: 2.6476, Train: 0.2214, Val: 0.2340, Test: 0.2370
Epoch: 12, Loss: 2.6088, Train: 0.2143, Val: 0.2340, Test: 0.2310
Epoch: 13, Loss: 2.5095, Train: 0.2214, Val: 0.2440, Test: 0.2420
Epoch: 14, Loss: 2.4571, Train: 0.2143, Val: 0.2500, Test: 0.2470
Epoch: 15, Loss: 2.2171, Train: 0.2143, Val: 0.2420, Test: 0.2570
Epoch: 16, Loss: 2.6562, Train: 0.1929, Val: 0.2380, Test: 0.2620
Epoch: 17, Loss: 2.4550, Train: 0.2214, Val: 0.1960, Test: 0.2480
Epoch: 18, Loss: 2.6675, Train: 0.2714, Val: 0.1820, Test: 0.2150
Epoch: 19, Loss: 2.2450, Train: 0.2500, Val: 0.1620, Test: 0.1890
Epoch: 20, Loss: 2.1209, Train: 0.2000, Val: 0.1400, Test: 0.1730
Epoch: 21, Loss: 2.1203, Train: 0.1929, Val: 0.1240, Test: 0.1570
Epoch: 22, Loss: 2.2336, Train: 0.1857, Val: 0.1240, Test: 0.1330
Epoch: 23, Loss: 2.0259, Train: 0.1857, Val: 0.0980, Test: 0.1340
Epoch: 24, Loss: 1.9628, Train: 0.1786, Val: 0.0920, Test: 0.1230
Epoch: 25, Loss: 2.1034, Train: 0.1571, Val: 0.0900, Test: 0.1130
Epoch: 26, Loss: 1.9318, Train: 0.1571, Val: 0.0880, Test: 0.1020
Epoch: 27, Loss: 1.9236, Train: 0.1429, Val: 0.0760, Test: 0.0950
Epoch: 28, Loss: 1.9783, Train: 0.1357, Val: 0.0740, Test: 0.0910
Epoch: 29, Loss: 2.1410, Train: 0.1429, Val: 0.0760, Test: 0.0910
Epoch: 30, Loss: 1.9764, Train: 0.1500, Val: 0.0740, Test: 0.0900
Epoch: 31, Loss: 2.0112, Train: 0.1429, Val: 0.0740, Test: 0.0920
Epoch: 32, Loss: 2.0026, Train: 0.1429, Val: 0.0740, Test: 0.0930
Epoch: 33, Loss: 1.9555, Train: 0.1429, Val: 0.0740, Test: 0.0930
Epoch: 34, Loss: 1.9503, Train: 0.1429, Val: 0.0740, Test: 0.0930
Epoch: 35, Loss: 2.2258, Train: 0.1429, Val: 0.0720, Test: 0.0930
Epoch: 36, Loss: 2.0484, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 37, Loss: 1.9561, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 38, Loss: 2.1499, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 39, Loss: 1.9534, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 40, Loss: 1.9890, Train: 0.1500, Val: 0.0700, Test: 0.0920
Epoch: 41, Loss: 1.9460, Train: 0.1500, Val: 0.0700, Test: 0.0920
Epoch: 42, Loss: 1.9664, Train: 0.1500, Val: 0.0700, Test: 0.0920
Epoch: 43, Loss: 1.9743, Train: 0.1500, Val: 0.0700, Test: 0.0920
Epoch: 44, Loss: 1.9953, Train: 0.1500, Val: 0.0700, Test: 0.0910
Epoch: 45, Loss: 1.9780, Train: 0.1500, Val: 0.0700, Test: 0.0910
Epoch: 46, Loss: 1.9777, Train: 0.1500, Val: 0.0700, Test: 0.0910
Epoch: 47, Loss: 1.9394, Train: 0.1500, Val: 0.0700, Test: 0.0910
Epoch: 48, Loss: 1.9279, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 49, Loss: 2.1259, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 50, Loss: 2.0892, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 51, Loss: 2.0292, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 52, Loss: 1.9087, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 53, Loss: 2.0443, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 54, Loss: 1.9037, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 55, Loss: 1.9127, Train: 0.1500, Val: 0.0700, Test: 0.0920
Epoch: 56, Loss: 2.0056, Train: 0.1571, Val: 0.0700, Test: 0.0920
Epoch: 57, Loss: 1.9916, Train: 0.1643, Val: 0.0700, Test: 0.0920
Epoch: 58, Loss: 2.0347, Train: 0.1643, Val: 0.0700, Test: 0.0920
Epoch: 59, Loss: 1.9480, Train: 0.1714, Val: 0.0720, Test: 0.0930
Epoch: 60, Loss: 2.1543, Train: 0.1714, Val: 0.0720, Test: 0.0930
Epoch: 61, Loss: 1.9778, Train: 0.1714, Val: 0.0720, Test: 0.0930
Epoch: 62, Loss: 1.9533, Train: 0.1714, Val: 0.0720, Test: 0.0930
Epoch: 63, Loss: 1.9522, Train: 0.1714, Val: 0.0720, Test: 0.0930
Epoch: 64, Loss: 2.0369, Train: 0.1714, Val: 0.0720, Test: 0.0930
Epoch: 65, Loss: 2.0526, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 66, Loss: 1.8589, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 67, Loss: 2.0054, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 68, Loss: 1.9099, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 69, Loss: 1.9236, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 70, Loss: 1.9128, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 71, Loss: 2.0145, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 72, Loss: 1.9314, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 73, Loss: 1.9046, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 74, Loss: 1.8822, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 75, Loss: 1.8561, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 76, Loss: 1.9391, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 77, Loss: 1.8225, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 78, Loss: 1.9417, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 79, Loss: 1.8617, Train: 0.1929, Val: 0.0720, Test: 0.0950
Epoch: 80, Loss: 1.9431, Train: 0.1857, Val: 0.0720, Test: 0.0940
Epoch: 81, Loss: 1.8724, Train: 0.1929, Val: 0.0720, Test: 0.0940
Epoch: 82, Loss: 1.8339, Train: 0.1929, Val: 0.0720, Test: 0.0940
Epoch: 83, Loss: 1.8091, Train: 0.1929, Val: 0.0720, Test: 0.0940
Epoch: 84, Loss: 1.8802, Train: 0.1929, Val: 0.0720, Test: 0.0940
Epoch: 85, Loss: 1.8622, Train: 0.2000, Val: 0.0700, Test: 0.0940
Epoch: 86, Loss: 1.8620, Train: 0.2000, Val: 0.0700, Test: 0.0940
Epoch: 87, Loss: 1.9003, Train: 0.2000, Val: 0.0700, Test: 0.0940
Epoch: 88, Loss: 1.8013, Train: 0.2000, Val: 0.0700, Test: 0.0950
Epoch: 89, Loss: 1.8676, Train: 0.2000, Val: 0.0700, Test: 0.0960
Epoch: 90, Loss: 1.7663, Train: 0.2071, Val: 0.0700, Test: 0.0970
Epoch: 91, Loss: 1.7602, Train: 0.2071, Val: 0.0720, Test: 0.0980
Epoch: 92, Loss: 1.7854, Train: 0.2071, Val: 0.0720, Test: 0.0990
Epoch: 93, Loss: 1.9972, Train: 0.2071, Val: 0.0720, Test: 0.1000
Epoch: 94, Loss: 1.7914, Train: 0.2071, Val: 0.0740, Test: 0.1000
Epoch: 95, Loss: 1.8657, Train: 0.2071, Val: 0.0740, Test: 0.1000
Epoch: 96, Loss: 1.7924, Train: 0.2071, Val: 0.0740, Test: 0.1010
Epoch: 97, Loss: 1.7594, Train: 0.2071, Val: 0.0740, Test: 0.1030
Epoch: 98, Loss: 1.7917, Train: 0.2071, Val: 0.0740, Test: 0.1020
Epoch: 99, Loss: 1.7803, Train: 0.2071, Val: 0.0720, Test: 0.1020
Epoch: 100, Loss: 1.8523, Train: 0.2071, Val: 0.0720, Test: 0.1030
Epoch: 101, Loss: 1.8110, Train: 0.2071, Val: 0.0740, Test: 0.1030
Epoch: 102, Loss: 1.8227, Train: 0.2071, Val: 0.0740, Test: 0.1030
Epoch: 103, Loss: 1.8398, Train: 0.2143, Val: 0.0760, Test: 0.1040
Epoch: 104, Loss: 1.8985, Train: 0.2143, Val: 0.0740, Test: 0.1040
Epoch: 105, Loss: 1.7283, Train: 0.2143, Val: 0.0740, Test: 0.1030
Epoch: 106, Loss: 1.7916, Train: 0.2143, Val: 0.0740, Test: 0.1030
Epoch: 107, Loss: 1.8043, Train: 0.2214, Val: 0.0740, Test: 0.1030
Epoch: 108, Loss: 1.8785, Train: 0.2214, Val: 0.0760, Test: 0.1060
Epoch: 109, Loss: 1.7731, Train: 0.2214, Val: 0.0760, Test: 0.1060
Epoch: 110, Loss: 1.7691, Train: 0.2214, Val: 0.0780, Test: 0.1060
Epoch: 111, Loss: 1.7387, Train: 0.2286, Val: 0.0780, Test: 0.1060
Epoch: 112, Loss: 1.7313, Train: 0.2286, Val: 0.0780, Test: 0.1060
Epoch: 113, Loss: 1.8514, Train: 0.2286, Val: 0.0780, Test: 0.1060
Epoch: 114, Loss: 1.6865, Train: 0.2286, Val: 0.0800, Test: 0.1060
Epoch: 115, Loss: 1.7105, Train: 0.2286, Val: 0.0820, Test: 0.1060
Epoch: 116, Loss: 1.6913, Train: 0.2286, Val: 0.0820, Test: 0.1070
Epoch: 117, Loss: 1.7308, Train: 0.2286, Val: 0.0820, Test: 0.1080
Epoch: 118, Loss: 1.7504, Train: 0.2286, Val: 0.0780, Test: 0.1080
Epoch: 119, Loss: 1.7423, Train: 0.2286, Val: 0.0760, Test: 0.1080
Epoch: 120, Loss: 1.6846, Train: 0.2286, Val: 0.0760, Test: 0.1080
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 121, Loss: 1.7545, Train: 0.2286, Val: 0.0760, Test: 0.1080
Epoch: 122, Loss: 1.6764, Train: 0.2286, Val: 0.0760, Test: 0.1090
Epoch: 123, Loss: 1.7681, Train: 0.2286, Val: 0.0760, Test: 0.1100
Epoch: 124, Loss: 1.7224, Train: 0.2286, Val: 0.0760, Test: 0.1100
Epoch: 125, Loss: 1.6752, Train: 0.2286, Val: 0.0760, Test: 0.1100
Epoch: 126, Loss: 1.7489, Train: 0.2357, Val: 0.0760, Test: 0.1110
Epoch: 127, Loss: 1.6885, Train: 0.2357, Val: 0.0780, Test: 0.1130
Epoch: 128, Loss: 1.6854, Train: 0.2357, Val: 0.0780, Test: 0.1130
Epoch: 129, Loss: 1.6584, Train: 0.2429, Val: 0.0780, Test: 0.1130
Epoch: 130, Loss: 1.6968, Train: 0.2429, Val: 0.0780, Test: 0.1140
Epoch: 131, Loss: 1.6696, Train: 0.2429, Val: 0.0800, Test: 0.1140
Epoch: 132, Loss: 1.6563, Train: 0.2429, Val: 0.0800, Test: 0.1140
Epoch: 133, Loss: 2.0898, Train: 0.2429, Val: 0.0840, Test: 0.1150
Epoch: 134, Loss: 1.7450, Train: 0.2429, Val: 0.0880, Test: 0.1150
Epoch: 135, Loss: 1.6778, Train: 0.2429, Val: 0.0860, Test: 0.1150
Epoch: 136, Loss: 1.6791, Train: 0.2429, Val: 0.0860, Test: 0.1180
Epoch: 137, Loss: 1.9147, Train: 0.2429, Val: 0.0860, Test: 0.1180
Epoch: 138, Loss: 1.6670, Train: 0.2429, Val: 0.0900, Test: 0.1200
Epoch: 139, Loss: 1.6379, Train: 0.2429, Val: 0.0920, Test: 0.1200
Epoch: 140, Loss: 1.7182, Train: 0.2571, Val: 0.0920, Test: 0.1220
Epoch: 141, Loss: 1.7362, Train: 0.2571, Val: 0.0920, Test: 0.1220
Epoch: 142, Loss: 1.7057, Train: 0.2571, Val: 0.0920, Test: 0.1220
Epoch: 143, Loss: 1.6675, Train: 0.2571, Val: 0.0940, Test: 0.1230
Epoch: 144, Loss: 1.6653, Train: 0.2571, Val: 0.0940, Test: 0.1230
Epoch: 145, Loss: 1.6217, Train: 0.2571, Val: 0.0940, Test: 0.1250
Epoch: 146, Loss: 1.7151, Train: 0.2571, Val: 0.0940, Test: 0.1250
Epoch: 147, Loss: 1.6487, Train: 0.2571, Val: 0.0940, Test: 0.1260
Epoch: 148, Loss: 1.6213, Train: 0.2571, Val: 0.0940, Test: 0.1260
Epoch: 149, Loss: 1.6624, Train: 0.2571, Val: 0.0960, Test: 0.1270
Epoch: 150, Loss: 1.6208, Train: 0.2571, Val: 0.0960, Test: 0.1260
Epoch: 151, Loss: 1.6771, Train: 0.2571, Val: 0.0960, Test: 0.1260
Epoch: 152, Loss: 1.6578, Train: 0.2571, Val: 0.0960, Test: 0.1260
Epoch: 153, Loss: 1.6325, Train: 0.2571, Val: 0.0980, Test: 0.1270
Epoch: 154, Loss: 1.5931, Train: 0.2571, Val: 0.0980, Test: 0.1270
Epoch: 155, Loss: 1.5967, Train: 0.2571, Val: 0.0980, Test: 0.1270
Epoch: 156, Loss: 1.6124, Train: 0.2571, Val: 0.0960, Test: 0.1270
Epoch: 157, Loss: 1.5869, Train: 0.2571, Val: 0.0960, Test: 0.1280
Epoch: 158, Loss: 1.6711, Train: 0.2571, Val: 0.0960, Test: 0.1270
Epoch: 159, Loss: 1.6606, Train: 0.2571, Val: 0.0960, Test: 0.1270
Epoch: 160, Loss: 1.6045, Train: 0.2571, Val: 0.0960, Test: 0.1260
Epoch: 161, Loss: 1.6359, Train: 0.2571, Val: 0.0980, Test: 0.1260
Epoch: 162, Loss: 1.6056, Train: 0.2571, Val: 0.0980, Test: 0.1250
Epoch: 163, Loss: 1.6157, Train: 0.2571, Val: 0.0980, Test: 0.1250
Epoch: 164, Loss: 1.6435, Train: 0.2571, Val: 0.0980, Test: 0.1260
Epoch: 165, Loss: 1.7000, Train: 0.2571, Val: 0.0920, Test: 0.1250
Epoch: 166, Loss: 1.6037, Train: 0.2571, Val: 0.0920, Test: 0.1250
Epoch: 167, Loss: 1.6123, Train: 0.2571, Val: 0.0920, Test: 0.1230
Epoch: 168, Loss: 1.5974, Train: 0.2571, Val: 0.0940, Test: 0.1230
Epoch: 169, Loss: 1.5750, Train: 0.2571, Val: 0.0940, Test: 0.1240
Epoch: 170, Loss: 1.5505, Train: 0.2571, Val: 0.0940, Test: 0.1250
Epoch: 171, Loss: 1.5992, Train: 0.2571, Val: 0.0940, Test: 0.1250
Epoch: 172, Loss: 1.5585, Train: 0.2571, Val: 0.0920, Test: 0.1280
Epoch: 173, Loss: 1.6179, Train: 0.2571, Val: 0.0940, Test: 0.1300
Epoch: 174, Loss: 1.5730, Train: 0.2571, Val: 0.0960, Test: 0.1320
Epoch: 175, Loss: 1.5532, Train: 0.2571, Val: 0.0960, Test: 0.1340
Epoch: 176, Loss: 1.5818, Train: 0.2571, Val: 0.0920, Test: 0.1360
Epoch: 177, Loss: 1.5333, Train: 0.2571, Val: 0.0940, Test: 0.1360
Epoch: 178, Loss: 1.5521, Train: 0.2571, Val: 0.0940, Test: 0.1380
Epoch: 179, Loss: 1.5983, Train: 0.2571, Val: 0.0980, Test: 0.1380
Epoch: 180, Loss: 1.6791, Train: 0.2571, Val: 0.0980, Test: 0.1430
Epoch: 181, Loss: 1.5584, Train: 0.2571, Val: 0.1000, Test: 0.1440
Epoch: 182, Loss: 1.5622, Train: 0.2643, Val: 0.1000, Test: 0.1470
Epoch: 183, Loss: 1.5465, Train: 0.2643, Val: 0.1000, Test: 0.1500
Epoch: 184, Loss: 1.5109, Train: 0.2714, Val: 0.1020, Test: 0.1510
Epoch: 185, Loss: 1.5577, Train: 0.2714, Val: 0.1040, Test: 0.1510
Epoch: 186, Loss: 1.6239, Train: 0.2714, Val: 0.1060, Test: 0.1510
Epoch: 187, Loss: 1.5268, Train: 0.2714, Val: 0.1060, Test: 0.1490
Epoch: 188, Loss: 1.5464, Train: 0.2714, Val: 0.1060, Test: 0.1490
Epoch: 189, Loss: 1.5232, Train: 0.2714, Val: 0.1060, Test: 0.1480
Epoch: 190, Loss: 1.5401, Train: 0.2714, Val: 0.1060, Test: 0.1470
Epoch: 191, Loss: 1.5047, Train: 0.2714, Val: 0.1040, Test: 0.1470
Epoch: 192, Loss: 1.5122, Train: 0.2643, Val: 0.1000, Test: 0.1450
Epoch: 193, Loss: 1.5942, Train: 0.2643, Val: 0.1000, Test: 0.1450
Epoch: 194, Loss: 1.5053, Train: 0.2643, Val: 0.1000, Test: 0.1450
Epoch: 195, Loss: 1.4828, Train: 0.2571, Val: 0.1020, Test: 0.1450
Epoch: 196, Loss: 1.6360, Train: 0.2571, Val: 0.1020, Test: 0.1460
Epoch: 197, Loss: 1.4822, Train: 0.2571, Val: 0.1020, Test: 0.1470
Epoch: 198, Loss: 1.5377, Train: 0.2571, Val: 0.1040, Test: 0.1470
Epoch: 199, Loss: 1.5197, Train: 0.2571, Val: 0.1040, Test: 0.1480
Epoch: 200, Loss: 1.5532, Train: 0.2571, Val: 0.1040, Test: 0.1490
MAD:  0.0542
Best Test Accuracy: 0.3050, Val Accuracy: 0.3160, Train Accuracy: 0.2000
Training completed.
Seed:  4
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 11.5060, Train: 0.2286, Val: 0.3200, Test: 0.3130
Epoch: 2, Loss: 8.2977, Train: 0.2214, Val: 0.2200, Test: 0.2170
Epoch: 3, Loss: 6.5137, Train: 0.1929, Val: 0.1700, Test: 0.1460
Epoch: 4, Loss: 5.4509, Train: 0.1429, Val: 0.1180, Test: 0.1170
Epoch: 5, Loss: 5.0767, Train: 0.1429, Val: 0.1180, Test: 0.1280
Epoch: 6, Loss: 4.9447, Train: 0.1429, Val: 0.1200, Test: 0.1280
Epoch: 7, Loss: 3.8655, Train: 0.1429, Val: 0.1200, Test: 0.1280
Epoch: 8, Loss: 3.5578, Train: 0.1429, Val: 0.1200, Test: 0.1280
Epoch: 9, Loss: 4.1492, Train: 0.1429, Val: 0.1200, Test: 0.1270
Epoch: 10, Loss: 3.2990, Train: 0.1429, Val: 0.1220, Test: 0.1270
Epoch: 11, Loss: 3.2716, Train: 0.1500, Val: 0.1220, Test: 0.1250
Epoch: 12, Loss: 2.9774, Train: 0.1643, Val: 0.1280, Test: 0.1220
Epoch: 13, Loss: 2.5669, Train: 0.1786, Val: 0.1300, Test: 0.1230
Epoch: 14, Loss: 2.8070, Train: 0.1571, Val: 0.1220, Test: 0.1200
Epoch: 15, Loss: 2.7672, Train: 0.2000, Val: 0.1000, Test: 0.1360
Epoch: 16, Loss: 2.4429, Train: 0.2071, Val: 0.1120, Test: 0.1410
Epoch: 17, Loss: 2.3572, Train: 0.2071, Val: 0.1220, Test: 0.1490
Epoch: 18, Loss: 2.2378, Train: 0.2071, Val: 0.1240, Test: 0.1610
Epoch: 19, Loss: 2.1472, Train: 0.2000, Val: 0.1400, Test: 0.1640
Epoch: 20, Loss: 2.0561, Train: 0.2000, Val: 0.1440, Test: 0.1660
Epoch: 21, Loss: 1.9772, Train: 0.1857, Val: 0.1480, Test: 0.1700
Epoch: 22, Loss: 2.1914, Train: 0.1786, Val: 0.1520, Test: 0.1650
Epoch: 23, Loss: 2.1172, Train: 0.1714, Val: 0.1560, Test: 0.1670
Epoch: 24, Loss: 2.3705, Train: 0.1714, Val: 0.1560, Test: 0.1680
Epoch: 25, Loss: 2.1264, Train: 0.1786, Val: 0.1560, Test: 0.1670
Epoch: 26, Loss: 2.1816, Train: 0.1714, Val: 0.1600, Test: 0.1670
Epoch: 27, Loss: 2.0332, Train: 0.1643, Val: 0.1560, Test: 0.1650
Epoch: 28, Loss: 2.0576, Train: 0.1643, Val: 0.1560, Test: 0.1670
Epoch: 29, Loss: 2.0659, Train: 0.1643, Val: 0.1580, Test: 0.1630
Epoch: 30, Loss: 2.1943, Train: 0.1571, Val: 0.1600, Test: 0.1600
Epoch: 31, Loss: 1.9638, Train: 0.1500, Val: 0.1620, Test: 0.1610
Epoch: 32, Loss: 1.9682, Train: 0.1500, Val: 0.1660, Test: 0.1570
Epoch: 33, Loss: 2.3110, Train: 0.1429, Val: 0.1640, Test: 0.1540
Epoch: 34, Loss: 2.0920, Train: 0.1500, Val: 0.1560, Test: 0.1550
Epoch: 35, Loss: 2.1705, Train: 0.1429, Val: 0.1580, Test: 0.1530
Epoch: 36, Loss: 2.0345, Train: 0.1429, Val: 0.1600, Test: 0.1560
Epoch: 37, Loss: 2.1586, Train: 0.1429, Val: 0.1600, Test: 0.1520
Epoch: 38, Loss: 2.2302, Train: 0.1500, Val: 0.1620, Test: 0.1520
Epoch: 39, Loss: 1.9059, Train: 0.1500, Val: 0.1640, Test: 0.1510
Epoch: 40, Loss: 1.9928, Train: 0.1571, Val: 0.1660, Test: 0.1510
Epoch: 41, Loss: 2.1064, Train: 0.1500, Val: 0.1620, Test: 0.1500
Epoch: 42, Loss: 2.0695, Train: 0.1571, Val: 0.1580, Test: 0.1520
Epoch: 43, Loss: 2.0306, Train: 0.1643, Val: 0.1560, Test: 0.1510
Epoch: 44, Loss: 2.0758, Train: 0.1643, Val: 0.1540, Test: 0.1480
Epoch: 45, Loss: 2.0159, Train: 0.1643, Val: 0.1480, Test: 0.1480
Epoch: 46, Loss: 2.0551, Train: 0.1500, Val: 0.1440, Test: 0.1420
Epoch: 47, Loss: 2.0351, Train: 0.1643, Val: 0.1380, Test: 0.1340
Epoch: 48, Loss: 1.9953, Train: 0.1500, Val: 0.1280, Test: 0.1290
Epoch: 49, Loss: 1.9521, Train: 0.1571, Val: 0.1120, Test: 0.1160
Epoch: 50, Loss: 2.0171, Train: 0.1357, Val: 0.1040, Test: 0.1030
Epoch: 51, Loss: 1.9324, Train: 0.1214, Val: 0.1020, Test: 0.1000
Epoch: 52, Loss: 1.9910, Train: 0.1143, Val: 0.1020, Test: 0.0970
Epoch: 53, Loss: 2.2417, Train: 0.1143, Val: 0.0960, Test: 0.0960
Epoch: 54, Loss: 2.4281, Train: 0.1286, Val: 0.0880, Test: 0.0960
Epoch: 55, Loss: 1.9876, Train: 0.1214, Val: 0.0860, Test: 0.0940
Epoch: 56, Loss: 1.9509, Train: 0.1214, Val: 0.0840, Test: 0.0900
Epoch: 57, Loss: 2.1875, Train: 0.1357, Val: 0.0860, Test: 0.0890
Epoch: 58, Loss: 1.9957, Train: 0.1357, Val: 0.0840, Test: 0.0890
Epoch: 59, Loss: 2.0395, Train: 0.1429, Val: 0.0820, Test: 0.0870
Epoch: 60, Loss: 2.0699, Train: 0.1357, Val: 0.0760, Test: 0.0890
Epoch: 61, Loss: 1.9687, Train: 0.1357, Val: 0.0740, Test: 0.0890
Epoch: 62, Loss: 1.8984, Train: 0.1357, Val: 0.0740, Test: 0.0890
Epoch: 63, Loss: 1.9688, Train: 0.1357, Val: 0.0740, Test: 0.0890
Epoch: 64, Loss: 1.9218, Train: 0.1357, Val: 0.0720, Test: 0.0890
Epoch: 65, Loss: 1.9717, Train: 0.1357, Val: 0.0720, Test: 0.0890
Epoch: 66, Loss: 1.9162, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 67, Loss: 1.9189, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 68, Loss: 1.9080, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 69, Loss: 1.8959, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 70, Loss: 1.9778, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 71, Loss: 1.9564, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 72, Loss: 1.8923, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 73, Loss: 1.9748, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 74, Loss: 2.1924, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 75, Loss: 1.9843, Train: 0.1429, Val: 0.0720, Test: 0.0890
Epoch: 76, Loss: 1.8730, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 77, Loss: 1.9440, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 78, Loss: 1.9342, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 79, Loss: 1.9853, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 80, Loss: 2.1523, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 81, Loss: 1.9134, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 82, Loss: 1.9699, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 83, Loss: 2.0824, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 84, Loss: 1.8934, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 85, Loss: 1.8978, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 86, Loss: 1.9576, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 87, Loss: 2.1678, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 88, Loss: 1.8609, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 89, Loss: 1.9414, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 90, Loss: 1.8891, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 91, Loss: 1.8964, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 92, Loss: 1.9717, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 93, Loss: 1.9945, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 94, Loss: 1.8729, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 95, Loss: 1.8591, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 96, Loss: 1.8686, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 97, Loss: 1.9051, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 98, Loss: 2.2065, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 99, Loss: 1.9168, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 100, Loss: 1.8579, Train: 0.1571, Val: 0.0720, Test: 0.0900
Epoch: 101, Loss: 1.9813, Train: 0.1643, Val: 0.0720, Test: 0.0910
Epoch: 102, Loss: 1.8572, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 103, Loss: 1.9971, Train: 0.1714, Val: 0.0720, Test: 0.0960
Epoch: 104, Loss: 1.9555, Train: 0.1714, Val: 0.0720, Test: 0.0980
Epoch: 105, Loss: 1.8823, Train: 0.1786, Val: 0.0720, Test: 0.0980
Epoch: 106, Loss: 1.9598, Train: 0.1786, Val: 0.0720, Test: 0.0980
Epoch: 107, Loss: 1.9191, Train: 0.1857, Val: 0.0720, Test: 0.1000
Epoch: 108, Loss: 1.8249, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 109, Loss: 1.8253, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 110, Loss: 1.8336, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 111, Loss: 1.9123, Train: 0.2000, Val: 0.0720, Test: 0.1010
Epoch: 112, Loss: 1.8292, Train: 0.2000, Val: 0.0720, Test: 0.1030
Epoch: 113, Loss: 1.8041, Train: 0.2000, Val: 0.0720, Test: 0.1030
Epoch: 114, Loss: 1.8794, Train: 0.2071, Val: 0.0720, Test: 0.1040
Epoch: 115, Loss: 1.8260, Train: 0.2071, Val: 0.0720, Test: 0.1040
Epoch: 116, Loss: 1.7769, Train: 0.2071, Val: 0.0740, Test: 0.1050
Epoch: 117, Loss: 1.7696, Train: 0.2071, Val: 0.0740, Test: 0.1050
Epoch: 118, Loss: 1.8579, Train: 0.2071, Val: 0.0740, Test: 0.1050
Epoch: 119, Loss: 1.7689, Train: 0.2071, Val: 0.0760, Test: 0.1050
Epoch: 120, Loss: 1.7877, Train: 0.2071, Val: 0.0760, Test: 0.1050
Epoch: 121, Loss: 1.7913, Train: 0.2071, Val: 0.0760, Test: 0.1050
Epoch: 122, Loss: 1.7216, Train: 0.2071, Val: 0.0780, Test: 0.1050
Epoch: 123, Loss: 1.8108, Train: 0.2071, Val: 0.0780, Test: 0.1050
Epoch: 124, Loss: 1.7597, Train: 0.2071, Val: 0.0780, Test: 0.1050
Epoch: 125, Loss: 1.7541, Train: 0.2071, Val: 0.0780, Test: 0.1050
Epoch: 126, Loss: 1.7206, Train: 0.2071, Val: 0.0780, Test: 0.1050
Epoch: 127, Loss: 1.7299, Train: 0.2071, Val: 0.0780, Test: 0.1050
Epoch: 128, Loss: 1.7328, Train: 0.2143, Val: 0.0780, Test: 0.1050
Epoch: 129, Loss: 1.7350, Train: 0.2143, Val: 0.0780, Test: 0.1050
Epoch: 130, Loss: 1.7902, Train: 0.2143, Val: 0.0780, Test: 0.1050
Epoch: 131, Loss: 1.7678, Train: 0.2143, Val: 0.0780, Test: 0.1050
Epoch: 132, Loss: 1.7353, Train: 0.2214, Val: 0.0780, Test: 0.1050
Epoch: 133, Loss: 1.7445, Train: 0.2214, Val: 0.0820, Test: 0.1060
Epoch: 134, Loss: 1.9048, Train: 0.2214, Val: 0.0820, Test: 0.1060
Epoch: 135, Loss: 1.7040, Train: 0.2286, Val: 0.0840, Test: 0.1070
Epoch: 136, Loss: 1.7084, Train: 0.2286, Val: 0.0840, Test: 0.1070
Epoch: 137, Loss: 1.7174, Train: 0.2286, Val: 0.0840, Test: 0.1070
Epoch: 138, Loss: 1.6869, Train: 0.2286, Val: 0.0860, Test: 0.1090
Epoch: 139, Loss: 1.7026, Train: 0.2286, Val: 0.0840, Test: 0.1090
Epoch: 140, Loss: 1.7165, Train: 0.2357, Val: 0.0860, Test: 0.1080
Epoch: 141, Loss: 1.7292, Train: 0.2357, Val: 0.0880, Test: 0.1090
Epoch: 142, Loss: 1.6892, Train: 0.2357, Val: 0.0900, Test: 0.1090
Epoch: 143, Loss: 1.7029, Train: 0.2357, Val: 0.0900, Test: 0.1090
Epoch: 144, Loss: 1.6666, Train: 0.2357, Val: 0.0900, Test: 0.1090
Epoch: 145, Loss: 1.7527, Train: 0.2357, Val: 0.0900, Test: 0.1090
Epoch: 146, Loss: 1.6737, Train: 0.2357, Val: 0.0900, Test: 0.1100
Epoch: 147, Loss: 1.6683, Train: 0.2357, Val: 0.0900, Test: 0.1100
Epoch: 148, Loss: 1.7383, Train: 0.2357, Val: 0.0900, Test: 0.1090
Epoch: 149, Loss: 1.6574, Train: 0.2357, Val: 0.0900, Test: 0.1090
Epoch: 150, Loss: 1.6883, Train: 0.2357, Val: 0.0920, Test: 0.1090
Epoch: 151, Loss: 1.7417, Train: 0.2357, Val: 0.0920, Test: 0.1090
Epoch: 152, Loss: 1.6554, Train: 0.2357, Val: 0.0900, Test: 0.1090
Epoch: 153, Loss: 1.6723, Train: 0.2357, Val: 0.0860, Test: 0.1100
Epoch: 154, Loss: 1.6534, Train: 0.2357, Val: 0.0880, Test: 0.1110
Epoch: 155, Loss: 1.6387, Train: 0.2357, Val: 0.0880, Test: 0.1110
Epoch: 156, Loss: 1.6672, Train: 0.2357, Val: 0.0880, Test: 0.1120
Epoch: 157, Loss: 1.8601, Train: 0.2357, Val: 0.0880, Test: 0.1130
Epoch: 158, Loss: 1.8253, Train: 0.2357, Val: 0.0880, Test: 0.1130
Epoch: 159, Loss: 1.6542, Train: 0.2357, Val: 0.0880, Test: 0.1130
Epoch: 160, Loss: 1.6550, Train: 0.2357, Val: 0.0880, Test: 0.1140
Epoch: 161, Loss: 1.6646, Train: 0.2357, Val: 0.0880, Test: 0.1140
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 162, Loss: 1.6894, Train: 0.2357, Val: 0.0880, Test: 0.1160
Epoch: 163, Loss: 1.6582, Train: 0.2357, Val: 0.0880, Test: 0.1160
Epoch: 164, Loss: 1.6467, Train: 0.2357, Val: 0.0880, Test: 0.1170
Epoch: 165, Loss: 1.6884, Train: 0.2357, Val: 0.0880, Test: 0.1180
Epoch: 166, Loss: 1.8045, Train: 0.2429, Val: 0.0860, Test: 0.1190
Epoch: 167, Loss: 1.6296, Train: 0.2429, Val: 0.0880, Test: 0.1200
Epoch: 168, Loss: 1.8614, Train: 0.2429, Val: 0.0900, Test: 0.1210
Epoch: 169, Loss: 1.6386, Train: 0.2429, Val: 0.0920, Test: 0.1210
Epoch: 170, Loss: 1.6145, Train: 0.2429, Val: 0.0940, Test: 0.1210
Epoch: 171, Loss: 1.6106, Train: 0.2429, Val: 0.0920, Test: 0.1200
Epoch: 172, Loss: 1.6637, Train: 0.2429, Val: 0.0920, Test: 0.1200
Epoch: 173, Loss: 1.6065, Train: 0.2571, Val: 0.0960, Test: 0.1220
Epoch: 174, Loss: 1.5936, Train: 0.2571, Val: 0.0960, Test: 0.1220
Epoch: 175, Loss: 1.6999, Train: 0.2571, Val: 0.0960, Test: 0.1220
Epoch: 176, Loss: 1.7197, Train: 0.2571, Val: 0.0980, Test: 0.1220
Epoch: 177, Loss: 1.6477, Train: 0.2571, Val: 0.0980, Test: 0.1210
Epoch: 178, Loss: 1.6849, Train: 0.2571, Val: 0.0960, Test: 0.1220
Epoch: 179, Loss: 1.6067, Train: 0.2571, Val: 0.0960, Test: 0.1220
Epoch: 180, Loss: 1.6180, Train: 0.2571, Val: 0.0960, Test: 0.1220
Epoch: 181, Loss: 1.5747, Train: 0.2571, Val: 0.0980, Test: 0.1240
Epoch: 182, Loss: 1.6371, Train: 0.2571, Val: 0.1000, Test: 0.1250
Epoch: 183, Loss: 1.6313, Train: 0.2571, Val: 0.1000, Test: 0.1280
Epoch: 184, Loss: 1.6440, Train: 0.2571, Val: 0.1000, Test: 0.1290
Epoch: 185, Loss: 1.5908, Train: 0.2571, Val: 0.1000, Test: 0.1300
Epoch: 186, Loss: 1.6047, Train: 0.2571, Val: 0.1000, Test: 0.1310
Epoch: 187, Loss: 1.5985, Train: 0.2571, Val: 0.1000, Test: 0.1290
Epoch: 188, Loss: 1.5766, Train: 0.2571, Val: 0.1020, Test: 0.1330
Epoch: 189, Loss: 1.5750, Train: 0.2571, Val: 0.1020, Test: 0.1330
Epoch: 190, Loss: 1.5692, Train: 0.2571, Val: 0.1060, Test: 0.1350
Epoch: 191, Loss: 1.6837, Train: 0.2571, Val: 0.1120, Test: 0.1370
Epoch: 192, Loss: 1.5982, Train: 0.2571, Val: 0.1120, Test: 0.1350
Epoch: 193, Loss: 1.5548, Train: 0.2643, Val: 0.1140, Test: 0.1400
Epoch: 194, Loss: 1.5311, Train: 0.2643, Val: 0.1220, Test: 0.1440
Epoch: 195, Loss: 1.5685, Train: 0.2643, Val: 0.1260, Test: 0.1480
Epoch: 196, Loss: 1.6090, Train: 0.2714, Val: 0.1240, Test: 0.1490
Epoch: 197, Loss: 1.5848, Train: 0.2786, Val: 0.1320, Test: 0.1530
Epoch: 198, Loss: 1.5369, Train: 0.2786, Val: 0.1340, Test: 0.1550
Epoch: 199, Loss: 1.5648, Train: 0.2786, Val: 0.1360, Test: 0.1580
Epoch: 200, Loss: 1.5899, Train: 0.2857, Val: 0.1400, Test: 0.1590
MAD:  0.1261
Best Test Accuracy: 0.3130, Val Accuracy: 0.3200, Train Accuracy: 0.2286
Training completed.
Seed:  5
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 12.4419, Train: 0.1357, Val: 0.1960, Test: 0.1940
Epoch: 2, Loss: 7.7523, Train: 0.1286, Val: 0.1120, Test: 0.1190
Epoch: 3, Loss: 6.1378, Train: 0.1571, Val: 0.1440, Test: 0.1680
Epoch: 4, Loss: 5.6302, Train: 0.1571, Val: 0.1540, Test: 0.1500
Epoch: 5, Loss: 3.6860, Train: 0.1500, Val: 0.1500, Test: 0.1590
Epoch: 6, Loss: 4.8622, Train: 0.1357, Val: 0.1500, Test: 0.1570
Epoch: 7, Loss: 3.3781, Train: 0.1714, Val: 0.1340, Test: 0.1390
Epoch: 8, Loss: 3.2209, Train: 0.1929, Val: 0.1480, Test: 0.1400
Epoch: 9, Loss: 3.4043, Train: 0.2143, Val: 0.1500, Test: 0.1440
Epoch: 10, Loss: 3.0566, Train: 0.2071, Val: 0.1580, Test: 0.1550
Epoch: 11, Loss: 2.8388, Train: 0.2429, Val: 0.1560, Test: 0.1600
Epoch: 12, Loss: 2.9049, Train: 0.2571, Val: 0.1700, Test: 0.1690
Epoch: 13, Loss: 2.3646, Train: 0.2357, Val: 0.1940, Test: 0.1780
Epoch: 14, Loss: 3.1100, Train: 0.2571, Val: 0.2080, Test: 0.1900
Epoch: 15, Loss: 2.7483, Train: 0.2786, Val: 0.1980, Test: 0.1930
Epoch: 16, Loss: 2.6417, Train: 0.2286, Val: 0.2140, Test: 0.1930
Epoch: 17, Loss: 2.4335, Train: 0.2000, Val: 0.2240, Test: 0.1930
Epoch: 18, Loss: 2.3584, Train: 0.1714, Val: 0.2080, Test: 0.1920
Epoch: 19, Loss: 2.3148, Train: 0.1786, Val: 0.2020, Test: 0.1840
Epoch: 20, Loss: 2.4017, Train: 0.1929, Val: 0.2000, Test: 0.1760
Epoch: 21, Loss: 2.6289, Train: 0.2071, Val: 0.2000, Test: 0.1770
Epoch: 22, Loss: 2.1664, Train: 0.2286, Val: 0.1980, Test: 0.1680
Epoch: 23, Loss: 2.3829, Train: 0.2071, Val: 0.1680, Test: 0.1590
Epoch: 24, Loss: 2.2768, Train: 0.1643, Val: 0.1560, Test: 0.1530
Epoch: 25, Loss: 2.3108, Train: 0.1714, Val: 0.1400, Test: 0.1470
Epoch: 26, Loss: 2.3065, Train: 0.1571, Val: 0.1220, Test: 0.1300
Epoch: 27, Loss: 2.0979, Train: 0.1357, Val: 0.1040, Test: 0.1190
Epoch: 28, Loss: 2.2296, Train: 0.1357, Val: 0.0980, Test: 0.1120
Epoch: 29, Loss: 2.2447, Train: 0.1429, Val: 0.0920, Test: 0.1060
Epoch: 30, Loss: 2.0646, Train: 0.1429, Val: 0.0840, Test: 0.0990
Epoch: 31, Loss: 2.1227, Train: 0.1429, Val: 0.0840, Test: 0.0980
Epoch: 32, Loss: 2.1062, Train: 0.1429, Val: 0.0800, Test: 0.0970
Epoch: 33, Loss: 2.0541, Train: 0.1429, Val: 0.0800, Test: 0.0960
Epoch: 34, Loss: 2.0447, Train: 0.1429, Val: 0.0800, Test: 0.0960
Epoch: 35, Loss: 2.1383, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 36, Loss: 2.2482, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 37, Loss: 2.0845, Train: 0.1429, Val: 0.0760, Test: 0.0960
Epoch: 38, Loss: 2.0132, Train: 0.1429, Val: 0.0760, Test: 0.0960
Epoch: 39, Loss: 2.0681, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 40, Loss: 1.9575, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 41, Loss: 2.0717, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 42, Loss: 2.0765, Train: 0.1500, Val: 0.0760, Test: 0.0960
Epoch: 43, Loss: 2.0810, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 44, Loss: 2.1935, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 45, Loss: 2.2309, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 46, Loss: 1.9550, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 47, Loss: 1.9778, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 48, Loss: 2.0510, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 49, Loss: 2.0730, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 50, Loss: 2.0939, Train: 0.1500, Val: 0.0760, Test: 0.0950
Epoch: 51, Loss: 2.0384, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 52, Loss: 1.9483, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 53, Loss: 2.1326, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 54, Loss: 1.9410, Train: 0.1429, Val: 0.0760, Test: 0.0950
Epoch: 55, Loss: 1.9920, Train: 0.1429, Val: 0.0760, Test: 0.0950
Epoch: 56, Loss: 1.9752, Train: 0.1429, Val: 0.0760, Test: 0.0950
Epoch: 57, Loss: 2.0232, Train: 0.1429, Val: 0.0760, Test: 0.0950
Epoch: 58, Loss: 1.9990, Train: 0.1429, Val: 0.0760, Test: 0.0950
Epoch: 59, Loss: 1.9057, Train: 0.1429, Val: 0.0760, Test: 0.0950
Epoch: 60, Loss: 1.9547, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 61, Loss: 2.0194, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 62, Loss: 1.9844, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 63, Loss: 1.9830, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 64, Loss: 2.0276, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 65, Loss: 1.9355, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 66, Loss: 1.9272, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 67, Loss: 1.9915, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 68, Loss: 2.0353, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 69, Loss: 2.1226, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 70, Loss: 1.9529, Train: 0.1429, Val: 0.0780, Test: 0.0960
Epoch: 71, Loss: 2.1215, Train: 0.1429, Val: 0.0780, Test: 0.0940
Epoch: 72, Loss: 2.1081, Train: 0.1429, Val: 0.0780, Test: 0.0940
Epoch: 73, Loss: 1.8692, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 74, Loss: 1.9287, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 75, Loss: 2.0042, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 76, Loss: 1.8839, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 77, Loss: 2.0270, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 78, Loss: 1.9751, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 79, Loss: 1.9638, Train: 0.1429, Val: 0.0760, Test: 0.0930
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 80, Loss: 1.9082, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 81, Loss: 1.9365, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 82, Loss: 1.8972, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 83, Loss: 1.9435, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 84, Loss: 2.0160, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 85, Loss: 1.9615, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 86, Loss: 1.8787, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 87, Loss: 1.8970, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 88, Loss: 1.9265, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 89, Loss: 1.8775, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 90, Loss: 2.0715, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 91, Loss: 1.9177, Train: 0.1429, Val: 0.0760, Test: 0.0930
Epoch: 92, Loss: 1.9819, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 93, Loss: 1.9515, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 94, Loss: 1.8961, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 95, Loss: 2.0743, Train: 0.1429, Val: 0.0780, Test: 0.0940
Epoch: 96, Loss: 1.8822, Train: 0.1429, Val: 0.0780, Test: 0.0940
Epoch: 97, Loss: 1.8997, Train: 0.1429, Val: 0.0780, Test: 0.0940
Epoch: 98, Loss: 1.9265, Train: 0.1429, Val: 0.0780, Test: 0.0940
Epoch: 99, Loss: 2.0962, Train: 0.1429, Val: 0.0760, Test: 0.0940
Epoch: 100, Loss: 1.8440, Train: 0.1429, Val: 0.0740, Test: 0.0940
Epoch: 101, Loss: 1.8757, Train: 0.1429, Val: 0.0740, Test: 0.0950
Epoch: 102, Loss: 2.0570, Train: 0.1429, Val: 0.0740, Test: 0.0950
Epoch: 103, Loss: 1.8659, Train: 0.1429, Val: 0.0740, Test: 0.0960
Epoch: 104, Loss: 1.8850, Train: 0.1429, Val: 0.0740, Test: 0.0960
Epoch: 105, Loss: 1.8595, Train: 0.1429, Val: 0.0740, Test: 0.0950
Epoch: 106, Loss: 1.8864, Train: 0.1500, Val: 0.0740, Test: 0.0950
Epoch: 107, Loss: 1.8320, Train: 0.1571, Val: 0.0720, Test: 0.0960
Epoch: 108, Loss: 1.8628, Train: 0.1571, Val: 0.0720, Test: 0.0960
Epoch: 109, Loss: 1.8166, Train: 0.1571, Val: 0.0720, Test: 0.0960
Epoch: 110, Loss: 1.9567, Train: 0.1571, Val: 0.0720, Test: 0.0960
Epoch: 111, Loss: 1.8053, Train: 0.1571, Val: 0.0720, Test: 0.0950
Epoch: 112, Loss: 1.7600, Train: 0.1571, Val: 0.0720, Test: 0.0950
Epoch: 113, Loss: 1.8323, Train: 0.1571, Val: 0.0720, Test: 0.0950
Epoch: 114, Loss: 1.8507, Train: 0.1786, Val: 0.0720, Test: 0.0950
Epoch: 115, Loss: 1.8372, Train: 0.1786, Val: 0.0720, Test: 0.0960
Epoch: 116, Loss: 1.8243, Train: 0.1786, Val: 0.0720, Test: 0.0960
Epoch: 117, Loss: 1.8903, Train: 0.1857, Val: 0.0720, Test: 0.0960
Epoch: 118, Loss: 1.9769, Train: 0.1857, Val: 0.0720, Test: 0.0980
Epoch: 119, Loss: 1.8585, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 120, Loss: 1.8658, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 121, Loss: 1.7999, Train: 0.1929, Val: 0.0720, Test: 0.1010
Epoch: 122, Loss: 1.8069, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 123, Loss: 1.7981, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 124, Loss: 1.7687, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 125, Loss: 1.7692, Train: 0.2000, Val: 0.0720, Test: 0.1000
Epoch: 126, Loss: 1.7931, Train: 0.2000, Val: 0.0720, Test: 0.1000
Epoch: 127, Loss: 1.8393, Train: 0.2000, Val: 0.0720, Test: 0.1000
Epoch: 128, Loss: 1.8360, Train: 0.2071, Val: 0.0720, Test: 0.1000
Epoch: 129, Loss: 1.8314, Train: 0.2071, Val: 0.0720, Test: 0.1000
Epoch: 130, Loss: 1.8449, Train: 0.2071, Val: 0.0720, Test: 0.1000
Epoch: 131, Loss: 1.7525, Train: 0.2071, Val: 0.0720, Test: 0.1010
Epoch: 132, Loss: 1.7884, Train: 0.2214, Val: 0.0720, Test: 0.1010
Epoch: 133, Loss: 1.8238, Train: 0.2214, Val: 0.0740, Test: 0.1010
Epoch: 134, Loss: 1.8196, Train: 0.2214, Val: 0.0740, Test: 0.1020
Epoch: 135, Loss: 1.7920, Train: 0.2214, Val: 0.0740, Test: 0.1030
Epoch: 136, Loss: 1.8128, Train: 0.2214, Val: 0.0760, Test: 0.1030
Epoch: 137, Loss: 1.7620, Train: 0.2214, Val: 0.0760, Test: 0.1040
Epoch: 138, Loss: 1.7172, Train: 0.2214, Val: 0.0760, Test: 0.1050
Epoch: 139, Loss: 1.9068, Train: 0.2214, Val: 0.0760, Test: 0.1050
Epoch: 140, Loss: 1.6970, Train: 0.2214, Val: 0.0760, Test: 0.1050
Epoch: 141, Loss: 1.7667, Train: 0.2214, Val: 0.0760, Test: 0.1050
Epoch: 142, Loss: 1.9102, Train: 0.2286, Val: 0.0760, Test: 0.1050
Epoch: 143, Loss: 1.7285, Train: 0.2286, Val: 0.0760, Test: 0.1050
Epoch: 144, Loss: 1.7453, Train: 0.2286, Val: 0.0760, Test: 0.1050
Epoch: 145, Loss: 1.7318, Train: 0.2286, Val: 0.0760, Test: 0.1050
Epoch: 146, Loss: 1.7168, Train: 0.2286, Val: 0.0760, Test: 0.1050
Epoch: 147, Loss: 1.7482, Train: 0.2286, Val: 0.0760, Test: 0.1060
Epoch: 148, Loss: 1.7277, Train: 0.2286, Val: 0.0760, Test: 0.1070
Epoch: 149, Loss: 1.7382, Train: 0.2357, Val: 0.0760, Test: 0.1090
Epoch: 150, Loss: 1.7268, Train: 0.2357, Val: 0.0760, Test: 0.1100
Epoch: 151, Loss: 1.7401, Train: 0.2357, Val: 0.0760, Test: 0.1100
Epoch: 152, Loss: 1.7035, Train: 0.2357, Val: 0.0780, Test: 0.1110
Epoch: 153, Loss: 1.6973, Train: 0.2357, Val: 0.0740, Test: 0.1110
Epoch: 154, Loss: 1.7634, Train: 0.2357, Val: 0.0760, Test: 0.1110
Epoch: 155, Loss: 1.8810, Train: 0.2357, Val: 0.0760, Test: 0.1100
Epoch: 156, Loss: 1.7723, Train: 0.2357, Val: 0.0760, Test: 0.1110
Epoch: 157, Loss: 1.7232, Train: 0.2357, Val: 0.0800, Test: 0.1130
Epoch: 158, Loss: 1.7067, Train: 0.2357, Val: 0.0800, Test: 0.1130
Epoch: 159, Loss: 1.8171, Train: 0.2357, Val: 0.0800, Test: 0.1140
Epoch: 160, Loss: 1.7382, Train: 0.2357, Val: 0.0820, Test: 0.1140
Epoch: 161, Loss: 1.6462, Train: 0.2357, Val: 0.0820, Test: 0.1140
Epoch: 162, Loss: 1.6967, Train: 0.2357, Val: 0.0820, Test: 0.1140
Epoch: 163, Loss: 1.6301, Train: 0.2357, Val: 0.0820, Test: 0.1140
Epoch: 164, Loss: 1.7163, Train: 0.2357, Val: 0.0800, Test: 0.1140
Epoch: 165, Loss: 1.6383, Train: 0.2357, Val: 0.0800, Test: 0.1140
Epoch: 166, Loss: 1.7156, Train: 0.2357, Val: 0.0800, Test: 0.1150
Epoch: 167, Loss: 1.6730, Train: 0.2357, Val: 0.0800, Test: 0.1140
Epoch: 168, Loss: 1.6350, Train: 0.2357, Val: 0.0780, Test: 0.1150
Epoch: 169, Loss: 1.6933, Train: 0.2357, Val: 0.0780, Test: 0.1150
Epoch: 170, Loss: 1.6379, Train: 0.2429, Val: 0.0780, Test: 0.1150
Epoch: 171, Loss: 1.6399, Train: 0.2429, Val: 0.0840, Test: 0.1150
Epoch: 172, Loss: 1.6069, Train: 0.2429, Val: 0.0860, Test: 0.1180
Epoch: 173, Loss: 1.7279, Train: 0.2429, Val: 0.0860, Test: 0.1200
Epoch: 174, Loss: 1.6485, Train: 0.2429, Val: 0.0860, Test: 0.1190
Epoch: 175, Loss: 1.6302, Train: 0.2429, Val: 0.0860, Test: 0.1220
Epoch: 176, Loss: 1.6348, Train: 0.2429, Val: 0.0880, Test: 0.1240
Epoch: 177, Loss: 1.6970, Train: 0.2429, Val: 0.0940, Test: 0.1260
Epoch: 178, Loss: 1.5997, Train: 0.2429, Val: 0.0980, Test: 0.1290
Epoch: 179, Loss: 1.6244, Train: 0.2429, Val: 0.0980, Test: 0.1310
Epoch: 180, Loss: 1.6365, Train: 0.2500, Val: 0.1020, Test: 0.1340
Epoch: 181, Loss: 1.6204, Train: 0.2429, Val: 0.1020, Test: 0.1320
Epoch: 182, Loss: 1.6198, Train: 0.2500, Val: 0.1020, Test: 0.1350
Epoch: 183, Loss: 1.6145, Train: 0.2714, Val: 0.1020, Test: 0.1410
Epoch: 184, Loss: 1.6392, Train: 0.2714, Val: 0.1060, Test: 0.1460
Epoch: 185, Loss: 1.6497, Train: 0.2786, Val: 0.1100, Test: 0.1550
Epoch: 186, Loss: 1.5895, Train: 0.2929, Val: 0.1200, Test: 0.1630
Epoch: 187, Loss: 1.6347, Train: 0.2786, Val: 0.1140, Test: 0.1580
Epoch: 188, Loss: 1.5840, Train: 0.2643, Val: 0.1060, Test: 0.1510
Epoch: 189, Loss: 1.6349, Train: 0.2571, Val: 0.1060, Test: 0.1430
Epoch: 190, Loss: 1.5647, Train: 0.2571, Val: 0.1020, Test: 0.1440
Epoch: 191, Loss: 1.5739, Train: 0.2571, Val: 0.1080, Test: 0.1470
Epoch: 192, Loss: 1.5608, Train: 0.2571, Val: 0.1080, Test: 0.1500
Epoch: 193, Loss: 1.6347, Train: 0.2500, Val: 0.1120, Test: 0.1470
Epoch: 194, Loss: 1.5472, Train: 0.2500, Val: 0.1160, Test: 0.1480
Epoch: 195, Loss: 1.5329, Train: 0.2500, Val: 0.1160, Test: 0.1490
Epoch: 196, Loss: 1.6109, Train: 0.2571, Val: 0.1220, Test: 0.1550
Epoch: 197, Loss: 1.5759, Train: 0.2857, Val: 0.1260, Test: 0.1590
Epoch: 198, Loss: 1.5915, Train: 0.2857, Val: 0.1300, Test: 0.1630
Epoch: 199, Loss: 1.5674, Train: 0.3000, Val: 0.1320, Test: 0.1680
Epoch: 200, Loss: 1.5934, Train: 0.3000, Val: 0.1340, Test: 0.1740
MAD:  0.0461
Best Test Accuracy: 0.1940, Val Accuracy: 0.1960, Train Accuracy: 0.1357
Training completed.
Seed:  6
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 9.1057, Train: 0.1500, Val: 0.1240, Test: 0.1340
Epoch: 2, Loss: 6.7925, Train: 0.1643, Val: 0.1740, Test: 0.1690
Epoch: 3, Loss: 4.6562, Train: 0.2000, Val: 0.1980, Test: 0.1900
Epoch: 4, Loss: 4.6939, Train: 0.1714, Val: 0.2040, Test: 0.1890
Epoch: 5, Loss: 4.2372, Train: 0.1857, Val: 0.2040, Test: 0.1890
Epoch: 6, Loss: 3.7023, Train: 0.2000, Val: 0.1980, Test: 0.1930
Epoch: 7, Loss: 4.1791, Train: 0.2357, Val: 0.1740, Test: 0.1840
Epoch: 8, Loss: 3.5444, Train: 0.2429, Val: 0.1760, Test: 0.1640
Epoch: 9, Loss: 2.8067, Train: 0.2214, Val: 0.1380, Test: 0.1370
Epoch: 10, Loss: 3.3610, Train: 0.2286, Val: 0.1220, Test: 0.1240
Epoch: 11, Loss: 2.7044, Train: 0.2214, Val: 0.1220, Test: 0.1230
Epoch: 12, Loss: 2.4939, Train: 0.2143, Val: 0.1260, Test: 0.1220
Epoch: 13, Loss: 2.7352, Train: 0.2500, Val: 0.1240, Test: 0.1220
Epoch: 14, Loss: 3.2304, Train: 0.2357, Val: 0.1300, Test: 0.1180
Epoch: 15, Loss: 2.8193, Train: 0.2286, Val: 0.1420, Test: 0.1190
Epoch: 16, Loss: 2.6238, Train: 0.2429, Val: 0.1480, Test: 0.1350
Epoch: 17, Loss: 2.2128, Train: 0.2071, Val: 0.1420, Test: 0.1440
Epoch: 18, Loss: 2.6234, Train: 0.1857, Val: 0.1460, Test: 0.1400
Epoch: 19, Loss: 2.2417, Train: 0.1643, Val: 0.1460, Test: 0.1510
Epoch: 20, Loss: 2.2711, Train: 0.1500, Val: 0.1420, Test: 0.1550
Epoch: 21, Loss: 2.1539, Train: 0.1714, Val: 0.1500, Test: 0.1540
Epoch: 22, Loss: 2.1502, Train: 0.1571, Val: 0.1560, Test: 0.1490
Epoch: 23, Loss: 2.3047, Train: 0.1500, Val: 0.1520, Test: 0.1500
Epoch: 24, Loss: 2.3567, Train: 0.1500, Val: 0.1600, Test: 0.1490
Epoch: 25, Loss: 2.2097, Train: 0.1500, Val: 0.1580, Test: 0.1480
Epoch: 26, Loss: 2.4452, Train: 0.1500, Val: 0.1560, Test: 0.1480
Epoch: 27, Loss: 2.1085, Train: 0.1500, Val: 0.1560, Test: 0.1460
Epoch: 28, Loss: 2.1691, Train: 0.1500, Val: 0.1620, Test: 0.1430
Epoch: 29, Loss: 1.9901, Train: 0.1500, Val: 0.1620, Test: 0.1430
Epoch: 30, Loss: 2.2215, Train: 0.1500, Val: 0.1620, Test: 0.1430
Epoch: 31, Loss: 2.0350, Train: 0.1571, Val: 0.1600, Test: 0.1420
Epoch: 32, Loss: 2.2028, Train: 0.1571, Val: 0.1580, Test: 0.1430
Epoch: 33, Loss: 2.2521, Train: 0.1571, Val: 0.1580, Test: 0.1430
Epoch: 34, Loss: 2.1572, Train: 0.1500, Val: 0.1580, Test: 0.1450
Epoch: 35, Loss: 2.2478, Train: 0.1500, Val: 0.1540, Test: 0.1440
Epoch: 36, Loss: 2.0679, Train: 0.1500, Val: 0.1540, Test: 0.1440
Epoch: 37, Loss: 2.1395, Train: 0.1429, Val: 0.1500, Test: 0.1430
Epoch: 38, Loss: 2.1138, Train: 0.1429, Val: 0.1520, Test: 0.1420
Epoch: 39, Loss: 1.9235, Train: 0.1429, Val: 0.1520, Test: 0.1420
Epoch: 40, Loss: 2.0931, Train: 0.1429, Val: 0.1520, Test: 0.1410
Epoch: 41, Loss: 1.9196, Train: 0.1429, Val: 0.1540, Test: 0.1410
Epoch: 42, Loss: 1.9666, Train: 0.1500, Val: 0.1540, Test: 0.1410
Epoch: 43, Loss: 2.1002, Train: 0.1500, Val: 0.1540, Test: 0.1410
Epoch: 44, Loss: 2.0002, Train: 0.1500, Val: 0.1540, Test: 0.1410
Epoch: 45, Loss: 1.9199, Train: 0.1571, Val: 0.1520, Test: 0.1400
Epoch: 46, Loss: 1.9976, Train: 0.1643, Val: 0.1540, Test: 0.1410
Epoch: 47, Loss: 2.2554, Train: 0.1643, Val: 0.1540, Test: 0.1420
Epoch: 48, Loss: 1.9417, Train: 0.1571, Val: 0.1520, Test: 0.1340
Epoch: 49, Loss: 2.1720, Train: 0.1714, Val: 0.1500, Test: 0.1300
Epoch: 50, Loss: 1.9259, Train: 0.1571, Val: 0.1420, Test: 0.1320
Epoch: 51, Loss: 1.9784, Train: 0.1714, Val: 0.1340, Test: 0.1200
Epoch: 52, Loss: 2.1599, Train: 0.1714, Val: 0.1220, Test: 0.1130
Epoch: 53, Loss: 2.0095, Train: 0.1714, Val: 0.1180, Test: 0.1080
Epoch: 54, Loss: 2.0897, Train: 0.1786, Val: 0.1060, Test: 0.1020
Epoch: 55, Loss: 1.9498, Train: 0.1714, Val: 0.0900, Test: 0.1020
Epoch: 56, Loss: 2.0051, Train: 0.1643, Val: 0.0740, Test: 0.1030
Epoch: 57, Loss: 1.9788, Train: 0.1643, Val: 0.0640, Test: 0.1020
Epoch: 58, Loss: 1.9907, Train: 0.1643, Val: 0.0680, Test: 0.1010
Epoch: 59, Loss: 2.0782, Train: 0.1643, Val: 0.0700, Test: 0.0970
Epoch: 60, Loss: 2.0357, Train: 0.1786, Val: 0.0760, Test: 0.0960
Epoch: 61, Loss: 2.1814, Train: 0.1643, Val: 0.0740, Test: 0.0970
Epoch: 62, Loss: 1.9188, Train: 0.1643, Val: 0.0740, Test: 0.0940
Epoch: 63, Loss: 1.9946, Train: 0.1500, Val: 0.0740, Test: 0.0930
Epoch: 64, Loss: 1.9160, Train: 0.1500, Val: 0.0720, Test: 0.0930
Epoch: 65, Loss: 1.9128, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 66, Loss: 1.9112, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 67, Loss: 1.9569, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 68, Loss: 2.1252, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 69, Loss: 1.8981, Train: 0.1571, Val: 0.0720, Test: 0.0920
Epoch: 70, Loss: 2.0179, Train: 0.1643, Val: 0.0720, Test: 0.0930
Epoch: 71, Loss: 1.9032, Train: 0.1643, Val: 0.0720, Test: 0.0930
Epoch: 72, Loss: 1.9695, Train: 0.1786, Val: 0.0720, Test: 0.0950
Epoch: 73, Loss: 1.9839, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 74, Loss: 1.8687, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 75, Loss: 1.9263, Train: 0.1714, Val: 0.0720, Test: 0.0940
Epoch: 76, Loss: 1.9937, Train: 0.1786, Val: 0.0720, Test: 0.0950
Epoch: 77, Loss: 1.9497, Train: 0.1786, Val: 0.0720, Test: 0.0950
Epoch: 78, Loss: 1.9020, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 79, Loss: 1.9540, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 80, Loss: 1.8558, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 81, Loss: 1.8815, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 82, Loss: 1.9606, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 83, Loss: 1.9204, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 84, Loss: 1.8248, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 85, Loss: 1.9155, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 86, Loss: 1.9024, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 87, Loss: 1.9424, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 88, Loss: 1.9156, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 89, Loss: 1.8635, Train: 0.1857, Val: 0.0720, Test: 0.0960
Epoch: 90, Loss: 1.8575, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 91, Loss: 1.9162, Train: 0.1857, Val: 0.0720, Test: 0.0960
Epoch: 92, Loss: 1.9302, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 93, Loss: 1.8617, Train: 0.1929, Val: 0.0720, Test: 0.0960
Epoch: 94, Loss: 1.9540, Train: 0.2000, Val: 0.0720, Test: 0.0970
Epoch: 95, Loss: 1.8689, Train: 0.2000, Val: 0.0720, Test: 0.0980
Epoch: 96, Loss: 1.8618, Train: 0.2000, Val: 0.0720, Test: 0.0990
Epoch: 97, Loss: 1.8119, Train: 0.2000, Val: 0.0720, Test: 0.1000
Epoch: 98, Loss: 1.8047, Train: 0.2000, Val: 0.0720, Test: 0.1000
Epoch: 99, Loss: 1.8466, Train: 0.2000, Val: 0.0720, Test: 0.1000
Epoch: 100, Loss: 1.8094, Train: 0.2000, Val: 0.0720, Test: 0.1000
Epoch: 101, Loss: 1.8002, Train: 0.2000, Val: 0.0720, Test: 0.1010
Epoch: 102, Loss: 1.8660, Train: 0.1929, Val: 0.0700, Test: 0.0990
Epoch: 103, Loss: 1.8299, Train: 0.1929, Val: 0.0700, Test: 0.0940
Epoch: 104, Loss: 1.7899, Train: 0.1857, Val: 0.0620, Test: 0.0920
Epoch: 105, Loss: 1.8007, Train: 0.1786, Val: 0.0740, Test: 0.0890
Epoch: 106, Loss: 1.8626, Train: 0.1929, Val: 0.0720, Test: 0.0920
Epoch: 107, Loss: 1.7508, Train: 0.2071, Val: 0.0840, Test: 0.1010
Epoch: 108, Loss: 1.8675, Train: 0.2143, Val: 0.0900, Test: 0.1160
Epoch: 109, Loss: 1.7721, Train: 0.2357, Val: 0.0920, Test: 0.1140
Epoch: 110, Loss: 1.8762, Train: 0.2214, Val: 0.1100, Test: 0.1140
Epoch: 111, Loss: 1.7343, Train: 0.2000, Val: 0.1120, Test: 0.1080
Epoch: 112, Loss: 1.7722, Train: 0.2000, Val: 0.1120, Test: 0.1070
Epoch: 113, Loss: 1.8279, Train: 0.2000, Val: 0.1100, Test: 0.1080
Epoch: 114, Loss: 1.8254, Train: 0.2000, Val: 0.1140, Test: 0.1080
Epoch: 115, Loss: 1.7458, Train: 0.2000, Val: 0.1140, Test: 0.1090
Epoch: 116, Loss: 1.7596, Train: 0.2000, Val: 0.1140, Test: 0.1110
Epoch: 117, Loss: 1.7428, Train: 0.2000, Val: 0.1160, Test: 0.1130
Epoch: 118, Loss: 1.7033, Train: 0.2071, Val: 0.1180, Test: 0.1130
Epoch: 119, Loss: 1.7118, Train: 0.2071, Val: 0.1200, Test: 0.1130
Epoch: 120, Loss: 1.6746, Train: 0.2143, Val: 0.1180, Test: 0.1130
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 121, Loss: 1.9613, Train: 0.2143, Val: 0.1180, Test: 0.1130
Epoch: 122, Loss: 1.6772, Train: 0.2143, Val: 0.1180, Test: 0.1130
Epoch: 123, Loss: 1.7160, Train: 0.2143, Val: 0.1180, Test: 0.1130
Epoch: 124, Loss: 1.7792, Train: 0.2143, Val: 0.1180, Test: 0.1140
Epoch: 125, Loss: 1.6484, Train: 0.2143, Val: 0.1180, Test: 0.1140
Epoch: 126, Loss: 1.7549, Train: 0.2214, Val: 0.1200, Test: 0.1150
Epoch: 127, Loss: 1.6356, Train: 0.2286, Val: 0.1200, Test: 0.1150
Epoch: 128, Loss: 1.7127, Train: 0.2286, Val: 0.1220, Test: 0.1160
Epoch: 129, Loss: 1.7172, Train: 0.2286, Val: 0.1180, Test: 0.1180
Epoch: 130, Loss: 1.6655, Train: 0.2286, Val: 0.1240, Test: 0.1170
Epoch: 131, Loss: 1.6605, Train: 0.2286, Val: 0.1260, Test: 0.1180
Epoch: 132, Loss: 1.6640, Train: 0.2286, Val: 0.1260, Test: 0.1170
Epoch: 133, Loss: 1.6941, Train: 0.2286, Val: 0.1280, Test: 0.1170
Epoch: 134, Loss: 1.7157, Train: 0.2286, Val: 0.1280, Test: 0.1180
Epoch: 135, Loss: 1.6445, Train: 0.2286, Val: 0.1280, Test: 0.1180
Epoch: 136, Loss: 1.6435, Train: 0.2357, Val: 0.1280, Test: 0.1190
Epoch: 137, Loss: 1.6571, Train: 0.2286, Val: 0.1260, Test: 0.1190
Epoch: 138, Loss: 1.6813, Train: 0.2357, Val: 0.1260, Test: 0.1180
Epoch: 139, Loss: 1.6463, Train: 0.2357, Val: 0.1260, Test: 0.1190
Epoch: 140, Loss: 1.6183, Train: 0.2357, Val: 0.1260, Test: 0.1190
Epoch: 141, Loss: 1.8471, Train: 0.2286, Val: 0.1260, Test: 0.1190
Epoch: 142, Loss: 1.6356, Train: 0.2286, Val: 0.1280, Test: 0.1190
Epoch: 143, Loss: 1.6477, Train: 0.2286, Val: 0.1280, Test: 0.1180
Epoch: 144, Loss: 1.6976, Train: 0.2286, Val: 0.1280, Test: 0.1180
Epoch: 145, Loss: 1.6130, Train: 0.2286, Val: 0.1280, Test: 0.1190
Epoch: 146, Loss: 1.6464, Train: 0.2286, Val: 0.1280, Test: 0.1200
Epoch: 147, Loss: 1.6019, Train: 0.2286, Val: 0.1280, Test: 0.1190
Epoch: 148, Loss: 1.6047, Train: 0.2286, Val: 0.1280, Test: 0.1180
Epoch: 149, Loss: 1.6223, Train: 0.2357, Val: 0.1280, Test: 0.1180
Epoch: 150, Loss: 1.6153, Train: 0.2357, Val: 0.1280, Test: 0.1180
Epoch: 151, Loss: 1.6513, Train: 0.2357, Val: 0.1300, Test: 0.1190
Epoch: 152, Loss: 1.5854, Train: 0.2357, Val: 0.1280, Test: 0.1180
Epoch: 153, Loss: 1.5746, Train: 0.2357, Val: 0.1300, Test: 0.1180
Epoch: 154, Loss: 1.6260, Train: 0.2357, Val: 0.1300, Test: 0.1180
Epoch: 155, Loss: 1.6589, Train: 0.2429, Val: 0.1300, Test: 0.1180
Epoch: 156, Loss: 1.6204, Train: 0.2429, Val: 0.1320, Test: 0.1180
Epoch: 157, Loss: 1.5362, Train: 0.2429, Val: 0.1320, Test: 0.1190
Epoch: 158, Loss: 1.6457, Train: 0.2429, Val: 0.1320, Test: 0.1180
Epoch: 159, Loss: 1.5972, Train: 0.2429, Val: 0.1320, Test: 0.1180
Epoch: 160, Loss: 1.6295, Train: 0.2429, Val: 0.1320, Test: 0.1190
Epoch: 161, Loss: 1.5366, Train: 0.2500, Val: 0.1340, Test: 0.1210
Epoch: 162, Loss: 1.5272, Train: 0.2643, Val: 0.1440, Test: 0.1250
Epoch: 163, Loss: 1.5524, Train: 0.2643, Val: 0.1400, Test: 0.1270
Epoch: 164, Loss: 1.5510, Train: 0.2714, Val: 0.1400, Test: 0.1300
Epoch: 165, Loss: 1.5546, Train: 0.2714, Val: 0.1420, Test: 0.1290
Epoch: 166, Loss: 1.4944, Train: 0.2786, Val: 0.1460, Test: 0.1300
Epoch: 167, Loss: 1.5135, Train: 0.2786, Val: 0.1480, Test: 0.1310
Epoch: 168, Loss: 1.6448, Train: 0.2857, Val: 0.1480, Test: 0.1310
Epoch: 169, Loss: 1.5513, Train: 0.2857, Val: 0.1500, Test: 0.1320
Epoch: 170, Loss: 1.6425, Train: 0.2857, Val: 0.1480, Test: 0.1320
Epoch: 171, Loss: 1.5191, Train: 0.2857, Val: 0.1420, Test: 0.1310
Epoch: 172, Loss: 1.5795, Train: 0.2714, Val: 0.1420, Test: 0.1330
Epoch: 173, Loss: 1.5053, Train: 0.2714, Val: 0.1420, Test: 0.1320
Epoch: 174, Loss: 1.5356, Train: 0.2714, Val: 0.1420, Test: 0.1320
Epoch: 175, Loss: 1.4944, Train: 0.2714, Val: 0.1400, Test: 0.1310
Epoch: 176, Loss: 1.4690, Train: 0.2714, Val: 0.1380, Test: 0.1310
Epoch: 177, Loss: 1.5081, Train: 0.2786, Val: 0.1380, Test: 0.1310
Epoch: 178, Loss: 1.5403, Train: 0.2786, Val: 0.1440, Test: 0.1320
Epoch: 179, Loss: 1.5328, Train: 0.2857, Val: 0.1420, Test: 0.1350
Epoch: 180, Loss: 1.4610, Train: 0.2857, Val: 0.1460, Test: 0.1330
Epoch: 181, Loss: 1.4612, Train: 0.2857, Val: 0.1460, Test: 0.1340
Epoch: 182, Loss: 1.4828, Train: 0.2857, Val: 0.1440, Test: 0.1310
Epoch: 183, Loss: 1.5088, Train: 0.2857, Val: 0.1440, Test: 0.1310
Epoch: 184, Loss: 1.4811, Train: 0.2857, Val: 0.1440, Test: 0.1300
Epoch: 185, Loss: 1.4373, Train: 0.2786, Val: 0.1440, Test: 0.1290
Epoch: 186, Loss: 1.4851, Train: 0.2786, Val: 0.1440, Test: 0.1300
Epoch: 187, Loss: 1.5030, Train: 0.2786, Val: 0.1440, Test: 0.1280
Epoch: 188, Loss: 1.4236, Train: 0.2714, Val: 0.1440, Test: 0.1280
Epoch: 189, Loss: 1.4754, Train: 0.2500, Val: 0.1400, Test: 0.1280
Epoch: 190, Loss: 1.4641, Train: 0.2571, Val: 0.1380, Test: 0.1290
Epoch: 191, Loss: 1.4919, Train: 0.2643, Val: 0.1480, Test: 0.1350
Epoch: 192, Loss: 1.4789, Train: 0.2929, Val: 0.1520, Test: 0.1400
Epoch: 193, Loss: 1.3940, Train: 0.3071, Val: 0.1640, Test: 0.1550
Epoch: 194, Loss: 1.4152, Train: 0.3071, Val: 0.1640, Test: 0.1540
Epoch: 195, Loss: 1.3396, Train: 0.2929, Val: 0.1660, Test: 0.1480
Epoch: 196, Loss: 1.4234, Train: 0.2786, Val: 0.1640, Test: 0.1400
Epoch: 197, Loss: 1.4340, Train: 0.2857, Val: 0.1600, Test: 0.1380
Epoch: 198, Loss: 1.4133, Train: 0.2714, Val: 0.1580, Test: 0.1370
Epoch: 199, Loss: 1.3564, Train: 0.2714, Val: 0.1580, Test: 0.1390
Epoch: 200, Loss: 1.4918, Train: 0.2786, Val: 0.1580, Test: 0.1440
MAD:  0.1235
Best Test Accuracy: 0.1930, Val Accuracy: 0.1980, Train Accuracy: 0.2000
Training completed.
Seed:  7
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 12.2105, Train: 0.1857, Val: 0.1460, Test: 0.1410
Epoch: 2, Loss: 7.6858, Train: 0.1357, Val: 0.1020, Test: 0.0990
Epoch: 3, Loss: 4.6133, Train: 0.1214, Val: 0.0960, Test: 0.0940
Epoch: 4, Loss: 4.4292, Train: 0.1571, Val: 0.1140, Test: 0.1150
Epoch: 5, Loss: 4.0876, Train: 0.1571, Val: 0.1040, Test: 0.1120
Epoch: 6, Loss: 3.7858, Train: 0.1714, Val: 0.1080, Test: 0.1250
Epoch: 7, Loss: 3.7274, Train: 0.1714, Val: 0.1100, Test: 0.1160
Epoch: 8, Loss: 3.6721, Train: 0.1500, Val: 0.0940, Test: 0.1060
Epoch: 9, Loss: 2.8609, Train: 0.1500, Val: 0.1000, Test: 0.1120
Epoch: 10, Loss: 2.7824, Train: 0.1500, Val: 0.1020, Test: 0.1090
Epoch: 11, Loss: 3.0162, Train: 0.1500, Val: 0.0980, Test: 0.1090
Epoch: 12, Loss: 3.4437, Train: 0.1429, Val: 0.1020, Test: 0.1050
Epoch: 13, Loss: 2.4891, Train: 0.1500, Val: 0.1120, Test: 0.1120
Epoch: 14, Loss: 2.5740, Train: 0.1500, Val: 0.1060, Test: 0.1260
Epoch: 15, Loss: 2.4164, Train: 0.1500, Val: 0.1160, Test: 0.1380
Epoch: 16, Loss: 2.6567, Train: 0.1429, Val: 0.1260, Test: 0.1400
Epoch: 17, Loss: 2.5366, Train: 0.1643, Val: 0.1440, Test: 0.1610
Epoch: 18, Loss: 2.4553, Train: 0.2071, Val: 0.1500, Test: 0.1670
Epoch: 19, Loss: 2.6530, Train: 0.2000, Val: 0.1580, Test: 0.1740
Epoch: 20, Loss: 2.4256, Train: 0.2071, Val: 0.1560, Test: 0.1690
Epoch: 21, Loss: 2.5388, Train: 0.2071, Val: 0.1540, Test: 0.1590
Epoch: 22, Loss: 2.2474, Train: 0.2071, Val: 0.1640, Test: 0.1550
Epoch: 23, Loss: 2.1646, Train: 0.2000, Val: 0.1680, Test: 0.1540
Epoch: 24, Loss: 2.1829, Train: 0.2143, Val: 0.1620, Test: 0.1570
Epoch: 25, Loss: 2.2992, Train: 0.2143, Val: 0.1740, Test: 0.1520
Epoch: 26, Loss: 2.0409, Train: 0.2286, Val: 0.1800, Test: 0.1620
Epoch: 27, Loss: 2.1029, Train: 0.2214, Val: 0.1960, Test: 0.1630
Epoch: 28, Loss: 2.0011, Train: 0.2071, Val: 0.1960, Test: 0.1660
Epoch: 29, Loss: 2.1353, Train: 0.2143, Val: 0.1920, Test: 0.1660
Epoch: 30, Loss: 1.9852, Train: 0.2071, Val: 0.1840, Test: 0.1690
Epoch: 31, Loss: 2.0412, Train: 0.2071, Val: 0.1760, Test: 0.1690
Epoch: 32, Loss: 2.2494, Train: 0.2000, Val: 0.1740, Test: 0.1680
Epoch: 33, Loss: 2.1706, Train: 0.1929, Val: 0.1720, Test: 0.1580
Epoch: 34, Loss: 2.0719, Train: 0.2000, Val: 0.1640, Test: 0.1540
Epoch: 35, Loss: 2.2517, Train: 0.2071, Val: 0.1580, Test: 0.1510
Epoch: 36, Loss: 2.0857, Train: 0.2214, Val: 0.1520, Test: 0.1510
Epoch: 37, Loss: 2.0201, Train: 0.2071, Val: 0.1520, Test: 0.1490
Epoch: 38, Loss: 2.0266, Train: 0.2071, Val: 0.1500, Test: 0.1470
Epoch: 39, Loss: 2.0782, Train: 0.2214, Val: 0.1520, Test: 0.1480
Epoch: 40, Loss: 1.9961, Train: 0.2214, Val: 0.1480, Test: 0.1450
Epoch: 41, Loss: 2.0534, Train: 0.2214, Val: 0.1480, Test: 0.1470
Epoch: 42, Loss: 2.0229, Train: 0.2214, Val: 0.1500, Test: 0.1450
Epoch: 43, Loss: 2.0183, Train: 0.2143, Val: 0.1460, Test: 0.1430
Epoch: 44, Loss: 2.1212, Train: 0.2000, Val: 0.1420, Test: 0.1440
Epoch: 45, Loss: 1.9751, Train: 0.2071, Val: 0.1440, Test: 0.1440
Epoch: 46, Loss: 2.2353, Train: 0.2000, Val: 0.1440, Test: 0.1480
Epoch: 47, Loss: 2.0336, Train: 0.1929, Val: 0.1420, Test: 0.1460
Epoch: 48, Loss: 1.9834, Train: 0.1929, Val: 0.1460, Test: 0.1450
Epoch: 49, Loss: 2.1007, Train: 0.1929, Val: 0.1560, Test: 0.1420
Epoch: 50, Loss: 2.0364, Train: 0.1857, Val: 0.1700, Test: 0.1430
Epoch: 51, Loss: 2.0565, Train: 0.1857, Val: 0.1680, Test: 0.1440
Epoch: 52, Loss: 2.1216, Train: 0.1786, Val: 0.1660, Test: 0.1440
Epoch: 53, Loss: 2.0181, Train: 0.1643, Val: 0.1580, Test: 0.1480
Epoch: 54, Loss: 2.2327, Train: 0.1714, Val: 0.1560, Test: 0.1480
Epoch: 55, Loss: 1.9670, Train: 0.1714, Val: 0.1600, Test: 0.1480
Epoch: 56, Loss: 2.0280, Train: 0.1786, Val: 0.1600, Test: 0.1470
Epoch: 57, Loss: 2.0294, Train: 0.1714, Val: 0.1580, Test: 0.1490
Epoch: 58, Loss: 2.0675, Train: 0.1714, Val: 0.1560, Test: 0.1490
Epoch: 59, Loss: 1.9531, Train: 0.1714, Val: 0.1600, Test: 0.1490
Epoch: 60, Loss: 1.9932, Train: 0.1714, Val: 0.1600, Test: 0.1460
Epoch: 61, Loss: 1.9564, Train: 0.1786, Val: 0.1600, Test: 0.1450
Epoch: 62, Loss: 2.1390, Train: 0.1786, Val: 0.1620, Test: 0.1460
Epoch: 63, Loss: 1.8942, Train: 0.1786, Val: 0.1620, Test: 0.1440
Epoch: 64, Loss: 1.9582, Train: 0.1714, Val: 0.1640, Test: 0.1390
Epoch: 65, Loss: 1.9481, Train: 0.1643, Val: 0.1620, Test: 0.1380
Epoch: 66, Loss: 2.1301, Train: 0.1786, Val: 0.1640, Test: 0.1400
Epoch: 67, Loss: 1.9672, Train: 0.1786, Val: 0.1620, Test: 0.1420
Epoch: 68, Loss: 1.9949, Train: 0.1786, Val: 0.1600, Test: 0.1410
Epoch: 69, Loss: 2.0272, Train: 0.1786, Val: 0.1560, Test: 0.1460
Epoch: 70, Loss: 1.8960, Train: 0.1714, Val: 0.1600, Test: 0.1440
Epoch: 71, Loss: 1.9310, Train: 0.1643, Val: 0.1580, Test: 0.1410
Epoch: 72, Loss: 1.9502, Train: 0.1786, Val: 0.1580, Test: 0.1400
Epoch: 73, Loss: 1.8610, Train: 0.1857, Val: 0.1580, Test: 0.1440
Epoch: 74, Loss: 1.9306, Train: 0.1929, Val: 0.1540, Test: 0.1460
Epoch: 75, Loss: 1.9069, Train: 0.2000, Val: 0.1560, Test: 0.1430
Epoch: 76, Loss: 1.9595, Train: 0.2071, Val: 0.1560, Test: 0.1440
Epoch: 77, Loss: 1.9126, Train: 0.2071, Val: 0.1480, Test: 0.1400
Epoch: 78, Loss: 2.0810, Train: 0.2071, Val: 0.1320, Test: 0.1420
Epoch: 79, Loss: 1.9170, Train: 0.2071, Val: 0.1300, Test: 0.1430
Epoch: 80, Loss: 1.8858, Train: 0.2071, Val: 0.1320, Test: 0.1460
Epoch: 81, Loss: 2.0300, Train: 0.2071, Val: 0.1300, Test: 0.1450
Epoch: 82, Loss: 1.8904, Train: 0.2071, Val: 0.1240, Test: 0.1440
Epoch: 83, Loss: 1.8871, Train: 0.2071, Val: 0.1280, Test: 0.1420
Epoch: 84, Loss: 2.0027, Train: 0.2071, Val: 0.1280, Test: 0.1410
Epoch: 85, Loss: 1.9185, Train: 0.2071, Val: 0.1280, Test: 0.1380
Epoch: 86, Loss: 1.8228, Train: 0.2071, Val: 0.1300, Test: 0.1370
Epoch: 87, Loss: 1.8845, Train: 0.2000, Val: 0.1280, Test: 0.1370
Epoch: 88, Loss: 2.1314, Train: 0.1929, Val: 0.1280, Test: 0.1360
Epoch: 89, Loss: 1.8861, Train: 0.1929, Val: 0.1260, Test: 0.1360
Epoch: 90, Loss: 1.9712, Train: 0.2000, Val: 0.1260, Test: 0.1360
Epoch: 91, Loss: 1.9251, Train: 0.1929, Val: 0.1260, Test: 0.1390
Epoch: 92, Loss: 1.8450, Train: 0.1929, Val: 0.1260, Test: 0.1370
Epoch: 93, Loss: 1.9030, Train: 0.1929, Val: 0.1260, Test: 0.1390
Epoch: 94, Loss: 1.9613, Train: 0.1929, Val: 0.1260, Test: 0.1390
Epoch: 95, Loss: 1.9464, Train: 0.2000, Val: 0.1260, Test: 0.1410
Epoch: 96, Loss: 1.9322, Train: 0.2000, Val: 0.1240, Test: 0.1400
Epoch: 97, Loss: 1.8006, Train: 0.2071, Val: 0.1240, Test: 0.1400
Epoch: 98, Loss: 1.9818, Train: 0.1929, Val: 0.1240, Test: 0.1390
Epoch: 99, Loss: 1.8641, Train: 0.2000, Val: 0.1240, Test: 0.1400
Epoch: 100, Loss: 2.1051, Train: 0.2000, Val: 0.1240, Test: 0.1400
Epoch: 101, Loss: 1.7737, Train: 0.2000, Val: 0.1240, Test: 0.1400
Epoch: 102, Loss: 1.8947, Train: 0.2000, Val: 0.1240, Test: 0.1400
Epoch: 103, Loss: 2.1474, Train: 0.2000, Val: 0.1240, Test: 0.1400
Epoch: 104, Loss: 1.9131, Train: 0.2000, Val: 0.1260, Test: 0.1400
Epoch: 105, Loss: 1.9186, Train: 0.2000, Val: 0.1260, Test: 0.1400
Epoch: 106, Loss: 1.8171, Train: 0.2000, Val: 0.1260, Test: 0.1400
Epoch: 107, Loss: 1.9073, Train: 0.2000, Val: 0.1260, Test: 0.1410
Epoch: 108, Loss: 1.7741, Train: 0.2000, Val: 0.1280, Test: 0.1410
Epoch: 109, Loss: 1.8829, Train: 0.2000, Val: 0.1320, Test: 0.1410
Epoch: 110, Loss: 1.9165, Train: 0.2000, Val: 0.1320, Test: 0.1420
Epoch: 111, Loss: 1.9802, Train: 0.2000, Val: 0.1320, Test: 0.1430
Epoch: 112, Loss: 1.8221, Train: 0.2071, Val: 0.1320, Test: 0.1430
Epoch: 113, Loss: 1.8252, Train: 0.2071, Val: 0.1320, Test: 0.1420
Epoch: 114, Loss: 1.9090, Train: 0.2071, Val: 0.1320, Test: 0.1420
Epoch: 115, Loss: 1.7717, Train: 0.2071, Val: 0.1340, Test: 0.1420
Epoch: 116, Loss: 1.7762, Train: 0.2071, Val: 0.1340, Test: 0.1420
Epoch: 117, Loss: 1.7884, Train: 0.2143, Val: 0.1340, Test: 0.1420
Epoch: 118, Loss: 1.7668, Train: 0.2143, Val: 0.1340, Test: 0.1420
Epoch: 119, Loss: 1.8472, Train: 0.2143, Val: 0.1340, Test: 0.1430
Epoch: 120, Loss: 1.8246, Train: 0.2143, Val: 0.1340, Test: 0.1420
Epoch: 121, Loss: 1.8957, Train: 0.2143, Val: 0.1340, Test: 0.1420
Epoch: 122, Loss: 1.7963, Train: 0.2143, Val: 0.1340, Test: 0.1420
Epoch: 123, Loss: 1.7680, Train: 0.2214, Val: 0.1340, Test: 0.1430
Epoch: 124, Loss: 1.7238, Train: 0.2214, Val: 0.1340, Test: 0.1420
Epoch: 125, Loss: 1.7637, Train: 0.2214, Val: 0.1320, Test: 0.1430
Epoch: 126, Loss: 1.6888, Train: 0.2214, Val: 0.1320, Test: 0.1430
Epoch: 127, Loss: 1.7494, Train: 0.2214, Val: 0.1320, Test: 0.1430
Epoch: 128, Loss: 1.9587, Train: 0.2214, Val: 0.1320, Test: 0.1440
Epoch: 129, Loss: 1.7683, Train: 0.2286, Val: 0.1340, Test: 0.1440
Epoch: 130, Loss: 1.7239, Train: 0.2286, Val: 0.1340, Test: 0.1440
Epoch: 131, Loss: 1.8074, Train: 0.2286, Val: 0.1360, Test: 0.1440
Epoch: 132, Loss: 1.7609, Train: 0.2357, Val: 0.1360, Test: 0.1450
Epoch: 133, Loss: 1.7194, Train: 0.2357, Val: 0.1340, Test: 0.1450
Epoch: 134, Loss: 1.8154, Train: 0.2357, Val: 0.1320, Test: 0.1450
Epoch: 135, Loss: 1.7594, Train: 0.2429, Val: 0.1320, Test: 0.1460
Epoch: 136, Loss: 1.8549, Train: 0.2429, Val: 0.1320, Test: 0.1470
Epoch: 137, Loss: 1.7514, Train: 0.2429, Val: 0.1320, Test: 0.1470
Epoch: 138, Loss: 1.7865, Train: 0.2429, Val: 0.1320, Test: 0.1470
Epoch: 139, Loss: 1.6684, Train: 0.2429, Val: 0.1320, Test: 0.1470
Epoch: 140, Loss: 1.8515, Train: 0.2429, Val: 0.1340, Test: 0.1480
Epoch: 141, Loss: 1.7449, Train: 0.2429, Val: 0.1360, Test: 0.1490
Epoch: 142, Loss: 1.7619, Train: 0.2429, Val: 0.1380, Test: 0.1500
Epoch: 143, Loss: 1.7297, Train: 0.2500, Val: 0.1440, Test: 0.1510
Epoch: 144, Loss: 1.7190, Train: 0.2500, Val: 0.1440, Test: 0.1510
Epoch: 145, Loss: 1.6486, Train: 0.2500, Val: 0.1440, Test: 0.1500
Epoch: 146, Loss: 1.6953, Train: 0.2500, Val: 0.1440, Test: 0.1480
Epoch: 147, Loss: 1.6854, Train: 0.2500, Val: 0.1460, Test: 0.1480
Epoch: 148, Loss: 1.7293, Train: 0.2500, Val: 0.1460, Test: 0.1500
Epoch: 149, Loss: 1.6634, Train: 0.2500, Val: 0.1460, Test: 0.1510
Epoch: 150, Loss: 1.6333, Train: 0.2500, Val: 0.1460, Test: 0.1520
Epoch: 151, Loss: 1.6451, Train: 0.2500, Val: 0.1460, Test: 0.1520
Epoch: 152, Loss: 1.6593, Train: 0.2500, Val: 0.1460, Test: 0.1520
Epoch: 153, Loss: 1.7050, Train: 0.2500, Val: 0.1460, Test: 0.1510
Epoch: 154, Loss: 1.7080, Train: 0.2500, Val: 0.1460, Test: 0.1510
Epoch: 155, Loss: 1.6338, Train: 0.2500, Val: 0.1460, Test: 0.1510
Epoch: 156, Loss: 1.6256, Train: 0.2500, Val: 0.1460, Test: 0.1520
Epoch: 157, Loss: 1.6392, Train: 0.2500, Val: 0.1460, Test: 0.1530
Epoch: 158, Loss: 1.6530, Train: 0.2500, Val: 0.1460, Test: 0.1530
Epoch: 159, Loss: 1.7071, Train: 0.2500, Val: 0.1460, Test: 0.1530
Epoch: 160, Loss: 1.7018, Train: 0.2500, Val: 0.1460, Test: 0.1530
Epoch: 161, Loss: 1.6115, Train: 0.2500, Val: 0.1480, Test: 0.1540
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 162, Loss: 1.6407, Train: 0.2571, Val: 0.1500, Test: 0.1580
Epoch: 163, Loss: 1.7332, Train: 0.2643, Val: 0.1500, Test: 0.1580
Epoch: 164, Loss: 1.5970, Train: 0.2643, Val: 0.1500, Test: 0.1580
Epoch: 165, Loss: 1.6759, Train: 0.2643, Val: 0.1480, Test: 0.1580
Epoch: 166, Loss: 1.5975, Train: 0.2643, Val: 0.1500, Test: 0.1580
Epoch: 167, Loss: 1.5834, Train: 0.2786, Val: 0.1500, Test: 0.1600
Epoch: 168, Loss: 1.6985, Train: 0.2857, Val: 0.1500, Test: 0.1600
Epoch: 169, Loss: 1.5843, Train: 0.2857, Val: 0.1520, Test: 0.1600
Epoch: 170, Loss: 1.6350, Train: 0.2857, Val: 0.1500, Test: 0.1600
Epoch: 171, Loss: 1.6229, Train: 0.2857, Val: 0.1500, Test: 0.1620
Epoch: 172, Loss: 1.6096, Train: 0.2857, Val: 0.1520, Test: 0.1620
Epoch: 173, Loss: 1.6256, Train: 0.2857, Val: 0.1520, Test: 0.1620
Epoch: 174, Loss: 1.5865, Train: 0.2857, Val: 0.1500, Test: 0.1620
Epoch: 175, Loss: 1.6449, Train: 0.2857, Val: 0.1500, Test: 0.1630
Epoch: 176, Loss: 1.6160, Train: 0.2857, Val: 0.1500, Test: 0.1650
Epoch: 177, Loss: 1.6003, Train: 0.3000, Val: 0.1500, Test: 0.1670
Epoch: 178, Loss: 1.6074, Train: 0.3000, Val: 0.1540, Test: 0.1670
Epoch: 179, Loss: 1.5278, Train: 0.3000, Val: 0.1540, Test: 0.1690
Epoch: 180, Loss: 1.6165, Train: 0.3000, Val: 0.1580, Test: 0.1690
Epoch: 181, Loss: 1.5859, Train: 0.3071, Val: 0.1580, Test: 0.1680
Epoch: 182, Loss: 1.6070, Train: 0.3071, Val: 0.1600, Test: 0.1690
Epoch: 183, Loss: 1.5564, Train: 0.3071, Val: 0.1600, Test: 0.1710
Epoch: 184, Loss: 1.5684, Train: 0.3071, Val: 0.1640, Test: 0.1730
Epoch: 185, Loss: 1.5854, Train: 0.3071, Val: 0.1680, Test: 0.1760
Epoch: 186, Loss: 1.5721, Train: 0.3143, Val: 0.1680, Test: 0.1760
Epoch: 187, Loss: 1.6133, Train: 0.3143, Val: 0.1700, Test: 0.1760
Epoch: 188, Loss: 1.5561, Train: 0.3143, Val: 0.1680, Test: 0.1780
Epoch: 189, Loss: 1.5420, Train: 0.3143, Val: 0.1700, Test: 0.1780
Epoch: 190, Loss: 1.6047, Train: 0.3143, Val: 0.1700, Test: 0.1790
Epoch: 191, Loss: 1.5266, Train: 0.3143, Val: 0.1700, Test: 0.1800
Epoch: 192, Loss: 1.5609, Train: 0.3143, Val: 0.1700, Test: 0.1800
Epoch: 193, Loss: 1.5410, Train: 0.3143, Val: 0.1720, Test: 0.1810
Epoch: 194, Loss: 1.6380, Train: 0.3143, Val: 0.1720, Test: 0.1790
Epoch: 195, Loss: 1.5337, Train: 0.3143, Val: 0.1680, Test: 0.1780
Epoch: 196, Loss: 1.5430, Train: 0.3143, Val: 0.1680, Test: 0.1780
Epoch: 197, Loss: 1.5343, Train: 0.3071, Val: 0.1640, Test: 0.1770
Epoch: 198, Loss: 1.5100, Train: 0.3071, Val: 0.1620, Test: 0.1790
Epoch: 199, Loss: 1.5298, Train: 0.3071, Val: 0.1620, Test: 0.1790
Epoch: 200, Loss: 1.5460, Train: 0.3071, Val: 0.1640, Test: 0.1800
MAD:  0.2587
Best Test Accuracy: 0.1810, Val Accuracy: 0.1720, Train Accuracy: 0.3143
Training completed.
Seed:  8
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 13.2464, Train: 0.1714, Val: 0.1220, Test: 0.1080
Epoch: 2, Loss: 6.6790, Train: 0.1143, Val: 0.0520, Test: 0.0670
Epoch: 3, Loss: 5.9579, Train: 0.1500, Val: 0.0640, Test: 0.0840
Epoch: 4, Loss: 4.3258, Train: 0.1429, Val: 0.0640, Test: 0.0760
Epoch: 5, Loss: 4.0051, Train: 0.1571, Val: 0.0880, Test: 0.1120
Epoch: 6, Loss: 3.7912, Train: 0.1857, Val: 0.1300, Test: 0.1350
Epoch: 7, Loss: 3.5083, Train: 0.1786, Val: 0.1320, Test: 0.1470
Epoch: 8, Loss: 3.4811, Train: 0.1786, Val: 0.1280, Test: 0.1520
Epoch: 9, Loss: 3.0091, Train: 0.1857, Val: 0.1300, Test: 0.1460
Epoch: 10, Loss: 2.7090, Train: 0.1929, Val: 0.1380, Test: 0.1450
Epoch: 11, Loss: 2.9179, Train: 0.1786, Val: 0.1240, Test: 0.1460
Epoch: 12, Loss: 2.5306, Train: 0.1571, Val: 0.1140, Test: 0.1370
Epoch: 13, Loss: 2.7198, Train: 0.1929, Val: 0.0980, Test: 0.1220
Epoch: 14, Loss: 2.3165, Train: 0.1714, Val: 0.0880, Test: 0.1240
Epoch: 15, Loss: 2.2440, Train: 0.1857, Val: 0.0800, Test: 0.1280
Epoch: 16, Loss: 2.2801, Train: 0.2214, Val: 0.0860, Test: 0.1340
Epoch: 17, Loss: 2.0900, Train: 0.1929, Val: 0.1040, Test: 0.1380
Epoch: 18, Loss: 2.2947, Train: 0.1857, Val: 0.1120, Test: 0.1520
Epoch: 19, Loss: 2.4728, Train: 0.1929, Val: 0.1300, Test: 0.1520
Epoch: 20, Loss: 2.3819, Train: 0.2071, Val: 0.1340, Test: 0.1390
Epoch: 21, Loss: 2.4184, Train: 0.1643, Val: 0.1340, Test: 0.1290
Epoch: 22, Loss: 2.0639, Train: 0.1500, Val: 0.1260, Test: 0.1240
Epoch: 23, Loss: 2.0424, Train: 0.1500, Val: 0.1280, Test: 0.1220
Epoch: 24, Loss: 2.0156, Train: 0.1500, Val: 0.1260, Test: 0.1200
Epoch: 25, Loss: 2.0538, Train: 0.1500, Val: 0.1240, Test: 0.1200
Epoch: 26, Loss: 2.1868, Train: 0.1429, Val: 0.1180, Test: 0.1210
Epoch: 27, Loss: 2.2311, Train: 0.1500, Val: 0.1200, Test: 0.1180
Epoch: 28, Loss: 1.9847, Train: 0.1643, Val: 0.1180, Test: 0.1130
Epoch: 29, Loss: 2.0597, Train: 0.1643, Val: 0.1200, Test: 0.1120
Epoch: 30, Loss: 2.0680, Train: 0.1643, Val: 0.1240, Test: 0.1130
Epoch: 31, Loss: 2.0980, Train: 0.1643, Val: 0.1260, Test: 0.1190
Epoch: 32, Loss: 2.0752, Train: 0.1714, Val: 0.1320, Test: 0.1210
Epoch: 33, Loss: 2.0353, Train: 0.1714, Val: 0.1400, Test: 0.1170
Epoch: 34, Loss: 1.9763, Train: 0.1786, Val: 0.1360, Test: 0.1200
Epoch: 35, Loss: 2.1708, Train: 0.1714, Val: 0.1340, Test: 0.1210
Epoch: 36, Loss: 2.1300, Train: 0.1714, Val: 0.1360, Test: 0.1220
Epoch: 37, Loss: 2.2474, Train: 0.1571, Val: 0.1380, Test: 0.1250
Epoch: 38, Loss: 1.9746, Train: 0.1571, Val: 0.1380, Test: 0.1230
Epoch: 39, Loss: 1.9843, Train: 0.1500, Val: 0.1420, Test: 0.1200
Epoch: 40, Loss: 1.9939, Train: 0.1500, Val: 0.1420, Test: 0.1230
Epoch: 41, Loss: 2.0943, Train: 0.1357, Val: 0.1380, Test: 0.1200
Epoch: 42, Loss: 2.0273, Train: 0.1286, Val: 0.1400, Test: 0.1180
Epoch: 43, Loss: 1.9554, Train: 0.1357, Val: 0.1300, Test: 0.1180
Epoch: 44, Loss: 2.0235, Train: 0.1357, Val: 0.1260, Test: 0.1180
Epoch: 45, Loss: 2.0375, Train: 0.1357, Val: 0.1220, Test: 0.1140
Epoch: 46, Loss: 2.0766, Train: 0.1429, Val: 0.1260, Test: 0.1110
Epoch: 47, Loss: 2.1273, Train: 0.1500, Val: 0.1240, Test: 0.0990
Epoch: 48, Loss: 1.9550, Train: 0.1500, Val: 0.0900, Test: 0.0910
Epoch: 49, Loss: 1.9653, Train: 0.1571, Val: 0.0820, Test: 0.0840
Epoch: 50, Loss: 2.0448, Train: 0.1571, Val: 0.0800, Test: 0.0840
Epoch: 51, Loss: 2.0615, Train: 0.1643, Val: 0.0880, Test: 0.0890
Epoch: 52, Loss: 2.0003, Train: 0.1714, Val: 0.0820, Test: 0.0900
Epoch: 53, Loss: 1.9256, Train: 0.1714, Val: 0.0800, Test: 0.0900
Epoch: 54, Loss: 1.9661, Train: 0.1643, Val: 0.0800, Test: 0.0910
Epoch: 55, Loss: 2.0303, Train: 0.1571, Val: 0.0760, Test: 0.0910
Epoch: 56, Loss: 1.9646, Train: 0.1429, Val: 0.0760, Test: 0.0900
Epoch: 57, Loss: 1.9827, Train: 0.1429, Val: 0.0720, Test: 0.0900
Epoch: 58, Loss: 1.9380, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 59, Loss: 1.9800, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 60, Loss: 2.0095, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 61, Loss: 2.0563, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 62, Loss: 1.9839, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 63, Loss: 1.9672, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 64, Loss: 1.9086, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 65, Loss: 2.1222, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 66, Loss: 1.9640, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 67, Loss: 1.8860, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 68, Loss: 1.9206, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 69, Loss: 2.0226, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 70, Loss: 1.9858, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 71, Loss: 1.9362, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 72, Loss: 2.0127, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 73, Loss: 1.9430, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 74, Loss: 2.0042, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 75, Loss: 1.9093, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 76, Loss: 2.0785, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 77, Loss: 1.8895, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 78, Loss: 1.9113, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 79, Loss: 2.0148, Train: 0.1429, Val: 0.0720, Test: 0.0910
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 80, Loss: 1.9388, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 81, Loss: 1.9032, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 82, Loss: 1.8602, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 83, Loss: 1.9268, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 84, Loss: 1.8712, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 85, Loss: 1.9076, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 86, Loss: 2.0598, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 87, Loss: 1.8299, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 88, Loss: 1.9584, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 89, Loss: 1.8743, Train: 0.1786, Val: 0.0720, Test: 0.0920
Epoch: 90, Loss: 1.9166, Train: 0.1786, Val: 0.0720, Test: 0.0930
Epoch: 91, Loss: 2.0153, Train: 0.1786, Val: 0.0720, Test: 0.0930
Epoch: 92, Loss: 1.8736, Train: 0.1786, Val: 0.0720, Test: 0.0930
Epoch: 93, Loss: 1.9963, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 94, Loss: 2.0418, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 95, Loss: 1.9100, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 96, Loss: 1.8994, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 97, Loss: 1.8592, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 98, Loss: 1.8557, Train: 0.1786, Val: 0.0720, Test: 0.0940
Epoch: 99, Loss: 1.8198, Train: 0.1857, Val: 0.0720, Test: 0.0940
Epoch: 100, Loss: 1.8708, Train: 0.1857, Val: 0.0720, Test: 0.0940
Epoch: 101, Loss: 1.8590, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 102, Loss: 1.8106, Train: 0.1857, Val: 0.0720, Test: 0.0970
Epoch: 103, Loss: 1.8987, Train: 0.1857, Val: 0.0720, Test: 0.0990
Epoch: 104, Loss: 1.8182, Train: 0.1857, Val: 0.0720, Test: 0.0990
Epoch: 105, Loss: 1.9340, Train: 0.1857, Val: 0.0720, Test: 0.0990
Epoch: 106, Loss: 1.9052, Train: 0.1929, Val: 0.0720, Test: 0.1000
Epoch: 107, Loss: 1.8750, Train: 0.2071, Val: 0.0720, Test: 0.1040
Epoch: 108, Loss: 1.8172, Train: 0.2071, Val: 0.0720, Test: 0.1060
Epoch: 109, Loss: 1.8473, Train: 0.2071, Val: 0.0740, Test: 0.1060
Epoch: 110, Loss: 1.8836, Train: 0.2071, Val: 0.0740, Test: 0.1060
Epoch: 111, Loss: 1.8089, Train: 0.2071, Val: 0.0760, Test: 0.1060
Epoch: 112, Loss: 1.8664, Train: 0.2071, Val: 0.0780, Test: 0.1060
Epoch: 113, Loss: 1.8614, Train: 0.2071, Val: 0.0780, Test: 0.1060
Epoch: 114, Loss: 1.7703, Train: 0.2071, Val: 0.0780, Test: 0.1060
Epoch: 115, Loss: 1.8721, Train: 0.2071, Val: 0.0780, Test: 0.1060
Epoch: 116, Loss: 1.9305, Train: 0.2071, Val: 0.0780, Test: 0.1060
Epoch: 117, Loss: 1.8377, Train: 0.2071, Val: 0.0760, Test: 0.1040
Epoch: 118, Loss: 1.7450, Train: 0.2071, Val: 0.0760, Test: 0.1040
Epoch: 119, Loss: 1.7834, Train: 0.2071, Val: 0.0760, Test: 0.1030
Epoch: 120, Loss: 1.8157, Train: 0.2071, Val: 0.0760, Test: 0.1040
Epoch: 121, Loss: 1.7590, Train: 0.2071, Val: 0.0780, Test: 0.1050
Epoch: 122, Loss: 1.8266, Train: 0.2071, Val: 0.0780, Test: 0.1050
Epoch: 123, Loss: 1.7352, Train: 0.2000, Val: 0.0780, Test: 0.1050
Epoch: 124, Loss: 1.7528, Train: 0.2000, Val: 0.0780, Test: 0.1050
Epoch: 125, Loss: 1.7594, Train: 0.2000, Val: 0.0780, Test: 0.1050
Epoch: 126, Loss: 1.7298, Train: 0.2000, Val: 0.0800, Test: 0.1040
Epoch: 127, Loss: 1.6894, Train: 0.2000, Val: 0.0820, Test: 0.1050
Epoch: 128, Loss: 1.7511, Train: 0.2000, Val: 0.0800, Test: 0.1050
Epoch: 129, Loss: 1.8142, Train: 0.2000, Val: 0.0800, Test: 0.1040
Epoch: 130, Loss: 1.7194, Train: 0.2000, Val: 0.0820, Test: 0.1040
Epoch: 131, Loss: 1.8184, Train: 0.2071, Val: 0.0820, Test: 0.1050
Epoch: 132, Loss: 1.7697, Train: 0.2071, Val: 0.0860, Test: 0.1050
Epoch: 133, Loss: 1.6969, Train: 0.2071, Val: 0.0880, Test: 0.1050
Epoch: 134, Loss: 1.7136, Train: 0.2071, Val: 0.0880, Test: 0.1040
Epoch: 135, Loss: 1.7578, Train: 0.2143, Val: 0.0880, Test: 0.1040
Epoch: 136, Loss: 1.7428, Train: 0.2143, Val: 0.0900, Test: 0.1040
Epoch: 137, Loss: 1.7425, Train: 0.2214, Val: 0.0940, Test: 0.1060
Epoch: 138, Loss: 1.6724, Train: 0.2286, Val: 0.0940, Test: 0.1080
Epoch: 139, Loss: 1.7351, Train: 0.2357, Val: 0.0900, Test: 0.1070
Epoch: 140, Loss: 1.7046, Train: 0.2286, Val: 0.0900, Test: 0.1050
Epoch: 141, Loss: 1.7253, Train: 0.2286, Val: 0.0900, Test: 0.1060
Epoch: 142, Loss: 1.6867, Train: 0.2286, Val: 0.0900, Test: 0.1060
Epoch: 143, Loss: 1.7601, Train: 0.2286, Val: 0.0900, Test: 0.1060
Epoch: 144, Loss: 1.6866, Train: 0.2286, Val: 0.0900, Test: 0.1070
Epoch: 145, Loss: 1.7033, Train: 0.2286, Val: 0.0900, Test: 0.1070
Epoch: 146, Loss: 1.7041, Train: 0.2357, Val: 0.0900, Test: 0.1070
Epoch: 147, Loss: 1.6979, Train: 0.2357, Val: 0.0920, Test: 0.1080
Epoch: 148, Loss: 1.6798, Train: 0.2357, Val: 0.0920, Test: 0.1110
Epoch: 149, Loss: 1.7510, Train: 0.2357, Val: 0.0940, Test: 0.1110
Epoch: 150, Loss: 1.7285, Train: 0.2357, Val: 0.0940, Test: 0.1120
Epoch: 151, Loss: 1.7654, Train: 0.2357, Val: 0.0940, Test: 0.1120
Epoch: 152, Loss: 1.7323, Train: 0.2357, Val: 0.0940, Test: 0.1140
Epoch: 153, Loss: 1.7088, Train: 0.2357, Val: 0.0960, Test: 0.1140
Epoch: 154, Loss: 1.6650, Train: 0.2357, Val: 0.0960, Test: 0.1140
Epoch: 155, Loss: 1.6164, Train: 0.2357, Val: 0.0960, Test: 0.1140
Epoch: 156, Loss: 1.6606, Train: 0.2357, Val: 0.0980, Test: 0.1140
Epoch: 157, Loss: 1.7448, Train: 0.2500, Val: 0.1000, Test: 0.1180
Epoch: 158, Loss: 1.6535, Train: 0.2571, Val: 0.1020, Test: 0.1190
Epoch: 159, Loss: 1.8216, Train: 0.2571, Val: 0.1040, Test: 0.1210
Epoch: 160, Loss: 1.6269, Train: 0.2643, Val: 0.1080, Test: 0.1230
Epoch: 161, Loss: 1.6415, Train: 0.2643, Val: 0.1120, Test: 0.1230
Epoch: 162, Loss: 1.6168, Train: 0.2643, Val: 0.1140, Test: 0.1220
Epoch: 163, Loss: 1.6173, Train: 0.2643, Val: 0.1120, Test: 0.1220
Epoch: 164, Loss: 1.7048, Train: 0.2500, Val: 0.1100, Test: 0.1210
Epoch: 165, Loss: 1.6021, Train: 0.2571, Val: 0.1080, Test: 0.1190
Epoch: 166, Loss: 1.6131, Train: 0.2571, Val: 0.1120, Test: 0.1210
Epoch: 167, Loss: 1.5981, Train: 0.2571, Val: 0.1160, Test: 0.1250
Epoch: 168, Loss: 1.9067, Train: 0.2643, Val: 0.1200, Test: 0.1250
Epoch: 169, Loss: 1.6333, Train: 0.2786, Val: 0.1220, Test: 0.1270
Epoch: 170, Loss: 1.5887, Train: 0.2786, Val: 0.1260, Test: 0.1310
Epoch: 171, Loss: 1.6017, Train: 0.2786, Val: 0.1260, Test: 0.1310
Epoch: 172, Loss: 1.6292, Train: 0.2857, Val: 0.1320, Test: 0.1310
Epoch: 173, Loss: 1.7253, Train: 0.2857, Val: 0.1320, Test: 0.1320
Epoch: 174, Loss: 1.6269, Train: 0.2857, Val: 0.1320, Test: 0.1330
Epoch: 175, Loss: 1.5764, Train: 0.2857, Val: 0.1320, Test: 0.1340
Epoch: 176, Loss: 1.7730, Train: 0.2786, Val: 0.1320, Test: 0.1320
Epoch: 177, Loss: 1.6320, Train: 0.2786, Val: 0.1340, Test: 0.1310
Epoch: 178, Loss: 1.5995, Train: 0.2786, Val: 0.1360, Test: 0.1310
Epoch: 179, Loss: 1.6666, Train: 0.2786, Val: 0.1360, Test: 0.1320
Epoch: 180, Loss: 1.8563, Train: 0.2786, Val: 0.1380, Test: 0.1360
Epoch: 181, Loss: 1.5911, Train: 0.2786, Val: 0.1400, Test: 0.1390
Epoch: 182, Loss: 1.5550, Train: 0.2857, Val: 0.1400, Test: 0.1410
Epoch: 183, Loss: 1.5816, Train: 0.2857, Val: 0.1400, Test: 0.1400
Epoch: 184, Loss: 1.6165, Train: 0.2857, Val: 0.1400, Test: 0.1390
Epoch: 185, Loss: 1.5284, Train: 0.2857, Val: 0.1380, Test: 0.1410
Epoch: 186, Loss: 1.5680, Train: 0.2857, Val: 0.1360, Test: 0.1420
Epoch: 187, Loss: 1.6654, Train: 0.2857, Val: 0.1360, Test: 0.1420
Epoch: 188, Loss: 1.5842, Train: 0.2929, Val: 0.1380, Test: 0.1410
Epoch: 189, Loss: 1.5504, Train: 0.2929, Val: 0.1400, Test: 0.1450
Epoch: 190, Loss: 1.5742, Train: 0.2929, Val: 0.1420, Test: 0.1470
Epoch: 191, Loss: 1.5248, Train: 0.2929, Val: 0.1420, Test: 0.1450
Epoch: 192, Loss: 1.5490, Train: 0.2929, Val: 0.1380, Test: 0.1450
Epoch: 193, Loss: 1.4884, Train: 0.2929, Val: 0.1400, Test: 0.1460
Epoch: 194, Loss: 1.6291, Train: 0.2929, Val: 0.1400, Test: 0.1490
Epoch: 195, Loss: 1.5293, Train: 0.3000, Val: 0.1440, Test: 0.1570
Epoch: 196, Loss: 1.5467, Train: 0.3000, Val: 0.1480, Test: 0.1600
Epoch: 197, Loss: 1.5595, Train: 0.3071, Val: 0.1380, Test: 0.1590
Epoch: 198, Loss: 1.5499, Train: 0.3000, Val: 0.1400, Test: 0.1600
Epoch: 199, Loss: 1.4770, Train: 0.3071, Val: 0.1380, Test: 0.1620
Epoch: 200, Loss: 1.5716, Train: 0.3071, Val: 0.1420, Test: 0.1670
MAD:  0.3766
Best Test Accuracy: 0.1670, Val Accuracy: 0.1420, Train Accuracy: 0.3071
Training completed.
Seed:  9
GCN(
  (convs): ModuleList(
    (0): GCNConv(1433, 128)
    (1-10): 10 x GCNConv(128, 128)
    (11): GCNConv(128, 7)
  )
  (residual_fc): Linear(in_features=1433, out_features=128, bias=True)
)
Epoch: 1, Loss: 11.6940, Train: 0.1071, Val: 0.1120, Test: 0.1100
Epoch: 2, Loss: 8.1021, Train: 0.1643, Val: 0.2260, Test: 0.2100
Epoch: 3, Loss: 5.4517, Train: 0.1500, Val: 0.1660, Test: 0.1660
Epoch: 4, Loss: 4.6486, Train: 0.1429, Val: 0.1680, Test: 0.1370
Epoch: 5, Loss: 3.8858, Train: 0.1429, Val: 0.1500, Test: 0.1350
Epoch: 6, Loss: 3.0968, Train: 0.1429, Val: 0.1440, Test: 0.1380
Epoch: 7, Loss: 3.3247, Train: 0.1714, Val: 0.1480, Test: 0.1530
Epoch: 8, Loss: 2.7768, Train: 0.1929, Val: 0.1680, Test: 0.1720
Epoch: 9, Loss: 2.8463, Train: 0.1714, Val: 0.1620, Test: 0.1640
Epoch: 10, Loss: 2.7338, Train: 0.1643, Val: 0.1460, Test: 0.1330
Epoch: 11, Loss: 2.8501, Train: 0.1571, Val: 0.1240, Test: 0.1190
Epoch: 12, Loss: 2.5508, Train: 0.1500, Val: 0.1040, Test: 0.1040
Epoch: 13, Loss: 2.5651, Train: 0.1429, Val: 0.0940, Test: 0.0960
Epoch: 14, Loss: 2.3408, Train: 0.1571, Val: 0.0860, Test: 0.0990
Epoch: 15, Loss: 3.0228, Train: 0.1571, Val: 0.0840, Test: 0.0990
Epoch: 16, Loss: 2.5119, Train: 0.1500, Val: 0.0840, Test: 0.0990
Epoch: 17, Loss: 2.1701, Train: 0.1500, Val: 0.0860, Test: 0.0980
Epoch: 18, Loss: 2.2914, Train: 0.1500, Val: 0.0860, Test: 0.0980
Epoch: 19, Loss: 2.2585, Train: 0.1500, Val: 0.0900, Test: 0.0980
Epoch: 20, Loss: 2.2609, Train: 0.1429, Val: 0.0920, Test: 0.0990
Epoch: 21, Loss: 2.2922, Train: 0.1500, Val: 0.0920, Test: 0.1000
Epoch: 22, Loss: 2.3335, Train: 0.1500, Val: 0.0860, Test: 0.0990
Epoch: 23, Loss: 2.1808, Train: 0.1500, Val: 0.0860, Test: 0.0990
Epoch: 24, Loss: 2.1835, Train: 0.1500, Val: 0.0840, Test: 0.1000
Epoch: 25, Loss: 2.0041, Train: 0.1500, Val: 0.0840, Test: 0.0980
Epoch: 26, Loss: 2.1243, Train: 0.1500, Val: 0.0820, Test: 0.0990
Epoch: 27, Loss: 2.2974, Train: 0.1500, Val: 0.0820, Test: 0.0980
Epoch: 28, Loss: 2.0904, Train: 0.1429, Val: 0.0820, Test: 0.0990
Epoch: 29, Loss: 2.3269, Train: 0.1429, Val: 0.0800, Test: 0.0970
Epoch: 30, Loss: 2.1977, Train: 0.1429, Val: 0.0800, Test: 0.0970
Epoch: 31, Loss: 2.1201, Train: 0.1357, Val: 0.0800, Test: 0.0970
Epoch: 32, Loss: 2.0224, Train: 0.1357, Val: 0.0780, Test: 0.0980
Epoch: 33, Loss: 2.2064, Train: 0.1357, Val: 0.0780, Test: 0.0970
Epoch: 34, Loss: 1.9996, Train: 0.1429, Val: 0.0780, Test: 0.0980
Epoch: 35, Loss: 2.0823, Train: 0.1429, Val: 0.0800, Test: 0.0980
Epoch: 36, Loss: 2.2403, Train: 0.1429, Val: 0.0800, Test: 0.1000
Epoch: 37, Loss: 1.9609, Train: 0.1357, Val: 0.0800, Test: 0.1000
Epoch: 38, Loss: 2.0111, Train: 0.1357, Val: 0.0820, Test: 0.1020
Epoch: 39, Loss: 2.0885, Train: 0.1357, Val: 0.0800, Test: 0.1020
Epoch: 40, Loss: 2.0021, Train: 0.1429, Val: 0.0800, Test: 0.1030
Epoch: 41, Loss: 1.9713, Train: 0.1357, Val: 0.0800, Test: 0.1020
Epoch: 42, Loss: 2.2127, Train: 0.1429, Val: 0.0760, Test: 0.1010
Epoch: 43, Loss: 2.0338, Train: 0.1500, Val: 0.0760, Test: 0.0990
Epoch: 44, Loss: 2.0603, Train: 0.1500, Val: 0.0760, Test: 0.0990
Epoch: 45, Loss: 2.0504, Train: 0.1643, Val: 0.0800, Test: 0.0990
Epoch: 46, Loss: 1.9885, Train: 0.1643, Val: 0.0800, Test: 0.1010
Epoch: 47, Loss: 2.2087, Train: 0.1571, Val: 0.0840, Test: 0.1010
Epoch: 48, Loss: 1.9066, Train: 0.1571, Val: 0.0800, Test: 0.1030
Epoch: 49, Loss: 2.0247, Train: 0.1429, Val: 0.0820, Test: 0.1060
Epoch: 50, Loss: 1.9464, Train: 0.1500, Val: 0.0840, Test: 0.1060
Epoch: 51, Loss: 1.9526, Train: 0.1500, Val: 0.0840, Test: 0.1070
Epoch: 52, Loss: 2.0065, Train: 0.1500, Val: 0.0860, Test: 0.1060
Epoch: 53, Loss: 1.9502, Train: 0.1571, Val: 0.0820, Test: 0.1050
Epoch: 54, Loss: 2.0141, Train: 0.1571, Val: 0.0820, Test: 0.1050
Epoch: 55, Loss: 1.9994, Train: 0.1571, Val: 0.0860, Test: 0.1040
Epoch: 56, Loss: 1.9874, Train: 0.1643, Val: 0.0840, Test: 0.0980
Epoch: 57, Loss: 1.9465, Train: 0.1571, Val: 0.0820, Test: 0.0980
Epoch: 58, Loss: 2.3142, Train: 0.1571, Val: 0.0780, Test: 0.0980
Epoch: 59, Loss: 1.9469, Train: 0.1500, Val: 0.0740, Test: 0.0970
Epoch: 60, Loss: 1.9770, Train: 0.1500, Val: 0.0720, Test: 0.0940
Epoch: 61, Loss: 1.9593, Train: 0.1571, Val: 0.0700, Test: 0.0940
Epoch: 62, Loss: 1.8997, Train: 0.1571, Val: 0.0700, Test: 0.0930
Epoch: 63, Loss: 1.9750, Train: 0.1571, Val: 0.0680, Test: 0.0930
Epoch: 64, Loss: 1.9374, Train: 0.1571, Val: 0.0680, Test: 0.0930
Epoch: 65, Loss: 1.9257, Train: 0.1429, Val: 0.0680, Test: 0.0920
Epoch: 66, Loss: 2.0140, Train: 0.1429, Val: 0.0680, Test: 0.0920
Epoch: 67, Loss: 2.0240, Train: 0.1429, Val: 0.0680, Test: 0.0920
Epoch: 68, Loss: 2.0693, Train: 0.1500, Val: 0.0680, Test: 0.0920
Epoch: 69, Loss: 2.0559, Train: 0.1429, Val: 0.0680, Test: 0.0910
Epoch: 70, Loss: 2.0117, Train: 0.1500, Val: 0.0680, Test: 0.0910
Epoch: 71, Loss: 1.9734, Train: 0.1571, Val: 0.0680, Test: 0.0920
Epoch: 72, Loss: 2.0386, Train: 0.1643, Val: 0.0680, Test: 0.0920
Epoch: 73, Loss: 1.9178, Train: 0.1643, Val: 0.0680, Test: 0.0920
Epoch: 74, Loss: 1.9870, Train: 0.1571, Val: 0.0680, Test: 0.0910
Epoch: 75, Loss: 1.9467, Train: 0.1571, Val: 0.0680, Test: 0.0910
Epoch: 76, Loss: 2.0047, Train: 0.1571, Val: 0.0680, Test: 0.0900
Epoch: 77, Loss: 2.0125, Train: 0.1571, Val: 0.0700, Test: 0.0900
Epoch: 78, Loss: 2.0307, Train: 0.1571, Val: 0.0700, Test: 0.0900
Epoch: 79, Loss: 1.9859, Train: 0.1571, Val: 0.0700, Test: 0.0900
Epoch: 80, Loss: 1.9545, Train: 0.1571, Val: 0.0700, Test: 0.0900
Epoch: 81, Loss: 1.9872, Train: 0.1571, Val: 0.0700, Test: 0.0900
Epoch: 82, Loss: 1.9109, Train: 0.1500, Val: 0.0700, Test: 0.0900
Epoch: 83, Loss: 1.9567, Train: 0.1500, Val: 0.0700, Test: 0.0900
Epoch: 84, Loss: 1.9909, Train: 0.1500, Val: 0.0700, Test: 0.0900
Epoch: 85, Loss: 2.0269, Train: 0.1571, Val: 0.0720, Test: 0.0900
Epoch: 86, Loss: 2.0080, Train: 0.1500, Val: 0.0740, Test: 0.0900
Epoch: 87, Loss: 1.9716, Train: 0.1571, Val: 0.0740, Test: 0.0910
Epoch: 88, Loss: 1.9125, Train: 0.1571, Val: 0.0740, Test: 0.0910
Epoch: 89, Loss: 2.0262, Train: 0.1571, Val: 0.0760, Test: 0.0910
Epoch: 90, Loss: 2.2459, Train: 0.1571, Val: 0.0760, Test: 0.0910
Epoch: 91, Loss: 2.0137, Train: 0.1571, Val: 0.0740, Test: 0.0910
Epoch: 92, Loss: 1.9627, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 93, Loss: 1.9982, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 94, Loss: 1.8979, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 95, Loss: 1.9223, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 96, Loss: 2.0153, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 97, Loss: 1.9668, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 98, Loss: 1.9916, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 99, Loss: 1.9324, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 100, Loss: 1.9267, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 101, Loss: 2.1105, Train: 0.1429, Val: 0.0700, Test: 0.0900
Epoch: 102, Loss: 1.9440, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 103, Loss: 2.1056, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 104, Loss: 1.9417, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 105, Loss: 1.9895, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 106, Loss: 1.9045, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 107, Loss: 1.8961, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 108, Loss: 1.9814, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 109, Loss: 1.9657, Train: 0.1429, Val: 0.0700, Test: 0.0910
Epoch: 110, Loss: 2.0208, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 111, Loss: 1.9171, Train: 0.1429, Val: 0.0720, Test: 0.0910
Epoch: 112, Loss: 1.8990, Train: 0.1500, Val: 0.0720, Test: 0.0910
Epoch: 113, Loss: 1.8827, Train: 0.1500, Val: 0.0720, Test: 0.0920
Epoch: 114, Loss: 1.9598, Train: 0.1500, Val: 0.0720, Test: 0.0920
Epoch: 115, Loss: 1.9070, Train: 0.1500, Val: 0.0720, Test: 0.0920
Epoch: 116, Loss: 1.9117, Train: 0.1571, Val: 0.0700, Test: 0.0910
Epoch: 117, Loss: 1.9412, Train: 0.1643, Val: 0.0700, Test: 0.0920
Epoch: 118, Loss: 2.0955, Train: 0.1643, Val: 0.0700, Test: 0.0920
Epoch: 119, Loss: 2.0516, Train: 0.1714, Val: 0.0700, Test: 0.0930
Epoch: 120, Loss: 1.8893, Train: 0.1714, Val: 0.0700, Test: 0.0930
/root/code/DIR/DIR-GNN/train/cora.py:393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 121, Loss: 1.9128, Train: 0.1786, Val: 0.0700, Test: 0.0930
Epoch: 122, Loss: 1.8635, Train: 0.1786, Val: 0.0700, Test: 0.0930
Epoch: 123, Loss: 1.8565, Train: 0.1786, Val: 0.0700, Test: 0.0930
Epoch: 124, Loss: 1.9697, Train: 0.1857, Val: 0.0700, Test: 0.0930
Epoch: 125, Loss: 1.8816, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 126, Loss: 2.0353, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 127, Loss: 1.9371, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 128, Loss: 1.9031, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 129, Loss: 1.9715, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 130, Loss: 1.9511, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 131, Loss: 2.0111, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 132, Loss: 2.0074, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 133, Loss: 1.8591, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 134, Loss: 1.9169, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 135, Loss: 1.9127, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 136, Loss: 1.9682, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 137, Loss: 1.9673, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 138, Loss: 1.9114, Train: 0.1929, Val: 0.0700, Test: 0.0950
Epoch: 139, Loss: 1.9098, Train: 0.1929, Val: 0.0700, Test: 0.0950
Epoch: 140, Loss: 1.9018, Train: 0.1929, Val: 0.0700, Test: 0.0950
Epoch: 141, Loss: 1.8163, Train: 0.1929, Val: 0.0700, Test: 0.0950
Epoch: 142, Loss: 1.8357, Train: 0.1929, Val: 0.0700, Test: 0.0950
Epoch: 143, Loss: 1.8971, Train: 0.1929, Val: 0.0700, Test: 0.0950
Epoch: 144, Loss: 1.9291, Train: 0.1929, Val: 0.0700, Test: 0.0950
Epoch: 145, Loss: 1.9569, Train: 0.1929, Val: 0.0700, Test: 0.0950
Epoch: 146, Loss: 1.8535, Train: 0.1929, Val: 0.0700, Test: 0.0940
Epoch: 147, Loss: 1.8381, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 148, Loss: 2.1547, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 149, Loss: 1.8538, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 150, Loss: 1.8355, Train: 0.1857, Val: 0.0700, Test: 0.0940
Epoch: 151, Loss: 1.8985, Train: 0.1857, Val: 0.0720, Test: 0.0950
Epoch: 152, Loss: 1.8400, Train: 0.1857, Val: 0.0720, Test: 0.0960
Epoch: 153, Loss: 1.8058, Train: 0.1857, Val: 0.0720, Test: 0.0960
Epoch: 154, Loss: 2.0244, Train: 0.1857, Val: 0.0740, Test: 0.0960
Epoch: 155, Loss: 1.9139, Train: 0.1857, Val: 0.0720, Test: 0.0960
Epoch: 156, Loss: 2.0175, Train: 0.1857, Val: 0.0720, Test: 0.0960
Epoch: 157, Loss: 1.8779, Train: 0.1857, Val: 0.0720, Test: 0.0960
Epoch: 158, Loss: 1.7903, Train: 0.1857, Val: 0.0720, Test: 0.0970
Epoch: 159, Loss: 1.7718, Train: 0.1857, Val: 0.0720, Test: 0.0970
Epoch: 160, Loss: 1.8806, Train: 0.1857, Val: 0.0720, Test: 0.0970
Epoch: 161, Loss: 1.8285, Train: 0.1857, Val: 0.0720, Test: 0.0970
Epoch: 162, Loss: 1.7460, Train: 0.1857, Val: 0.0720, Test: 0.0970
Epoch: 163, Loss: 1.7967, Train: 0.1929, Val: 0.0700, Test: 0.0980
Epoch: 164, Loss: 1.7721, Train: 0.1929, Val: 0.0700, Test: 0.1000
Epoch: 165, Loss: 1.8189, Train: 0.1929, Val: 0.0740, Test: 0.1010
Epoch: 166, Loss: 1.7712, Train: 0.2000, Val: 0.0740, Test: 0.1010
Epoch: 167, Loss: 1.8086, Train: 0.2000, Val: 0.0760, Test: 0.1020
Epoch: 168, Loss: 1.7628, Train: 0.2000, Val: 0.0780, Test: 0.1050
Epoch: 169, Loss: 1.7428, Train: 0.2000, Val: 0.0820, Test: 0.1060
Epoch: 170, Loss: 1.9138, Train: 0.2000, Val: 0.0820, Test: 0.1070
Epoch: 171, Loss: 1.7547, Train: 0.2000, Val: 0.0820, Test: 0.1070
Epoch: 172, Loss: 1.7950, Train: 0.2000, Val: 0.0840, Test: 0.1080
Epoch: 173, Loss: 1.8561, Train: 0.2071, Val: 0.0840, Test: 0.1090
Epoch: 174, Loss: 1.7158, Train: 0.2071, Val: 0.0860, Test: 0.1130
Epoch: 175, Loss: 1.8103, Train: 0.2143, Val: 0.0860, Test: 0.1140
Epoch: 176, Loss: 1.7672, Train: 0.2214, Val: 0.0860, Test: 0.1140
Epoch: 177, Loss: 1.7231, Train: 0.2214, Val: 0.0840, Test: 0.1150
Epoch: 178, Loss: 1.8381, Train: 0.2214, Val: 0.0840, Test: 0.1150
Epoch: 179, Loss: 1.7924, Train: 0.2286, Val: 0.0840, Test: 0.1160
Epoch: 180, Loss: 1.7934, Train: 0.2286, Val: 0.0840, Test: 0.1160
Epoch: 181, Loss: 1.8554, Train: 0.2357, Val: 0.0820, Test: 0.1160
Epoch: 182, Loss: 1.6994, Train: 0.2286, Val: 0.0800, Test: 0.1150
Epoch: 183, Loss: 1.7210, Train: 0.2286, Val: 0.0800, Test: 0.1160
Epoch: 184, Loss: 1.7377, Train: 0.2357, Val: 0.0800, Test: 0.1170
Epoch: 185, Loss: 1.6780, Train: 0.2429, Val: 0.0800, Test: 0.1180
Epoch: 186, Loss: 1.6885, Train: 0.2429, Val: 0.0800, Test: 0.1160
Epoch: 187, Loss: 1.7755, Train: 0.2429, Val: 0.0800, Test: 0.1160
Epoch: 188, Loss: 1.6907, Train: 0.2357, Val: 0.0800, Test: 0.1170
Epoch: 189, Loss: 1.7842, Train: 0.2357, Val: 0.0780, Test: 0.1180
Epoch: 190, Loss: 1.6700, Train: 0.2357, Val: 0.0760, Test: 0.1180
Epoch: 191, Loss: 1.7378, Train: 0.2357, Val: 0.0760, Test: 0.1180
Epoch: 192, Loss: 1.7741, Train: 0.2500, Val: 0.0760, Test: 0.1180
Epoch: 193, Loss: 1.6495, Train: 0.2571, Val: 0.0760, Test: 0.1160
Epoch: 194, Loss: 1.8445, Train: 0.2500, Val: 0.0760, Test: 0.1160
Epoch: 195, Loss: 1.6199, Train: 0.2500, Val: 0.0760, Test: 0.1200
Epoch: 196, Loss: 1.7462, Train: 0.2500, Val: 0.0760, Test: 0.1200
Epoch: 197, Loss: 1.8241, Train: 0.2571, Val: 0.0760, Test: 0.1200
Epoch: 198, Loss: 1.6158, Train: 0.2571, Val: 0.0760, Test: 0.1210
Epoch: 199, Loss: 1.6559, Train: 0.2571, Val: 0.0760, Test: 0.1230
Epoch: 200, Loss: 1.6035, Train: 0.2643, Val: 0.0780, Test: 0.1260
MAD:  0.0737
Best Test Accuracy: 0.2100, Val Accuracy: 0.2260, Train Accuracy: 0.1643
Training completed.
Average Test Accuracy:  0.2347 ± 0.057635145527707314
Average MAD:  0.16446 ± 0.12850054630234067
