Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8480, Train: 0.1143, Val: 0.0780, Test: 0.0780
Epoch: 2, Loss: 4.8191, Train: 0.2143, Val: 0.1860, Test: 0.1760
Epoch: 3, Loss: 4.7663, Train: 0.2857, Val: 0.2160, Test: 0.2230
Epoch: 4, Loss: 4.7703, Train: 0.2929, Val: 0.2260, Test: 0.2280
Epoch: 5, Loss: 4.6846, Train: 0.2857, Val: 0.2340, Test: 0.2250
Epoch: 6, Loss: 4.6479, Train: 0.2786, Val: 0.2400, Test: 0.2230
Epoch: 7, Loss: 4.5536, Train: 0.2857, Val: 0.2400, Test: 0.2240
Epoch: 8, Loss: 4.5383, Train: 0.2857, Val: 0.2380, Test: 0.2340
Epoch: 9, Loss: 4.4590, Train: 0.2857, Val: 0.2380, Test: 0.2380
Epoch: 10, Loss: 4.3633, Train: 0.2929, Val: 0.2420, Test: 0.2400
Epoch: 11, Loss: 4.3148, Train: 0.2929, Val: 0.2460, Test: 0.2440
Epoch: 12, Loss: 4.2438, Train: 0.3000, Val: 0.2500, Test: 0.2530
Epoch: 13, Loss: 3.9882, Train: 0.3286, Val: 0.2600, Test: 0.2570
Epoch: 14, Loss: 3.9807, Train: 0.3500, Val: 0.2680, Test: 0.2750
Epoch: 15, Loss: 4.0995, Train: 0.3929, Val: 0.2960, Test: 0.3080
Epoch: 16, Loss: 3.7950, Train: 0.4643, Val: 0.3500, Test: 0.3920
Epoch: 17, Loss: 3.5946, Train: 0.5500, Val: 0.4140, Test: 0.4670
Epoch: 18, Loss: 3.5769, Train: 0.6643, Val: 0.5040, Test: 0.5520
Epoch: 19, Loss: 3.6577, Train: 0.7286, Val: 0.5500, Test: 0.6040
Epoch: 20, Loss: 3.6627, Train: 0.7929, Val: 0.6280, Test: 0.6460
Epoch: 21, Loss: 3.5581, Train: 0.8857, Val: 0.6720, Test: 0.7060
Epoch: 22, Loss: 3.5862, Train: 0.9286, Val: 0.7340, Test: 0.7690
Epoch: 23, Loss: 3.4006, Train: 0.9500, Val: 0.7580, Test: 0.7960
Epoch: 24, Loss: 3.4089, Train: 0.9500, Val: 0.7800, Test: 0.8030
Epoch: 25, Loss: 3.6285, Train: 0.9429, Val: 0.7860, Test: 0.8020
Epoch: 26, Loss: 3.4869, Train: 0.9571, Val: 0.7780, Test: 0.8040
Epoch: 27, Loss: 3.2953, Train: 0.9571, Val: 0.7720, Test: 0.7900
Epoch: 28, Loss: 3.5907, Train: 0.9571, Val: 0.7740, Test: 0.7890
Epoch: 29, Loss: 3.3596, Train: 0.9571, Val: 0.7640, Test: 0.7810
Epoch: 30, Loss: 3.0597, Train: 0.9571, Val: 0.7660, Test: 0.7860
Epoch: 31, Loss: 3.1678, Train: 0.9643, Val: 0.7680, Test: 0.7940
Epoch: 32, Loss: 3.2367, Train: 0.9714, Val: 0.7680, Test: 0.7930
Epoch: 33, Loss: 3.2453, Train: 0.9714, Val: 0.7720, Test: 0.7990
Epoch: 34, Loss: 3.3252, Train: 0.9714, Val: 0.7780, Test: 0.8010
Epoch: 35, Loss: 3.1002, Train: 0.9714, Val: 0.7780, Test: 0.8100
Epoch: 36, Loss: 3.4411, Train: 0.9714, Val: 0.7800, Test: 0.8180
Epoch: 37, Loss: 3.0506, Train: 0.9714, Val: 0.7760, Test: 0.8200
Epoch: 38, Loss: 3.0583, Train: 0.9714, Val: 0.7760, Test: 0.8170
Epoch: 39, Loss: 3.1327, Train: 0.9786, Val: 0.7760, Test: 0.8180
Epoch: 40, Loss: 3.3349, Train: 0.9786, Val: 0.7860, Test: 0.8240
Epoch: 41, Loss: 2.6426, Train: 0.9857, Val: 0.7960, Test: 0.8270
Epoch: 42, Loss: 2.7734, Train: 0.9857, Val: 0.8040, Test: 0.8350
Epoch: 43, Loss: 2.6345, Train: 0.9857, Val: 0.8000, Test: 0.8370
Epoch: 44, Loss: 3.0380, Train: 0.9857, Val: 0.8020, Test: 0.8380
Epoch: 45, Loss: 2.8033, Train: 0.9857, Val: 0.7940, Test: 0.8350
Epoch: 46, Loss: 3.1374, Train: 0.9929, Val: 0.7940, Test: 0.8330
Epoch: 47, Loss: 2.7749, Train: 1.0000, Val: 0.7900, Test: 0.8300
Epoch: 48, Loss: 2.9478, Train: 1.0000, Val: 0.7880, Test: 0.8300
Epoch: 49, Loss: 2.8014, Train: 1.0000, Val: 0.7880, Test: 0.8230
Epoch: 50, Loss: 2.9241, Train: 0.9929, Val: 0.7880, Test: 0.8170
Epoch: 51, Loss: 2.6788, Train: 0.9929, Val: 0.7880, Test: 0.8170
Epoch: 52, Loss: 2.8872, Train: 0.9929, Val: 0.7900, Test: 0.8220
Epoch: 53, Loss: 2.5438, Train: 0.9929, Val: 0.7900, Test: 0.8230
Epoch: 54, Loss: 2.8155, Train: 0.9857, Val: 0.7880, Test: 0.8230
Epoch: 55, Loss: 2.7609, Train: 0.9929, Val: 0.7880, Test: 0.8230
Epoch: 56, Loss: 2.7541, Train: 0.9929, Val: 0.7820, Test: 0.8230
Epoch: 57, Loss: 2.7422, Train: 1.0000, Val: 0.7840, Test: 0.8230
Epoch: 58, Loss: 2.7667, Train: 1.0000, Val: 0.7860, Test: 0.8200
Epoch: 59, Loss: 2.9034, Train: 1.0000, Val: 0.7840, Test: 0.8180
Epoch: 60, Loss: 2.7263, Train: 1.0000, Val: 0.7840, Test: 0.8190
Epoch: 61, Loss: 2.9296, Train: 1.0000, Val: 0.7780, Test: 0.8170
Epoch: 62, Loss: 2.5086, Train: 1.0000, Val: 0.7800, Test: 0.8170
Epoch: 63, Loss: 2.3478, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 64, Loss: 2.6895, Train: 1.0000, Val: 0.7760, Test: 0.8150
Epoch: 65, Loss: 2.6439, Train: 1.0000, Val: 0.7780, Test: 0.8170
Epoch: 66, Loss: 2.3420, Train: 1.0000, Val: 0.7760, Test: 0.8140
Epoch: 67, Loss: 2.9443, Train: 1.0000, Val: 0.7820, Test: 0.8150
Epoch: 68, Loss: 2.7886, Train: 1.0000, Val: 0.7800, Test: 0.8160
Epoch: 69, Loss: 2.8592, Train: 1.0000, Val: 0.7840, Test: 0.8180
Epoch: 70, Loss: 2.7167, Train: 1.0000, Val: 0.7840, Test: 0.8170
Epoch: 71, Loss: 2.7811, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 72, Loss: 2.7735, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 73, Loss: 2.4432, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 74, Loss: 2.7712, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 75, Loss: 2.3949, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 76, Loss: 2.4957, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 77, Loss: 2.5164, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 78, Loss: 2.4466, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 79, Loss: 2.4097, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 80, Loss: 2.4734, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 81, Loss: 2.4908, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 82, Loss: 2.7194, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 83, Loss: 2.4840, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 84, Loss: 2.5134, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 85, Loss: 2.5505, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 86, Loss: 2.5053, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 87, Loss: 2.6029, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 88, Loss: 2.4764, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 89, Loss: 2.3665, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 90, Loss: 2.5685, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 91, Loss: 2.4801, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 92, Loss: 2.3453, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 93, Loss: 2.4060, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 94, Loss: 2.3707, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 95, Loss: 2.4923, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 96, Loss: 2.5713, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 97, Loss: 2.7095, Train: 1.0000, Val: 0.7880, Test: 0.8160
Epoch: 98, Loss: 2.6953, Train: 1.0000, Val: 0.7880, Test: 0.8180
Epoch: 99, Loss: 2.6975, Train: 1.0000, Val: 0.7820, Test: 0.8180
Epoch: 100, Loss: 2.4754, Train: 1.0000, Val: 0.7840, Test: 0.8170
Epoch: 101, Loss: 2.2645, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 102, Loss: 2.3753, Train: 1.0000, Val: 0.7860, Test: 0.8150
Epoch: 103, Loss: 2.5244, Train: 1.0000, Val: 0.7820, Test: 0.8140
Epoch: 104, Loss: 2.1850, Train: 1.0000, Val: 0.7820, Test: 0.8140
Epoch: 105, Loss: 2.6460, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 106, Loss: 2.3263, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 107, Loss: 2.5788, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 108, Loss: 2.2480, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 109, Loss: 2.3572, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 110, Loss: 2.4249, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 111, Loss: 2.5441, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 112, Loss: 2.7632, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 113, Loss: 2.3481, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 114, Loss: 2.3393, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 115, Loss: 2.4559, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 116, Loss: 2.5702, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 117, Loss: 2.4056, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 118, Loss: 2.3680, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 119, Loss: 2.5825, Train: 1.0000, Val: 0.7780, Test: 0.8040
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 2.3323, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 121, Loss: 2.5076, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 122, Loss: 2.2857, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 123, Loss: 2.4648, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 124, Loss: 2.2164, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 125, Loss: 2.6503, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 126, Loss: 2.5278, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 127, Loss: 2.6769, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 128, Loss: 2.7303, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 129, Loss: 2.4923, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 130, Loss: 2.5222, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 131, Loss: 2.5229, Train: 1.0000, Val: 0.7640, Test: 0.8050
Epoch: 132, Loss: 2.2012, Train: 1.0000, Val: 0.7640, Test: 0.8050
Epoch: 133, Loss: 2.6851, Train: 1.0000, Val: 0.7620, Test: 0.8060
Epoch: 134, Loss: 2.1839, Train: 1.0000, Val: 0.7620, Test: 0.8080
Epoch: 135, Loss: 2.4920, Train: 1.0000, Val: 0.7600, Test: 0.8080
Epoch: 136, Loss: 2.6792, Train: 1.0000, Val: 0.7620, Test: 0.8110
Epoch: 137, Loss: 2.4323, Train: 1.0000, Val: 0.7700, Test: 0.8090
Epoch: 138, Loss: 2.1718, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 139, Loss: 2.2106, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 140, Loss: 2.6280, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 141, Loss: 2.6230, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 142, Loss: 2.3828, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 143, Loss: 2.5962, Train: 1.0000, Val: 0.7780, Test: 0.8170
Epoch: 144, Loss: 2.6035, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 145, Loss: 2.2899, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 146, Loss: 2.4887, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 147, Loss: 2.7045, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 148, Loss: 2.5621, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 149, Loss: 2.0166, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 150, Loss: 2.5767, Train: 1.0000, Val: 0.7820, Test: 0.8140
Epoch: 151, Loss: 2.5754, Train: 1.0000, Val: 0.7800, Test: 0.8130
Epoch: 152, Loss: 2.5936, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 153, Loss: 2.4563, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 154, Loss: 2.5405, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 155, Loss: 2.3835, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 156, Loss: 2.4546, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 157, Loss: 2.1327, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 158, Loss: 1.9488, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 159, Loss: 2.2860, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 160, Loss: 2.6686, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 161, Loss: 2.6741, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 162, Loss: 2.4462, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 163, Loss: 2.5136, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 164, Loss: 2.6582, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 165, Loss: 2.7005, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 166, Loss: 2.7999, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 167, Loss: 2.2664, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 168, Loss: 2.5543, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 169, Loss: 2.5656, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 170, Loss: 2.6931, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 171, Loss: 2.1502, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 172, Loss: 2.2760, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 173, Loss: 2.7266, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 174, Loss: 2.2375, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 175, Loss: 2.7598, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 176, Loss: 2.2559, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 177, Loss: 2.6684, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 178, Loss: 2.5184, Train: 1.0000, Val: 0.7640, Test: 0.8010
Epoch: 179, Loss: 2.5179, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 180, Loss: 2.5132, Train: 1.0000, Val: 0.7660, Test: 0.8030
Epoch: 181, Loss: 2.2565, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 182, Loss: 2.4357, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 183, Loss: 2.6865, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 184, Loss: 2.4256, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 185, Loss: 2.5938, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 186, Loss: 1.9332, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 187, Loss: 2.1722, Train: 1.0000, Val: 0.7720, Test: 0.8110
Epoch: 188, Loss: 2.9382, Train: 1.0000, Val: 0.7800, Test: 0.8120
Epoch: 189, Loss: 2.3625, Train: 1.0000, Val: 0.7820, Test: 0.8140
Epoch: 190, Loss: 2.1975, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 191, Loss: 2.8846, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 192, Loss: 2.7549, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 193, Loss: 2.6647, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 194, Loss: 2.6344, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 195, Loss: 2.3798, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 196, Loss: 2.3640, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 197, Loss: 2.2042, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 198, Loss: 2.5519, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 199, Loss: 2.6143, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 200, Loss: 2.4184, Train: 1.0000, Val: 0.7640, Test: 0.8000
MAD:  0.1676
Best Test Accuracy: 0.8380, Val Accuracy: 0.8020, Train Accuracy: 0.9857
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8567, Train: 0.0143, Val: 0.0040, Test: 0.0090
Epoch: 2, Loss: 4.8395, Train: 0.1643, Val: 0.1160, Test: 0.1210
Epoch: 3, Loss: 4.8131, Train: 0.3214, Val: 0.1900, Test: 0.2280
Epoch: 4, Loss: 4.7946, Train: 0.3929, Val: 0.2520, Test: 0.2870
Epoch: 5, Loss: 4.7311, Train: 0.4643, Val: 0.2840, Test: 0.3210
Epoch: 6, Loss: 4.6098, Train: 0.5000, Val: 0.3120, Test: 0.3460
Epoch: 7, Loss: 4.6263, Train: 0.5000, Val: 0.3100, Test: 0.3550
Epoch: 8, Loss: 4.5220, Train: 0.5214, Val: 0.3100, Test: 0.3540
Epoch: 9, Loss: 4.4432, Train: 0.5429, Val: 0.3200, Test: 0.3600
Epoch: 10, Loss: 4.3721, Train: 0.5643, Val: 0.3140, Test: 0.3470
Epoch: 11, Loss: 4.2381, Train: 0.5643, Val: 0.3120, Test: 0.3410
Epoch: 12, Loss: 4.2765, Train: 0.5286, Val: 0.3040, Test: 0.3190
Epoch: 13, Loss: 4.0412, Train: 0.5286, Val: 0.3000, Test: 0.3170
Epoch: 14, Loss: 3.9297, Train: 0.5071, Val: 0.2980, Test: 0.3120
Epoch: 15, Loss: 3.9079, Train: 0.5143, Val: 0.3240, Test: 0.3340
Epoch: 16, Loss: 3.6939, Train: 0.5429, Val: 0.3520, Test: 0.3520
Epoch: 17, Loss: 3.9341, Train: 0.6000, Val: 0.3700, Test: 0.3740
Epoch: 18, Loss: 3.7163, Train: 0.6357, Val: 0.4060, Test: 0.4110
Epoch: 19, Loss: 3.7652, Train: 0.6786, Val: 0.4780, Test: 0.4710
Epoch: 20, Loss: 3.4782, Train: 0.8286, Val: 0.6000, Test: 0.5710
Epoch: 21, Loss: 3.5243, Train: 0.9071, Val: 0.7040, Test: 0.7090
Epoch: 22, Loss: 3.9858, Train: 0.9500, Val: 0.7520, Test: 0.7820
Epoch: 23, Loss: 3.5745, Train: 0.9500, Val: 0.7580, Test: 0.7840
Epoch: 24, Loss: 3.5456, Train: 0.9357, Val: 0.7520, Test: 0.7740
Epoch: 25, Loss: 3.5784, Train: 0.9429, Val: 0.7580, Test: 0.7770
Epoch: 26, Loss: 3.8836, Train: 0.9357, Val: 0.7580, Test: 0.7770
Epoch: 27, Loss: 3.3824, Train: 0.9357, Val: 0.7640, Test: 0.7800
Epoch: 28, Loss: 3.3737, Train: 0.9357, Val: 0.7560, Test: 0.7830
Epoch: 29, Loss: 3.6504, Train: 0.9357, Val: 0.7580, Test: 0.7920
Epoch: 30, Loss: 3.2246, Train: 0.9429, Val: 0.7680, Test: 0.7950
Epoch: 31, Loss: 3.1131, Train: 0.9571, Val: 0.7740, Test: 0.8030
Epoch: 32, Loss: 3.4005, Train: 0.9571, Val: 0.7760, Test: 0.8060
Epoch: 33, Loss: 3.1269, Train: 0.9643, Val: 0.7820, Test: 0.8030
Epoch: 34, Loss: 3.0958, Train: 0.9714, Val: 0.7820, Test: 0.8040
Epoch: 35, Loss: 3.2701, Train: 0.9714, Val: 0.7860, Test: 0.8040
Epoch: 36, Loss: 2.8475, Train: 0.9714, Val: 0.7840, Test: 0.8040
Epoch: 37, Loss: 3.1478, Train: 0.9643, Val: 0.7860, Test: 0.8020
Epoch: 38, Loss: 3.0773, Train: 0.9643, Val: 0.7860, Test: 0.8060
Epoch: 39, Loss: 2.9990, Train: 0.9714, Val: 0.7900, Test: 0.8090
Epoch: 40, Loss: 2.7838, Train: 0.9857, Val: 0.7940, Test: 0.8110
Epoch: 41, Loss: 2.9694, Train: 0.9857, Val: 0.7940, Test: 0.8190
Epoch: 42, Loss: 3.0547, Train: 0.9857, Val: 0.7960, Test: 0.8190
Epoch: 43, Loss: 2.9660, Train: 0.9786, Val: 0.7960, Test: 0.8180
Epoch: 44, Loss: 3.1418, Train: 0.9786, Val: 0.7980, Test: 0.8170
Epoch: 45, Loss: 2.9770, Train: 0.9857, Val: 0.7980, Test: 0.8200
Epoch: 46, Loss: 3.2805, Train: 0.9857, Val: 0.7960, Test: 0.8220
Epoch: 47, Loss: 2.7068, Train: 0.9929, Val: 0.7920, Test: 0.8210
Epoch: 48, Loss: 2.8945, Train: 0.9929, Val: 0.7940, Test: 0.8150
Epoch: 49, Loss: 2.8018, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 50, Loss: 2.8847, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 51, Loss: 2.6350, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 52, Loss: 2.9833, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 53, Loss: 3.0595, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 54, Loss: 3.1607, Train: 0.9929, Val: 0.7780, Test: 0.7970
Epoch: 55, Loss: 2.9942, Train: 0.9929, Val: 0.7860, Test: 0.8000
Epoch: 56, Loss: 2.9729, Train: 0.9929, Val: 0.7840, Test: 0.7970
Epoch: 57, Loss: 2.9831, Train: 0.9929, Val: 0.7800, Test: 0.7980
Epoch: 58, Loss: 2.8293, Train: 0.9929, Val: 0.7780, Test: 0.7970
Epoch: 59, Loss: 2.6834, Train: 0.9929, Val: 0.7780, Test: 0.7980
Epoch: 60, Loss: 2.7210, Train: 0.9929, Val: 0.7780, Test: 0.8000
Epoch: 61, Loss: 2.6209, Train: 0.9929, Val: 0.7760, Test: 0.7990
Epoch: 62, Loss: 2.6371, Train: 0.9929, Val: 0.7740, Test: 0.8000
Epoch: 63, Loss: 2.3683, Train: 0.9929, Val: 0.7760, Test: 0.8020
Epoch: 64, Loss: 2.6270, Train: 0.9929, Val: 0.7800, Test: 0.8070
Epoch: 65, Loss: 2.2768, Train: 0.9929, Val: 0.7880, Test: 0.8090
Epoch: 66, Loss: 2.4660, Train: 0.9929, Val: 0.7900, Test: 0.8150
Epoch: 67, Loss: 2.6239, Train: 1.0000, Val: 0.7880, Test: 0.8140
Epoch: 68, Loss: 2.6227, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 69, Loss: 2.9889, Train: 1.0000, Val: 0.7920, Test: 0.8150
Epoch: 70, Loss: 2.8324, Train: 1.0000, Val: 0.7920, Test: 0.8140
Epoch: 71, Loss: 2.6469, Train: 1.0000, Val: 0.7920, Test: 0.8120
Epoch: 72, Loss: 2.4155, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 73, Loss: 2.7850, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 74, Loss: 2.8909, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 75, Loss: 2.7761, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 76, Loss: 2.9450, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 77, Loss: 2.5719, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 78, Loss: 2.7704, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 79, Loss: 2.4564, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 80, Loss: 3.0080, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 81, Loss: 2.5451, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 82, Loss: 2.5896, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 83, Loss: 2.5964, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 84, Loss: 2.5068, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 85, Loss: 2.6722, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 86, Loss: 2.4177, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 87, Loss: 2.3888, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 88, Loss: 2.5706, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 89, Loss: 2.9302, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 90, Loss: 2.6489, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 91, Loss: 2.3446, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 92, Loss: 2.6734, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 93, Loss: 2.3867, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 94, Loss: 2.5063, Train: 1.0000, Val: 0.7860, Test: 0.8150
Epoch: 95, Loss: 2.6076, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 96, Loss: 2.3490, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 97, Loss: 2.6289, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 98, Loss: 2.4830, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 99, Loss: 2.9394, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 100, Loss: 2.5320, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 101, Loss: 2.5204, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 102, Loss: 2.3003, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 103, Loss: 2.4861, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 104, Loss: 2.5777, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 105, Loss: 2.2012, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 106, Loss: 2.7334, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 107, Loss: 2.4644, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 108, Loss: 2.4598, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 109, Loss: 2.9067, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 110, Loss: 2.5102, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 111, Loss: 2.5157, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 112, Loss: 2.3716, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 113, Loss: 2.7570, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 114, Loss: 2.4240, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 115, Loss: 2.3676, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 116, Loss: 2.4959, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 117, Loss: 2.4714, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 118, Loss: 2.8399, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 119, Loss: 2.3859, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 120, Loss: 2.3083, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 121, Loss: 2.6599, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 122, Loss: 2.5164, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 123, Loss: 1.9793, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 124, Loss: 2.4952, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 125, Loss: 2.2160, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 126, Loss: 2.3613, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 127, Loss: 2.1740, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 128, Loss: 2.6924, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 129, Loss: 2.2396, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 130, Loss: 2.5909, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 131, Loss: 2.3698, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 132, Loss: 2.6367, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 133, Loss: 2.8888, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 134, Loss: 2.4801, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 135, Loss: 2.4993, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 136, Loss: 2.5767, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 137, Loss: 2.4356, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 138, Loss: 1.9671, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 139, Loss: 2.5026, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 140, Loss: 2.3368, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 141, Loss: 2.0196, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 142, Loss: 2.3098, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 143, Loss: 2.5124, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 144, Loss: 2.4591, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 145, Loss: 2.4219, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 146, Loss: 2.7351, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 147, Loss: 2.7809, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 148, Loss: 3.1385, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 149, Loss: 2.2562, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 150, Loss: 2.6319, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 151, Loss: 2.4599, Train: 1.0000, Val: 0.7760, Test: 0.7840
Epoch: 152, Loss: 2.7461, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 153, Loss: 2.3530, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 154, Loss: 2.5955, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 155, Loss: 3.0995, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 156, Loss: 2.5894, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 157, Loss: 2.5099, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 158, Loss: 2.7571, Train: 1.0000, Val: 0.7720, Test: 0.7900
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 159, Loss: 2.7011, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 160, Loss: 2.5889, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 161, Loss: 2.4913, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 162, Loss: 2.4029, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 163, Loss: 2.5350, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 164, Loss: 2.5508, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 165, Loss: 2.8710, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 166, Loss: 2.4517, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 167, Loss: 2.9846, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 168, Loss: 2.6113, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 169, Loss: 2.5433, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 170, Loss: 2.3482, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 171, Loss: 2.4841, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 172, Loss: 2.1254, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 173, Loss: 2.4540, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 174, Loss: 2.3554, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 175, Loss: 2.2768, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 176, Loss: 2.5949, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 177, Loss: 2.5446, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 178, Loss: 2.3194, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 179, Loss: 2.5040, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 180, Loss: 2.5128, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 181, Loss: 2.5392, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 182, Loss: 2.3112, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 183, Loss: 2.3561, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 184, Loss: 2.6967, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 185, Loss: 2.4741, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 186, Loss: 2.3833, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 187, Loss: 2.3652, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 188, Loss: 2.8908, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 189, Loss: 2.6815, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 190, Loss: 2.0874, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 191, Loss: 2.3478, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 192, Loss: 2.6648, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 193, Loss: 2.7638, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 194, Loss: 2.4569, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 195, Loss: 2.1456, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 196, Loss: 2.3963, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 197, Loss: 2.5139, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 198, Loss: 2.5528, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 199, Loss: 2.7080, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 200, Loss: 2.2915, Train: 1.0000, Val: 0.7740, Test: 0.7960
MAD:  0.1981
Best Test Accuracy: 0.8220, Val Accuracy: 0.7960, Train Accuracy: 0.9857
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8692, Train: 0.0643, Val: 0.0640, Test: 0.0600
Epoch: 2, Loss: 4.8233, Train: 0.1643, Val: 0.1760, Test: 0.1560
Epoch: 3, Loss: 4.7807, Train: 0.2286, Val: 0.1980, Test: 0.1880
Epoch: 4, Loss: 4.7565, Train: 0.2857, Val: 0.1980, Test: 0.1940
Epoch: 5, Loss: 4.7616, Train: 0.3071, Val: 0.2160, Test: 0.2060
Epoch: 6, Loss: 4.7074, Train: 0.3714, Val: 0.2500, Test: 0.2450
Epoch: 7, Loss: 4.5892, Train: 0.4286, Val: 0.2740, Test: 0.2770
Epoch: 8, Loss: 4.5266, Train: 0.4643, Val: 0.2840, Test: 0.2820
Epoch: 9, Loss: 4.6020, Train: 0.4643, Val: 0.2700, Test: 0.2770
Epoch: 10, Loss: 4.4253, Train: 0.4571, Val: 0.2580, Test: 0.2630
Epoch: 11, Loss: 4.2832, Train: 0.4286, Val: 0.2460, Test: 0.2570
Epoch: 12, Loss: 4.2489, Train: 0.4214, Val: 0.2420, Test: 0.2510
Epoch: 13, Loss: 4.0808, Train: 0.4357, Val: 0.2460, Test: 0.2530
Epoch: 14, Loss: 4.0085, Train: 0.4429, Val: 0.2440, Test: 0.2560
Epoch: 15, Loss: 4.1356, Train: 0.4571, Val: 0.2600, Test: 0.2690
Epoch: 16, Loss: 3.8186, Train: 0.5000, Val: 0.2760, Test: 0.2840
Epoch: 17, Loss: 4.0646, Train: 0.5500, Val: 0.3000, Test: 0.3090
Epoch: 18, Loss: 3.7748, Train: 0.6071, Val: 0.3440, Test: 0.3470
Epoch: 19, Loss: 3.6028, Train: 0.6786, Val: 0.4100, Test: 0.4050
Epoch: 20, Loss: 3.7862, Train: 0.7571, Val: 0.4860, Test: 0.4870
Epoch: 21, Loss: 3.6036, Train: 0.8071, Val: 0.5840, Test: 0.5930
Epoch: 22, Loss: 3.6801, Train: 0.8786, Val: 0.6260, Test: 0.6550
Epoch: 23, Loss: 3.7352, Train: 0.8857, Val: 0.6480, Test: 0.6880
Epoch: 24, Loss: 3.4664, Train: 0.9071, Val: 0.6680, Test: 0.7050
Epoch: 25, Loss: 3.4430, Train: 0.9357, Val: 0.6840, Test: 0.7210
Epoch: 26, Loss: 3.7498, Train: 0.9357, Val: 0.7060, Test: 0.7390
Epoch: 27, Loss: 3.5614, Train: 0.9571, Val: 0.7360, Test: 0.7500
Epoch: 28, Loss: 3.5965, Train: 0.9643, Val: 0.7460, Test: 0.7600
Epoch: 29, Loss: 3.4209, Train: 0.9643, Val: 0.7500, Test: 0.7660
Epoch: 30, Loss: 3.3750, Train: 0.9857, Val: 0.7560, Test: 0.7720
Epoch: 31, Loss: 3.4395, Train: 0.9929, Val: 0.7640, Test: 0.7760
Epoch: 32, Loss: 3.1840, Train: 0.9929, Val: 0.7740, Test: 0.7850
Epoch: 33, Loss: 3.2246, Train: 0.9929, Val: 0.7820, Test: 0.7970
Epoch: 34, Loss: 3.5691, Train: 0.9857, Val: 0.7940, Test: 0.8060
Epoch: 35, Loss: 3.4680, Train: 0.9857, Val: 0.7960, Test: 0.8090
Epoch: 36, Loss: 3.3035, Train: 0.9929, Val: 0.7980, Test: 0.8120
Epoch: 37, Loss: 3.1386, Train: 0.9929, Val: 0.8020, Test: 0.8150
Epoch: 38, Loss: 3.1008, Train: 0.9929, Val: 0.8020, Test: 0.8190
Epoch: 39, Loss: 3.1678, Train: 0.9857, Val: 0.8020, Test: 0.8170
Epoch: 40, Loss: 3.0168, Train: 0.9857, Val: 0.8040, Test: 0.8190
Epoch: 41, Loss: 3.0699, Train: 0.9857, Val: 0.8020, Test: 0.8200
Epoch: 42, Loss: 3.1284, Train: 0.9857, Val: 0.8000, Test: 0.8160
Epoch: 43, Loss: 3.1908, Train: 0.9857, Val: 0.7960, Test: 0.8160
Epoch: 44, Loss: 2.6979, Train: 0.9929, Val: 0.7880, Test: 0.8150
Epoch: 45, Loss: 3.1743, Train: 0.9929, Val: 0.7860, Test: 0.8050
Epoch: 46, Loss: 2.8757, Train: 0.9929, Val: 0.7840, Test: 0.8040
Epoch: 47, Loss: 3.2889, Train: 0.9929, Val: 0.7820, Test: 0.8040
Epoch: 48, Loss: 2.8426, Train: 0.9929, Val: 0.7800, Test: 0.8020
Epoch: 49, Loss: 3.0688, Train: 0.9929, Val: 0.7800, Test: 0.8030
Epoch: 50, Loss: 2.7364, Train: 0.9929, Val: 0.7840, Test: 0.8040
Epoch: 51, Loss: 2.9097, Train: 0.9929, Val: 0.7800, Test: 0.8060
Epoch: 52, Loss: 3.0168, Train: 0.9929, Val: 0.7900, Test: 0.8100
Epoch: 53, Loss: 3.0812, Train: 0.9929, Val: 0.7960, Test: 0.8150
Epoch: 54, Loss: 2.8185, Train: 0.9929, Val: 0.8020, Test: 0.8200
Epoch: 55, Loss: 3.1258, Train: 0.9929, Val: 0.8040, Test: 0.8220
Epoch: 56, Loss: 2.7893, Train: 0.9929, Val: 0.8020, Test: 0.8240
Epoch: 57, Loss: 2.8010, Train: 0.9929, Val: 0.7960, Test: 0.8260
Epoch: 58, Loss: 2.9322, Train: 0.9929, Val: 0.7980, Test: 0.8260
Epoch: 59, Loss: 2.5789, Train: 0.9929, Val: 0.8000, Test: 0.8260
Epoch: 60, Loss: 2.7688, Train: 0.9929, Val: 0.8000, Test: 0.8280
Epoch: 61, Loss: 2.7093, Train: 0.9929, Val: 0.7940, Test: 0.8200
Epoch: 62, Loss: 2.4532, Train: 0.9929, Val: 0.7940, Test: 0.8210
Epoch: 63, Loss: 2.7584, Train: 1.0000, Val: 0.7940, Test: 0.8220
Epoch: 64, Loss: 2.6357, Train: 1.0000, Val: 0.7920, Test: 0.8220
Epoch: 65, Loss: 2.4936, Train: 1.0000, Val: 0.7960, Test: 0.8280
Epoch: 66, Loss: 2.6889, Train: 1.0000, Val: 0.8020, Test: 0.8300
Epoch: 67, Loss: 2.8458, Train: 0.9929, Val: 0.8000, Test: 0.8270
Epoch: 68, Loss: 2.7438, Train: 0.9929, Val: 0.8000, Test: 0.8260
Epoch: 69, Loss: 3.0178, Train: 0.9929, Val: 0.8040, Test: 0.8240
Epoch: 70, Loss: 2.5288, Train: 0.9929, Val: 0.8020, Test: 0.8240
Epoch: 71, Loss: 2.5246, Train: 0.9929, Val: 0.8040, Test: 0.8210
Epoch: 72, Loss: 2.7332, Train: 1.0000, Val: 0.8040, Test: 0.8200
Epoch: 73, Loss: 2.7510, Train: 1.0000, Val: 0.8020, Test: 0.8180
Epoch: 74, Loss: 2.6109, Train: 1.0000, Val: 0.8020, Test: 0.8170
Epoch: 75, Loss: 2.5093, Train: 1.0000, Val: 0.8020, Test: 0.8170
Epoch: 76, Loss: 2.6831, Train: 1.0000, Val: 0.8020, Test: 0.8180
Epoch: 77, Loss: 2.7209, Train: 1.0000, Val: 0.8020, Test: 0.8200
Epoch: 78, Loss: 2.6326, Train: 1.0000, Val: 0.8000, Test: 0.8190
Epoch: 79, Loss: 2.8682, Train: 1.0000, Val: 0.7980, Test: 0.8210
Epoch: 80, Loss: 2.4956, Train: 1.0000, Val: 0.7960, Test: 0.8190
Epoch: 81, Loss: 2.5174, Train: 1.0000, Val: 0.7940, Test: 0.8220
Epoch: 82, Loss: 2.9352, Train: 1.0000, Val: 0.7920, Test: 0.8250
Epoch: 83, Loss: 2.5356, Train: 1.0000, Val: 0.7900, Test: 0.8260
Epoch: 84, Loss: 2.6293, Train: 1.0000, Val: 0.7860, Test: 0.8260
Epoch: 85, Loss: 2.6742, Train: 1.0000, Val: 0.7840, Test: 0.8250
Epoch: 86, Loss: 3.0863, Train: 1.0000, Val: 0.7840, Test: 0.8220
Epoch: 87, Loss: 2.8691, Train: 1.0000, Val: 0.7820, Test: 0.8180
Epoch: 88, Loss: 2.9515, Train: 1.0000, Val: 0.7820, Test: 0.8160
Epoch: 89, Loss: 2.4515, Train: 1.0000, Val: 0.7820, Test: 0.8160
Epoch: 90, Loss: 2.3489, Train: 1.0000, Val: 0.7840, Test: 0.8200
Epoch: 91, Loss: 2.5750, Train: 1.0000, Val: 0.7880, Test: 0.8220
Epoch: 92, Loss: 2.4372, Train: 1.0000, Val: 0.7880, Test: 0.8200
Epoch: 93, Loss: 2.5646, Train: 1.0000, Val: 0.7880, Test: 0.8190
Epoch: 94, Loss: 2.4660, Train: 1.0000, Val: 0.7900, Test: 0.8190
Epoch: 95, Loss: 2.7278, Train: 1.0000, Val: 0.7860, Test: 0.8200
Epoch: 96, Loss: 2.6919, Train: 1.0000, Val: 0.7860, Test: 0.8150
Epoch: 97, Loss: 2.5219, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 98, Loss: 2.6622, Train: 1.0000, Val: 0.7860, Test: 0.8130
Epoch: 99, Loss: 2.4582, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 100, Loss: 2.8444, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 101, Loss: 2.4309, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 102, Loss: 2.4381, Train: 1.0000, Val: 0.7900, Test: 0.8060
Epoch: 103, Loss: 2.5763, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 104, Loss: 2.6380, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 105, Loss: 2.8694, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 106, Loss: 2.5393, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 107, Loss: 2.6306, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 108, Loss: 2.6649, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 109, Loss: 2.5133, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 110, Loss: 2.2266, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 111, Loss: 2.5847, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 112, Loss: 2.2018, Train: 1.0000, Val: 0.7980, Test: 0.8150
Epoch: 113, Loss: 2.7575, Train: 1.0000, Val: 0.7980, Test: 0.8180
Epoch: 114, Loss: 2.6609, Train: 1.0000, Val: 0.7880, Test: 0.8210
Epoch: 115, Loss: 2.4089, Train: 1.0000, Val: 0.7860, Test: 0.8170
Epoch: 116, Loss: 2.4436, Train: 1.0000, Val: 0.7840, Test: 0.8150
Epoch: 117, Loss: 2.7591, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 118, Loss: 2.3350, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 119, Loss: 2.1841, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 120, Loss: 2.1172, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 121, Loss: 2.4415, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 122, Loss: 2.5979, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 123, Loss: 2.5872, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 124, Loss: 2.6670, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 125, Loss: 2.7109, Train: 1.0000, Val: 0.7680, Test: 0.8020
Epoch: 126, Loss: 2.8038, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 127, Loss: 2.3239, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 128, Loss: 2.4367, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 129, Loss: 2.8702, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 130, Loss: 2.5028, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 131, Loss: 2.5038, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 132, Loss: 2.6260, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 133, Loss: 2.2299, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 134, Loss: 2.5851, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 135, Loss: 2.5477, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 136, Loss: 2.6180, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 137, Loss: 2.6140, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 138, Loss: 2.6130, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 139, Loss: 2.4802, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 140, Loss: 2.3632, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 141, Loss: 2.6043, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 142, Loss: 2.6150, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 143, Loss: 2.4882, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 144, Loss: 2.6656, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 145, Loss: 2.5539, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 146, Loss: 1.9832, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 147, Loss: 2.5772, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 148, Loss: 2.1840, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 149, Loss: 2.5405, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 150, Loss: 2.4788, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 151, Loss: 2.4133, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 152, Loss: 2.8458, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 153, Loss: 2.2263, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 154, Loss: 2.7490, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 155, Loss: 2.9455, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 156, Loss: 2.0193, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 157, Loss: 2.8785, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 158, Loss: 2.8638, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 159, Loss: 2.6746, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 160, Loss: 2.3216, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 161, Loss: 2.1879, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 162, Loss: 2.8909, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 163, Loss: 2.6100, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 164, Loss: 2.5187, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 165, Loss: 2.4945, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 166, Loss: 2.4257, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 167, Loss: 2.7615, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 168, Loss: 2.2409, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 169, Loss: 2.5915, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 170, Loss: 2.3846, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 171, Loss: 2.4537, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 172, Loss: 2.3513, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 173, Loss: 2.5013, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 174, Loss: 2.5703, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 175, Loss: 2.4131, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 176, Loss: 2.4426, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 177, Loss: 2.6099, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 178, Loss: 2.8586, Train: 1.0000, Val: 0.7780, Test: 0.8130
Epoch: 179, Loss: 2.1362, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 180, Loss: 2.7324, Train: 1.0000, Val: 0.7760, Test: 0.8140
Epoch: 181, Loss: 2.1159, Train: 1.0000, Val: 0.7760, Test: 0.8120
Epoch: 182, Loss: 2.3582, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 183, Loss: 2.9093, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 184, Loss: 2.3620, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 185, Loss: 2.2058, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 186, Loss: 2.1751, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 187, Loss: 2.4925, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 188, Loss: 2.3415, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 189, Loss: 2.2084, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 190, Loss: 2.6257, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 191, Loss: 2.5898, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 192, Loss: 2.3619, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 193, Loss: 2.1479, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 194, Loss: 2.7628, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 195, Loss: 2.4947, Train: 1.0000, Val: 0.7560, Test: 0.7940
Epoch: 196, Loss: 2.5502, Train: 1.0000, Val: 0.7560, Test: 0.7930
Epoch: 197, Loss: 2.6290, Train: 1.0000, Val: 0.7600, Test: 0.7950
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 198, Loss: 2.3860, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 199, Loss: 2.4607, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 200, Loss: 2.1448, Train: 1.0000, Val: 0.7680, Test: 0.7970
MAD:  0.4657
Best Test Accuracy: 0.8300, Val Accuracy: 0.8020, Train Accuracy: 1.0000
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8741, Train: 0.0071, Val: 0.0060, Test: 0.0090
Epoch: 2, Loss: 4.8616, Train: 0.1071, Val: 0.0920, Test: 0.0970
Epoch: 3, Loss: 4.8193, Train: 0.2571, Val: 0.1920, Test: 0.1910
Epoch: 4, Loss: 4.8019, Train: 0.3429, Val: 0.2300, Test: 0.2180
Epoch: 5, Loss: 4.7656, Train: 0.3857, Val: 0.2340, Test: 0.2360
Epoch: 6, Loss: 4.7487, Train: 0.4214, Val: 0.2340, Test: 0.2540
Epoch: 7, Loss: 4.7140, Train: 0.4857, Val: 0.2540, Test: 0.2850
Epoch: 8, Loss: 4.6793, Train: 0.4929, Val: 0.2820, Test: 0.3060
Epoch: 9, Loss: 4.6129, Train: 0.5214, Val: 0.3000, Test: 0.3190
Epoch: 10, Loss: 4.4746, Train: 0.5429, Val: 0.3140, Test: 0.3320
Epoch: 11, Loss: 4.4737, Train: 0.5143, Val: 0.3200, Test: 0.3370
Epoch: 12, Loss: 4.2084, Train: 0.5071, Val: 0.3080, Test: 0.3360
Epoch: 13, Loss: 4.2612, Train: 0.5071, Val: 0.3020, Test: 0.3270
Epoch: 14, Loss: 4.2378, Train: 0.5000, Val: 0.3000, Test: 0.3210
Epoch: 15, Loss: 4.1102, Train: 0.5000, Val: 0.3040, Test: 0.3210
Epoch: 16, Loss: 3.7285, Train: 0.5071, Val: 0.3080, Test: 0.3290
Epoch: 17, Loss: 3.9492, Train: 0.5143, Val: 0.3140, Test: 0.3340
Epoch: 18, Loss: 3.8977, Train: 0.5643, Val: 0.3260, Test: 0.3430
Epoch: 19, Loss: 3.8641, Train: 0.5929, Val: 0.3560, Test: 0.3720
Epoch: 20, Loss: 3.9113, Train: 0.6500, Val: 0.4160, Test: 0.4120
Epoch: 21, Loss: 3.6040, Train: 0.7214, Val: 0.4780, Test: 0.4650
Epoch: 22, Loss: 3.6484, Train: 0.7643, Val: 0.4980, Test: 0.5010
Epoch: 23, Loss: 3.5387, Train: 0.7929, Val: 0.5340, Test: 0.5360
Epoch: 24, Loss: 3.7324, Train: 0.8000, Val: 0.5440, Test: 0.5490
Epoch: 25, Loss: 3.7532, Train: 0.8429, Val: 0.5640, Test: 0.5690
Epoch: 26, Loss: 3.4272, Train: 0.8714, Val: 0.5940, Test: 0.5990
Epoch: 27, Loss: 3.5693, Train: 0.9214, Val: 0.6680, Test: 0.6730
Epoch: 28, Loss: 3.6045, Train: 0.9357, Val: 0.7180, Test: 0.7290
Epoch: 29, Loss: 3.3577, Train: 0.9500, Val: 0.7480, Test: 0.7720
Epoch: 30, Loss: 3.2966, Train: 0.9500, Val: 0.7720, Test: 0.8010
Epoch: 31, Loss: 3.4904, Train: 0.9429, Val: 0.7920, Test: 0.8100
Epoch: 32, Loss: 3.1109, Train: 0.9500, Val: 0.7840, Test: 0.8120
Epoch: 33, Loss: 3.1041, Train: 0.9500, Val: 0.7920, Test: 0.8060
Epoch: 34, Loss: 3.1802, Train: 0.9571, Val: 0.8000, Test: 0.8160
Epoch: 35, Loss: 3.2457, Train: 0.9643, Val: 0.7980, Test: 0.8220
Epoch: 36, Loss: 3.2132, Train: 0.9643, Val: 0.8080, Test: 0.8240
Epoch: 37, Loss: 3.3423, Train: 0.9643, Val: 0.8020, Test: 0.8160
Epoch: 38, Loss: 3.1570, Train: 0.9643, Val: 0.7920, Test: 0.8040
Epoch: 39, Loss: 3.0924, Train: 0.9643, Val: 0.7840, Test: 0.7990
Epoch: 40, Loss: 3.1367, Train: 0.9643, Val: 0.7700, Test: 0.7810
Epoch: 41, Loss: 2.7647, Train: 0.9571, Val: 0.7580, Test: 0.7700
Epoch: 42, Loss: 3.3604, Train: 0.9571, Val: 0.7540, Test: 0.7700
Epoch: 43, Loss: 2.8677, Train: 0.9571, Val: 0.7440, Test: 0.7670
Epoch: 44, Loss: 2.9358, Train: 0.9571, Val: 0.7420, Test: 0.7650
Epoch: 45, Loss: 3.1676, Train: 0.9571, Val: 0.7440, Test: 0.7640
Epoch: 46, Loss: 2.8326, Train: 0.9643, Val: 0.7580, Test: 0.7630
Epoch: 47, Loss: 2.8756, Train: 0.9714, Val: 0.7620, Test: 0.7700
Epoch: 48, Loss: 2.7719, Train: 0.9714, Val: 0.7740, Test: 0.7790
Epoch: 49, Loss: 2.6520, Train: 0.9786, Val: 0.7820, Test: 0.7870
Epoch: 50, Loss: 2.8683, Train: 0.9786, Val: 0.7880, Test: 0.7940
Epoch: 51, Loss: 2.9815, Train: 0.9857, Val: 0.7880, Test: 0.8020
Epoch: 52, Loss: 2.6506, Train: 0.9929, Val: 0.7920, Test: 0.8000
Epoch: 53, Loss: 3.1926, Train: 0.9929, Val: 0.7940, Test: 0.8010
Epoch: 54, Loss: 2.7235, Train: 0.9929, Val: 0.8040, Test: 0.8090
Epoch: 55, Loss: 2.9805, Train: 0.9929, Val: 0.8020, Test: 0.8170
Epoch: 56, Loss: 2.5970, Train: 0.9929, Val: 0.8020, Test: 0.8180
Epoch: 57, Loss: 3.0337, Train: 0.9929, Val: 0.8020, Test: 0.8240
Epoch: 58, Loss: 2.8581, Train: 0.9929, Val: 0.8000, Test: 0.8200
Epoch: 59, Loss: 2.8206, Train: 0.9929, Val: 0.7980, Test: 0.8130
Epoch: 60, Loss: 2.7361, Train: 0.9929, Val: 0.8020, Test: 0.8150
Epoch: 61, Loss: 2.8137, Train: 0.9929, Val: 0.7960, Test: 0.8170
Epoch: 62, Loss: 2.7235, Train: 1.0000, Val: 0.7940, Test: 0.8110
Epoch: 63, Loss: 2.8747, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 64, Loss: 2.3160, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 65, Loss: 2.6742, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 66, Loss: 2.7317, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 67, Loss: 2.3463, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 68, Loss: 2.9168, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 69, Loss: 2.7715, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 70, Loss: 2.5448, Train: 1.0000, Val: 0.7920, Test: 0.8120
Epoch: 71, Loss: 2.7484, Train: 1.0000, Val: 0.7940, Test: 0.8110
Epoch: 72, Loss: 2.6283, Train: 1.0000, Val: 0.7920, Test: 0.8070
Epoch: 73, Loss: 2.3314, Train: 1.0000, Val: 0.7940, Test: 0.8070
Epoch: 74, Loss: 2.6239, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 75, Loss: 2.8613, Train: 1.0000, Val: 0.7940, Test: 0.8090
Epoch: 76, Loss: 2.9152, Train: 1.0000, Val: 0.7920, Test: 0.8070
Epoch: 77, Loss: 2.6117, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 78, Loss: 2.5610, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 79, Loss: 2.7378, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 80, Loss: 2.6179, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 81, Loss: 2.9557, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 82, Loss: 2.1859, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 83, Loss: 2.6656, Train: 1.0000, Val: 0.7860, Test: 0.7910
Epoch: 84, Loss: 2.3859, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 85, Loss: 2.5141, Train: 1.0000, Val: 0.7800, Test: 0.7870
Epoch: 86, Loss: 2.5642, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 87, Loss: 2.4506, Train: 1.0000, Val: 0.7820, Test: 0.7890
Epoch: 88, Loss: 2.6195, Train: 1.0000, Val: 0.7840, Test: 0.7890
Epoch: 89, Loss: 2.5323, Train: 1.0000, Val: 0.7820, Test: 0.7870
Epoch: 90, Loss: 2.6714, Train: 1.0000, Val: 0.7820, Test: 0.7890
Epoch: 91, Loss: 2.5970, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 92, Loss: 2.6368, Train: 1.0000, Val: 0.7820, Test: 0.7940
Epoch: 93, Loss: 2.2521, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 94, Loss: 2.4611, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 95, Loss: 2.8153, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 96, Loss: 2.7759, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 97, Loss: 2.6694, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 98, Loss: 2.2058, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 99, Loss: 3.0053, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 100, Loss: 2.4714, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 101, Loss: 2.7063, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 102, Loss: 2.2931, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 103, Loss: 2.6935, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 104, Loss: 2.6559, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 105, Loss: 2.5059, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 106, Loss: 2.3536, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 107, Loss: 2.1522, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 108, Loss: 2.9477, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 109, Loss: 2.5098, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 110, Loss: 2.7902, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 111, Loss: 2.3342, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 112, Loss: 2.3253, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 113, Loss: 2.4100, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 114, Loss: 2.9607, Train: 1.0000, Val: 0.7860, Test: 0.7970
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 115, Loss: 2.9981, Train: 1.0000, Val: 0.7880, Test: 0.7960
Epoch: 116, Loss: 2.5629, Train: 1.0000, Val: 0.7900, Test: 0.7960
Epoch: 117, Loss: 2.2951, Train: 1.0000, Val: 0.7900, Test: 0.7980
Epoch: 118, Loss: 2.8373, Train: 1.0000, Val: 0.7900, Test: 0.8010
Epoch: 119, Loss: 2.4490, Train: 1.0000, Val: 0.7920, Test: 0.8020
Epoch: 120, Loss: 2.3059, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 121, Loss: 2.4208, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 122, Loss: 2.0969, Train: 1.0000, Val: 0.7940, Test: 0.8030
Epoch: 123, Loss: 2.1768, Train: 1.0000, Val: 0.7920, Test: 0.8040
Epoch: 124, Loss: 2.5616, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 125, Loss: 2.2172, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 126, Loss: 2.7705, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 127, Loss: 2.7919, Train: 1.0000, Val: 0.7940, Test: 0.8060
Epoch: 128, Loss: 2.6973, Train: 1.0000, Val: 0.7960, Test: 0.8080
Epoch: 129, Loss: 2.5268, Train: 1.0000, Val: 0.7960, Test: 0.8090
Epoch: 130, Loss: 2.7382, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 131, Loss: 2.4962, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 132, Loss: 2.7387, Train: 1.0000, Val: 0.7960, Test: 0.8130
Epoch: 133, Loss: 2.8144, Train: 1.0000, Val: 0.7960, Test: 0.8120
Epoch: 134, Loss: 2.5073, Train: 1.0000, Val: 0.7940, Test: 0.8120
Epoch: 135, Loss: 2.5059, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 136, Loss: 2.3781, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 137, Loss: 2.7409, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 138, Loss: 2.3993, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 139, Loss: 2.6226, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 140, Loss: 2.7321, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 141, Loss: 2.2870, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 142, Loss: 2.4234, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 143, Loss: 2.3407, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 144, Loss: 2.4791, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 145, Loss: 2.3160, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 146, Loss: 2.3669, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 147, Loss: 2.3971, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 148, Loss: 2.9926, Train: 1.0000, Val: 0.7820, Test: 0.7920
Epoch: 149, Loss: 2.7028, Train: 1.0000, Val: 0.7840, Test: 0.7920
Epoch: 150, Loss: 2.5084, Train: 1.0000, Val: 0.7880, Test: 0.7930
Epoch: 151, Loss: 2.5026, Train: 1.0000, Val: 0.7860, Test: 0.7930
Epoch: 152, Loss: 2.6050, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 153, Loss: 2.4864, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 154, Loss: 2.4759, Train: 1.0000, Val: 0.7860, Test: 0.7940
Epoch: 155, Loss: 2.3170, Train: 1.0000, Val: 0.7880, Test: 0.7960
Epoch: 156, Loss: 2.4546, Train: 1.0000, Val: 0.7920, Test: 0.7960
Epoch: 157, Loss: 1.9092, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 158, Loss: 2.5069, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 159, Loss: 2.7220, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 160, Loss: 2.2825, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 161, Loss: 2.8341, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 162, Loss: 2.3697, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 163, Loss: 2.6787, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 164, Loss: 2.5655, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 165, Loss: 2.4809, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 166, Loss: 2.1768, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 167, Loss: 2.8142, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 168, Loss: 2.0918, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 169, Loss: 2.5733, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 170, Loss: 2.2217, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 171, Loss: 2.2868, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 172, Loss: 2.5225, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 173, Loss: 2.5397, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 174, Loss: 2.4892, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 175, Loss: 2.4741, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 176, Loss: 2.6265, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 177, Loss: 2.4236, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 178, Loss: 2.6402, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 179, Loss: 2.6105, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 180, Loss: 2.6318, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 181, Loss: 2.6537, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 182, Loss: 2.4119, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 183, Loss: 2.5911, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 184, Loss: 2.4575, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 185, Loss: 2.4637, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 186, Loss: 2.3018, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 187, Loss: 2.9201, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 188, Loss: 2.6727, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 189, Loss: 2.1417, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 190, Loss: 2.5534, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 191, Loss: 2.4690, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 192, Loss: 2.5704, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 193, Loss: 2.0418, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 194, Loss: 2.3844, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 195, Loss: 2.5058, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 196, Loss: 2.4149, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 197, Loss: 2.2870, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 198, Loss: 2.5526, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 199, Loss: 2.7274, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 200, Loss: 2.5335, Train: 1.0000, Val: 0.7760, Test: 0.7990
MAD:  0.1079
Best Test Accuracy: 0.8240, Val Accuracy: 0.8080, Train Accuracy: 0.9643
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8573, Train: 0.1143, Val: 0.1220, Test: 0.1110
Epoch: 2, Loss: 4.8487, Train: 0.1929, Val: 0.1600, Test: 0.1490
Epoch: 3, Loss: 4.8179, Train: 0.2643, Val: 0.1800, Test: 0.1730
Epoch: 4, Loss: 4.7680, Train: 0.2929, Val: 0.2000, Test: 0.2010
Epoch: 5, Loss: 4.7616, Train: 0.3214, Val: 0.2200, Test: 0.2260
Epoch: 6, Loss: 4.6993, Train: 0.3500, Val: 0.2380, Test: 0.2430
Epoch: 7, Loss: 4.6480, Train: 0.3643, Val: 0.2600, Test: 0.2490
Epoch: 8, Loss: 4.5938, Train: 0.3786, Val: 0.2620, Test: 0.2490
Epoch: 9, Loss: 4.4951, Train: 0.3786, Val: 0.2600, Test: 0.2470
Epoch: 10, Loss: 4.3906, Train: 0.3714, Val: 0.2580, Test: 0.2480
Epoch: 11, Loss: 4.4393, Train: 0.3714, Val: 0.2580, Test: 0.2440
Epoch: 12, Loss: 4.3937, Train: 0.3714, Val: 0.2560, Test: 0.2440
Epoch: 13, Loss: 4.2362, Train: 0.3714, Val: 0.2540, Test: 0.2380
Epoch: 14, Loss: 4.2112, Train: 0.3714, Val: 0.2460, Test: 0.2370
Epoch: 15, Loss: 4.1004, Train: 0.3857, Val: 0.2420, Test: 0.2390
Epoch: 16, Loss: 4.2311, Train: 0.3857, Val: 0.2400, Test: 0.2430
Epoch: 17, Loss: 4.1609, Train: 0.3929, Val: 0.2500, Test: 0.2580
Epoch: 18, Loss: 3.9394, Train: 0.4929, Val: 0.3000, Test: 0.2910
Epoch: 19, Loss: 4.0428, Train: 0.5286, Val: 0.3560, Test: 0.3480
Epoch: 20, Loss: 3.8429, Train: 0.5643, Val: 0.3900, Test: 0.3830
Epoch: 21, Loss: 3.9112, Train: 0.5786, Val: 0.4020, Test: 0.4100
Epoch: 22, Loss: 3.8283, Train: 0.5929, Val: 0.4140, Test: 0.4270
Epoch: 23, Loss: 3.6420, Train: 0.6429, Val: 0.4480, Test: 0.4620
Epoch: 24, Loss: 3.9200, Train: 0.6786, Val: 0.4860, Test: 0.4980
Epoch: 25, Loss: 3.7917, Train: 0.7000, Val: 0.5180, Test: 0.5350
Epoch: 26, Loss: 3.9956, Train: 0.7357, Val: 0.5540, Test: 0.5690
Epoch: 27, Loss: 3.7844, Train: 0.7857, Val: 0.5960, Test: 0.6280
Epoch: 28, Loss: 3.5542, Train: 0.8286, Val: 0.6260, Test: 0.6740
Epoch: 29, Loss: 3.6494, Train: 0.8357, Val: 0.6660, Test: 0.6910
Epoch: 30, Loss: 3.7145, Train: 0.8286, Val: 0.6700, Test: 0.6960
Epoch: 31, Loss: 3.5331, Train: 0.8214, Val: 0.6700, Test: 0.6930
Epoch: 32, Loss: 3.4786, Train: 0.8214, Val: 0.6700, Test: 0.6820
Epoch: 33, Loss: 3.5360, Train: 0.8143, Val: 0.6720, Test: 0.6840
Epoch: 34, Loss: 3.6615, Train: 0.8143, Val: 0.6620, Test: 0.6850
Epoch: 35, Loss: 3.7388, Train: 0.8143, Val: 0.6640, Test: 0.6830
Epoch: 36, Loss: 3.3856, Train: 0.8143, Val: 0.6640, Test: 0.6840
Epoch: 37, Loss: 3.3659, Train: 0.8214, Val: 0.6680, Test: 0.6870
Epoch: 38, Loss: 3.2782, Train: 0.8286, Val: 0.6680, Test: 0.6880
Epoch: 39, Loss: 3.4274, Train: 0.8429, Val: 0.6720, Test: 0.7020
Epoch: 40, Loss: 3.3729, Train: 0.8429, Val: 0.6760, Test: 0.7090
Epoch: 41, Loss: 3.2527, Train: 0.8286, Val: 0.6860, Test: 0.7120
Epoch: 42, Loss: 2.7441, Train: 0.8286, Val: 0.6960, Test: 0.7200
Epoch: 43, Loss: 3.3447, Train: 0.8286, Val: 0.7080, Test: 0.7220
Epoch: 44, Loss: 2.8924, Train: 0.8571, Val: 0.7060, Test: 0.7270
Epoch: 45, Loss: 3.0147, Train: 0.9000, Val: 0.7140, Test: 0.7340
Epoch: 46, Loss: 3.1727, Train: 0.9071, Val: 0.7240, Test: 0.7400
Epoch: 47, Loss: 3.2090, Train: 0.9143, Val: 0.7340, Test: 0.7440
Epoch: 48, Loss: 3.0457, Train: 0.9214, Val: 0.7400, Test: 0.7530
Epoch: 49, Loss: 2.9619, Train: 0.9429, Val: 0.7400, Test: 0.7580
Epoch: 50, Loss: 2.9967, Train: 0.9429, Val: 0.7420, Test: 0.7670
Epoch: 51, Loss: 3.3776, Train: 0.9500, Val: 0.7460, Test: 0.7750
Epoch: 52, Loss: 2.9665, Train: 0.9714, Val: 0.7560, Test: 0.7830
Epoch: 53, Loss: 2.8552, Train: 0.9786, Val: 0.7680, Test: 0.7960
Epoch: 54, Loss: 3.1431, Train: 0.9857, Val: 0.7760, Test: 0.8050
Epoch: 55, Loss: 2.8107, Train: 0.9857, Val: 0.7740, Test: 0.8040
Epoch: 56, Loss: 2.8649, Train: 0.9929, Val: 0.7800, Test: 0.8060
Epoch: 57, Loss: 2.7393, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 58, Loss: 2.6121, Train: 1.0000, Val: 0.7880, Test: 0.8060
Epoch: 59, Loss: 2.8191, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 60, Loss: 2.9915, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 61, Loss: 2.7059, Train: 1.0000, Val: 0.7940, Test: 0.8150
Epoch: 62, Loss: 2.5704, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 63, Loss: 2.7023, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 64, Loss: 2.8416, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 65, Loss: 2.8168, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 66, Loss: 2.7463, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 67, Loss: 2.7897, Train: 0.9929, Val: 0.7720, Test: 0.7960
Epoch: 68, Loss: 3.1756, Train: 0.9929, Val: 0.7740, Test: 0.7950
Epoch: 69, Loss: 3.0279, Train: 0.9929, Val: 0.7740, Test: 0.7900
Epoch: 70, Loss: 2.9386, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 71, Loss: 2.4600, Train: 0.9929, Val: 0.7640, Test: 0.7880
Epoch: 72, Loss: 2.4113, Train: 0.9929, Val: 0.7600, Test: 0.7870
Epoch: 73, Loss: 2.8274, Train: 1.0000, Val: 0.7600, Test: 0.7860
Epoch: 74, Loss: 2.4548, Train: 1.0000, Val: 0.7540, Test: 0.7850
Epoch: 75, Loss: 2.8986, Train: 0.9929, Val: 0.7560, Test: 0.7850
Epoch: 76, Loss: 2.6275, Train: 0.9929, Val: 0.7520, Test: 0.7850
Epoch: 77, Loss: 2.6356, Train: 0.9929, Val: 0.7580, Test: 0.7870
Epoch: 78, Loss: 2.8421, Train: 1.0000, Val: 0.7600, Test: 0.7870
Epoch: 79, Loss: 2.4459, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 80, Loss: 2.4498, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 81, Loss: 2.6687, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 82, Loss: 2.6276, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 83, Loss: 2.6018, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 84, Loss: 2.6436, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 85, Loss: 2.4438, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 86, Loss: 2.5395, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 87, Loss: 2.8908, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 88, Loss: 2.3771, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 89, Loss: 2.2789, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 90, Loss: 2.5832, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 91, Loss: 2.4891, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 92, Loss: 2.5883, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 93, Loss: 2.5355, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 94, Loss: 2.7007, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 95, Loss: 2.6966, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 96, Loss: 3.0033, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 97, Loss: 2.8070, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 98, Loss: 2.6594, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 99, Loss: 2.6124, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 100, Loss: 2.7059, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 101, Loss: 2.3727, Train: 1.0000, Val: 0.7580, Test: 0.7820
Epoch: 102, Loss: 2.3810, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 103, Loss: 2.4506, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 104, Loss: 2.3806, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 105, Loss: 2.3230, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 106, Loss: 2.6756, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 107, Loss: 2.6498, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 108, Loss: 2.4499, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 109, Loss: 2.3527, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 110, Loss: 2.4170, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 111, Loss: 2.6186, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 112, Loss: 2.6443, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 113, Loss: 2.6680, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 114, Loss: 2.3744, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 115, Loss: 2.3864, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 116, Loss: 2.4243, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 117, Loss: 2.5666, Train: 1.0000, Val: 0.7920, Test: 0.8050
Epoch: 118, Loss: 2.6564, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 119, Loss: 2.3678, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 120, Loss: 2.4083, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 121, Loss: 2.6780, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 122, Loss: 2.7375, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 123, Loss: 2.1802, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 124, Loss: 2.5705, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 125, Loss: 2.6776, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 126, Loss: 2.7876, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 127, Loss: 2.6775, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 128, Loss: 2.8444, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 129, Loss: 2.7748, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 130, Loss: 2.3979, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 131, Loss: 2.3214, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 132, Loss: 2.5808, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 133, Loss: 2.7363, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 134, Loss: 2.7067, Train: 1.0000, Val: 0.7880, Test: 0.7970
Epoch: 135, Loss: 2.4256, Train: 1.0000, Val: 0.7880, Test: 0.7950
Epoch: 136, Loss: 2.7980, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 137, Loss: 2.7393, Train: 1.0000, Val: 0.7880, Test: 0.7940
Epoch: 138, Loss: 2.2478, Train: 1.0000, Val: 0.7860, Test: 0.7890
Epoch: 139, Loss: 2.6810, Train: 1.0000, Val: 0.7840, Test: 0.7920
Epoch: 140, Loss: 2.5993, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 141, Loss: 2.8202, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 142, Loss: 2.2315, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 143, Loss: 2.4742, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 144, Loss: 2.1538, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 145, Loss: 2.5159, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 146, Loss: 2.7099, Train: 1.0000, Val: 0.7640, Test: 0.7900
Epoch: 147, Loss: 2.4547, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 148, Loss: 2.8506, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 149, Loss: 2.7388, Train: 1.0000, Val: 0.7600, Test: 0.7870
Epoch: 150, Loss: 2.1774, Train: 1.0000, Val: 0.7600, Test: 0.7870
Epoch: 151, Loss: 2.7197, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 152, Loss: 2.4622, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 153, Loss: 2.2815, Train: 1.0000, Val: 0.7620, Test: 0.7820
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 2.4707, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 155, Loss: 2.6951, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 156, Loss: 2.5726, Train: 1.0000, Val: 0.7560, Test: 0.7820
Epoch: 157, Loss: 2.4744, Train: 1.0000, Val: 0.7540, Test: 0.7850
Epoch: 158, Loss: 2.2278, Train: 1.0000, Val: 0.7580, Test: 0.7880
Epoch: 159, Loss: 2.7661, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 160, Loss: 2.4653, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 161, Loss: 2.5308, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 162, Loss: 2.9686, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 163, Loss: 2.7752, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 164, Loss: 2.7087, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 165, Loss: 2.5781, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 166, Loss: 2.4182, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 167, Loss: 2.6160, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 168, Loss: 2.3589, Train: 1.0000, Val: 0.7800, Test: 0.7870
Epoch: 169, Loss: 2.5417, Train: 1.0000, Val: 0.7800, Test: 0.7890
Epoch: 170, Loss: 2.1929, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 171, Loss: 2.2843, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 172, Loss: 2.5311, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 173, Loss: 2.0778, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 174, Loss: 2.3042, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 175, Loss: 2.5100, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 176, Loss: 2.6744, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 177, Loss: 2.5997, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 178, Loss: 2.2421, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 179, Loss: 2.5105, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 180, Loss: 2.9121, Train: 1.0000, Val: 0.7720, Test: 0.7870
Epoch: 181, Loss: 2.3876, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 182, Loss: 2.3667, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 183, Loss: 2.6879, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 184, Loss: 2.8947, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 185, Loss: 2.5946, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 186, Loss: 2.1313, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 187, Loss: 2.7814, Train: 1.0000, Val: 0.7640, Test: 0.7900
Epoch: 188, Loss: 2.3363, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 189, Loss: 2.1915, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 190, Loss: 2.3209, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 191, Loss: 2.5118, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 192, Loss: 2.6900, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 193, Loss: 2.3008, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 194, Loss: 2.3625, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 195, Loss: 2.8311, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 196, Loss: 2.6781, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 197, Loss: 2.6014, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 198, Loss: 2.5790, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 199, Loss: 2.5630, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 200, Loss: 2.5807, Train: 1.0000, Val: 0.7640, Test: 0.7930
MAD:  0.3746
Best Test Accuracy: 0.8150, Val Accuracy: 0.7940, Train Accuracy: 1.0000
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8729, Train: 0.1143, Val: 0.0920, Test: 0.0860
Epoch: 2, Loss: 4.8028, Train: 0.1643, Val: 0.1260, Test: 0.1400
Epoch: 3, Loss: 4.7753, Train: 0.2000, Val: 0.1320, Test: 0.1600
Epoch: 4, Loss: 4.7694, Train: 0.2286, Val: 0.1420, Test: 0.1670
Epoch: 5, Loss: 4.7107, Train: 0.2643, Val: 0.1600, Test: 0.1900
Epoch: 6, Loss: 4.7223, Train: 0.2857, Val: 0.1700, Test: 0.1990
Epoch: 7, Loss: 4.6075, Train: 0.2857, Val: 0.1720, Test: 0.2030
Epoch: 8, Loss: 4.5558, Train: 0.2929, Val: 0.1740, Test: 0.2050
Epoch: 9, Loss: 4.4811, Train: 0.3071, Val: 0.1740, Test: 0.2030
Epoch: 10, Loss: 4.4308, Train: 0.2929, Val: 0.1680, Test: 0.1960
Epoch: 11, Loss: 4.3862, Train: 0.2857, Val: 0.1520, Test: 0.1770
Epoch: 12, Loss: 4.2696, Train: 0.2429, Val: 0.1360, Test: 0.1630
Epoch: 13, Loss: 4.0857, Train: 0.2143, Val: 0.1300, Test: 0.1580
Epoch: 14, Loss: 4.0924, Train: 0.2000, Val: 0.1260, Test: 0.1510
Epoch: 15, Loss: 4.1000, Train: 0.1929, Val: 0.1240, Test: 0.1510
Epoch: 16, Loss: 3.8282, Train: 0.2214, Val: 0.1280, Test: 0.1530
Epoch: 17, Loss: 3.6749, Train: 0.2571, Val: 0.1360, Test: 0.1630
Epoch: 18, Loss: 4.0440, Train: 0.3571, Val: 0.1580, Test: 0.1940
Epoch: 19, Loss: 4.1071, Train: 0.5286, Val: 0.2440, Test: 0.2740
Epoch: 20, Loss: 3.6785, Train: 0.6857, Val: 0.4280, Test: 0.4340
Epoch: 21, Loss: 3.6691, Train: 0.7929, Val: 0.5900, Test: 0.5900
Epoch: 22, Loss: 3.6370, Train: 0.8286, Val: 0.6240, Test: 0.6520
Epoch: 23, Loss: 3.6722, Train: 0.8071, Val: 0.6180, Test: 0.6450
Epoch: 24, Loss: 3.7927, Train: 0.7786, Val: 0.6280, Test: 0.6460
Epoch: 25, Loss: 3.4003, Train: 0.7786, Val: 0.6400, Test: 0.6610
Epoch: 26, Loss: 3.8053, Train: 0.7929, Val: 0.6440, Test: 0.6670
Epoch: 27, Loss: 3.5310, Train: 0.8214, Val: 0.6620, Test: 0.6810
Epoch: 28, Loss: 3.4804, Train: 0.8571, Val: 0.6800, Test: 0.7010
Epoch: 29, Loss: 3.4312, Train: 0.8786, Val: 0.7080, Test: 0.7300
Epoch: 30, Loss: 3.0880, Train: 0.9071, Val: 0.7240, Test: 0.7550
Epoch: 31, Loss: 3.3893, Train: 0.9357, Val: 0.7360, Test: 0.7830
Epoch: 32, Loss: 3.0326, Train: 0.9357, Val: 0.7540, Test: 0.8100
Epoch: 33, Loss: 3.1325, Train: 0.9714, Val: 0.7700, Test: 0.8170
Epoch: 34, Loss: 3.3867, Train: 0.9714, Val: 0.7800, Test: 0.8170
Epoch: 35, Loss: 3.3516, Train: 0.9714, Val: 0.7920, Test: 0.8210
Epoch: 36, Loss: 3.1461, Train: 0.9714, Val: 0.7900, Test: 0.8250
Epoch: 37, Loss: 3.1019, Train: 0.9714, Val: 0.7920, Test: 0.8260
Epoch: 38, Loss: 2.9306, Train: 0.9714, Val: 0.7960, Test: 0.8220
Epoch: 39, Loss: 3.4366, Train: 0.9714, Val: 0.7960, Test: 0.8200
Epoch: 40, Loss: 3.1113, Train: 0.9714, Val: 0.7940, Test: 0.8170
Epoch: 41, Loss: 3.2444, Train: 0.9714, Val: 0.7900, Test: 0.8170
Epoch: 42, Loss: 2.9102, Train: 0.9714, Val: 0.7940, Test: 0.8170
Epoch: 43, Loss: 3.0938, Train: 0.9857, Val: 0.7940, Test: 0.8190
Epoch: 44, Loss: 3.0440, Train: 0.9857, Val: 0.7920, Test: 0.8180
Epoch: 45, Loss: 2.8524, Train: 0.9857, Val: 0.7940, Test: 0.8190
Epoch: 46, Loss: 2.8225, Train: 0.9857, Val: 0.7880, Test: 0.8160
Epoch: 47, Loss: 2.6971, Train: 0.9929, Val: 0.7840, Test: 0.8130
Epoch: 48, Loss: 3.0381, Train: 0.9929, Val: 0.7940, Test: 0.8100
Epoch: 49, Loss: 3.2321, Train: 0.9929, Val: 0.7900, Test: 0.8110
Epoch: 50, Loss: 2.9997, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 51, Loss: 2.8975, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 52, Loss: 3.0312, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 53, Loss: 3.1776, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 54, Loss: 2.6897, Train: 1.0000, Val: 0.7940, Test: 0.8130
Epoch: 55, Loss: 2.8503, Train: 1.0000, Val: 0.7940, Test: 0.8170
Epoch: 56, Loss: 2.8040, Train: 1.0000, Val: 0.7980, Test: 0.8180
Epoch: 57, Loss: 2.6772, Train: 1.0000, Val: 0.7980, Test: 0.8190
Epoch: 58, Loss: 2.7200, Train: 1.0000, Val: 0.7980, Test: 0.8230
Epoch: 59, Loss: 3.2150, Train: 1.0000, Val: 0.8040, Test: 0.8240
Epoch: 60, Loss: 3.0923, Train: 1.0000, Val: 0.8020, Test: 0.8250
Epoch: 61, Loss: 2.8993, Train: 1.0000, Val: 0.8020, Test: 0.8230
Epoch: 62, Loss: 3.0522, Train: 1.0000, Val: 0.8020, Test: 0.8210
Epoch: 63, Loss: 2.9329, Train: 1.0000, Val: 0.8020, Test: 0.8210
Epoch: 64, Loss: 2.8111, Train: 1.0000, Val: 0.8060, Test: 0.8240
Epoch: 65, Loss: 2.6022, Train: 1.0000, Val: 0.8020, Test: 0.8210
Epoch: 66, Loss: 2.5236, Train: 1.0000, Val: 0.8040, Test: 0.8180
Epoch: 67, Loss: 2.4265, Train: 1.0000, Val: 0.7960, Test: 0.8210
Epoch: 68, Loss: 2.7836, Train: 1.0000, Val: 0.7940, Test: 0.8200
Epoch: 69, Loss: 2.8676, Train: 1.0000, Val: 0.7860, Test: 0.8170
Epoch: 70, Loss: 2.5193, Train: 1.0000, Val: 0.7800, Test: 0.8150
Epoch: 71, Loss: 2.6346, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 72, Loss: 2.5251, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 73, Loss: 3.1610, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 74, Loss: 2.6086, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 75, Loss: 2.7496, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 76, Loss: 2.7301, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 77, Loss: 2.7489, Train: 1.0000, Val: 0.7860, Test: 0.8050
Epoch: 78, Loss: 2.4574, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 79, Loss: 2.8019, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 80, Loss: 2.6992, Train: 0.9929, Val: 0.7920, Test: 0.8110
Epoch: 81, Loss: 2.8979, Train: 0.9929, Val: 0.7960, Test: 0.8120
Epoch: 82, Loss: 2.8653, Train: 0.9929, Val: 0.7920, Test: 0.8110
Epoch: 83, Loss: 2.7733, Train: 0.9929, Val: 0.7880, Test: 0.8080
Epoch: 84, Loss: 2.2995, Train: 0.9929, Val: 0.7880, Test: 0.8070
Epoch: 85, Loss: 2.4040, Train: 0.9929, Val: 0.7900, Test: 0.8050
Epoch: 86, Loss: 2.5836, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 87, Loss: 2.7701, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 88, Loss: 2.3945, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 89, Loss: 2.8711, Train: 1.0000, Val: 0.7700, Test: 0.7980
Epoch: 90, Loss: 2.3982, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 91, Loss: 2.5781, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 92, Loss: 2.7141, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 93, Loss: 2.5970, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 94, Loss: 2.8265, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 95, Loss: 2.4022, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 96, Loss: 2.6036, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 97, Loss: 2.5724, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 98, Loss: 2.8625, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 99, Loss: 2.8330, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 100, Loss: 2.3353, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 101, Loss: 2.6300, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 102, Loss: 2.8151, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 103, Loss: 2.6416, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 104, Loss: 2.6122, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 105, Loss: 2.1612, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 106, Loss: 2.0595, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 107, Loss: 2.5671, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 108, Loss: 2.5398, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 109, Loss: 2.4506, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 110, Loss: 2.3286, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 111, Loss: 2.5764, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 112, Loss: 3.0458, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 113, Loss: 2.6535, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 114, Loss: 2.8020, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 115, Loss: 1.9010, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 116, Loss: 2.6754, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 117, Loss: 2.7377, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 118, Loss: 2.5133, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 119, Loss: 2.5124, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 120, Loss: 2.1283, Train: 1.0000, Val: 0.7640, Test: 0.7900
Epoch: 121, Loss: 2.7704, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 122, Loss: 2.3176, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 123, Loss: 2.5164, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 124, Loss: 2.7837, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 125, Loss: 2.8507, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 126, Loss: 2.7380, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 127, Loss: 2.3444, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 128, Loss: 2.3766, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 129, Loss: 2.7567, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 130, Loss: 2.6836, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 131, Loss: 2.7466, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 132, Loss: 2.5607, Train: 1.0000, Val: 0.7880, Test: 0.7980
Epoch: 133, Loss: 2.5237, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 134, Loss: 2.4865, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 135, Loss: 2.8035, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 136, Loss: 2.3994, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 137, Loss: 2.3548, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 138, Loss: 2.5520, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 139, Loss: 2.2643, Train: 1.0000, Val: 0.7900, Test: 0.8030
Epoch: 140, Loss: 2.5326, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 141, Loss: 2.5311, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 142, Loss: 2.4730, Train: 1.0000, Val: 0.7900, Test: 0.7990
Epoch: 143, Loss: 2.1501, Train: 1.0000, Val: 0.7900, Test: 0.7970
Epoch: 144, Loss: 2.2487, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 145, Loss: 2.5066, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 146, Loss: 2.6286, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 147, Loss: 2.6186, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 148, Loss: 2.1155, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 149, Loss: 2.6149, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 150, Loss: 2.7933, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 151, Loss: 2.3635, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 152, Loss: 2.2071, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 153, Loss: 2.4659, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 154, Loss: 2.6451, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 155, Loss: 2.5118, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 156, Loss: 2.4834, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 157, Loss: 2.0927, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 158, Loss: 2.1418, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 159, Loss: 2.3591, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 160, Loss: 2.6757, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 161, Loss: 2.4581, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 162, Loss: 2.8298, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 163, Loss: 2.1768, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 164, Loss: 2.5748, Train: 1.0000, Val: 0.7840, Test: 0.8020
Epoch: 165, Loss: 2.6026, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 166, Loss: 2.3522, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 167, Loss: 2.6202, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 168, Loss: 2.4667, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 169, Loss: 3.1208, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 170, Loss: 2.5295, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 171, Loss: 2.6518, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 172, Loss: 2.5218, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 173, Loss: 2.4742, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 174, Loss: 2.2321, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 175, Loss: 2.2763, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 176, Loss: 2.3940, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 177, Loss: 2.1503, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 178, Loss: 2.5409, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 179, Loss: 2.4636, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 180, Loss: 2.7070, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 181, Loss: 2.5744, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 182, Loss: 2.6271, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 183, Loss: 2.8253, Train: 1.0000, Val: 0.7580, Test: 0.7890
Epoch: 184, Loss: 2.4190, Train: 1.0000, Val: 0.7540, Test: 0.7880
Epoch: 185, Loss: 2.4928, Train: 1.0000, Val: 0.7540, Test: 0.7850
Epoch: 186, Loss: 2.5341, Train: 1.0000, Val: 0.7520, Test: 0.7870
Epoch: 187, Loss: 2.4863, Train: 1.0000, Val: 0.7540, Test: 0.7850
Epoch: 188, Loss: 2.6193, Train: 1.0000, Val: 0.7560, Test: 0.7850
Epoch: 189, Loss: 2.7088, Train: 1.0000, Val: 0.7560, Test: 0.7820
Epoch: 190, Loss: 2.7862, Train: 1.0000, Val: 0.7560, Test: 0.7790
Epoch: 191, Loss: 2.4306, Train: 1.0000, Val: 0.7560, Test: 0.7810
Epoch: 192, Loss: 2.3745, Train: 1.0000, Val: 0.7580, Test: 0.7830
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 2.0009, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 194, Loss: 2.2205, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 195, Loss: 2.4467, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 196, Loss: 2.7239, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 197, Loss: 2.0838, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 198, Loss: 2.3219, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 199, Loss: 2.8241, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 200, Loss: 2.2670, Train: 1.0000, Val: 0.7700, Test: 0.7870
MAD:  0.0882
Best Test Accuracy: 0.8260, Val Accuracy: 0.7920, Train Accuracy: 0.9714
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8620, Train: 0.1357, Val: 0.0760, Test: 0.0710
Epoch: 2, Loss: 4.8274, Train: 0.1929, Val: 0.0780, Test: 0.0970
Epoch: 3, Loss: 4.8123, Train: 0.2000, Val: 0.0800, Test: 0.1050
Epoch: 4, Loss: 4.7700, Train: 0.2071, Val: 0.0780, Test: 0.1060
Epoch: 5, Loss: 4.7487, Train: 0.2500, Val: 0.0960, Test: 0.1150
Epoch: 6, Loss: 4.6600, Train: 0.2714, Val: 0.1100, Test: 0.1320
Epoch: 7, Loss: 4.6788, Train: 0.2786, Val: 0.1140, Test: 0.1360
Epoch: 8, Loss: 4.5634, Train: 0.2786, Val: 0.1360, Test: 0.1530
Epoch: 9, Loss: 4.5211, Train: 0.3000, Val: 0.1600, Test: 0.1660
Epoch: 10, Loss: 4.4043, Train: 0.3143, Val: 0.1820, Test: 0.1920
Epoch: 11, Loss: 4.3294, Train: 0.3143, Val: 0.1940, Test: 0.2010
Epoch: 12, Loss: 4.4052, Train: 0.3214, Val: 0.2000, Test: 0.2130
Epoch: 13, Loss: 4.1500, Train: 0.3214, Val: 0.2120, Test: 0.2210
Epoch: 14, Loss: 4.1833, Train: 0.3143, Val: 0.2180, Test: 0.2240
Epoch: 15, Loss: 3.8322, Train: 0.3214, Val: 0.2260, Test: 0.2230
Epoch: 16, Loss: 4.0128, Train: 0.3214, Val: 0.2260, Test: 0.2240
Epoch: 17, Loss: 3.8580, Train: 0.3286, Val: 0.2240, Test: 0.2230
Epoch: 18, Loss: 4.0746, Train: 0.3357, Val: 0.2320, Test: 0.2230
Epoch: 19, Loss: 3.8299, Train: 0.4143, Val: 0.2520, Test: 0.2600
Epoch: 20, Loss: 3.8429, Train: 0.5714, Val: 0.3420, Test: 0.3540
Epoch: 21, Loss: 3.6657, Train: 0.7500, Val: 0.4600, Test: 0.4610
Epoch: 22, Loss: 3.6048, Train: 0.8286, Val: 0.5800, Test: 0.5800
Epoch: 23, Loss: 3.6147, Train: 0.8857, Val: 0.6820, Test: 0.6840
Epoch: 24, Loss: 3.8697, Train: 0.9286, Val: 0.7260, Test: 0.7360
Epoch: 25, Loss: 3.4628, Train: 0.9429, Val: 0.7460, Test: 0.7770
Epoch: 26, Loss: 3.6727, Train: 0.9571, Val: 0.7420, Test: 0.7860
Epoch: 27, Loss: 3.5402, Train: 0.9714, Val: 0.7580, Test: 0.7820
Epoch: 28, Loss: 3.4840, Train: 0.9786, Val: 0.7600, Test: 0.7830
Epoch: 29, Loss: 3.5182, Train: 0.9786, Val: 0.7460, Test: 0.7810
Epoch: 30, Loss: 3.4614, Train: 0.9786, Val: 0.7560, Test: 0.7820
Epoch: 31, Loss: 3.5219, Train: 0.9857, Val: 0.7540, Test: 0.7850
Epoch: 32, Loss: 3.2829, Train: 0.9857, Val: 0.7520, Test: 0.7870
Epoch: 33, Loss: 3.4161, Train: 0.9786, Val: 0.7480, Test: 0.7870
Epoch: 34, Loss: 2.9834, Train: 0.9786, Val: 0.7520, Test: 0.7890
Epoch: 35, Loss: 3.2003, Train: 0.9714, Val: 0.7440, Test: 0.7810
Epoch: 36, Loss: 3.0690, Train: 0.9643, Val: 0.7420, Test: 0.7710
Epoch: 37, Loss: 3.5663, Train: 0.9643, Val: 0.7420, Test: 0.7640
Epoch: 38, Loss: 3.1895, Train: 0.9571, Val: 0.7400, Test: 0.7670
Epoch: 39, Loss: 3.5933, Train: 0.9571, Val: 0.7380, Test: 0.7620
Epoch: 40, Loss: 3.2076, Train: 0.9643, Val: 0.7400, Test: 0.7660
Epoch: 41, Loss: 2.8167, Train: 0.9643, Val: 0.7520, Test: 0.7710
Epoch: 42, Loss: 3.0644, Train: 0.9643, Val: 0.7580, Test: 0.7720
Epoch: 43, Loss: 2.5490, Train: 0.9643, Val: 0.7560, Test: 0.7690
Epoch: 44, Loss: 3.0125, Train: 0.9643, Val: 0.7580, Test: 0.7740
Epoch: 45, Loss: 2.9293, Train: 0.9786, Val: 0.7540, Test: 0.7790
Epoch: 46, Loss: 3.2826, Train: 0.9786, Val: 0.7540, Test: 0.7760
Epoch: 47, Loss: 2.8484, Train: 0.9786, Val: 0.7560, Test: 0.7800
Epoch: 48, Loss: 2.5051, Train: 0.9857, Val: 0.7660, Test: 0.7850
Epoch: 49, Loss: 3.0841, Train: 0.9857, Val: 0.7700, Test: 0.7900
Epoch: 50, Loss: 2.9158, Train: 0.9857, Val: 0.7800, Test: 0.7940
Epoch: 51, Loss: 2.8072, Train: 0.9857, Val: 0.7800, Test: 0.8010
Epoch: 52, Loss: 2.5237, Train: 0.9857, Val: 0.7820, Test: 0.8010
Epoch: 53, Loss: 2.8392, Train: 0.9857, Val: 0.7880, Test: 0.8040
Epoch: 54, Loss: 2.6189, Train: 0.9857, Val: 0.7920, Test: 0.8070
Epoch: 55, Loss: 2.6735, Train: 0.9857, Val: 0.7880, Test: 0.8050
Epoch: 56, Loss: 3.1410, Train: 0.9929, Val: 0.7860, Test: 0.8070
Epoch: 57, Loss: 2.6334, Train: 0.9929, Val: 0.7880, Test: 0.8080
Epoch: 58, Loss: 2.3449, Train: 0.9929, Val: 0.7900, Test: 0.8020
Epoch: 59, Loss: 2.6281, Train: 0.9929, Val: 0.7900, Test: 0.8020
Epoch: 60, Loss: 2.5439, Train: 0.9929, Val: 0.7860, Test: 0.8020
Epoch: 61, Loss: 2.1806, Train: 0.9929, Val: 0.7880, Test: 0.8010
Epoch: 62, Loss: 2.5210, Train: 0.9929, Val: 0.7860, Test: 0.8010
Epoch: 63, Loss: 2.5534, Train: 0.9929, Val: 0.7860, Test: 0.7990
Epoch: 64, Loss: 2.8379, Train: 0.9929, Val: 0.7860, Test: 0.7950
Epoch: 65, Loss: 2.5479, Train: 0.9929, Val: 0.7800, Test: 0.7940
Epoch: 66, Loss: 2.7817, Train: 0.9929, Val: 0.7740, Test: 0.7950
Epoch: 67, Loss: 2.6041, Train: 0.9929, Val: 0.7740, Test: 0.7910
Epoch: 68, Loss: 2.4137, Train: 0.9929, Val: 0.7720, Test: 0.7920
Epoch: 69, Loss: 2.7959, Train: 0.9857, Val: 0.7720, Test: 0.7900
Epoch: 70, Loss: 2.5597, Train: 0.9857, Val: 0.7720, Test: 0.7910
Epoch: 71, Loss: 3.2237, Train: 0.9857, Val: 0.7700, Test: 0.7920
Epoch: 72, Loss: 2.7590, Train: 0.9929, Val: 0.7700, Test: 0.7910
Epoch: 73, Loss: 2.5889, Train: 0.9929, Val: 0.7720, Test: 0.7950
Epoch: 74, Loss: 2.5352, Train: 0.9929, Val: 0.7700, Test: 0.7950
Epoch: 75, Loss: 2.6777, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 76, Loss: 2.5363, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 77, Loss: 2.6254, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 78, Loss: 2.5378, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 79, Loss: 2.3867, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 80, Loss: 2.7034, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 81, Loss: 2.4274, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 82, Loss: 2.6601, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 83, Loss: 2.6657, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 84, Loss: 2.5515, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 85, Loss: 2.4892, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 86, Loss: 2.6083, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 87, Loss: 2.8837, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 88, Loss: 2.9418, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 89, Loss: 2.4358, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 90, Loss: 2.7576, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 91, Loss: 2.3579, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 92, Loss: 3.0362, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 93, Loss: 2.7795, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 94, Loss: 2.1555, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 95, Loss: 2.4374, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 96, Loss: 2.6579, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 97, Loss: 2.5792, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 98, Loss: 2.3830, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 99, Loss: 2.4902, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 100, Loss: 2.6117, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 101, Loss: 2.2621, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 102, Loss: 2.7870, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 103, Loss: 2.2900, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 104, Loss: 2.2350, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 105, Loss: 2.2924, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 106, Loss: 2.6120, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 107, Loss: 2.2439, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 108, Loss: 2.7955, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 109, Loss: 2.4390, Train: 1.0000, Val: 0.7720, Test: 0.8040
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 110, Loss: 2.6028, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 111, Loss: 2.3891, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 112, Loss: 1.9951, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 113, Loss: 2.4519, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 114, Loss: 2.3446, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 115, Loss: 2.7027, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 116, Loss: 2.6473, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 117, Loss: 2.5945, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 118, Loss: 2.2565, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 119, Loss: 2.6219, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 120, Loss: 2.2597, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 121, Loss: 2.5327, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 122, Loss: 2.0579, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 123, Loss: 2.3414, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 124, Loss: 2.1678, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 125, Loss: 2.3963, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 126, Loss: 2.3281, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 127, Loss: 2.3118, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 128, Loss: 2.2480, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 129, Loss: 2.2713, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 130, Loss: 2.4958, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 131, Loss: 2.4916, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 132, Loss: 2.5041, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 133, Loss: 2.4037, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 134, Loss: 2.2013, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 135, Loss: 2.4716, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 136, Loss: 2.4378, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 137, Loss: 2.5964, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 138, Loss: 2.2622, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 139, Loss: 2.5814, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 140, Loss: 2.6027, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 141, Loss: 1.9665, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 142, Loss: 2.8051, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 143, Loss: 2.4695, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 144, Loss: 2.5193, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 145, Loss: 2.1527, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 146, Loss: 2.3359, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 147, Loss: 2.6105, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 148, Loss: 2.2631, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 149, Loss: 2.5640, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 150, Loss: 2.6975, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 151, Loss: 2.3631, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 152, Loss: 2.6012, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 153, Loss: 2.4906, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 154, Loss: 2.5389, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 155, Loss: 2.2887, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 156, Loss: 2.4535, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 157, Loss: 2.2540, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 158, Loss: 2.6690, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 159, Loss: 3.0098, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 160, Loss: 2.5795, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 161, Loss: 2.8238, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 162, Loss: 2.3166, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 163, Loss: 2.6343, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 164, Loss: 2.1995, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 165, Loss: 2.3197, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 166, Loss: 2.3868, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 167, Loss: 2.5528, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 168, Loss: 2.4202, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 169, Loss: 2.6613, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 170, Loss: 2.5907, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 171, Loss: 2.7864, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 172, Loss: 2.4975, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 173, Loss: 2.5916, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 174, Loss: 2.6412, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 175, Loss: 2.4261, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 176, Loss: 2.5656, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 177, Loss: 2.7617, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 178, Loss: 2.7619, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 179, Loss: 2.4567, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 180, Loss: 2.4574, Train: 1.0000, Val: 0.7720, Test: 0.7830
Epoch: 181, Loss: 2.6889, Train: 1.0000, Val: 0.7680, Test: 0.7800
Epoch: 182, Loss: 2.7392, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 183, Loss: 2.7290, Train: 1.0000, Val: 0.7620, Test: 0.7760
Epoch: 184, Loss: 2.4812, Train: 1.0000, Val: 0.7620, Test: 0.7740
Epoch: 185, Loss: 2.4782, Train: 1.0000, Val: 0.7660, Test: 0.7760
Epoch: 186, Loss: 2.3526, Train: 1.0000, Val: 0.7660, Test: 0.7810
Epoch: 187, Loss: 2.6874, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 188, Loss: 2.3102, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 189, Loss: 2.3457, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 190, Loss: 2.2770, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 191, Loss: 2.5162, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 192, Loss: 2.6212, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 193, Loss: 2.1084, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 194, Loss: 2.2164, Train: 1.0000, Val: 0.7580, Test: 0.7930
Epoch: 195, Loss: 2.3728, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 196, Loss: 2.5002, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 197, Loss: 2.4204, Train: 1.0000, Val: 0.7620, Test: 0.7940
Epoch: 198, Loss: 2.7261, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 199, Loss: 2.3252, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 200, Loss: 2.0621, Train: 1.0000, Val: 0.7620, Test: 0.7900
MAD:  0.361
Best Test Accuracy: 0.8080, Val Accuracy: 0.7880, Train Accuracy: 0.9929
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8517, Train: 0.1571, Val: 0.3060, Test: 0.3140
Epoch: 2, Loss: 4.8143, Train: 0.1857, Val: 0.3260, Test: 0.3250
Epoch: 3, Loss: 4.7857, Train: 0.1857, Val: 0.3280, Test: 0.3310
Epoch: 4, Loss: 4.7301, Train: 0.2000, Val: 0.3320, Test: 0.3360
Epoch: 5, Loss: 4.6942, Train: 0.2143, Val: 0.3380, Test: 0.3370
Epoch: 6, Loss: 4.6074, Train: 0.2143, Val: 0.3400, Test: 0.3360
Epoch: 7, Loss: 4.5617, Train: 0.2143, Val: 0.3380, Test: 0.3360
Epoch: 8, Loss: 4.5341, Train: 0.2071, Val: 0.3380, Test: 0.3350
Epoch: 9, Loss: 4.5287, Train: 0.2071, Val: 0.3380, Test: 0.3340
Epoch: 10, Loss: 4.4734, Train: 0.2143, Val: 0.3400, Test: 0.3360
Epoch: 11, Loss: 4.2617, Train: 0.2143, Val: 0.3420, Test: 0.3370
Epoch: 12, Loss: 4.3321, Train: 0.2143, Val: 0.3420, Test: 0.3390
Epoch: 13, Loss: 4.2523, Train: 0.2286, Val: 0.3460, Test: 0.3420
Epoch: 14, Loss: 4.2815, Train: 0.2643, Val: 0.3520, Test: 0.3510
Epoch: 15, Loss: 4.1557, Train: 0.2786, Val: 0.3560, Test: 0.3590
Epoch: 16, Loss: 4.0466, Train: 0.3000, Val: 0.3620, Test: 0.3710
Epoch: 17, Loss: 3.9902, Train: 0.3286, Val: 0.3680, Test: 0.3780
Epoch: 18, Loss: 3.8528, Train: 0.3286, Val: 0.3760, Test: 0.3840
Epoch: 19, Loss: 3.8029, Train: 0.3786, Val: 0.4060, Test: 0.4030
Epoch: 20, Loss: 4.1842, Train: 0.5714, Val: 0.4660, Test: 0.4830
Epoch: 21, Loss: 3.7825, Train: 0.6786, Val: 0.5620, Test: 0.5740
Epoch: 22, Loss: 3.6207, Train: 0.7929, Val: 0.6420, Test: 0.6640
Epoch: 23, Loss: 3.8814, Train: 0.8214, Val: 0.6500, Test: 0.7070
Epoch: 24, Loss: 3.3866, Train: 0.8214, Val: 0.6240, Test: 0.6610
Epoch: 25, Loss: 3.4112, Train: 0.8143, Val: 0.5920, Test: 0.6220
Epoch: 26, Loss: 3.5753, Train: 0.8071, Val: 0.5580, Test: 0.5970
Epoch: 27, Loss: 3.3999, Train: 0.7929, Val: 0.5420, Test: 0.5710
Epoch: 28, Loss: 3.2955, Train: 0.7929, Val: 0.5200, Test: 0.5510
Epoch: 29, Loss: 3.4580, Train: 0.8143, Val: 0.5380, Test: 0.5430
Epoch: 30, Loss: 3.6522, Train: 0.9000, Val: 0.5860, Test: 0.5870
Epoch: 31, Loss: 3.4496, Train: 0.9286, Val: 0.6500, Test: 0.6520
Epoch: 32, Loss: 3.2357, Train: 0.9429, Val: 0.6860, Test: 0.7010
Epoch: 33, Loss: 3.4620, Train: 0.9500, Val: 0.7240, Test: 0.7350
Epoch: 34, Loss: 3.2030, Train: 0.9571, Val: 0.7540, Test: 0.7560
Epoch: 35, Loss: 3.2614, Train: 0.9571, Val: 0.7660, Test: 0.7730
Epoch: 36, Loss: 3.3469, Train: 0.9714, Val: 0.7780, Test: 0.7930
Epoch: 37, Loss: 3.1051, Train: 0.9714, Val: 0.7840, Test: 0.8040
Epoch: 38, Loss: 3.2781, Train: 0.9714, Val: 0.7880, Test: 0.8190
Epoch: 39, Loss: 3.1290, Train: 0.9786, Val: 0.7860, Test: 0.8190
Epoch: 40, Loss: 3.2309, Train: 0.9786, Val: 0.7880, Test: 0.8250
Epoch: 41, Loss: 3.2143, Train: 0.9714, Val: 0.7920, Test: 0.8300
Epoch: 42, Loss: 3.0709, Train: 0.9714, Val: 0.7920, Test: 0.8350
Epoch: 43, Loss: 3.3038, Train: 0.9714, Val: 0.7880, Test: 0.8330
Epoch: 44, Loss: 3.0591, Train: 0.9786, Val: 0.7880, Test: 0.8340
Epoch: 45, Loss: 3.1127, Train: 0.9786, Val: 0.7840, Test: 0.8300
Epoch: 46, Loss: 3.0655, Train: 0.9786, Val: 0.7840, Test: 0.8300
Epoch: 47, Loss: 2.8858, Train: 0.9786, Val: 0.7880, Test: 0.8270
Epoch: 48, Loss: 2.5312, Train: 0.9786, Val: 0.7880, Test: 0.8230
Epoch: 49, Loss: 2.7357, Train: 0.9786, Val: 0.7940, Test: 0.8250
Epoch: 50, Loss: 2.8445, Train: 0.9786, Val: 0.7980, Test: 0.8260
Epoch: 51, Loss: 3.2137, Train: 0.9786, Val: 0.7980, Test: 0.8270
Epoch: 52, Loss: 2.9979, Train: 0.9857, Val: 0.7980, Test: 0.8270
Epoch: 53, Loss: 3.0877, Train: 0.9857, Val: 0.7940, Test: 0.8250
Epoch: 54, Loss: 2.9485, Train: 0.9857, Val: 0.7920, Test: 0.8220
Epoch: 55, Loss: 3.0005, Train: 0.9857, Val: 0.7920, Test: 0.8190
Epoch: 56, Loss: 2.5125, Train: 0.9857, Val: 0.7900, Test: 0.8190
Epoch: 57, Loss: 2.7525, Train: 0.9857, Val: 0.7820, Test: 0.8140
Epoch: 58, Loss: 2.8547, Train: 0.9857, Val: 0.7760, Test: 0.8100
Epoch: 59, Loss: 2.7302, Train: 0.9857, Val: 0.7720, Test: 0.8070
Epoch: 60, Loss: 2.5358, Train: 0.9857, Val: 0.7760, Test: 0.8120
Epoch: 61, Loss: 2.7940, Train: 0.9857, Val: 0.7800, Test: 0.8140
Epoch: 62, Loss: 2.5378, Train: 0.9857, Val: 0.7860, Test: 0.8180
Epoch: 63, Loss: 2.7667, Train: 0.9857, Val: 0.7920, Test: 0.8280
Epoch: 64, Loss: 2.8568, Train: 0.9857, Val: 0.7940, Test: 0.8270
Epoch: 65, Loss: 2.6124, Train: 0.9929, Val: 0.7980, Test: 0.8280
Epoch: 66, Loss: 2.8018, Train: 0.9929, Val: 0.7980, Test: 0.8260
Epoch: 67, Loss: 2.7170, Train: 0.9929, Val: 0.8000, Test: 0.8250
Epoch: 68, Loss: 3.0353, Train: 0.9929, Val: 0.8040, Test: 0.8250
Epoch: 69, Loss: 2.3788, Train: 1.0000, Val: 0.8020, Test: 0.8210
Epoch: 70, Loss: 2.4124, Train: 1.0000, Val: 0.8040, Test: 0.8180
Epoch: 71, Loss: 2.7284, Train: 1.0000, Val: 0.8000, Test: 0.8180
Epoch: 72, Loss: 2.4604, Train: 1.0000, Val: 0.8040, Test: 0.8160
Epoch: 73, Loss: 2.8657, Train: 1.0000, Val: 0.8020, Test: 0.8170
Epoch: 74, Loss: 2.6053, Train: 1.0000, Val: 0.8040, Test: 0.8160
Epoch: 75, Loss: 2.5016, Train: 1.0000, Val: 0.8040, Test: 0.8190
Epoch: 76, Loss: 2.9198, Train: 1.0000, Val: 0.8020, Test: 0.8170
Epoch: 77, Loss: 3.0073, Train: 1.0000, Val: 0.7980, Test: 0.8160
Epoch: 78, Loss: 2.5478, Train: 1.0000, Val: 0.7960, Test: 0.8160
Epoch: 79, Loss: 2.8567, Train: 1.0000, Val: 0.7940, Test: 0.8170
Epoch: 80, Loss: 2.6690, Train: 1.0000, Val: 0.7940, Test: 0.8110
Epoch: 81, Loss: 2.8653, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 82, Loss: 2.1433, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 83, Loss: 2.5122, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 84, Loss: 2.7034, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 85, Loss: 2.6084, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 86, Loss: 3.0737, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 87, Loss: 2.5153, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 88, Loss: 2.8578, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 89, Loss: 2.2070, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 90, Loss: 2.8049, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 91, Loss: 2.6533, Train: 1.0000, Val: 0.7880, Test: 0.8040
Epoch: 92, Loss: 2.3066, Train: 1.0000, Val: 0.7900, Test: 0.8040
Epoch: 93, Loss: 2.5345, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 94, Loss: 2.7713, Train: 1.0000, Val: 0.7940, Test: 0.8050
Epoch: 95, Loss: 2.5291, Train: 1.0000, Val: 0.8000, Test: 0.8050
Epoch: 96, Loss: 2.2983, Train: 1.0000, Val: 0.7980, Test: 0.8070
Epoch: 97, Loss: 2.5924, Train: 1.0000, Val: 0.7920, Test: 0.8110
Epoch: 98, Loss: 2.5167, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 99, Loss: 2.7212, Train: 1.0000, Val: 0.7920, Test: 0.8150
Epoch: 100, Loss: 2.4158, Train: 1.0000, Val: 0.7900, Test: 0.8150
Epoch: 101, Loss: 2.5434, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 102, Loss: 2.5640, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 103, Loss: 2.4788, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 104, Loss: 2.4436, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 105, Loss: 2.8693, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 106, Loss: 2.4075, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 107, Loss: 2.8534, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 108, Loss: 2.4683, Train: 1.0000, Val: 0.7720, Test: 0.8030
Epoch: 109, Loss: 2.6102, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 110, Loss: 2.2081, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 111, Loss: 2.5069, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 112, Loss: 2.6647, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 113, Loss: 2.6750, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 114, Loss: 2.4317, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 115, Loss: 2.6079, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 116, Loss: 2.4749, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 117, Loss: 2.3976, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 118, Loss: 2.5176, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 119, Loss: 2.0229, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 120, Loss: 2.5350, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 121, Loss: 2.6678, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 122, Loss: 2.4539, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 123, Loss: 2.6820, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 124, Loss: 2.8206, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 125, Loss: 2.8183, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 126, Loss: 2.9995, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 127, Loss: 2.4282, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 128, Loss: 2.7512, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 129, Loss: 2.6395, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 130, Loss: 2.6290, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 131, Loss: 2.6973, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 132, Loss: 2.6194, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 133, Loss: 2.1586, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 134, Loss: 2.5346, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 135, Loss: 2.5429, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 136, Loss: 2.2185, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 137, Loss: 2.6532, Train: 1.0000, Val: 0.7820, Test: 0.8110
Epoch: 138, Loss: 2.3621, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 139, Loss: 2.4866, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 140, Loss: 2.4390, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 141, Loss: 2.7154, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 142, Loss: 2.2128, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 143, Loss: 3.2430, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 144, Loss: 2.2096, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 145, Loss: 2.4701, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 146, Loss: 2.7826, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 147, Loss: 2.2493, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 148, Loss: 2.6591, Train: 1.0000, Val: 0.7800, Test: 0.8020
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 149, Loss: 2.5317, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 150, Loss: 2.5574, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 151, Loss: 2.6103, Train: 1.0000, Val: 0.7780, Test: 0.8030
Epoch: 152, Loss: 2.8222, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 153, Loss: 2.4002, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 154, Loss: 2.1180, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 155, Loss: 2.3012, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 156, Loss: 2.5015, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 157, Loss: 2.4778, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 158, Loss: 2.6778, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 159, Loss: 2.7818, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 160, Loss: 2.3398, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 161, Loss: 2.2976, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 162, Loss: 2.1387, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 163, Loss: 2.6731, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 164, Loss: 2.1151, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 165, Loss: 2.8261, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 166, Loss: 2.8956, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 167, Loss: 2.7317, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 168, Loss: 2.5515, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 169, Loss: 2.3697, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 170, Loss: 2.8149, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 171, Loss: 2.4703, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 172, Loss: 2.3218, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 173, Loss: 2.5844, Train: 1.0000, Val: 0.7800, Test: 0.8110
Epoch: 174, Loss: 2.5335, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 175, Loss: 2.7340, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 176, Loss: 2.5935, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 177, Loss: 2.6390, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 178, Loss: 2.1247, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 179, Loss: 2.8417, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 180, Loss: 2.2985, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 181, Loss: 2.7095, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 182, Loss: 2.1778, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 183, Loss: 2.9256, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 184, Loss: 2.2928, Train: 1.0000, Val: 0.7680, Test: 0.8000
Epoch: 185, Loss: 2.3001, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 186, Loss: 2.6189, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 187, Loss: 2.5621, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 188, Loss: 2.4678, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 189, Loss: 2.0424, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 190, Loss: 2.3146, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 191, Loss: 2.9136, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 192, Loss: 2.8699, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 193, Loss: 2.9408, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 194, Loss: 2.2222, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 195, Loss: 2.3068, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 196, Loss: 2.2865, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 197, Loss: 2.5292, Train: 1.0000, Val: 0.7680, Test: 0.8030
Epoch: 198, Loss: 2.5311, Train: 1.0000, Val: 0.7700, Test: 0.8030
Epoch: 199, Loss: 2.4213, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 200, Loss: 2.4156, Train: 1.0000, Val: 0.7720, Test: 0.8000
MAD:  0.1577
Best Test Accuracy: 0.8350, Val Accuracy: 0.7920, Train Accuracy: 0.9714
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8501, Train: 0.1000, Val: 0.1380, Test: 0.1500
Epoch: 2, Loss: 4.7863, Train: 0.2571, Val: 0.2780, Test: 0.3150
Epoch: 3, Loss: 4.7609, Train: 0.3071, Val: 0.3220, Test: 0.3480
Epoch: 4, Loss: 4.7246, Train: 0.3500, Val: 0.3440, Test: 0.3850
Epoch: 5, Loss: 4.6362, Train: 0.4643, Val: 0.3420, Test: 0.3970
Epoch: 6, Loss: 4.5624, Train: 0.5071, Val: 0.3400, Test: 0.4030
Epoch: 7, Loss: 4.5331, Train: 0.5214, Val: 0.3500, Test: 0.3930
Epoch: 8, Loss: 4.4180, Train: 0.5286, Val: 0.3540, Test: 0.3940
Epoch: 9, Loss: 4.3073, Train: 0.5500, Val: 0.3640, Test: 0.4120
Epoch: 10, Loss: 4.2578, Train: 0.5786, Val: 0.3940, Test: 0.4400
Epoch: 11, Loss: 4.3268, Train: 0.6000, Val: 0.4220, Test: 0.4630
Epoch: 12, Loss: 4.1399, Train: 0.6286, Val: 0.4480, Test: 0.4990
Epoch: 13, Loss: 4.0777, Train: 0.6429, Val: 0.4740, Test: 0.5230
Epoch: 14, Loss: 3.7393, Train: 0.6714, Val: 0.5200, Test: 0.5530
Epoch: 15, Loss: 3.8351, Train: 0.6929, Val: 0.5440, Test: 0.5740
Epoch: 16, Loss: 3.8781, Train: 0.7071, Val: 0.5540, Test: 0.5850
Epoch: 17, Loss: 3.8128, Train: 0.7643, Val: 0.5600, Test: 0.5970
Epoch: 18, Loss: 3.8870, Train: 0.8000, Val: 0.5880, Test: 0.6270
Epoch: 19, Loss: 3.3380, Train: 0.8643, Val: 0.6320, Test: 0.6640
Epoch: 20, Loss: 3.4159, Train: 0.8929, Val: 0.6680, Test: 0.7060
Epoch: 21, Loss: 3.5675, Train: 0.9357, Val: 0.7280, Test: 0.7440
Epoch: 22, Loss: 3.5788, Train: 0.9286, Val: 0.7360, Test: 0.7630
Epoch: 23, Loss: 3.5907, Train: 0.9429, Val: 0.7280, Test: 0.7620
Epoch: 24, Loss: 3.7392, Train: 0.9429, Val: 0.7280, Test: 0.7520
Epoch: 25, Loss: 3.3222, Train: 0.9429, Val: 0.7180, Test: 0.7510
Epoch: 26, Loss: 3.5086, Train: 0.9500, Val: 0.7120, Test: 0.7490
Epoch: 27, Loss: 3.3524, Train: 0.9500, Val: 0.7060, Test: 0.7470
Epoch: 28, Loss: 3.4639, Train: 0.9429, Val: 0.7020, Test: 0.7420
Epoch: 29, Loss: 3.1098, Train: 0.9500, Val: 0.7180, Test: 0.7460
Epoch: 30, Loss: 3.2751, Train: 0.9429, Val: 0.7280, Test: 0.7530
Epoch: 31, Loss: 3.2113, Train: 0.9429, Val: 0.7400, Test: 0.7700
Epoch: 32, Loss: 3.1162, Train: 0.9429, Val: 0.7460, Test: 0.7810
Epoch: 33, Loss: 3.1873, Train: 0.9357, Val: 0.7560, Test: 0.7870
Epoch: 34, Loss: 3.1563, Train: 0.9357, Val: 0.7620, Test: 0.7960
Epoch: 35, Loss: 3.4533, Train: 0.9571, Val: 0.7760, Test: 0.8020
Epoch: 36, Loss: 2.9467, Train: 0.9643, Val: 0.7880, Test: 0.8080
Epoch: 37, Loss: 2.7638, Train: 0.9714, Val: 0.7800, Test: 0.8080
Epoch: 38, Loss: 3.1800, Train: 0.9857, Val: 0.7820, Test: 0.8160
Epoch: 39, Loss: 3.1136, Train: 0.9857, Val: 0.7880, Test: 0.8250
Epoch: 40, Loss: 2.8596, Train: 0.9714, Val: 0.7840, Test: 0.8260
Epoch: 41, Loss: 2.9566, Train: 0.9786, Val: 0.7820, Test: 0.8240
Epoch: 42, Loss: 2.9048, Train: 0.9786, Val: 0.7860, Test: 0.8190
Epoch: 43, Loss: 3.1695, Train: 0.9786, Val: 0.7800, Test: 0.8160
Epoch: 44, Loss: 3.1644, Train: 0.9786, Val: 0.7760, Test: 0.8140
Epoch: 45, Loss: 2.6767, Train: 0.9786, Val: 0.7700, Test: 0.8080
Epoch: 46, Loss: 2.7061, Train: 0.9786, Val: 0.7700, Test: 0.8080
Epoch: 47, Loss: 2.8330, Train: 0.9786, Val: 0.7720, Test: 0.8070
Epoch: 48, Loss: 3.1838, Train: 0.9857, Val: 0.7760, Test: 0.8120
Epoch: 49, Loss: 3.1297, Train: 0.9857, Val: 0.7840, Test: 0.8110
Epoch: 50, Loss: 2.9452, Train: 0.9857, Val: 0.7780, Test: 0.8130
Epoch: 51, Loss: 2.6440, Train: 0.9857, Val: 0.7800, Test: 0.8170
Epoch: 52, Loss: 2.7828, Train: 0.9929, Val: 0.7820, Test: 0.8190
Epoch: 53, Loss: 2.8072, Train: 0.9929, Val: 0.7840, Test: 0.8190
Epoch: 54, Loss: 2.8106, Train: 0.9929, Val: 0.7900, Test: 0.8250
Epoch: 55, Loss: 3.0126, Train: 0.9929, Val: 0.7900, Test: 0.8240
Epoch: 56, Loss: 2.9880, Train: 1.0000, Val: 0.7920, Test: 0.8260
Epoch: 57, Loss: 2.7944, Train: 1.0000, Val: 0.7920, Test: 0.8260
Epoch: 58, Loss: 2.5026, Train: 1.0000, Val: 0.7900, Test: 0.8270
Epoch: 59, Loss: 2.5351, Train: 1.0000, Val: 0.7900, Test: 0.8250
Epoch: 60, Loss: 2.8036, Train: 1.0000, Val: 0.7920, Test: 0.8270
Epoch: 61, Loss: 2.9653, Train: 0.9929, Val: 0.7920, Test: 0.8290
Epoch: 62, Loss: 2.8570, Train: 1.0000, Val: 0.7940, Test: 0.8310
Epoch: 63, Loss: 2.7190, Train: 1.0000, Val: 0.7920, Test: 0.8290
Epoch: 64, Loss: 2.9954, Train: 1.0000, Val: 0.7900, Test: 0.8300
Epoch: 65, Loss: 2.5181, Train: 1.0000, Val: 0.7860, Test: 0.8300
Epoch: 66, Loss: 2.4074, Train: 0.9929, Val: 0.7880, Test: 0.8330
Epoch: 67, Loss: 2.5039, Train: 0.9929, Val: 0.7840, Test: 0.8260
Epoch: 68, Loss: 2.7810, Train: 0.9929, Val: 0.7800, Test: 0.8230
Epoch: 69, Loss: 2.6397, Train: 0.9929, Val: 0.7720, Test: 0.8210
Epoch: 70, Loss: 2.9340, Train: 0.9929, Val: 0.7680, Test: 0.8160
Epoch: 71, Loss: 2.9795, Train: 0.9929, Val: 0.7680, Test: 0.8130
Epoch: 72, Loss: 2.6678, Train: 1.0000, Val: 0.7640, Test: 0.8100
Epoch: 73, Loss: 2.4575, Train: 0.9929, Val: 0.7660, Test: 0.8080
Epoch: 74, Loss: 2.5843, Train: 0.9929, Val: 0.7660, Test: 0.8070
Epoch: 75, Loss: 3.1559, Train: 0.9929, Val: 0.7740, Test: 0.8080
Epoch: 76, Loss: 2.7610, Train: 0.9929, Val: 0.7760, Test: 0.8080
Epoch: 77, Loss: 2.6411, Train: 0.9929, Val: 0.7780, Test: 0.8020
Epoch: 78, Loss: 2.8291, Train: 0.9929, Val: 0.7760, Test: 0.8040
Epoch: 79, Loss: 2.3259, Train: 0.9929, Val: 0.7800, Test: 0.8040
Epoch: 80, Loss: 2.4703, Train: 0.9929, Val: 0.7800, Test: 0.8090
Epoch: 81, Loss: 2.6872, Train: 0.9929, Val: 0.7800, Test: 0.8100
Epoch: 82, Loss: 2.4125, Train: 0.9929, Val: 0.7820, Test: 0.8150
Epoch: 83, Loss: 2.7632, Train: 0.9929, Val: 0.7840, Test: 0.8220
Epoch: 84, Loss: 2.6153, Train: 1.0000, Val: 0.7820, Test: 0.8250
Epoch: 85, Loss: 2.6654, Train: 1.0000, Val: 0.7840, Test: 0.8250
Epoch: 86, Loss: 2.5997, Train: 1.0000, Val: 0.7880, Test: 0.8220
Epoch: 87, Loss: 2.4525, Train: 1.0000, Val: 0.7860, Test: 0.8230
Epoch: 88, Loss: 2.5492, Train: 1.0000, Val: 0.7820, Test: 0.8200
Epoch: 89, Loss: 2.5564, Train: 1.0000, Val: 0.7820, Test: 0.8180
Epoch: 90, Loss: 2.7456, Train: 1.0000, Val: 0.7800, Test: 0.8180
Epoch: 91, Loss: 2.5449, Train: 1.0000, Val: 0.7800, Test: 0.8160
Epoch: 92, Loss: 2.4263, Train: 1.0000, Val: 0.7780, Test: 0.8140
Epoch: 93, Loss: 2.6043, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 94, Loss: 2.2187, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 95, Loss: 2.5763, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 96, Loss: 2.5820, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 97, Loss: 2.7293, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 98, Loss: 2.9689, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 99, Loss: 2.4594, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 100, Loss: 2.2572, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 101, Loss: 2.4685, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 102, Loss: 2.9990, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 103, Loss: 2.3830, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 104, Loss: 2.3811, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 105, Loss: 2.6476, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 106, Loss: 2.3420, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 107, Loss: 2.6659, Train: 1.0000, Val: 0.7840, Test: 0.8120
Epoch: 108, Loss: 2.3573, Train: 1.0000, Val: 0.7840, Test: 0.8190
Epoch: 109, Loss: 2.5848, Train: 1.0000, Val: 0.7800, Test: 0.8210
Epoch: 110, Loss: 2.3723, Train: 1.0000, Val: 0.7800, Test: 0.8190
Epoch: 111, Loss: 2.5577, Train: 1.0000, Val: 0.7800, Test: 0.8150
Epoch: 112, Loss: 2.4641, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 113, Loss: 2.5799, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 114, Loss: 2.2876, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 115, Loss: 2.4887, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 116, Loss: 2.6150, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 117, Loss: 2.2224, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 118, Loss: 2.2154, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 119, Loss: 2.6279, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 120, Loss: 2.6516, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 121, Loss: 2.2022, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 122, Loss: 2.5173, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 123, Loss: 2.2240, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 124, Loss: 2.5061, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 125, Loss: 2.2204, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 126, Loss: 2.6286, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 127, Loss: 2.5478, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 128, Loss: 3.0261, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 129, Loss: 2.3610, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 130, Loss: 2.5464, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 131, Loss: 2.3817, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 132, Loss: 2.4189, Train: 1.0000, Val: 0.7860, Test: 0.8040
Epoch: 133, Loss: 2.0449, Train: 1.0000, Val: 0.7880, Test: 0.8050
Epoch: 134, Loss: 2.4799, Train: 1.0000, Val: 0.7840, Test: 0.8040
Epoch: 135, Loss: 2.4766, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 136, Loss: 2.4855, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 137, Loss: 2.4521, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 138, Loss: 2.5621, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 139, Loss: 2.2020, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 140, Loss: 2.5080, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 141, Loss: 2.7051, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 142, Loss: 2.9162, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 143, Loss: 2.5837, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 144, Loss: 2.3736, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 145, Loss: 2.4103, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 146, Loss: 2.1611, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 147, Loss: 2.4932, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 148, Loss: 2.6186, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 149, Loss: 2.6892, Train: 1.0000, Val: 0.7800, Test: 0.8120
Epoch: 150, Loss: 2.3064, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 151, Loss: 2.5090, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 152, Loss: 2.4519, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 153, Loss: 2.6068, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 154, Loss: 2.4743, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 155, Loss: 2.3951, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 156, Loss: 2.4273, Train: 1.0000, Val: 0.7700, Test: 0.8020
Epoch: 157, Loss: 2.8534, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 158, Loss: 2.6328, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 159, Loss: 2.0687, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 160, Loss: 2.2376, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 161, Loss: 2.3310, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 162, Loss: 2.1257, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 163, Loss: 2.4730, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 164, Loss: 2.4385, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 165, Loss: 2.2446, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 166, Loss: 2.4146, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 167, Loss: 2.5984, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 168, Loss: 2.6684, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 169, Loss: 2.1889, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 170, Loss: 2.2514, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 171, Loss: 2.5893, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 172, Loss: 2.3030, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 173, Loss: 2.5215, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 174, Loss: 2.7006, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 175, Loss: 2.5096, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 176, Loss: 2.5308, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 177, Loss: 2.6974, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 178, Loss: 2.7076, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 179, Loss: 2.4668, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 180, Loss: 2.7542, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 181, Loss: 2.2167, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 182, Loss: 2.4157, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 183, Loss: 2.2136, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 184, Loss: 2.5838, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 185, Loss: 2.0797, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 186, Loss: 2.4454, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 187, Loss: 2.5937, Train: 1.0000, Val: 0.7720, Test: 0.8040
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 188, Loss: 2.6990, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 189, Loss: 2.3026, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 190, Loss: 2.4973, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 191, Loss: 2.4916, Train: 1.0000, Val: 0.7660, Test: 0.8050
Epoch: 192, Loss: 2.3768, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 193, Loss: 2.2800, Train: 1.0000, Val: 0.7700, Test: 0.8080
Epoch: 194, Loss: 2.4322, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 195, Loss: 2.8618, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 196, Loss: 2.2677, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 197, Loss: 2.4847, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 198, Loss: 2.7613, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 199, Loss: 2.4935, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 200, Loss: 2.2046, Train: 1.0000, Val: 0.7700, Test: 0.7970
MAD:  0.5024
Best Test Accuracy: 0.8330, Val Accuracy: 0.7880, Train Accuracy: 0.9929
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8890, Train: 0.0000, Val: 0.0000, Test: 0.0010
Epoch: 2, Loss: 4.8567, Train: 0.0429, Val: 0.0020, Test: 0.0110
Epoch: 3, Loss: 4.8363, Train: 0.1429, Val: 0.0260, Test: 0.0350
Epoch: 4, Loss: 4.8208, Train: 0.3357, Val: 0.1540, Test: 0.1570
Epoch: 5, Loss: 4.8120, Train: 0.4857, Val: 0.2380, Test: 0.2270
Epoch: 6, Loss: 4.6914, Train: 0.5000, Val: 0.2800, Test: 0.2580
Epoch: 7, Loss: 4.6924, Train: 0.5357, Val: 0.2860, Test: 0.2850
Epoch: 8, Loss: 4.6557, Train: 0.5571, Val: 0.3000, Test: 0.2940
Epoch: 9, Loss: 4.5997, Train: 0.5929, Val: 0.3220, Test: 0.3090
Epoch: 10, Loss: 4.6811, Train: 0.5929, Val: 0.3320, Test: 0.3320
Epoch: 11, Loss: 4.4713, Train: 0.6000, Val: 0.3300, Test: 0.3380
Epoch: 12, Loss: 4.4265, Train: 0.6143, Val: 0.3120, Test: 0.3360
Epoch: 13, Loss: 4.4326, Train: 0.6071, Val: 0.3040, Test: 0.3380
Epoch: 14, Loss: 4.2044, Train: 0.6000, Val: 0.3000, Test: 0.3330
Epoch: 15, Loss: 3.9344, Train: 0.5929, Val: 0.3060, Test: 0.3250
Epoch: 16, Loss: 3.9284, Train: 0.5929, Val: 0.3020, Test: 0.3290
Epoch: 17, Loss: 4.0966, Train: 0.5857, Val: 0.2940, Test: 0.3220
Epoch: 18, Loss: 3.7229, Train: 0.6000, Val: 0.3180, Test: 0.3360
Epoch: 19, Loss: 3.5734, Train: 0.6071, Val: 0.3300, Test: 0.3460
Epoch: 20, Loss: 3.9147, Train: 0.6143, Val: 0.3440, Test: 0.3630
Epoch: 21, Loss: 3.7258, Train: 0.6500, Val: 0.3780, Test: 0.3870
Epoch: 22, Loss: 3.8314, Train: 0.6929, Val: 0.4040, Test: 0.4210
Epoch: 23, Loss: 3.7131, Train: 0.7714, Val: 0.4700, Test: 0.4810
Epoch: 24, Loss: 3.6423, Train: 0.8714, Val: 0.5400, Test: 0.5630
Epoch: 25, Loss: 3.6591, Train: 0.8929, Val: 0.6020, Test: 0.6580
Epoch: 26, Loss: 3.8414, Train: 0.9143, Val: 0.6700, Test: 0.6940
Epoch: 27, Loss: 3.5419, Train: 0.9143, Val: 0.6960, Test: 0.7250
Epoch: 28, Loss: 3.4771, Train: 0.9143, Val: 0.7280, Test: 0.7570
Epoch: 29, Loss: 3.4446, Train: 0.9143, Val: 0.7420, Test: 0.7700
Epoch: 30, Loss: 3.2963, Train: 0.9071, Val: 0.7400, Test: 0.7860
Epoch: 31, Loss: 3.6579, Train: 0.9286, Val: 0.7520, Test: 0.8040
Epoch: 32, Loss: 3.0823, Train: 0.9429, Val: 0.7680, Test: 0.8220
Epoch: 33, Loss: 3.5392, Train: 0.9500, Val: 0.7840, Test: 0.8220
Epoch: 34, Loss: 3.3613, Train: 0.9643, Val: 0.7820, Test: 0.8170
Epoch: 35, Loss: 3.3140, Train: 0.9643, Val: 0.7900, Test: 0.8060
Epoch: 36, Loss: 3.1149, Train: 0.9643, Val: 0.7820, Test: 0.8080
Epoch: 37, Loss: 3.3141, Train: 0.9643, Val: 0.7760, Test: 0.8000
Epoch: 38, Loss: 2.9191, Train: 0.9643, Val: 0.7680, Test: 0.7940
Epoch: 39, Loss: 3.0910, Train: 0.9714, Val: 0.7600, Test: 0.7900
Epoch: 40, Loss: 3.1024, Train: 0.9714, Val: 0.7580, Test: 0.7850
Epoch: 41, Loss: 2.9626, Train: 0.9786, Val: 0.7600, Test: 0.7810
Epoch: 42, Loss: 3.3154, Train: 0.9786, Val: 0.7640, Test: 0.7850
Epoch: 43, Loss: 3.2534, Train: 0.9786, Val: 0.7640, Test: 0.7810
Epoch: 44, Loss: 3.3963, Train: 0.9786, Val: 0.7660, Test: 0.7830
Epoch: 45, Loss: 2.9833, Train: 0.9786, Val: 0.7660, Test: 0.7810
Epoch: 46, Loss: 3.0958, Train: 0.9786, Val: 0.7700, Test: 0.7850
Epoch: 47, Loss: 2.7287, Train: 0.9929, Val: 0.7700, Test: 0.7870
Epoch: 48, Loss: 3.0891, Train: 0.9929, Val: 0.7680, Test: 0.7900
Epoch: 49, Loss: 2.9843, Train: 0.9929, Val: 0.7600, Test: 0.7890
Epoch: 50, Loss: 2.8426, Train: 0.9929, Val: 0.7600, Test: 0.7900
Epoch: 51, Loss: 2.5276, Train: 0.9929, Val: 0.7640, Test: 0.7890
Epoch: 52, Loss: 2.7255, Train: 0.9929, Val: 0.7700, Test: 0.7880
Epoch: 53, Loss: 2.8785, Train: 0.9929, Val: 0.7700, Test: 0.7920
Epoch: 54, Loss: 3.2517, Train: 0.9857, Val: 0.7720, Test: 0.7920
Epoch: 55, Loss: 2.5389, Train: 0.9857, Val: 0.7740, Test: 0.7930
Epoch: 56, Loss: 2.5300, Train: 0.9857, Val: 0.7720, Test: 0.7970
Epoch: 57, Loss: 3.0656, Train: 0.9857, Val: 0.7740, Test: 0.8010
Epoch: 58, Loss: 2.7080, Train: 0.9857, Val: 0.7720, Test: 0.8010
Epoch: 59, Loss: 3.0667, Train: 0.9857, Val: 0.7780, Test: 0.8010
Epoch: 60, Loss: 2.8474, Train: 0.9857, Val: 0.7780, Test: 0.8000
Epoch: 61, Loss: 2.7129, Train: 0.9857, Val: 0.7760, Test: 0.8010
Epoch: 62, Loss: 2.4446, Train: 0.9857, Val: 0.7740, Test: 0.8030
Epoch: 63, Loss: 2.7608, Train: 0.9857, Val: 0.7720, Test: 0.8060
Epoch: 64, Loss: 2.9075, Train: 0.9857, Val: 0.7740, Test: 0.8120
Epoch: 65, Loss: 2.7430, Train: 0.9857, Val: 0.7760, Test: 0.8080
Epoch: 66, Loss: 2.7217, Train: 0.9857, Val: 0.7680, Test: 0.8030
Epoch: 67, Loss: 2.7530, Train: 0.9857, Val: 0.7660, Test: 0.8030
Epoch: 68, Loss: 2.7152, Train: 0.9857, Val: 0.7700, Test: 0.8020
Epoch: 69, Loss: 2.8228, Train: 0.9857, Val: 0.7760, Test: 0.8020
Epoch: 70, Loss: 2.5187, Train: 0.9857, Val: 0.7740, Test: 0.8060
Epoch: 71, Loss: 2.6983, Train: 0.9857, Val: 0.7740, Test: 0.8080
Epoch: 72, Loss: 2.5865, Train: 0.9857, Val: 0.7740, Test: 0.8110
Epoch: 73, Loss: 2.6415, Train: 0.9929, Val: 0.7720, Test: 0.8120
Epoch: 74, Loss: 2.4990, Train: 1.0000, Val: 0.7720, Test: 0.8110
Epoch: 75, Loss: 2.9639, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 76, Loss: 2.6220, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 77, Loss: 2.1412, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 78, Loss: 2.3963, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 79, Loss: 2.7926, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 80, Loss: 2.3986, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 81, Loss: 2.3761, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 82, Loss: 2.4820, Train: 1.0000, Val: 0.7840, Test: 0.8030
Epoch: 83, Loss: 2.8008, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 84, Loss: 2.7192, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 85, Loss: 2.6698, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 86, Loss: 2.1033, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 87, Loss: 2.6287, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 88, Loss: 2.7872, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 89, Loss: 2.5669, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 90, Loss: 2.2245, Train: 1.0000, Val: 0.7880, Test: 0.8140
Epoch: 91, Loss: 2.6050, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 92, Loss: 2.4820, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 93, Loss: 2.6455, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 94, Loss: 2.5760, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 95, Loss: 2.7000, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 96, Loss: 2.3905, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 97, Loss: 2.4683, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 98, Loss: 2.3996, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 99, Loss: 2.6460, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 100, Loss: 2.4093, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 101, Loss: 2.5007, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 102, Loss: 2.6867, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 103, Loss: 2.6688, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 104, Loss: 2.3990, Train: 1.0000, Val: 0.7880, Test: 0.8080
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 105, Loss: 2.5382, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 106, Loss: 2.6668, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 107, Loss: 2.4411, Train: 1.0000, Val: 0.7920, Test: 0.8140
Epoch: 108, Loss: 2.3588, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 109, Loss: 2.2172, Train: 1.0000, Val: 0.7920, Test: 0.8130
Epoch: 110, Loss: 2.6127, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 111, Loss: 2.3637, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 112, Loss: 2.7028, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 113, Loss: 2.3715, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 114, Loss: 2.4502, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 115, Loss: 2.3857, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 116, Loss: 2.8042, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 117, Loss: 2.3817, Train: 1.0000, Val: 0.7840, Test: 0.8120
Epoch: 118, Loss: 2.4081, Train: 1.0000, Val: 0.7820, Test: 0.8140
Epoch: 119, Loss: 2.9311, Train: 1.0000, Val: 0.7820, Test: 0.8130
Epoch: 120, Loss: 2.7660, Train: 1.0000, Val: 0.7860, Test: 0.8130
Epoch: 121, Loss: 2.5895, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 122, Loss: 2.4245, Train: 1.0000, Val: 0.7900, Test: 0.8150
Epoch: 123, Loss: 2.5215, Train: 1.0000, Val: 0.7920, Test: 0.8120
Epoch: 124, Loss: 2.7981, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 125, Loss: 2.5706, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 126, Loss: 2.2132, Train: 1.0000, Val: 0.7880, Test: 0.8090
Epoch: 127, Loss: 2.4977, Train: 1.0000, Val: 0.7920, Test: 0.8000
Epoch: 128, Loss: 2.3368, Train: 1.0000, Val: 0.7940, Test: 0.7990
Epoch: 129, Loss: 2.5913, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 130, Loss: 2.4441, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 131, Loss: 2.8450, Train: 1.0000, Val: 0.7900, Test: 0.7890
Epoch: 132, Loss: 2.2259, Train: 1.0000, Val: 0.7900, Test: 0.7900
Epoch: 133, Loss: 2.2649, Train: 1.0000, Val: 0.7840, Test: 0.7890
Epoch: 134, Loss: 2.5367, Train: 1.0000, Val: 0.7840, Test: 0.7900
Epoch: 135, Loss: 2.5624, Train: 1.0000, Val: 0.7840, Test: 0.7900
Epoch: 136, Loss: 2.5044, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 137, Loss: 2.4333, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 138, Loss: 2.3811, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 139, Loss: 2.4593, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 140, Loss: 2.5032, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 141, Loss: 2.1141, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 142, Loss: 2.5350, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 143, Loss: 2.2501, Train: 1.0000, Val: 0.7780, Test: 0.8000
Epoch: 144, Loss: 2.6011, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 145, Loss: 2.6070, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 146, Loss: 2.0598, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 147, Loss: 2.2904, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 148, Loss: 2.8921, Train: 1.0000, Val: 0.7840, Test: 0.8120
Epoch: 149, Loss: 2.5647, Train: 1.0000, Val: 0.7860, Test: 0.8130
Epoch: 150, Loss: 2.4829, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 151, Loss: 2.6840, Train: 1.0000, Val: 0.7920, Test: 0.8120
Epoch: 152, Loss: 2.9490, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 153, Loss: 2.4918, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 154, Loss: 2.2308, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 155, Loss: 2.2650, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 156, Loss: 2.0083, Train: 1.0000, Val: 0.7860, Test: 0.8080
Epoch: 157, Loss: 2.3421, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 158, Loss: 2.7421, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 159, Loss: 2.7796, Train: 1.0000, Val: 0.7900, Test: 0.8080
Epoch: 160, Loss: 2.3935, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 161, Loss: 2.1971, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 162, Loss: 2.3298, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 163, Loss: 2.0347, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 164, Loss: 2.2519, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 165, Loss: 2.1744, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 166, Loss: 2.6689, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 167, Loss: 2.3537, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 168, Loss: 2.2443, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 169, Loss: 2.3894, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 170, Loss: 2.5435, Train: 1.0000, Val: 0.7860, Test: 0.8090
Epoch: 171, Loss: 2.5913, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 172, Loss: 2.5600, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 173, Loss: 2.4561, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 174, Loss: 2.5883, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 175, Loss: 2.4778, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 176, Loss: 2.3188, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 177, Loss: 2.1913, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 178, Loss: 2.5378, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 179, Loss: 2.8435, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 180, Loss: 2.3579, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 181, Loss: 2.3260, Train: 1.0000, Val: 0.7840, Test: 0.7930
Epoch: 182, Loss: 2.3709, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 183, Loss: 2.5285, Train: 1.0000, Val: 0.7860, Test: 0.7960
Epoch: 184, Loss: 2.6734, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 185, Loss: 2.6460, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 186, Loss: 2.6398, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 187, Loss: 2.6195, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 188, Loss: 2.2137, Train: 1.0000, Val: 0.7840, Test: 0.8060
Epoch: 189, Loss: 2.4927, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 190, Loss: 2.7068, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 191, Loss: 2.6622, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 192, Loss: 2.5325, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 193, Loss: 2.6613, Train: 1.0000, Val: 0.7860, Test: 0.8060
Epoch: 194, Loss: 2.2082, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 195, Loss: 2.6945, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 196, Loss: 2.3570, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 197, Loss: 2.4085, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 198, Loss: 2.4510, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 199, Loss: 2.2821, Train: 1.0000, Val: 0.7840, Test: 0.8100
Epoch: 200, Loss: 2.1727, Train: 1.0000, Val: 0.7760, Test: 0.8110
MAD:  0.0665
Best Test Accuracy: 0.8220, Val Accuracy: 0.7680, Train Accuracy: 0.9429
Training completed.
Average Test Accuracy:  0.8272222222222223 ± 0.0069406656385517474
Average MAD:  0.2692444444444444 ± 0.14874272427480734
