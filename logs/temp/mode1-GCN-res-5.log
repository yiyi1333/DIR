Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9101, Train: 0.0714, Val: 0.0400, Test: 0.0280
Epoch: 2, Loss: 4.7733, Train: 0.2357, Val: 0.1160, Test: 0.1010
Epoch: 3, Loss: 4.7791, Train: 0.4857, Val: 0.2220, Test: 0.2320
Epoch: 4, Loss: 4.7669, Train: 0.5857, Val: 0.3420, Test: 0.3550
Epoch: 5, Loss: 4.5740, Train: 0.7214, Val: 0.4360, Test: 0.4350
Epoch: 6, Loss: 4.5183, Train: 0.8071, Val: 0.5060, Test: 0.5250
Epoch: 7, Loss: 4.3858, Train: 0.8786, Val: 0.5720, Test: 0.5840
Epoch: 8, Loss: 4.6296, Train: 0.8929, Val: 0.6180, Test: 0.6140
Epoch: 9, Loss: 4.3025, Train: 0.9286, Val: 0.6500, Test: 0.6590
Epoch: 10, Loss: 4.4503, Train: 0.9286, Val: 0.6780, Test: 0.6680
Epoch: 11, Loss: 4.1759, Train: 0.9357, Val: 0.6960, Test: 0.6880
Epoch: 12, Loss: 4.2691, Train: 0.9500, Val: 0.7100, Test: 0.7030
Epoch: 13, Loss: 4.0464, Train: 0.9500, Val: 0.7140, Test: 0.7110
Epoch: 14, Loss: 3.8589, Train: 0.9500, Val: 0.7260, Test: 0.7210
Epoch: 15, Loss: 3.9207, Train: 0.9643, Val: 0.7400, Test: 0.7370
Epoch: 16, Loss: 3.9170, Train: 0.9714, Val: 0.7460, Test: 0.7510
Epoch: 17, Loss: 3.6823, Train: 0.9786, Val: 0.7420, Test: 0.7590
Epoch: 18, Loss: 3.6379, Train: 0.9786, Val: 0.7440, Test: 0.7660
Epoch: 19, Loss: 3.6015, Train: 0.9786, Val: 0.7460, Test: 0.7650
Epoch: 20, Loss: 3.7757, Train: 0.9857, Val: 0.7480, Test: 0.7720
Epoch: 21, Loss: 3.6734, Train: 0.9857, Val: 0.7520, Test: 0.7670
Epoch: 22, Loss: 3.6744, Train: 0.9857, Val: 0.7560, Test: 0.7640
Epoch: 23, Loss: 3.5432, Train: 0.9857, Val: 0.7560, Test: 0.7590
Epoch: 24, Loss: 3.4572, Train: 0.9857, Val: 0.7540, Test: 0.7590
Epoch: 25, Loss: 3.8133, Train: 0.9857, Val: 0.7540, Test: 0.7600
Epoch: 26, Loss: 3.5908, Train: 0.9857, Val: 0.7540, Test: 0.7610
Epoch: 27, Loss: 3.4502, Train: 0.9929, Val: 0.7580, Test: 0.7670
Epoch: 28, Loss: 3.7990, Train: 0.9929, Val: 0.7640, Test: 0.7710
Epoch: 29, Loss: 3.4135, Train: 0.9929, Val: 0.7620, Test: 0.7810
Epoch: 30, Loss: 3.2710, Train: 0.9929, Val: 0.7700, Test: 0.7840
Epoch: 31, Loss: 3.4161, Train: 0.9929, Val: 0.7780, Test: 0.7850
Epoch: 32, Loss: 3.3692, Train: 0.9929, Val: 0.7800, Test: 0.7960
Epoch: 33, Loss: 3.3249, Train: 0.9929, Val: 0.7780, Test: 0.7960
Epoch: 34, Loss: 3.3009, Train: 0.9929, Val: 0.7740, Test: 0.7990
Epoch: 35, Loss: 3.2448, Train: 0.9929, Val: 0.7760, Test: 0.8020
Epoch: 36, Loss: 3.6088, Train: 0.9929, Val: 0.7760, Test: 0.8050
Epoch: 37, Loss: 3.2721, Train: 0.9929, Val: 0.7840, Test: 0.8100
Epoch: 38, Loss: 3.1877, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 39, Loss: 3.3616, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 40, Loss: 3.4810, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 41, Loss: 2.8413, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 42, Loss: 2.9282, Train: 1.0000, Val: 0.7860, Test: 0.8110
Epoch: 43, Loss: 2.7773, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 44, Loss: 3.2061, Train: 1.0000, Val: 0.7940, Test: 0.8070
Epoch: 45, Loss: 3.0152, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 46, Loss: 3.2599, Train: 1.0000, Val: 0.7940, Test: 0.8080
Epoch: 47, Loss: 2.9106, Train: 1.0000, Val: 0.7940, Test: 0.8100
Epoch: 48, Loss: 3.0873, Train: 1.0000, Val: 0.7840, Test: 0.8140
Epoch: 49, Loss: 2.9001, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 50, Loss: 3.0774, Train: 1.0000, Val: 0.7800, Test: 0.8140
Epoch: 51, Loss: 2.9619, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 52, Loss: 3.0083, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 53, Loss: 2.6633, Train: 1.0000, Val: 0.7820, Test: 0.8080
Epoch: 54, Loss: 3.0246, Train: 1.0000, Val: 0.7860, Test: 0.8030
Epoch: 55, Loss: 2.9141, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 56, Loss: 2.9159, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 57, Loss: 2.9147, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 58, Loss: 2.9223, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 59, Loss: 3.1053, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 60, Loss: 2.9330, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 61, Loss: 3.1132, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 62, Loss: 2.6420, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 63, Loss: 2.5838, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 64, Loss: 2.8978, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 65, Loss: 2.8473, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 66, Loss: 2.5249, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 67, Loss: 3.1117, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 68, Loss: 2.9542, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 69, Loss: 2.9776, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 70, Loss: 2.8942, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 71, Loss: 2.9231, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 72, Loss: 2.9477, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 73, Loss: 2.5931, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 74, Loss: 2.8949, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 75, Loss: 2.4802, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 76, Loss: 2.6943, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 77, Loss: 2.6734, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 78, Loss: 2.6516, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 79, Loss: 2.5946, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 80, Loss: 2.6975, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 81, Loss: 2.6707, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 82, Loss: 2.8756, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 83, Loss: 2.6397, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 84, Loss: 2.6650, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 85, Loss: 2.7227, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 86, Loss: 2.6591, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 87, Loss: 2.6716, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 88, Loss: 2.6454, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 89, Loss: 2.4936, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 90, Loss: 2.7347, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 91, Loss: 2.6531, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 92, Loss: 2.5345, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 93, Loss: 2.5973, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 94, Loss: 2.4832, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 95, Loss: 2.6859, Train: 1.0000, Val: 0.7820, Test: 0.8090
Epoch: 96, Loss: 2.7411, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 97, Loss: 2.8778, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 98, Loss: 2.8757, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 99, Loss: 2.8548, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 100, Loss: 2.6710, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 101, Loss: 2.4556, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 102, Loss: 2.5371, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 103, Loss: 2.6466, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 104, Loss: 2.3012, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 105, Loss: 2.8040, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 106, Loss: 2.4507, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 107, Loss: 2.6951, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 108, Loss: 2.3793, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 109, Loss: 2.4888, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 110, Loss: 2.5745, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 111, Loss: 2.6416, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 112, Loss: 2.8665, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 113, Loss: 2.4747, Train: 1.0000, Val: 0.7680, Test: 0.7900
Epoch: 114, Loss: 2.4881, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 115, Loss: 2.6082, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 116, Loss: 2.7017, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 117, Loss: 2.5824, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 118, Loss: 2.4787, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 119, Loss: 2.7192, Train: 1.0000, Val: 0.7680, Test: 0.7910
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 120, Loss: 2.4562, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 121, Loss: 2.5920, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 122, Loss: 2.4009, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 123, Loss: 2.5526, Train: 1.0000, Val: 0.7800, Test: 0.7880
Epoch: 124, Loss: 2.3057, Train: 1.0000, Val: 0.7800, Test: 0.7880
Epoch: 125, Loss: 2.7126, Train: 1.0000, Val: 0.7800, Test: 0.7860
Epoch: 126, Loss: 2.6552, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 127, Loss: 2.7607, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 128, Loss: 2.8686, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 129, Loss: 2.5852, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 130, Loss: 2.6533, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 131, Loss: 2.6633, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 132, Loss: 2.3503, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 133, Loss: 2.7838, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 134, Loss: 2.2799, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 135, Loss: 2.5876, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 136, Loss: 2.8038, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 137, Loss: 2.5001, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 138, Loss: 2.2595, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 139, Loss: 2.3112, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 140, Loss: 2.7395, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 141, Loss: 2.6856, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 142, Loss: 2.4830, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 143, Loss: 2.6696, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 144, Loss: 2.7225, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 145, Loss: 2.3922, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 146, Loss: 2.5937, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 147, Loss: 2.7826, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 148, Loss: 2.6551, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 149, Loss: 2.0846, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 150, Loss: 2.6821, Train: 1.0000, Val: 0.7600, Test: 0.7860
Epoch: 151, Loss: 2.6538, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 152, Loss: 2.6952, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 153, Loss: 2.5572, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 154, Loss: 2.6230, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 155, Loss: 2.4589, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 156, Loss: 2.5389, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 157, Loss: 2.1840, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 158, Loss: 2.0518, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 159, Loss: 2.3646, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 160, Loss: 2.7534, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 161, Loss: 2.7794, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 162, Loss: 2.5120, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 163, Loss: 2.5928, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 164, Loss: 2.7251, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 165, Loss: 2.7775, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 166, Loss: 2.8828, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 167, Loss: 2.3562, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 168, Loss: 2.6400, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 169, Loss: 2.6375, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 170, Loss: 2.7578, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 171, Loss: 2.2146, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 172, Loss: 2.3271, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 173, Loss: 2.7875, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 174, Loss: 2.3009, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 175, Loss: 2.8149, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 176, Loss: 2.3050, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 177, Loss: 2.7360, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 178, Loss: 2.6064, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 179, Loss: 2.5987, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 180, Loss: 2.5819, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 181, Loss: 2.3300, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 182, Loss: 2.4841, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 183, Loss: 2.7495, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 184, Loss: 2.4825, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 185, Loss: 2.6327, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 186, Loss: 1.9953, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 187, Loss: 2.2400, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 188, Loss: 2.9672, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 189, Loss: 2.4037, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 190, Loss: 2.2472, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 191, Loss: 2.9345, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 192, Loss: 2.7822, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 193, Loss: 2.7036, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 194, Loss: 2.6906, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 195, Loss: 2.4567, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 196, Loss: 2.4358, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 197, Loss: 2.2523, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 198, Loss: 2.6198, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 199, Loss: 2.6689, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 200, Loss: 2.4815, Train: 1.0000, Val: 0.7680, Test: 0.7860
MAD:  0.3141
Best Test Accuracy: 0.8140, Val Accuracy: 0.7840, Train Accuracy: 1.0000
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9358, Train: 0.0857, Val: 0.0480, Test: 0.0320
Epoch: 2, Loss: 4.8561, Train: 0.2357, Val: 0.1420, Test: 0.1030
Epoch: 3, Loss: 4.7580, Train: 0.3357, Val: 0.1960, Test: 0.1670
Epoch: 4, Loss: 4.7029, Train: 0.4286, Val: 0.2320, Test: 0.2100
Epoch: 5, Loss: 4.7277, Train: 0.5071, Val: 0.2640, Test: 0.2640
Epoch: 6, Loss: 4.5924, Train: 0.6286, Val: 0.3000, Test: 0.3160
Epoch: 7, Loss: 4.4481, Train: 0.7143, Val: 0.3740, Test: 0.3760
Epoch: 8, Loss: 4.4510, Train: 0.7786, Val: 0.4260, Test: 0.4320
Epoch: 9, Loss: 4.4024, Train: 0.8357, Val: 0.4860, Test: 0.5030
Epoch: 10, Loss: 4.2806, Train: 0.8500, Val: 0.5140, Test: 0.5600
Epoch: 11, Loss: 4.2278, Train: 0.8643, Val: 0.5540, Test: 0.5870
Epoch: 12, Loss: 4.3302, Train: 0.8857, Val: 0.5860, Test: 0.6020
Epoch: 13, Loss: 4.0798, Train: 0.8857, Val: 0.5860, Test: 0.6250
Epoch: 14, Loss: 3.8889, Train: 0.9000, Val: 0.5960, Test: 0.6130
Epoch: 15, Loss: 4.0338, Train: 0.9071, Val: 0.6120, Test: 0.6190
Epoch: 16, Loss: 3.8539, Train: 0.9143, Val: 0.6340, Test: 0.6410
Epoch: 17, Loss: 4.0464, Train: 0.9143, Val: 0.6400, Test: 0.6470
Epoch: 18, Loss: 3.8608, Train: 0.9143, Val: 0.6560, Test: 0.6690
Epoch: 19, Loss: 4.0394, Train: 0.9214, Val: 0.6780, Test: 0.6830
Epoch: 20, Loss: 3.6289, Train: 0.9500, Val: 0.6900, Test: 0.7140
Epoch: 21, Loss: 3.7004, Train: 0.9500, Val: 0.7080, Test: 0.7310
Epoch: 22, Loss: 3.8617, Train: 0.9643, Val: 0.7160, Test: 0.7490
Epoch: 23, Loss: 3.5071, Train: 0.9714, Val: 0.7400, Test: 0.7620
Epoch: 24, Loss: 3.5398, Train: 0.9786, Val: 0.7500, Test: 0.7670
Epoch: 25, Loss: 3.8161, Train: 0.9929, Val: 0.7560, Test: 0.7610
Epoch: 26, Loss: 3.9057, Train: 0.9929, Val: 0.7620, Test: 0.7610
Epoch: 27, Loss: 3.4941, Train: 0.9929, Val: 0.7540, Test: 0.7700
Epoch: 28, Loss: 3.3263, Train: 0.9929, Val: 0.7600, Test: 0.7750
Epoch: 29, Loss: 3.7828, Train: 0.9929, Val: 0.7600, Test: 0.7690
Epoch: 30, Loss: 3.5300, Train: 0.9929, Val: 0.7580, Test: 0.7670
Epoch: 31, Loss: 3.3394, Train: 0.9929, Val: 0.7620, Test: 0.7690
Epoch: 32, Loss: 3.6487, Train: 0.9929, Val: 0.7660, Test: 0.7740
Epoch: 33, Loss: 3.3049, Train: 0.9929, Val: 0.7660, Test: 0.7820
Epoch: 34, Loss: 3.2170, Train: 0.9929, Val: 0.7660, Test: 0.7890
Epoch: 35, Loss: 3.4560, Train: 0.9929, Val: 0.7660, Test: 0.7950
Epoch: 36, Loss: 3.0615, Train: 1.0000, Val: 0.7620, Test: 0.7970
Epoch: 37, Loss: 3.4182, Train: 1.0000, Val: 0.7620, Test: 0.8040
Epoch: 38, Loss: 3.1693, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 39, Loss: 3.1599, Train: 1.0000, Val: 0.7700, Test: 0.8130
Epoch: 40, Loss: 2.8810, Train: 1.0000, Val: 0.7740, Test: 0.8170
Epoch: 41, Loss: 3.0967, Train: 1.0000, Val: 0.7720, Test: 0.8150
Epoch: 42, Loss: 3.3717, Train: 1.0000, Val: 0.7720, Test: 0.8150
Epoch: 43, Loss: 3.1778, Train: 1.0000, Val: 0.7740, Test: 0.8140
Epoch: 44, Loss: 3.3148, Train: 1.0000, Val: 0.7740, Test: 0.8140
Epoch: 45, Loss: 3.1243, Train: 1.0000, Val: 0.7760, Test: 0.8120
Epoch: 46, Loss: 3.4283, Train: 1.0000, Val: 0.7800, Test: 0.8120
Epoch: 47, Loss: 2.9122, Train: 1.0000, Val: 0.7860, Test: 0.8150
Epoch: 48, Loss: 3.1274, Train: 1.0000, Val: 0.7860, Test: 0.8160
Epoch: 49, Loss: 3.1080, Train: 1.0000, Val: 0.7820, Test: 0.8170
Epoch: 50, Loss: 3.0517, Train: 1.0000, Val: 0.7800, Test: 0.8170
Epoch: 51, Loss: 2.7790, Train: 1.0000, Val: 0.7760, Test: 0.8120
Epoch: 52, Loss: 3.2232, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 53, Loss: 3.3030, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 54, Loss: 3.4345, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 55, Loss: 3.2304, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 56, Loss: 3.1309, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 57, Loss: 3.2257, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 58, Loss: 3.1159, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 59, Loss: 2.7833, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 60, Loss: 2.9194, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 61, Loss: 2.8266, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 62, Loss: 2.8539, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 63, Loss: 2.5451, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 64, Loss: 2.6860, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 65, Loss: 2.3903, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 66, Loss: 2.6607, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 67, Loss: 2.8792, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 68, Loss: 2.8791, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 69, Loss: 3.1691, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 70, Loss: 3.0627, Train: 1.0000, Val: 0.7740, Test: 0.8100
Epoch: 71, Loss: 2.8689, Train: 1.0000, Val: 0.7740, Test: 0.8120
Epoch: 72, Loss: 2.6160, Train: 1.0000, Val: 0.7720, Test: 0.8150
Epoch: 73, Loss: 2.9630, Train: 1.0000, Val: 0.7720, Test: 0.8170
Epoch: 74, Loss: 3.0867, Train: 1.0000, Val: 0.7720, Test: 0.8180
Epoch: 75, Loss: 2.9313, Train: 1.0000, Val: 0.7700, Test: 0.8160
Epoch: 76, Loss: 3.1726, Train: 1.0000, Val: 0.7700, Test: 0.8140
Epoch: 77, Loss: 2.8058, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 78, Loss: 2.9575, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 79, Loss: 2.6981, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 80, Loss: 3.2578, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 81, Loss: 2.7213, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 82, Loss: 2.8185, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 83, Loss: 2.7898, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 84, Loss: 2.7099, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 85, Loss: 2.8536, Train: 1.0000, Val: 0.7800, Test: 0.8050
Epoch: 86, Loss: 2.6620, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 87, Loss: 2.5982, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 88, Loss: 2.7586, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 89, Loss: 3.0792, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 90, Loss: 2.8180, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 91, Loss: 2.4714, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 92, Loss: 2.8268, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 93, Loss: 2.5284, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 94, Loss: 2.6770, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 95, Loss: 2.7466, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 96, Loss: 2.5236, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 97, Loss: 2.8052, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 98, Loss: 2.6787, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 99, Loss: 3.0795, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 100, Loss: 2.6997, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 101, Loss: 2.6932, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 102, Loss: 2.4606, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 103, Loss: 2.6713, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 104, Loss: 2.7745, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 105, Loss: 2.3413, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 106, Loss: 2.8689, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 107, Loss: 2.6150, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 108, Loss: 2.5668, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 109, Loss: 3.0842, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 110, Loss: 2.6190, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 111, Loss: 2.6760, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 112, Loss: 2.4980, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 113, Loss: 2.8580, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 114, Loss: 2.5621, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 115, Loss: 2.4950, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 116, Loss: 2.6214, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 117, Loss: 2.5991, Train: 1.0000, Val: 0.7720, Test: 0.8090
Epoch: 118, Loss: 2.9466, Train: 1.0000, Val: 0.7720, Test: 0.8080
Epoch: 119, Loss: 2.5108, Train: 1.0000, Val: 0.7700, Test: 0.8080
Epoch: 120, Loss: 2.4475, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 121, Loss: 2.7681, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 122, Loss: 2.5789, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 123, Loss: 2.1083, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 124, Loss: 2.6285, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 125, Loss: 2.3360, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 126, Loss: 2.5145, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 127, Loss: 2.2543, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 128, Loss: 2.8402, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 129, Loss: 2.3976, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 130, Loss: 2.7187, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 131, Loss: 2.4945, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 132, Loss: 2.7638, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 133, Loss: 3.0254, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 134, Loss: 2.5997, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 135, Loss: 2.5999, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 136, Loss: 2.7044, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 137, Loss: 2.5539, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 138, Loss: 2.0631, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 139, Loss: 2.6488, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 140, Loss: 2.4609, Train: 1.0000, Val: 0.7900, Test: 0.8070
Epoch: 141, Loss: 2.1329, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 142, Loss: 2.4098, Train: 1.0000, Val: 0.7880, Test: 0.8070
Epoch: 143, Loss: 2.6034, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 144, Loss: 2.5649, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 145, Loss: 2.4897, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 146, Loss: 2.8405, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 147, Loss: 2.8731, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 148, Loss: 3.2316, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 149, Loss: 2.3416, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 150, Loss: 2.7148, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 151, Loss: 2.5228, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 152, Loss: 2.8344, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 153, Loss: 2.4686, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 154, Loss: 2.6996, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 155, Loss: 3.1797, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 156, Loss: 2.6682, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 157, Loss: 2.5958, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 158, Loss: 2.8351, Train: 1.0000, Val: 0.7580, Test: 0.7930
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 159, Loss: 2.7798, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 160, Loss: 2.6502, Train: 1.0000, Val: 0.7640, Test: 0.7970
Epoch: 161, Loss: 2.5475, Train: 1.0000, Val: 0.7680, Test: 0.7990
Epoch: 162, Loss: 2.4533, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 163, Loss: 2.6179, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 164, Loss: 2.6176, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 165, Loss: 2.9429, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 166, Loss: 2.5715, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 167, Loss: 3.0371, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 168, Loss: 2.6540, Train: 1.0000, Val: 0.7740, Test: 0.8010
Epoch: 169, Loss: 2.6408, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 170, Loss: 2.3843, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 171, Loss: 2.5989, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 172, Loss: 2.1922, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 173, Loss: 2.5201, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 174, Loss: 2.4347, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 175, Loss: 2.3081, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 176, Loss: 2.6817, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 177, Loss: 2.5987, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 178, Loss: 2.3619, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 179, Loss: 2.5749, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 180, Loss: 2.5590, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 181, Loss: 2.5906, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 182, Loss: 2.3891, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 183, Loss: 2.4071, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 184, Loss: 2.7623, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 185, Loss: 2.5174, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 186, Loss: 2.4638, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 187, Loss: 2.4216, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 188, Loss: 2.9299, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 189, Loss: 2.7164, Train: 1.0000, Val: 0.7600, Test: 0.7940
Epoch: 190, Loss: 2.1429, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 191, Loss: 2.3880, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 192, Loss: 2.7135, Train: 1.0000, Val: 0.7640, Test: 0.7950
Epoch: 193, Loss: 2.8257, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 194, Loss: 2.5236, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 195, Loss: 2.1818, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 196, Loss: 2.4234, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 197, Loss: 2.5937, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 198, Loss: 2.6334, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 199, Loss: 2.7583, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 200, Loss: 2.3205, Train: 1.0000, Val: 0.7680, Test: 0.7920
MAD:  0.3507
Best Test Accuracy: 0.8180, Val Accuracy: 0.7720, Train Accuracy: 1.0000
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9237, Train: 0.0429, Val: 0.0220, Test: 0.0300
Epoch: 2, Loss: 4.8891, Train: 0.1214, Val: 0.0660, Test: 0.0790
Epoch: 3, Loss: 4.7969, Train: 0.2214, Val: 0.1560, Test: 0.1580
Epoch: 4, Loss: 4.6672, Train: 0.4214, Val: 0.2540, Test: 0.2680
Epoch: 5, Loss: 4.6641, Train: 0.5786, Val: 0.3360, Test: 0.3540
Epoch: 6, Loss: 4.6197, Train: 0.6500, Val: 0.3900, Test: 0.4170
Epoch: 7, Loss: 4.4729, Train: 0.7357, Val: 0.4740, Test: 0.4690
Epoch: 8, Loss: 4.3670, Train: 0.7929, Val: 0.5100, Test: 0.5080
Epoch: 9, Loss: 4.6523, Train: 0.8429, Val: 0.5540, Test: 0.5340
Epoch: 10, Loss: 4.3074, Train: 0.8571, Val: 0.5640, Test: 0.5530
Epoch: 11, Loss: 4.1883, Train: 0.9214, Val: 0.5860, Test: 0.5830
Epoch: 12, Loss: 4.0697, Train: 0.9357, Val: 0.6100, Test: 0.5950
Epoch: 13, Loss: 4.0827, Train: 0.9429, Val: 0.6360, Test: 0.6230
Epoch: 14, Loss: 3.9293, Train: 0.9714, Val: 0.6320, Test: 0.6410
Epoch: 15, Loss: 4.0599, Train: 0.9643, Val: 0.6180, Test: 0.6520
Epoch: 16, Loss: 3.8940, Train: 0.9786, Val: 0.6360, Test: 0.6610
Epoch: 17, Loss: 4.0448, Train: 0.9786, Val: 0.6420, Test: 0.6660
Epoch: 18, Loss: 3.8599, Train: 0.9857, Val: 0.6520, Test: 0.6750
Epoch: 19, Loss: 3.9569, Train: 0.9857, Val: 0.6700, Test: 0.6840
Epoch: 20, Loss: 3.7533, Train: 0.9929, Val: 0.6800, Test: 0.6940
Epoch: 21, Loss: 3.7159, Train: 0.9929, Val: 0.6860, Test: 0.7040
Epoch: 22, Loss: 3.7629, Train: 0.9929, Val: 0.6880, Test: 0.7120
Epoch: 23, Loss: 3.8562, Train: 0.9929, Val: 0.6920, Test: 0.7170
Epoch: 24, Loss: 3.6733, Train: 1.0000, Val: 0.7020, Test: 0.7250
Epoch: 25, Loss: 3.4774, Train: 1.0000, Val: 0.7100, Test: 0.7420
Epoch: 26, Loss: 3.7595, Train: 1.0000, Val: 0.7160, Test: 0.7500
Epoch: 27, Loss: 3.6416, Train: 1.0000, Val: 0.7340, Test: 0.7600
Epoch: 28, Loss: 3.6289, Train: 1.0000, Val: 0.7480, Test: 0.7740
Epoch: 29, Loss: 3.5440, Train: 1.0000, Val: 0.7520, Test: 0.7820
Epoch: 30, Loss: 3.6198, Train: 1.0000, Val: 0.7600, Test: 0.7860
Epoch: 31, Loss: 3.5202, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 32, Loss: 3.2713, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 33, Loss: 3.2738, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 34, Loss: 3.7162, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 35, Loss: 3.6268, Train: 1.0000, Val: 0.7720, Test: 0.7860
Epoch: 36, Loss: 3.4162, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 37, Loss: 3.3544, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 38, Loss: 3.2331, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 39, Loss: 3.2979, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 40, Loss: 3.2194, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 41, Loss: 3.3093, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 42, Loss: 3.2600, Train: 1.0000, Val: 0.7860, Test: 0.8070
Epoch: 43, Loss: 3.3215, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 44, Loss: 2.8635, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 45, Loss: 3.3061, Train: 1.0000, Val: 0.7920, Test: 0.8080
Epoch: 46, Loss: 3.1067, Train: 1.0000, Val: 0.7920, Test: 0.8100
Epoch: 47, Loss: 3.4027, Train: 1.0000, Val: 0.7920, Test: 0.8090
Epoch: 48, Loss: 3.0423, Train: 1.0000, Val: 0.7920, Test: 0.8060
Epoch: 49, Loss: 3.1603, Train: 1.0000, Val: 0.7940, Test: 0.8040
Epoch: 50, Loss: 2.9678, Train: 1.0000, Val: 0.7900, Test: 0.8110
Epoch: 51, Loss: 3.0240, Train: 1.0000, Val: 0.7900, Test: 0.8100
Epoch: 52, Loss: 3.2015, Train: 1.0000, Val: 0.7900, Test: 0.8090
Epoch: 53, Loss: 3.2229, Train: 1.0000, Val: 0.7880, Test: 0.8050
Epoch: 54, Loss: 2.9788, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 55, Loss: 3.3108, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 56, Loss: 2.8628, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 57, Loss: 2.9144, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 58, Loss: 3.1134, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 59, Loss: 2.7593, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 60, Loss: 2.9032, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 61, Loss: 2.9031, Train: 1.0000, Val: 0.7860, Test: 0.8100
Epoch: 62, Loss: 2.5953, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 63, Loss: 2.8419, Train: 1.0000, Val: 0.7980, Test: 0.8150
Epoch: 64, Loss: 2.7905, Train: 1.0000, Val: 0.7980, Test: 0.8140
Epoch: 65, Loss: 2.7954, Train: 1.0000, Val: 0.7980, Test: 0.8160
Epoch: 66, Loss: 2.9018, Train: 1.0000, Val: 0.7980, Test: 0.8190
Epoch: 67, Loss: 3.0543, Train: 1.0000, Val: 0.7980, Test: 0.8210
Epoch: 68, Loss: 2.8787, Train: 1.0000, Val: 0.7980, Test: 0.8210
Epoch: 69, Loss: 3.2283, Train: 1.0000, Val: 0.7980, Test: 0.8220
Epoch: 70, Loss: 2.6686, Train: 1.0000, Val: 0.8020, Test: 0.8230
Epoch: 71, Loss: 2.7644, Train: 1.0000, Val: 0.8040, Test: 0.8210
Epoch: 72, Loss: 2.8524, Train: 1.0000, Val: 0.8020, Test: 0.8230
Epoch: 73, Loss: 2.8795, Train: 1.0000, Val: 0.7960, Test: 0.8190
Epoch: 74, Loss: 2.7633, Train: 1.0000, Val: 0.7920, Test: 0.8190
Epoch: 75, Loss: 2.7265, Train: 1.0000, Val: 0.7960, Test: 0.8180
Epoch: 76, Loss: 2.8705, Train: 1.0000, Val: 0.7900, Test: 0.8170
Epoch: 77, Loss: 2.9298, Train: 1.0000, Val: 0.7920, Test: 0.8190
Epoch: 78, Loss: 2.7900, Train: 1.0000, Val: 0.7960, Test: 0.8200
Epoch: 79, Loss: 3.0429, Train: 1.0000, Val: 0.7920, Test: 0.8170
Epoch: 80, Loss: 2.6822, Train: 1.0000, Val: 0.7920, Test: 0.8180
Epoch: 81, Loss: 2.6688, Train: 1.0000, Val: 0.7860, Test: 0.8160
Epoch: 82, Loss: 3.1420, Train: 1.0000, Val: 0.7880, Test: 0.8170
Epoch: 83, Loss: 2.7492, Train: 1.0000, Val: 0.7880, Test: 0.8160
Epoch: 84, Loss: 2.7721, Train: 1.0000, Val: 0.7800, Test: 0.8150
Epoch: 85, Loss: 2.8192, Train: 1.0000, Val: 0.7820, Test: 0.8150
Epoch: 86, Loss: 3.3724, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 87, Loss: 3.0609, Train: 1.0000, Val: 0.7820, Test: 0.8150
Epoch: 88, Loss: 3.0744, Train: 1.0000, Val: 0.7840, Test: 0.8130
Epoch: 89, Loss: 2.5923, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 90, Loss: 2.4729, Train: 1.0000, Val: 0.7860, Test: 0.8140
Epoch: 91, Loss: 2.7558, Train: 1.0000, Val: 0.7880, Test: 0.8100
Epoch: 92, Loss: 2.5807, Train: 1.0000, Val: 0.7880, Test: 0.8080
Epoch: 93, Loss: 2.7223, Train: 1.0000, Val: 0.7900, Test: 0.8130
Epoch: 94, Loss: 2.6700, Train: 1.0000, Val: 0.7920, Test: 0.8140
Epoch: 95, Loss: 2.8409, Train: 1.0000, Val: 0.7940, Test: 0.8140
Epoch: 96, Loss: 2.7931, Train: 1.0000, Val: 0.7880, Test: 0.8130
Epoch: 97, Loss: 2.7286, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 98, Loss: 2.8359, Train: 1.0000, Val: 0.7780, Test: 0.8110
Epoch: 99, Loss: 2.5875, Train: 1.0000, Val: 0.7800, Test: 0.8140
Epoch: 100, Loss: 3.0231, Train: 1.0000, Val: 0.7780, Test: 0.8120
Epoch: 101, Loss: 2.5702, Train: 1.0000, Val: 0.7760, Test: 0.8110
Epoch: 102, Loss: 2.5705, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 103, Loss: 2.7371, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 104, Loss: 2.7967, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 105, Loss: 3.0097, Train: 1.0000, Val: 0.7760, Test: 0.8070
Epoch: 106, Loss: 2.6654, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 107, Loss: 2.7718, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 108, Loss: 2.7963, Train: 1.0000, Val: 0.7840, Test: 0.8120
Epoch: 109, Loss: 2.6896, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 110, Loss: 2.3873, Train: 1.0000, Val: 0.7840, Test: 0.8110
Epoch: 111, Loss: 2.6979, Train: 1.0000, Val: 0.7820, Test: 0.8120
Epoch: 112, Loss: 2.3613, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 113, Loss: 2.9551, Train: 1.0000, Val: 0.7880, Test: 0.8120
Epoch: 114, Loss: 2.8053, Train: 1.0000, Val: 0.7900, Test: 0.8120
Epoch: 115, Loss: 2.5542, Train: 1.0000, Val: 0.7880, Test: 0.8110
Epoch: 116, Loss: 2.5789, Train: 1.0000, Val: 0.7860, Test: 0.8120
Epoch: 117, Loss: 2.8641, Train: 1.0000, Val: 0.7820, Test: 0.8100
Epoch: 118, Loss: 2.5000, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 119, Loss: 2.3304, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 120, Loss: 2.2388, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 121, Loss: 2.5902, Train: 1.0000, Val: 0.7780, Test: 0.8080
Epoch: 122, Loss: 2.6920, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 123, Loss: 2.6916, Train: 1.0000, Val: 0.7800, Test: 0.8080
Epoch: 124, Loss: 2.7921, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 125, Loss: 2.8264, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 126, Loss: 2.9070, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 127, Loss: 2.4256, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 128, Loss: 2.4766, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 129, Loss: 2.9716, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 130, Loss: 2.6229, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 131, Loss: 2.5654, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 132, Loss: 2.7532, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 133, Loss: 2.3179, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 134, Loss: 2.6651, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 135, Loss: 2.6721, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 136, Loss: 2.6843, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 137, Loss: 2.7016, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 138, Loss: 2.7049, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 139, Loss: 2.5868, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 140, Loss: 2.4498, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 141, Loss: 2.7144, Train: 1.0000, Val: 0.7760, Test: 0.8030
Epoch: 142, Loss: 2.7157, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 143, Loss: 2.6011, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 144, Loss: 2.7606, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 145, Loss: 2.6404, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 146, Loss: 2.1046, Train: 1.0000, Val: 0.7740, Test: 0.8110
Epoch: 147, Loss: 2.6736, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 148, Loss: 2.2896, Train: 1.0000, Val: 0.7740, Test: 0.8090
Epoch: 149, Loss: 2.5788, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 150, Loss: 2.5714, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 151, Loss: 2.5133, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 152, Loss: 2.8912, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 153, Loss: 2.3347, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 154, Loss: 2.8366, Train: 1.0000, Val: 0.7700, Test: 0.7990
Epoch: 155, Loss: 3.0393, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 156, Loss: 2.0698, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 157, Loss: 2.9555, Train: 1.0000, Val: 0.7680, Test: 0.8040
Epoch: 158, Loss: 2.9242, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 159, Loss: 2.7638, Train: 1.0000, Val: 0.7740, Test: 0.8070
Epoch: 160, Loss: 2.3669, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 161, Loss: 2.2756, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 162, Loss: 2.9544, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 163, Loss: 2.7165, Train: 1.0000, Val: 0.7760, Test: 0.8100
Epoch: 164, Loss: 2.5693, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 165, Loss: 2.6163, Train: 1.0000, Val: 0.7840, Test: 0.8090
Epoch: 166, Loss: 2.4867, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 167, Loss: 2.8135, Train: 1.0000, Val: 0.7840, Test: 0.8080
Epoch: 168, Loss: 2.2913, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 169, Loss: 2.6677, Train: 1.0000, Val: 0.7840, Test: 0.8070
Epoch: 170, Loss: 2.4370, Train: 1.0000, Val: 0.7820, Test: 0.8070
Epoch: 171, Loss: 2.4901, Train: 1.0000, Val: 0.7800, Test: 0.8070
Epoch: 172, Loss: 2.4200, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 173, Loss: 2.5539, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 174, Loss: 2.6549, Train: 1.0000, Val: 0.7800, Test: 0.8040
Epoch: 175, Loss: 2.4686, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 176, Loss: 2.4872, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 177, Loss: 2.6846, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 178, Loss: 2.9173, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 179, Loss: 2.2238, Train: 1.0000, Val: 0.7740, Test: 0.8050
Epoch: 180, Loss: 2.8051, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 181, Loss: 2.1800, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 182, Loss: 2.4199, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 183, Loss: 2.9763, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 184, Loss: 2.3881, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 185, Loss: 2.2439, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 186, Loss: 2.2494, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 187, Loss: 2.5612, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 188, Loss: 2.4030, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 189, Loss: 2.2636, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 190, Loss: 2.6756, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 191, Loss: 2.6634, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 192, Loss: 2.4032, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 193, Loss: 2.1776, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 194, Loss: 2.8354, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 195, Loss: 2.5664, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 196, Loss: 2.6068, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 197, Loss: 2.6756, Train: 1.0000, Val: 0.7840, Test: 0.7940
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 198, Loss: 2.4322, Train: 1.0000, Val: 0.7840, Test: 0.7920
Epoch: 199, Loss: 2.4946, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 200, Loss: 2.2145, Train: 1.0000, Val: 0.7780, Test: 0.7960
MAD:  0.3546
Best Test Accuracy: 0.8230, Val Accuracy: 0.8020, Train Accuracy: 1.0000
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9281, Train: 0.0429, Val: 0.0180, Test: 0.0190
Epoch: 2, Loss: 4.9167, Train: 0.1286, Val: 0.0860, Test: 0.0670
Epoch: 3, Loss: 4.8438, Train: 0.3286, Val: 0.1840, Test: 0.1780
Epoch: 4, Loss: 4.7191, Train: 0.4429, Val: 0.3200, Test: 0.3150
Epoch: 5, Loss: 4.6715, Train: 0.5429, Val: 0.3920, Test: 0.4030
Epoch: 6, Loss: 4.5894, Train: 0.5714, Val: 0.4620, Test: 0.4740
Epoch: 7, Loss: 4.4185, Train: 0.7071, Val: 0.5060, Test: 0.5170
Epoch: 8, Loss: 4.6468, Train: 0.7286, Val: 0.5180, Test: 0.5580
Epoch: 9, Loss: 4.3737, Train: 0.7643, Val: 0.5540, Test: 0.5670
Epoch: 10, Loss: 4.4662, Train: 0.7929, Val: 0.5520, Test: 0.5670
Epoch: 11, Loss: 4.2375, Train: 0.8071, Val: 0.5320, Test: 0.5590
Epoch: 12, Loss: 4.0061, Train: 0.8286, Val: 0.5340, Test: 0.5480
Epoch: 13, Loss: 4.2848, Train: 0.8500, Val: 0.5280, Test: 0.5400
Epoch: 14, Loss: 4.1119, Train: 0.8643, Val: 0.5360, Test: 0.5510
Epoch: 15, Loss: 4.1039, Train: 0.8786, Val: 0.5540, Test: 0.5620
Epoch: 16, Loss: 3.8668, Train: 0.9143, Val: 0.5600, Test: 0.5760
Epoch: 17, Loss: 4.1165, Train: 0.9357, Val: 0.5900, Test: 0.5920
Epoch: 18, Loss: 3.8555, Train: 0.9500, Val: 0.6260, Test: 0.6110
Epoch: 19, Loss: 4.0702, Train: 0.9571, Val: 0.6460, Test: 0.6420
Epoch: 20, Loss: 4.1223, Train: 0.9571, Val: 0.6660, Test: 0.6790
Epoch: 21, Loss: 3.6339, Train: 0.9786, Val: 0.6880, Test: 0.7110
Epoch: 22, Loss: 3.7873, Train: 0.9786, Val: 0.7000, Test: 0.7140
Epoch: 23, Loss: 3.6169, Train: 0.9786, Val: 0.7140, Test: 0.7260
Epoch: 24, Loss: 3.8513, Train: 0.9857, Val: 0.7160, Test: 0.7340
Epoch: 25, Loss: 3.8658, Train: 0.9857, Val: 0.7220, Test: 0.7430
Epoch: 26, Loss: 3.6487, Train: 0.9857, Val: 0.7400, Test: 0.7540
Epoch: 27, Loss: 3.7693, Train: 0.9786, Val: 0.7460, Test: 0.7590
Epoch: 28, Loss: 3.8035, Train: 0.9857, Val: 0.7500, Test: 0.7610
Epoch: 29, Loss: 3.5594, Train: 0.9857, Val: 0.7460, Test: 0.7610
Epoch: 30, Loss: 3.4537, Train: 0.9857, Val: 0.7480, Test: 0.7620
Epoch: 31, Loss: 3.6046, Train: 0.9929, Val: 0.7500, Test: 0.7590
Epoch: 32, Loss: 3.3754, Train: 0.9929, Val: 0.7380, Test: 0.7550
Epoch: 33, Loss: 3.3772, Train: 0.9929, Val: 0.7380, Test: 0.7540
Epoch: 34, Loss: 3.5652, Train: 0.9929, Val: 0.7400, Test: 0.7540
Epoch: 35, Loss: 3.2943, Train: 0.9929, Val: 0.7440, Test: 0.7560
Epoch: 36, Loss: 3.5609, Train: 0.9929, Val: 0.7440, Test: 0.7580
Epoch: 37, Loss: 3.6066, Train: 0.9929, Val: 0.7480, Test: 0.7620
Epoch: 38, Loss: 3.2657, Train: 0.9929, Val: 0.7520, Test: 0.7690
Epoch: 39, Loss: 3.2131, Train: 0.9929, Val: 0.7560, Test: 0.7720
Epoch: 40, Loss: 3.3248, Train: 0.9929, Val: 0.7580, Test: 0.7760
Epoch: 41, Loss: 3.0837, Train: 0.9929, Val: 0.7560, Test: 0.7720
Epoch: 42, Loss: 3.5667, Train: 0.9929, Val: 0.7560, Test: 0.7680
Epoch: 43, Loss: 3.1335, Train: 0.9929, Val: 0.7480, Test: 0.7690
Epoch: 44, Loss: 3.1514, Train: 1.0000, Val: 0.7540, Test: 0.7670
Epoch: 45, Loss: 3.3507, Train: 1.0000, Val: 0.7620, Test: 0.7670
Epoch: 46, Loss: 3.1134, Train: 1.0000, Val: 0.7620, Test: 0.7700
Epoch: 47, Loss: 3.1094, Train: 1.0000, Val: 0.7700, Test: 0.7720
Epoch: 48, Loss: 3.0217, Train: 1.0000, Val: 0.7720, Test: 0.7730
Epoch: 49, Loss: 2.8888, Train: 1.0000, Val: 0.7720, Test: 0.7750
Epoch: 50, Loss: 3.1290, Train: 1.0000, Val: 0.7780, Test: 0.7780
Epoch: 51, Loss: 3.1563, Train: 1.0000, Val: 0.7720, Test: 0.7780
Epoch: 52, Loss: 2.8756, Train: 1.0000, Val: 0.7640, Test: 0.7760
Epoch: 53, Loss: 3.4174, Train: 1.0000, Val: 0.7700, Test: 0.7780
Epoch: 54, Loss: 2.9745, Train: 1.0000, Val: 0.7700, Test: 0.7770
Epoch: 55, Loss: 3.2557, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 56, Loss: 2.8128, Train: 1.0000, Val: 0.7640, Test: 0.7780
Epoch: 57, Loss: 3.3011, Train: 1.0000, Val: 0.7660, Test: 0.7780
Epoch: 58, Loss: 2.9993, Train: 1.0000, Val: 0.7680, Test: 0.7770
Epoch: 59, Loss: 3.0531, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 60, Loss: 2.9632, Train: 1.0000, Val: 0.7680, Test: 0.7780
Epoch: 61, Loss: 3.0277, Train: 1.0000, Val: 0.7680, Test: 0.7790
Epoch: 62, Loss: 3.0129, Train: 1.0000, Val: 0.7700, Test: 0.7790
Epoch: 63, Loss: 3.0533, Train: 1.0000, Val: 0.7680, Test: 0.7780
Epoch: 64, Loss: 2.5563, Train: 1.0000, Val: 0.7680, Test: 0.7760
Epoch: 65, Loss: 2.9314, Train: 1.0000, Val: 0.7660, Test: 0.7760
Epoch: 66, Loss: 2.9751, Train: 1.0000, Val: 0.7700, Test: 0.7760
Epoch: 67, Loss: 2.6075, Train: 1.0000, Val: 0.7700, Test: 0.7760
Epoch: 68, Loss: 3.1291, Train: 1.0000, Val: 0.7740, Test: 0.7790
Epoch: 69, Loss: 2.9688, Train: 1.0000, Val: 0.7760, Test: 0.7820
Epoch: 70, Loss: 2.6861, Train: 1.0000, Val: 0.7800, Test: 0.7870
Epoch: 71, Loss: 2.9354, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 72, Loss: 2.8090, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 73, Loss: 2.5216, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 74, Loss: 2.9073, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 75, Loss: 3.0456, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 76, Loss: 3.1354, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 77, Loss: 2.8719, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 78, Loss: 2.7907, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 79, Loss: 2.9750, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 80, Loss: 2.7566, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 81, Loss: 3.1087, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 82, Loss: 2.3305, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 83, Loss: 2.8599, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 84, Loss: 2.5323, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 85, Loss: 2.7148, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 86, Loss: 2.7583, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 87, Loss: 2.6161, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 88, Loss: 2.8072, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 89, Loss: 2.6629, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 90, Loss: 2.8430, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 91, Loss: 2.7162, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 92, Loss: 2.7908, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 93, Loss: 2.3527, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 94, Loss: 2.6561, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 95, Loss: 2.9849, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 96, Loss: 2.9346, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 97, Loss: 2.8369, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 98, Loss: 2.3593, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 99, Loss: 3.2302, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 100, Loss: 2.5869, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 101, Loss: 2.8605, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 102, Loss: 2.4335, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 103, Loss: 2.8547, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 104, Loss: 2.7965, Train: 1.0000, Val: 0.7820, Test: 0.7990
Epoch: 105, Loss: 2.6498, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 106, Loss: 2.4958, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 107, Loss: 2.3114, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 108, Loss: 3.0315, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 109, Loss: 2.6677, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 110, Loss: 2.9402, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 111, Loss: 2.4838, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 112, Loss: 2.4632, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 113, Loss: 2.5156, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 114, Loss: 3.0175, Train: 1.0000, Val: 0.7800, Test: 0.7920
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 115, Loss: 3.1163, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 116, Loss: 2.6659, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 117, Loss: 2.3971, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 118, Loss: 2.9627, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 119, Loss: 2.5864, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 120, Loss: 2.4603, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 121, Loss: 2.5424, Train: 1.0000, Val: 0.7760, Test: 0.7920
Epoch: 122, Loss: 2.2436, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 123, Loss: 2.3004, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 124, Loss: 2.6942, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 125, Loss: 2.3665, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 126, Loss: 2.9205, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 127, Loss: 2.9203, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 128, Loss: 2.8125, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 129, Loss: 2.6021, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 130, Loss: 2.8323, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 131, Loss: 2.5783, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 132, Loss: 2.8599, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 133, Loss: 2.9410, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 134, Loss: 2.5896, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 135, Loss: 2.5834, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 136, Loss: 2.4272, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 137, Loss: 2.8317, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 138, Loss: 2.4593, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 139, Loss: 2.7239, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 140, Loss: 2.8433, Train: 1.0000, Val: 0.7860, Test: 0.7950
Epoch: 141, Loss: 2.3505, Train: 1.0000, Val: 0.7880, Test: 0.7950
Epoch: 142, Loss: 2.5330, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 143, Loss: 2.4072, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 144, Loss: 2.5680, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 145, Loss: 2.3774, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 146, Loss: 2.4467, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 147, Loss: 2.4925, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 148, Loss: 3.0695, Train: 1.0000, Val: 0.7680, Test: 0.7970
Epoch: 149, Loss: 2.7933, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 150, Loss: 2.5936, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 151, Loss: 2.5619, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 152, Loss: 2.6872, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 153, Loss: 2.5768, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 154, Loss: 2.5515, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 155, Loss: 2.3835, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 156, Loss: 2.5408, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 157, Loss: 2.0179, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 158, Loss: 2.5797, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 159, Loss: 2.7722, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 160, Loss: 2.3424, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 161, Loss: 2.8966, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 162, Loss: 2.4575, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 163, Loss: 2.7638, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 164, Loss: 2.6603, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 165, Loss: 2.5186, Train: 1.0000, Val: 0.7640, Test: 0.7890
Epoch: 166, Loss: 2.2704, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 167, Loss: 2.8803, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 168, Loss: 2.1578, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 169, Loss: 2.6452, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 170, Loss: 2.2622, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 171, Loss: 2.3361, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 172, Loss: 2.5933, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 173, Loss: 2.5888, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 174, Loss: 2.5342, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 175, Loss: 2.5276, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 176, Loss: 2.7020, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 177, Loss: 2.4904, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 178, Loss: 2.6854, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 179, Loss: 2.6759, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 180, Loss: 2.6884, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 181, Loss: 2.7040, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 182, Loss: 2.4715, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 183, Loss: 2.6346, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 184, Loss: 2.5015, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 185, Loss: 2.5136, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 186, Loss: 2.3599, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 187, Loss: 2.9419, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 188, Loss: 2.7201, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 189, Loss: 2.1891, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 190, Loss: 2.6071, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 191, Loss: 2.5014, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 192, Loss: 2.5811, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 193, Loss: 2.0954, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 194, Loss: 2.4435, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 195, Loss: 2.5444, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 196, Loss: 2.4628, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 197, Loss: 2.3331, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 198, Loss: 2.6138, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 199, Loss: 2.7833, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 200, Loss: 2.5737, Train: 1.0000, Val: 0.7680, Test: 0.7910
MAD:  0.4506
Best Test Accuracy: 0.8010, Val Accuracy: 0.7860, Train Accuracy: 1.0000
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9102, Train: 0.0357, Val: 0.0100, Test: 0.0260
Epoch: 2, Loss: 4.8485, Train: 0.1500, Val: 0.0500, Test: 0.0670
Epoch: 3, Loss: 4.8297, Train: 0.2571, Val: 0.1340, Test: 0.1420
Epoch: 4, Loss: 4.7039, Train: 0.4000, Val: 0.2100, Test: 0.1980
Epoch: 5, Loss: 4.5636, Train: 0.4286, Val: 0.2340, Test: 0.2270
Epoch: 6, Loss: 4.6233, Train: 0.4929, Val: 0.2860, Test: 0.2730
Epoch: 7, Loss: 4.4980, Train: 0.6000, Val: 0.3380, Test: 0.3490
Epoch: 8, Loss: 4.5424, Train: 0.7357, Val: 0.4060, Test: 0.4240
Epoch: 9, Loss: 4.4525, Train: 0.8286, Val: 0.4800, Test: 0.5040
Epoch: 10, Loss: 4.3574, Train: 0.8571, Val: 0.5160, Test: 0.5490
Epoch: 11, Loss: 4.3238, Train: 0.8857, Val: 0.5480, Test: 0.5890
Epoch: 12, Loss: 4.2353, Train: 0.9071, Val: 0.5840, Test: 0.6100
Epoch: 13, Loss: 4.2315, Train: 0.9357, Val: 0.6100, Test: 0.6350
Epoch: 14, Loss: 4.0589, Train: 0.9571, Val: 0.6520, Test: 0.6680
Epoch: 15, Loss: 4.0923, Train: 0.9571, Val: 0.6640, Test: 0.6920
Epoch: 16, Loss: 4.1076, Train: 0.9571, Val: 0.6860, Test: 0.7070
Epoch: 17, Loss: 4.1408, Train: 0.9571, Val: 0.7060, Test: 0.7210
Epoch: 18, Loss: 3.8107, Train: 0.9643, Val: 0.7040, Test: 0.7210
Epoch: 19, Loss: 3.8715, Train: 0.9714, Val: 0.7120, Test: 0.7260
Epoch: 20, Loss: 3.8632, Train: 0.9714, Val: 0.7200, Test: 0.7330
Epoch: 21, Loss: 3.7002, Train: 0.9786, Val: 0.7280, Test: 0.7440
Epoch: 22, Loss: 3.8310, Train: 0.9786, Val: 0.7300, Test: 0.7520
Epoch: 23, Loss: 3.6469, Train: 0.9786, Val: 0.7400, Test: 0.7640
Epoch: 24, Loss: 3.7391, Train: 0.9786, Val: 0.7440, Test: 0.7670
Epoch: 25, Loss: 3.7049, Train: 0.9786, Val: 0.7360, Test: 0.7700
Epoch: 26, Loss: 3.6612, Train: 0.9857, Val: 0.7460, Test: 0.7710
Epoch: 27, Loss: 3.5682, Train: 0.9929, Val: 0.7480, Test: 0.7740
Epoch: 28, Loss: 3.4948, Train: 0.9929, Val: 0.7540, Test: 0.7740
Epoch: 29, Loss: 3.5706, Train: 1.0000, Val: 0.7540, Test: 0.7780
Epoch: 30, Loss: 3.4946, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 31, Loss: 3.3495, Train: 0.9929, Val: 0.7680, Test: 0.7900
Epoch: 32, Loss: 3.1331, Train: 0.9929, Val: 0.7680, Test: 0.7900
Epoch: 33, Loss: 3.5039, Train: 0.9929, Val: 0.7640, Test: 0.7890
Epoch: 34, Loss: 3.5482, Train: 0.9929, Val: 0.7620, Test: 0.7890
Epoch: 35, Loss: 3.6790, Train: 0.9857, Val: 0.7620, Test: 0.7890
Epoch: 36, Loss: 3.3254, Train: 0.9857, Val: 0.7660, Test: 0.7870
Epoch: 37, Loss: 3.2771, Train: 0.9857, Val: 0.7620, Test: 0.7870
Epoch: 38, Loss: 3.3330, Train: 0.9929, Val: 0.7620, Test: 0.7900
Epoch: 39, Loss: 3.3088, Train: 0.9929, Val: 0.7620, Test: 0.7900
Epoch: 40, Loss: 3.2241, Train: 0.9929, Val: 0.7580, Test: 0.7930
Epoch: 41, Loss: 3.1454, Train: 0.9929, Val: 0.7620, Test: 0.7960
Epoch: 42, Loss: 2.7093, Train: 0.9929, Val: 0.7620, Test: 0.7950
Epoch: 43, Loss: 3.4090, Train: 0.9929, Val: 0.7620, Test: 0.7930
Epoch: 44, Loss: 2.8307, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 45, Loss: 3.0420, Train: 1.0000, Val: 0.7580, Test: 0.7940
Epoch: 46, Loss: 3.1026, Train: 1.0000, Val: 0.7580, Test: 0.7930
Epoch: 47, Loss: 3.1443, Train: 1.0000, Val: 0.7600, Test: 0.7940
Epoch: 48, Loss: 3.0320, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 49, Loss: 2.9304, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 50, Loss: 2.9643, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 51, Loss: 3.3727, Train: 1.0000, Val: 0.7680, Test: 0.7820
Epoch: 52, Loss: 2.9454, Train: 1.0000, Val: 0.7720, Test: 0.7830
Epoch: 53, Loss: 2.9551, Train: 1.0000, Val: 0.7740, Test: 0.7790
Epoch: 54, Loss: 3.1741, Train: 1.0000, Val: 0.7740, Test: 0.7770
Epoch: 55, Loss: 2.8766, Train: 1.0000, Val: 0.7740, Test: 0.7810
Epoch: 56, Loss: 2.9296, Train: 1.0000, Val: 0.7720, Test: 0.7830
Epoch: 57, Loss: 2.6544, Train: 1.0000, Val: 0.7720, Test: 0.7820
Epoch: 58, Loss: 2.7284, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 59, Loss: 2.8635, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 60, Loss: 3.0669, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 61, Loss: 2.7679, Train: 1.0000, Val: 0.7780, Test: 0.7870
Epoch: 62, Loss: 2.6251, Train: 1.0000, Val: 0.7800, Test: 0.7880
Epoch: 63, Loss: 2.7399, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 64, Loss: 2.8255, Train: 1.0000, Val: 0.7720, Test: 0.7870
Epoch: 65, Loss: 2.8920, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 66, Loss: 2.7648, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 67, Loss: 2.8416, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 68, Loss: 3.3009, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 69, Loss: 3.1441, Train: 1.0000, Val: 0.7620, Test: 0.7740
Epoch: 70, Loss: 2.9678, Train: 1.0000, Val: 0.7580, Test: 0.7740
Epoch: 71, Loss: 2.5699, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 72, Loss: 2.5885, Train: 1.0000, Val: 0.7560, Test: 0.7720
Epoch: 73, Loss: 2.8870, Train: 1.0000, Val: 0.7540, Test: 0.7720
Epoch: 74, Loss: 2.5587, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 75, Loss: 3.0418, Train: 1.0000, Val: 0.7580, Test: 0.7710
Epoch: 76, Loss: 2.7720, Train: 1.0000, Val: 0.7580, Test: 0.7750
Epoch: 77, Loss: 2.7371, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 78, Loss: 2.9280, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 79, Loss: 2.5742, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 80, Loss: 2.5824, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 81, Loss: 2.8086, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 82, Loss: 2.7652, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 83, Loss: 2.7518, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 84, Loss: 2.7901, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 85, Loss: 2.5438, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 86, Loss: 2.6420, Train: 1.0000, Val: 0.7640, Test: 0.7900
Epoch: 87, Loss: 3.0327, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 88, Loss: 2.4933, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 89, Loss: 2.4317, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 90, Loss: 2.7644, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 91, Loss: 2.6425, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 92, Loss: 2.6997, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 93, Loss: 2.6938, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 94, Loss: 2.8359, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 95, Loss: 2.8466, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 96, Loss: 3.1177, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 97, Loss: 2.9127, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 98, Loss: 2.7916, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 99, Loss: 2.7465, Train: 1.0000, Val: 0.7580, Test: 0.7790
Epoch: 100, Loss: 2.8328, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 101, Loss: 2.4793, Train: 1.0000, Val: 0.7540, Test: 0.7760
Epoch: 102, Loss: 2.5004, Train: 1.0000, Val: 0.7520, Test: 0.7760
Epoch: 103, Loss: 2.5667, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 104, Loss: 2.4866, Train: 1.0000, Val: 0.7580, Test: 0.7820
Epoch: 105, Loss: 2.4437, Train: 1.0000, Val: 0.7580, Test: 0.7820
Epoch: 106, Loss: 2.8040, Train: 1.0000, Val: 0.7540, Test: 0.7810
Epoch: 107, Loss: 2.8166, Train: 1.0000, Val: 0.7540, Test: 0.7790
Epoch: 108, Loss: 2.5764, Train: 1.0000, Val: 0.7560, Test: 0.7830
Epoch: 109, Loss: 2.4696, Train: 1.0000, Val: 0.7560, Test: 0.7850
Epoch: 110, Loss: 2.5445, Train: 1.0000, Val: 0.7540, Test: 0.7850
Epoch: 111, Loss: 2.7419, Train: 1.0000, Val: 0.7560, Test: 0.7870
Epoch: 112, Loss: 2.7628, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 113, Loss: 2.7666, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 114, Loss: 2.4336, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 115, Loss: 2.5146, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 116, Loss: 2.5692, Train: 1.0000, Val: 0.7660, Test: 0.7990
Epoch: 117, Loss: 2.6941, Train: 1.0000, Val: 0.7660, Test: 0.7960
Epoch: 118, Loss: 2.7665, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 119, Loss: 2.4865, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 120, Loss: 2.4949, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 121, Loss: 2.7894, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 122, Loss: 2.8369, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 123, Loss: 2.2677, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 124, Loss: 2.6728, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 125, Loss: 2.7677, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 126, Loss: 2.9192, Train: 1.0000, Val: 0.7640, Test: 0.7810
Epoch: 127, Loss: 2.7732, Train: 1.0000, Val: 0.7640, Test: 0.7820
Epoch: 128, Loss: 2.9009, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 129, Loss: 2.8843, Train: 1.0000, Val: 0.7620, Test: 0.7800
Epoch: 130, Loss: 2.4936, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 131, Loss: 2.4515, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 132, Loss: 2.6769, Train: 1.0000, Val: 0.7580, Test: 0.7780
Epoch: 133, Loss: 2.8238, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 134, Loss: 2.8475, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 135, Loss: 2.5365, Train: 1.0000, Val: 0.7540, Test: 0.7810
Epoch: 136, Loss: 2.8526, Train: 1.0000, Val: 0.7560, Test: 0.7830
Epoch: 137, Loss: 2.7674, Train: 1.0000, Val: 0.7560, Test: 0.7830
Epoch: 138, Loss: 2.3181, Train: 1.0000, Val: 0.7580, Test: 0.7840
Epoch: 139, Loss: 2.7542, Train: 1.0000, Val: 0.7620, Test: 0.7860
Epoch: 140, Loss: 2.6658, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 141, Loss: 2.8714, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 142, Loss: 2.2940, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 143, Loss: 2.5665, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 144, Loss: 2.2328, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 145, Loss: 2.5703, Train: 1.0000, Val: 0.7640, Test: 0.7870
Epoch: 146, Loss: 2.8122, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 147, Loss: 2.5327, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 148, Loss: 2.9386, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 149, Loss: 2.8389, Train: 1.0000, Val: 0.7560, Test: 0.7780
Epoch: 150, Loss: 2.2517, Train: 1.0000, Val: 0.7600, Test: 0.7770
Epoch: 151, Loss: 2.7916, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 152, Loss: 2.5681, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 153, Loss: 2.3422, Train: 1.0000, Val: 0.7600, Test: 0.7790
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 154, Loss: 2.5099, Train: 1.0000, Val: 0.7600, Test: 0.7800
Epoch: 155, Loss: 2.7675, Train: 1.0000, Val: 0.7620, Test: 0.7790
Epoch: 156, Loss: 2.6739, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 157, Loss: 2.5575, Train: 1.0000, Val: 0.7600, Test: 0.7810
Epoch: 158, Loss: 2.3095, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 159, Loss: 2.8395, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 160, Loss: 2.5353, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 161, Loss: 2.5725, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 162, Loss: 3.0234, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 163, Loss: 2.8468, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 164, Loss: 2.7652, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 165, Loss: 2.6570, Train: 1.0000, Val: 0.7600, Test: 0.7820
Epoch: 166, Loss: 2.4923, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 167, Loss: 2.6706, Train: 1.0000, Val: 0.7580, Test: 0.7820
Epoch: 168, Loss: 2.4139, Train: 1.0000, Val: 0.7600, Test: 0.7810
Epoch: 169, Loss: 2.5935, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 170, Loss: 2.2811, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 171, Loss: 2.3401, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 172, Loss: 2.5939, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 173, Loss: 2.1847, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 174, Loss: 2.3485, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 175, Loss: 2.5836, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 176, Loss: 2.7370, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 177, Loss: 2.6720, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 178, Loss: 2.2970, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 179, Loss: 2.5921, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 180, Loss: 2.9771, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 181, Loss: 2.4752, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 182, Loss: 2.4027, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 183, Loss: 2.7563, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 184, Loss: 2.9345, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 185, Loss: 2.6133, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 186, Loss: 2.1933, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 187, Loss: 2.8234, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 188, Loss: 2.3845, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 189, Loss: 2.2380, Train: 1.0000, Val: 0.7640, Test: 0.7840
Epoch: 190, Loss: 2.3517, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 191, Loss: 2.5644, Train: 1.0000, Val: 0.7620, Test: 0.7850
Epoch: 192, Loss: 2.7144, Train: 1.0000, Val: 0.7620, Test: 0.7840
Epoch: 193, Loss: 2.3321, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 194, Loss: 2.4128, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 195, Loss: 2.8898, Train: 1.0000, Val: 0.7580, Test: 0.7810
Epoch: 196, Loss: 2.7433, Train: 1.0000, Val: 0.7520, Test: 0.7820
Epoch: 197, Loss: 2.6350, Train: 1.0000, Val: 0.7520, Test: 0.7810
Epoch: 198, Loss: 2.6203, Train: 1.0000, Val: 0.7520, Test: 0.7800
Epoch: 199, Loss: 2.5896, Train: 1.0000, Val: 0.7520, Test: 0.7810
Epoch: 200, Loss: 2.6433, Train: 1.0000, Val: 0.7540, Test: 0.7820
MAD:  0.4784
Best Test Accuracy: 0.7990, Val Accuracy: 0.7660, Train Accuracy: 1.0000
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9512, Train: 0.1000, Val: 0.0460, Test: 0.0360
Epoch: 2, Loss: 4.7930, Train: 0.2286, Val: 0.0980, Test: 0.1010
Epoch: 3, Loss: 4.7283, Train: 0.3071, Val: 0.1500, Test: 0.1580
Epoch: 4, Loss: 4.6330, Train: 0.3429, Val: 0.1920, Test: 0.2010
Epoch: 5, Loss: 4.5305, Train: 0.3643, Val: 0.2140, Test: 0.2230
Epoch: 6, Loss: 4.6603, Train: 0.4500, Val: 0.2600, Test: 0.2640
Epoch: 7, Loss: 4.6591, Train: 0.5643, Val: 0.3160, Test: 0.3150
Epoch: 8, Loss: 4.4569, Train: 0.6571, Val: 0.4080, Test: 0.3830
Epoch: 9, Loss: 4.4151, Train: 0.7071, Val: 0.4820, Test: 0.4560
Epoch: 10, Loss: 4.3565, Train: 0.7786, Val: 0.5680, Test: 0.5510
Epoch: 11, Loss: 4.2513, Train: 0.8429, Val: 0.6380, Test: 0.6100
Epoch: 12, Loss: 4.1375, Train: 0.8643, Val: 0.6660, Test: 0.6540
Epoch: 13, Loss: 4.0754, Train: 0.9143, Val: 0.6940, Test: 0.6780
Epoch: 14, Loss: 4.1236, Train: 0.9571, Val: 0.7140, Test: 0.6910
Epoch: 15, Loss: 4.0136, Train: 0.9571, Val: 0.7100, Test: 0.7030
Epoch: 16, Loss: 4.0758, Train: 0.9571, Val: 0.7140, Test: 0.7040
Epoch: 17, Loss: 3.6810, Train: 0.9643, Val: 0.7140, Test: 0.6980
Epoch: 18, Loss: 4.0364, Train: 0.9643, Val: 0.7160, Test: 0.6900
Epoch: 19, Loss: 4.0545, Train: 0.9643, Val: 0.7040, Test: 0.6940
Epoch: 20, Loss: 3.9150, Train: 0.9714, Val: 0.7020, Test: 0.6950
Epoch: 21, Loss: 3.6381, Train: 0.9714, Val: 0.7100, Test: 0.6960
Epoch: 22, Loss: 3.8783, Train: 0.9643, Val: 0.7100, Test: 0.7000
Epoch: 23, Loss: 3.7441, Train: 0.9643, Val: 0.7200, Test: 0.7040
Epoch: 24, Loss: 3.8303, Train: 0.9643, Val: 0.7220, Test: 0.7050
Epoch: 25, Loss: 3.4592, Train: 0.9643, Val: 0.7240, Test: 0.7200
Epoch: 26, Loss: 3.9119, Train: 0.9786, Val: 0.7240, Test: 0.7260
Epoch: 27, Loss: 3.8016, Train: 0.9786, Val: 0.7240, Test: 0.7310
Epoch: 28, Loss: 3.5522, Train: 0.9786, Val: 0.7320, Test: 0.7340
Epoch: 29, Loss: 3.5692, Train: 0.9786, Val: 0.7340, Test: 0.7390
Epoch: 30, Loss: 3.3297, Train: 0.9857, Val: 0.7380, Test: 0.7420
Epoch: 31, Loss: 3.5449, Train: 0.9857, Val: 0.7460, Test: 0.7490
Epoch: 32, Loss: 3.2987, Train: 0.9857, Val: 0.7500, Test: 0.7560
Epoch: 33, Loss: 3.3435, Train: 0.9857, Val: 0.7500, Test: 0.7590
Epoch: 34, Loss: 3.5355, Train: 0.9929, Val: 0.7600, Test: 0.7640
Epoch: 35, Loss: 3.4196, Train: 0.9929, Val: 0.7600, Test: 0.7670
Epoch: 36, Loss: 3.3496, Train: 0.9929, Val: 0.7540, Test: 0.7740
Epoch: 37, Loss: 3.2975, Train: 1.0000, Val: 0.7580, Test: 0.7760
Epoch: 38, Loss: 3.1763, Train: 1.0000, Val: 0.7660, Test: 0.7740
Epoch: 39, Loss: 3.6082, Train: 1.0000, Val: 0.7680, Test: 0.7740
Epoch: 40, Loss: 3.1657, Train: 1.0000, Val: 0.7700, Test: 0.7740
Epoch: 41, Loss: 3.2535, Train: 1.0000, Val: 0.7700, Test: 0.7780
Epoch: 42, Loss: 2.9926, Train: 1.0000, Val: 0.7720, Test: 0.7820
Epoch: 43, Loss: 3.2059, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 44, Loss: 3.2222, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 45, Loss: 2.9193, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 46, Loss: 3.0403, Train: 1.0000, Val: 0.7860, Test: 0.7940
Epoch: 47, Loss: 2.8519, Train: 1.0000, Val: 0.7860, Test: 0.7910
Epoch: 48, Loss: 3.1618, Train: 1.0000, Val: 0.7840, Test: 0.7900
Epoch: 49, Loss: 3.3947, Train: 1.0000, Val: 0.7800, Test: 0.7890
Epoch: 50, Loss: 3.2057, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 51, Loss: 3.0508, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 52, Loss: 3.1617, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 53, Loss: 3.3681, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 54, Loss: 2.8773, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 55, Loss: 3.0421, Train: 1.0000, Val: 0.7740, Test: 0.8030
Epoch: 56, Loss: 2.9399, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 57, Loss: 2.8247, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 58, Loss: 2.9494, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 59, Loss: 3.3647, Train: 1.0000, Val: 0.7760, Test: 0.8020
Epoch: 60, Loss: 3.1605, Train: 1.0000, Val: 0.7860, Test: 0.8000
Epoch: 61, Loss: 2.9145, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 62, Loss: 3.2083, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 63, Loss: 3.1303, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 64, Loss: 3.0378, Train: 1.0000, Val: 0.7860, Test: 0.8010
Epoch: 65, Loss: 2.8165, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 66, Loss: 2.7610, Train: 1.0000, Val: 0.7860, Test: 0.8020
Epoch: 67, Loss: 2.5913, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 68, Loss: 2.9006, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 69, Loss: 3.0947, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 70, Loss: 2.6547, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 71, Loss: 2.7749, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 72, Loss: 2.7672, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 73, Loss: 3.2975, Train: 1.0000, Val: 0.7780, Test: 0.8020
Epoch: 74, Loss: 2.8002, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 75, Loss: 2.8966, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 76, Loss: 2.9345, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 77, Loss: 2.8278, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 78, Loss: 2.7153, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 79, Loss: 3.0371, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 80, Loss: 2.8720, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 81, Loss: 3.0310, Train: 1.0000, Val: 0.7820, Test: 0.7980
Epoch: 82, Loss: 3.0133, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 83, Loss: 2.9533, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 84, Loss: 2.4514, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 85, Loss: 2.5937, Train: 1.0000, Val: 0.7880, Test: 0.8020
Epoch: 86, Loss: 2.7820, Train: 1.0000, Val: 0.7880, Test: 0.8030
Epoch: 87, Loss: 2.8995, Train: 1.0000, Val: 0.7920, Test: 0.8030
Epoch: 88, Loss: 2.5972, Train: 1.0000, Val: 0.7900, Test: 0.8000
Epoch: 89, Loss: 3.0651, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 90, Loss: 2.5734, Train: 1.0000, Val: 0.7840, Test: 0.8010
Epoch: 91, Loss: 2.6829, Train: 1.0000, Val: 0.7840, Test: 0.7980
Epoch: 92, Loss: 2.8599, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 93, Loss: 2.7431, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 94, Loss: 3.0270, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 95, Loss: 2.5485, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 96, Loss: 2.7489, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 97, Loss: 2.7602, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 98, Loss: 3.0132, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 99, Loss: 3.0137, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 100, Loss: 2.5309, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 101, Loss: 2.7949, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 102, Loss: 2.9414, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 103, Loss: 2.7900, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 104, Loss: 2.7558, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 105, Loss: 2.3230, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 106, Loss: 2.2193, Train: 1.0000, Val: 0.7800, Test: 0.7890
Epoch: 107, Loss: 2.7289, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 108, Loss: 2.7180, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 109, Loss: 2.6066, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 110, Loss: 2.4931, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 111, Loss: 2.7148, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 112, Loss: 3.1812, Train: 1.0000, Val: 0.7800, Test: 0.7870
Epoch: 113, Loss: 2.7887, Train: 1.0000, Val: 0.7800, Test: 0.7880
Epoch: 114, Loss: 2.9586, Train: 1.0000, Val: 0.7840, Test: 0.7910
Epoch: 115, Loss: 2.0264, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 116, Loss: 2.8635, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 117, Loss: 2.8698, Train: 1.0000, Val: 0.7800, Test: 0.8020
Epoch: 118, Loss: 2.6684, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 119, Loss: 2.6442, Train: 1.0000, Val: 0.7800, Test: 0.8060
Epoch: 120, Loss: 2.2610, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 121, Loss: 2.8720, Train: 1.0000, Val: 0.7780, Test: 0.8060
Epoch: 122, Loss: 2.5144, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 123, Loss: 2.6693, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 124, Loss: 2.8928, Train: 1.0000, Val: 0.7800, Test: 0.8000
Epoch: 125, Loss: 3.0029, Train: 1.0000, Val: 0.7840, Test: 0.8000
Epoch: 126, Loss: 2.8456, Train: 1.0000, Val: 0.7820, Test: 0.8030
Epoch: 127, Loss: 2.4972, Train: 1.0000, Val: 0.7820, Test: 0.8040
Epoch: 128, Loss: 2.5075, Train: 1.0000, Val: 0.7820, Test: 0.8050
Epoch: 129, Loss: 2.8549, Train: 1.0000, Val: 0.7840, Test: 0.8050
Epoch: 130, Loss: 2.7954, Train: 1.0000, Val: 0.7820, Test: 0.8060
Epoch: 131, Loss: 2.8936, Train: 1.0000, Val: 0.7760, Test: 0.8040
Epoch: 132, Loss: 2.7004, Train: 1.0000, Val: 0.7760, Test: 0.8060
Epoch: 133, Loss: 2.6502, Train: 1.0000, Val: 0.7780, Test: 0.8040
Epoch: 134, Loss: 2.6061, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 135, Loss: 2.9084, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 136, Loss: 2.4739, Train: 1.0000, Val: 0.7740, Test: 0.8020
Epoch: 137, Loss: 2.4706, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 138, Loss: 2.6753, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 139, Loss: 2.3353, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 140, Loss: 2.6206, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 141, Loss: 2.6513, Train: 1.0000, Val: 0.7700, Test: 0.7920
Epoch: 142, Loss: 2.5744, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 143, Loss: 2.2586, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 144, Loss: 2.3606, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 145, Loss: 2.6240, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 146, Loss: 2.7264, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 147, Loss: 2.7185, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 148, Loss: 2.2294, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 149, Loss: 2.7154, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 150, Loss: 2.8864, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 151, Loss: 2.4657, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 152, Loss: 2.3283, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 153, Loss: 2.5418, Train: 1.0000, Val: 0.7800, Test: 0.7940
Epoch: 154, Loss: 2.7478, Train: 1.0000, Val: 0.7820, Test: 0.7930
Epoch: 155, Loss: 2.6023, Train: 1.0000, Val: 0.7820, Test: 0.7950
Epoch: 156, Loss: 2.5565, Train: 1.0000, Val: 0.7820, Test: 0.8000
Epoch: 157, Loss: 2.2027, Train: 1.0000, Val: 0.7860, Test: 0.7970
Epoch: 158, Loss: 2.2153, Train: 1.0000, Val: 0.7880, Test: 0.7960
Epoch: 159, Loss: 2.4426, Train: 1.0000, Val: 0.7860, Test: 0.7990
Epoch: 160, Loss: 2.7541, Train: 1.0000, Val: 0.7860, Test: 0.7980
Epoch: 161, Loss: 2.5763, Train: 1.0000, Val: 0.7880, Test: 0.7990
Epoch: 162, Loss: 2.9529, Train: 1.0000, Val: 0.7880, Test: 0.8010
Epoch: 163, Loss: 2.2687, Train: 1.0000, Val: 0.7880, Test: 0.8000
Epoch: 164, Loss: 2.6262, Train: 1.0000, Val: 0.7840, Test: 0.7990
Epoch: 165, Loss: 2.6219, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 166, Loss: 2.4056, Train: 1.0000, Val: 0.7840, Test: 0.7960
Epoch: 167, Loss: 2.7391, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 168, Loss: 2.5574, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 169, Loss: 3.1652, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 170, Loss: 2.5967, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 171, Loss: 2.7154, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 172, Loss: 2.5993, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 173, Loss: 2.5386, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 174, Loss: 2.2951, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 175, Loss: 2.3585, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 176, Loss: 2.4491, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 177, Loss: 2.2055, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 178, Loss: 2.5852, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 179, Loss: 2.5564, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 180, Loss: 2.7670, Train: 1.0000, Val: 0.7700, Test: 0.7900
Epoch: 181, Loss: 2.5950, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 182, Loss: 2.6983, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 183, Loss: 2.8679, Train: 1.0000, Val: 0.7720, Test: 0.7930
Epoch: 184, Loss: 2.4404, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 185, Loss: 2.5642, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 186, Loss: 2.5852, Train: 1.0000, Val: 0.7800, Test: 0.8010
Epoch: 187, Loss: 2.5483, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 188, Loss: 2.6829, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 189, Loss: 2.7682, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 190, Loss: 2.8448, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 191, Loss: 2.4797, Train: 1.0000, Val: 0.7820, Test: 0.8010
Epoch: 192, Loss: 2.4086, Train: 1.0000, Val: 0.7840, Test: 0.7990
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 193, Loss: 2.0726, Train: 1.0000, Val: 0.7840, Test: 0.7970
Epoch: 194, Loss: 2.2586, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 195, Loss: 2.5146, Train: 1.0000, Val: 0.7840, Test: 0.7950
Epoch: 196, Loss: 2.7928, Train: 1.0000, Val: 0.7840, Test: 0.7940
Epoch: 197, Loss: 2.1408, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 198, Loss: 2.3512, Train: 1.0000, Val: 0.7800, Test: 0.7920
Epoch: 199, Loss: 2.9107, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 200, Loss: 2.3038, Train: 1.0000, Val: 0.7800, Test: 0.7910
MAD:  0.4986
Best Test Accuracy: 0.8060, Val Accuracy: 0.7820, Train Accuracy: 1.0000
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8462, Train: 0.2000, Val: 0.0980, Test: 0.0970
Epoch: 2, Loss: 4.7663, Train: 0.2643, Val: 0.1280, Test: 0.1400
Epoch: 3, Loss: 4.6816, Train: 0.3000, Val: 0.1460, Test: 0.1570
Epoch: 4, Loss: 4.7165, Train: 0.3643, Val: 0.1700, Test: 0.1870
Epoch: 5, Loss: 4.5699, Train: 0.4714, Val: 0.2300, Test: 0.2330
Epoch: 6, Loss: 4.6138, Train: 0.5929, Val: 0.3040, Test: 0.3050
Epoch: 7, Loss: 4.3814, Train: 0.6786, Val: 0.3800, Test: 0.3770
Epoch: 8, Loss: 4.4345, Train: 0.7214, Val: 0.4620, Test: 0.4600
Epoch: 9, Loss: 4.5100, Train: 0.7857, Val: 0.5220, Test: 0.5070
Epoch: 10, Loss: 4.1211, Train: 0.8143, Val: 0.5480, Test: 0.5570
Epoch: 11, Loss: 4.0807, Train: 0.8429, Val: 0.5660, Test: 0.5590
Epoch: 12, Loss: 4.2172, Train: 0.8643, Val: 0.5900, Test: 0.5740
Epoch: 13, Loss: 4.1390, Train: 0.9000, Val: 0.6040, Test: 0.5950
Epoch: 14, Loss: 4.1119, Train: 0.9000, Val: 0.6200, Test: 0.6180
Epoch: 15, Loss: 3.9239, Train: 0.9143, Val: 0.6400, Test: 0.6410
Epoch: 16, Loss: 3.9957, Train: 0.9214, Val: 0.6480, Test: 0.6740
Epoch: 17, Loss: 3.9686, Train: 0.9429, Val: 0.6540, Test: 0.6800
Epoch: 18, Loss: 4.0314, Train: 0.9571, Val: 0.6720, Test: 0.6880
Epoch: 19, Loss: 3.8462, Train: 0.9643, Val: 0.6880, Test: 0.7040
Epoch: 20, Loss: 3.8834, Train: 0.9643, Val: 0.7020, Test: 0.7180
Epoch: 21, Loss: 3.7547, Train: 0.9643, Val: 0.7040, Test: 0.7230
Epoch: 22, Loss: 3.7970, Train: 0.9643, Val: 0.7120, Test: 0.7340
Epoch: 23, Loss: 3.8636, Train: 0.9643, Val: 0.7220, Test: 0.7410
Epoch: 24, Loss: 3.9326, Train: 0.9643, Val: 0.7300, Test: 0.7430
Epoch: 25, Loss: 3.6744, Train: 0.9643, Val: 0.7240, Test: 0.7480
Epoch: 26, Loss: 3.9606, Train: 0.9643, Val: 0.7280, Test: 0.7470
Epoch: 27, Loss: 3.8411, Train: 0.9643, Val: 0.7280, Test: 0.7480
Epoch: 28, Loss: 3.7195, Train: 0.9643, Val: 0.7220, Test: 0.7500
Epoch: 29, Loss: 3.7319, Train: 0.9714, Val: 0.7160, Test: 0.7460
Epoch: 30, Loss: 3.6074, Train: 0.9714, Val: 0.7140, Test: 0.7440
Epoch: 31, Loss: 3.5143, Train: 0.9714, Val: 0.7240, Test: 0.7510
Epoch: 32, Loss: 3.3281, Train: 0.9714, Val: 0.7220, Test: 0.7480
Epoch: 33, Loss: 3.3902, Train: 0.9714, Val: 0.7220, Test: 0.7470
Epoch: 34, Loss: 3.2764, Train: 0.9714, Val: 0.7280, Test: 0.7500
Epoch: 35, Loss: 3.4320, Train: 0.9786, Val: 0.7340, Test: 0.7500
Epoch: 36, Loss: 3.2599, Train: 0.9786, Val: 0.7380, Test: 0.7550
Epoch: 37, Loss: 3.8171, Train: 0.9857, Val: 0.7420, Test: 0.7590
Epoch: 38, Loss: 3.4975, Train: 0.9857, Val: 0.7480, Test: 0.7670
Epoch: 39, Loss: 3.6939, Train: 0.9857, Val: 0.7520, Test: 0.7720
Epoch: 40, Loss: 3.2101, Train: 0.9857, Val: 0.7560, Test: 0.7730
Epoch: 41, Loss: 3.0614, Train: 0.9857, Val: 0.7580, Test: 0.7750
Epoch: 42, Loss: 3.2538, Train: 0.9857, Val: 0.7620, Test: 0.7780
Epoch: 43, Loss: 2.8533, Train: 0.9857, Val: 0.7600, Test: 0.7790
Epoch: 44, Loss: 3.2028, Train: 0.9857, Val: 0.7600, Test: 0.7790
Epoch: 45, Loss: 3.1029, Train: 0.9857, Val: 0.7600, Test: 0.7800
Epoch: 46, Loss: 3.4889, Train: 0.9857, Val: 0.7600, Test: 0.7830
Epoch: 47, Loss: 2.8857, Train: 0.9857, Val: 0.7620, Test: 0.7850
Epoch: 48, Loss: 2.7351, Train: 0.9929, Val: 0.7520, Test: 0.7850
Epoch: 49, Loss: 3.2461, Train: 1.0000, Val: 0.7500, Test: 0.7840
Epoch: 50, Loss: 3.1248, Train: 1.0000, Val: 0.7460, Test: 0.7820
Epoch: 51, Loss: 2.9838, Train: 1.0000, Val: 0.7460, Test: 0.7840
Epoch: 52, Loss: 2.6858, Train: 1.0000, Val: 0.7460, Test: 0.7830
Epoch: 53, Loss: 3.0335, Train: 1.0000, Val: 0.7480, Test: 0.7820
Epoch: 54, Loss: 2.9176, Train: 1.0000, Val: 0.7500, Test: 0.7830
Epoch: 55, Loss: 3.0138, Train: 1.0000, Val: 0.7540, Test: 0.7850
Epoch: 56, Loss: 3.3387, Train: 1.0000, Val: 0.7540, Test: 0.7850
Epoch: 57, Loss: 2.8952, Train: 1.0000, Val: 0.7540, Test: 0.7870
Epoch: 58, Loss: 2.6038, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 59, Loss: 2.8811, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 60, Loss: 2.8138, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 61, Loss: 2.3977, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 62, Loss: 2.8305, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 63, Loss: 2.8365, Train: 1.0000, Val: 0.7620, Test: 0.7960
Epoch: 64, Loss: 3.1586, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 65, Loss: 2.8214, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 66, Loss: 3.0233, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 67, Loss: 2.8031, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 68, Loss: 2.6650, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 69, Loss: 2.9482, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 70, Loss: 2.7225, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 71, Loss: 3.4111, Train: 1.0000, Val: 0.7680, Test: 0.7960
Epoch: 72, Loss: 3.0117, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 73, Loss: 2.8146, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 74, Loss: 2.7239, Train: 1.0000, Val: 0.7680, Test: 0.7940
Epoch: 75, Loss: 2.8388, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 76, Loss: 2.7001, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 77, Loss: 2.8317, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 78, Loss: 2.7127, Train: 1.0000, Val: 0.7680, Test: 0.7830
Epoch: 79, Loss: 2.6136, Train: 1.0000, Val: 0.7680, Test: 0.7820
Epoch: 80, Loss: 2.8790, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 81, Loss: 2.6916, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 82, Loss: 2.8784, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 83, Loss: 2.8164, Train: 1.0000, Val: 0.7720, Test: 0.7840
Epoch: 84, Loss: 2.7598, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 85, Loss: 2.6936, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 86, Loss: 2.8073, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 87, Loss: 3.0727, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 88, Loss: 3.0981, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 89, Loss: 2.6024, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 90, Loss: 2.9202, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 91, Loss: 2.5290, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 92, Loss: 3.1599, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 93, Loss: 2.9680, Train: 1.0000, Val: 0.7800, Test: 0.7930
Epoch: 94, Loss: 2.3217, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 95, Loss: 2.6208, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 96, Loss: 2.8155, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 97, Loss: 2.7173, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 98, Loss: 2.5527, Train: 1.0000, Val: 0.7720, Test: 0.7890
Epoch: 99, Loss: 2.6771, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 100, Loss: 2.7737, Train: 1.0000, Val: 0.7760, Test: 0.7890
Epoch: 101, Loss: 2.3901, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 102, Loss: 2.9739, Train: 1.0000, Val: 0.7740, Test: 0.7850
Epoch: 103, Loss: 2.4418, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 104, Loss: 2.4125, Train: 1.0000, Val: 0.7680, Test: 0.7820
Epoch: 105, Loss: 2.4172, Train: 1.0000, Val: 0.7680, Test: 0.7790
Epoch: 106, Loss: 2.7182, Train: 1.0000, Val: 0.7680, Test: 0.7780
Epoch: 107, Loss: 2.4164, Train: 1.0000, Val: 0.7680, Test: 0.7760
Epoch: 108, Loss: 2.9557, Train: 1.0000, Val: 0.7660, Test: 0.7790
Epoch: 109, Loss: 2.5978, Train: 1.0000, Val: 0.7680, Test: 0.7820
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 110, Loss: 2.7262, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 111, Loss: 2.5005, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 112, Loss: 2.1515, Train: 1.0000, Val: 0.7620, Test: 0.7830
Epoch: 113, Loss: 2.5846, Train: 1.0000, Val: 0.7600, Test: 0.7850
Epoch: 114, Loss: 2.4908, Train: 1.0000, Val: 0.7660, Test: 0.7830
Epoch: 115, Loss: 2.7955, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 116, Loss: 2.7976, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 117, Loss: 2.7114, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 118, Loss: 2.3926, Train: 1.0000, Val: 0.7800, Test: 0.7890
Epoch: 119, Loss: 2.7262, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 120, Loss: 2.3643, Train: 1.0000, Val: 0.7800, Test: 0.7880
Epoch: 121, Loss: 2.6560, Train: 1.0000, Val: 0.7800, Test: 0.7890
Epoch: 122, Loss: 2.1912, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 123, Loss: 2.4658, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 124, Loss: 2.2782, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 125, Loss: 2.4851, Train: 1.0000, Val: 0.7800, Test: 0.7900
Epoch: 126, Loss: 2.4031, Train: 1.0000, Val: 0.7820, Test: 0.7900
Epoch: 127, Loss: 2.3784, Train: 1.0000, Val: 0.7780, Test: 0.7900
Epoch: 128, Loss: 2.3902, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 129, Loss: 2.3526, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 130, Loss: 2.5732, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 131, Loss: 2.5762, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 132, Loss: 2.6413, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 133, Loss: 2.5238, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 134, Loss: 2.2827, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 135, Loss: 2.5937, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 136, Loss: 2.5231, Train: 1.0000, Val: 0.7660, Test: 0.7870
Epoch: 137, Loss: 2.6922, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 138, Loss: 2.3054, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 139, Loss: 2.6553, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 140, Loss: 2.6915, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 141, Loss: 2.0130, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 142, Loss: 2.8904, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 143, Loss: 2.5106, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 144, Loss: 2.5994, Train: 1.0000, Val: 0.7820, Test: 0.7860
Epoch: 145, Loss: 2.2517, Train: 1.0000, Val: 0.7860, Test: 0.7850
Epoch: 146, Loss: 2.4551, Train: 1.0000, Val: 0.7860, Test: 0.7850
Epoch: 147, Loss: 2.6615, Train: 1.0000, Val: 0.7860, Test: 0.7860
Epoch: 148, Loss: 2.3709, Train: 1.0000, Val: 0.7880, Test: 0.7850
Epoch: 149, Loss: 2.6510, Train: 1.0000, Val: 0.7900, Test: 0.7830
Epoch: 150, Loss: 2.7981, Train: 1.0000, Val: 0.7840, Test: 0.7830
Epoch: 151, Loss: 2.4412, Train: 1.0000, Val: 0.7800, Test: 0.7820
Epoch: 152, Loss: 2.6557, Train: 1.0000, Val: 0.7760, Test: 0.7840
Epoch: 153, Loss: 2.5946, Train: 1.0000, Val: 0.7760, Test: 0.7840
Epoch: 154, Loss: 2.6098, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 155, Loss: 2.3474, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 156, Loss: 2.5190, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 157, Loss: 2.3345, Train: 1.0000, Val: 0.7720, Test: 0.7820
Epoch: 158, Loss: 2.7720, Train: 1.0000, Val: 0.7720, Test: 0.7810
Epoch: 159, Loss: 3.0289, Train: 1.0000, Val: 0.7720, Test: 0.7810
Epoch: 160, Loss: 2.6446, Train: 1.0000, Val: 0.7740, Test: 0.7820
Epoch: 161, Loss: 2.8803, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 162, Loss: 2.3904, Train: 1.0000, Val: 0.7760, Test: 0.7870
Epoch: 163, Loss: 2.7027, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 164, Loss: 2.2666, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 165, Loss: 2.3410, Train: 1.0000, Val: 0.7740, Test: 0.7840
Epoch: 166, Loss: 2.4609, Train: 1.0000, Val: 0.7760, Test: 0.7810
Epoch: 167, Loss: 2.5980, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 168, Loss: 2.4703, Train: 1.0000, Val: 0.7760, Test: 0.7820
Epoch: 169, Loss: 2.7431, Train: 1.0000, Val: 0.7760, Test: 0.7820
Epoch: 170, Loss: 2.6667, Train: 1.0000, Val: 0.7760, Test: 0.7810
Epoch: 171, Loss: 2.8528, Train: 1.0000, Val: 0.7760, Test: 0.7820
Epoch: 172, Loss: 2.5450, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 173, Loss: 2.6422, Train: 1.0000, Val: 0.7780, Test: 0.7840
Epoch: 174, Loss: 2.6375, Train: 1.0000, Val: 0.7780, Test: 0.7830
Epoch: 175, Loss: 2.4732, Train: 1.0000, Val: 0.7780, Test: 0.7800
Epoch: 176, Loss: 2.6227, Train: 1.0000, Val: 0.7780, Test: 0.7790
Epoch: 177, Loss: 2.7522, Train: 1.0000, Val: 0.7760, Test: 0.7780
Epoch: 178, Loss: 2.8028, Train: 1.0000, Val: 0.7740, Test: 0.7750
Epoch: 179, Loss: 2.5150, Train: 1.0000, Val: 0.7720, Test: 0.7760
Epoch: 180, Loss: 2.5150, Train: 1.0000, Val: 0.7700, Test: 0.7770
Epoch: 181, Loss: 2.7572, Train: 1.0000, Val: 0.7720, Test: 0.7750
Epoch: 182, Loss: 2.7964, Train: 1.0000, Val: 0.7720, Test: 0.7730
Epoch: 183, Loss: 2.7599, Train: 1.0000, Val: 0.7720, Test: 0.7710
Epoch: 184, Loss: 2.5449, Train: 1.0000, Val: 0.7740, Test: 0.7700
Epoch: 185, Loss: 2.5135, Train: 1.0000, Val: 0.7720, Test: 0.7720
Epoch: 186, Loss: 2.4078, Train: 1.0000, Val: 0.7720, Test: 0.7710
Epoch: 187, Loss: 2.7399, Train: 1.0000, Val: 0.7700, Test: 0.7710
Epoch: 188, Loss: 2.3653, Train: 1.0000, Val: 0.7700, Test: 0.7720
Epoch: 189, Loss: 2.3942, Train: 1.0000, Val: 0.7740, Test: 0.7760
Epoch: 190, Loss: 2.3298, Train: 1.0000, Val: 0.7740, Test: 0.7760
Epoch: 191, Loss: 2.5789, Train: 1.0000, Val: 0.7760, Test: 0.7760
Epoch: 192, Loss: 2.6791, Train: 1.0000, Val: 0.7740, Test: 0.7770
Epoch: 193, Loss: 2.1560, Train: 1.0000, Val: 0.7780, Test: 0.7790
Epoch: 194, Loss: 2.2664, Train: 1.0000, Val: 0.7780, Test: 0.7800
Epoch: 195, Loss: 2.3520, Train: 1.0000, Val: 0.7800, Test: 0.7830
Epoch: 196, Loss: 2.5319, Train: 1.0000, Val: 0.7800, Test: 0.7840
Epoch: 197, Loss: 2.4493, Train: 1.0000, Val: 0.7820, Test: 0.7860
Epoch: 198, Loss: 2.7800, Train: 1.0000, Val: 0.7820, Test: 0.7870
Epoch: 199, Loss: 2.3583, Train: 1.0000, Val: 0.7820, Test: 0.7880
Epoch: 200, Loss: 2.1035, Train: 1.0000, Val: 0.7800, Test: 0.7890
MAD:  0.3447
Best Test Accuracy: 0.7960, Val Accuracy: 0.7620, Train Accuracy: 1.0000
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9299, Train: 0.0571, Val: 0.0420, Test: 0.0680
Epoch: 2, Loss: 4.8259, Train: 0.1143, Val: 0.1100, Test: 0.1550
Epoch: 3, Loss: 4.7984, Train: 0.2429, Val: 0.2100, Test: 0.2520
Epoch: 4, Loss: 4.7549, Train: 0.3857, Val: 0.2800, Test: 0.3160
Epoch: 5, Loss: 4.6018, Train: 0.5000, Val: 0.3440, Test: 0.3700
Epoch: 6, Loss: 4.5854, Train: 0.5929, Val: 0.3780, Test: 0.4200
Epoch: 7, Loss: 4.4610, Train: 0.6429, Val: 0.4060, Test: 0.4470
Epoch: 8, Loss: 4.5039, Train: 0.6571, Val: 0.4320, Test: 0.4690
Epoch: 9, Loss: 4.4659, Train: 0.7143, Val: 0.4420, Test: 0.4910
Epoch: 10, Loss: 4.4041, Train: 0.7571, Val: 0.4680, Test: 0.5140
Epoch: 11, Loss: 4.2926, Train: 0.7857, Val: 0.4980, Test: 0.5480
Epoch: 12, Loss: 4.2177, Train: 0.8143, Val: 0.5120, Test: 0.5760
Epoch: 13, Loss: 4.1179, Train: 0.8714, Val: 0.5560, Test: 0.6160
Epoch: 14, Loss: 4.1406, Train: 0.9071, Val: 0.6020, Test: 0.6470
Epoch: 15, Loss: 4.1184, Train: 0.9071, Val: 0.6400, Test: 0.6900
Epoch: 16, Loss: 4.1597, Train: 0.9286, Val: 0.6740, Test: 0.7160
Epoch: 17, Loss: 4.0807, Train: 0.9571, Val: 0.7000, Test: 0.7420
Epoch: 18, Loss: 3.7887, Train: 0.9571, Val: 0.7240, Test: 0.7630
Epoch: 19, Loss: 4.0128, Train: 0.9571, Val: 0.7340, Test: 0.7760
Epoch: 20, Loss: 4.2158, Train: 0.9857, Val: 0.7340, Test: 0.7760
Epoch: 21, Loss: 3.8280, Train: 0.9857, Val: 0.7380, Test: 0.7680
Epoch: 22, Loss: 3.7435, Train: 0.9929, Val: 0.7400, Test: 0.7710
Epoch: 23, Loss: 3.9653, Train: 0.9929, Val: 0.7340, Test: 0.7740
Epoch: 24, Loss: 3.4871, Train: 0.9857, Val: 0.7320, Test: 0.7760
Epoch: 25, Loss: 3.5058, Train: 0.9857, Val: 0.7360, Test: 0.7820
Epoch: 26, Loss: 3.5093, Train: 0.9857, Val: 0.7460, Test: 0.7820
Epoch: 27, Loss: 3.4684, Train: 0.9857, Val: 0.7460, Test: 0.7820
Epoch: 28, Loss: 3.5188, Train: 0.9857, Val: 0.7560, Test: 0.7820
Epoch: 29, Loss: 3.4228, Train: 0.9857, Val: 0.7560, Test: 0.7850
Epoch: 30, Loss: 3.6127, Train: 0.9929, Val: 0.7560, Test: 0.7850
Epoch: 31, Loss: 3.6422, Train: 0.9929, Val: 0.7620, Test: 0.7820
Epoch: 32, Loss: 3.4135, Train: 0.9929, Val: 0.7660, Test: 0.7830
Epoch: 33, Loss: 3.6011, Train: 0.9929, Val: 0.7700, Test: 0.7870
Epoch: 34, Loss: 3.4390, Train: 0.9929, Val: 0.7740, Test: 0.7970
Epoch: 35, Loss: 3.3070, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 36, Loss: 3.4966, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 37, Loss: 3.2832, Train: 1.0000, Val: 0.7740, Test: 0.8040
Epoch: 38, Loss: 3.4529, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 39, Loss: 3.3191, Train: 1.0000, Val: 0.7740, Test: 0.8060
Epoch: 40, Loss: 3.3546, Train: 1.0000, Val: 0.7780, Test: 0.8090
Epoch: 41, Loss: 3.3073, Train: 1.0000, Val: 0.7800, Test: 0.8090
Epoch: 42, Loss: 3.2629, Train: 1.0000, Val: 0.7780, Test: 0.8100
Epoch: 43, Loss: 3.4070, Train: 1.0000, Val: 0.7800, Test: 0.8100
Epoch: 44, Loss: 3.1849, Train: 1.0000, Val: 0.7740, Test: 0.8130
Epoch: 45, Loss: 3.2512, Train: 1.0000, Val: 0.7760, Test: 0.8150
Epoch: 46, Loss: 3.2503, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 47, Loss: 3.0557, Train: 1.0000, Val: 0.7820, Test: 0.8140
Epoch: 48, Loss: 2.7255, Train: 1.0000, Val: 0.7820, Test: 0.8160
Epoch: 49, Loss: 2.9020, Train: 1.0000, Val: 0.7840, Test: 0.8160
Epoch: 50, Loss: 2.9699, Train: 1.0000, Val: 0.7860, Test: 0.8200
Epoch: 51, Loss: 3.2842, Train: 1.0000, Val: 0.7900, Test: 0.8160
Epoch: 52, Loss: 3.1101, Train: 1.0000, Val: 0.7900, Test: 0.8160
Epoch: 53, Loss: 3.2710, Train: 1.0000, Val: 0.7880, Test: 0.8170
Epoch: 54, Loss: 3.1372, Train: 1.0000, Val: 0.7880, Test: 0.8170
Epoch: 55, Loss: 3.1796, Train: 1.0000, Val: 0.7860, Test: 0.8200
Epoch: 56, Loss: 2.7108, Train: 1.0000, Val: 0.7840, Test: 0.8180
Epoch: 57, Loss: 3.0388, Train: 1.0000, Val: 0.7780, Test: 0.8160
Epoch: 58, Loss: 3.0655, Train: 1.0000, Val: 0.7760, Test: 0.8130
Epoch: 59, Loss: 2.9724, Train: 1.0000, Val: 0.7720, Test: 0.8100
Epoch: 60, Loss: 2.7090, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 61, Loss: 2.9484, Train: 1.0000, Val: 0.7760, Test: 0.8050
Epoch: 62, Loss: 2.7402, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 63, Loss: 2.8758, Train: 1.0000, Val: 0.7780, Test: 0.8070
Epoch: 64, Loss: 3.0585, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 65, Loss: 2.8545, Train: 1.0000, Val: 0.7760, Test: 0.8080
Epoch: 66, Loss: 2.9320, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 67, Loss: 2.9010, Train: 1.0000, Val: 0.7740, Test: 0.8080
Epoch: 68, Loss: 3.2265, Train: 1.0000, Val: 0.7720, Test: 0.8070
Epoch: 69, Loss: 2.5199, Train: 1.0000, Val: 0.7700, Test: 0.8070
Epoch: 70, Loss: 2.6080, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 71, Loss: 2.8982, Train: 1.0000, Val: 0.7680, Test: 0.8070
Epoch: 72, Loss: 2.5920, Train: 1.0000, Val: 0.7660, Test: 0.8070
Epoch: 73, Loss: 3.1138, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 74, Loss: 2.7246, Train: 1.0000, Val: 0.7660, Test: 0.8060
Epoch: 75, Loss: 2.6561, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 76, Loss: 2.9945, Train: 1.0000, Val: 0.7640, Test: 0.8050
Epoch: 77, Loss: 3.2316, Train: 1.0000, Val: 0.7640, Test: 0.8070
Epoch: 78, Loss: 2.6688, Train: 1.0000, Val: 0.7640, Test: 0.8060
Epoch: 79, Loss: 2.9980, Train: 1.0000, Val: 0.7660, Test: 0.8070
Epoch: 80, Loss: 2.8715, Train: 1.0000, Val: 0.7660, Test: 0.8100
Epoch: 81, Loss: 3.0717, Train: 1.0000, Val: 0.7660, Test: 0.8080
Epoch: 82, Loss: 2.3399, Train: 1.0000, Val: 0.7660, Test: 0.8060
Epoch: 83, Loss: 2.6902, Train: 1.0000, Val: 0.7640, Test: 0.8040
Epoch: 84, Loss: 2.9002, Train: 1.0000, Val: 0.7620, Test: 0.7990
Epoch: 85, Loss: 2.8315, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 86, Loss: 3.1774, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 87, Loss: 2.6795, Train: 1.0000, Val: 0.7640, Test: 0.7960
Epoch: 88, Loss: 2.9967, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 89, Loss: 2.3414, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 90, Loss: 2.8786, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 91, Loss: 2.7591, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 92, Loss: 2.4795, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 93, Loss: 2.6749, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 94, Loss: 2.9019, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 95, Loss: 2.6841, Train: 1.0000, Val: 0.7600, Test: 0.7960
Epoch: 96, Loss: 2.4613, Train: 1.0000, Val: 0.7620, Test: 0.7980
Epoch: 97, Loss: 2.6677, Train: 1.0000, Val: 0.7600, Test: 0.7980
Epoch: 98, Loss: 2.6456, Train: 1.0000, Val: 0.7580, Test: 0.7990
Epoch: 99, Loss: 2.8585, Train: 1.0000, Val: 0.7580, Test: 0.8000
Epoch: 100, Loss: 2.5646, Train: 1.0000, Val: 0.7580, Test: 0.8010
Epoch: 101, Loss: 2.6989, Train: 1.0000, Val: 0.7600, Test: 0.7990
Epoch: 102, Loss: 2.6773, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 103, Loss: 2.5867, Train: 1.0000, Val: 0.7620, Test: 0.8070
Epoch: 104, Loss: 2.5887, Train: 1.0000, Val: 0.7660, Test: 0.8070
Epoch: 105, Loss: 3.0075, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 106, Loss: 2.5199, Train: 1.0000, Val: 0.7720, Test: 0.8040
Epoch: 107, Loss: 2.9728, Train: 1.0000, Val: 0.7700, Test: 0.8060
Epoch: 108, Loss: 2.6056, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 109, Loss: 2.7256, Train: 1.0000, Val: 0.7680, Test: 0.8050
Epoch: 110, Loss: 2.3793, Train: 1.0000, Val: 0.7680, Test: 0.8090
Epoch: 111, Loss: 2.6134, Train: 1.0000, Val: 0.7620, Test: 0.8080
Epoch: 112, Loss: 2.7945, Train: 1.0000, Val: 0.7620, Test: 0.8050
Epoch: 113, Loss: 2.8573, Train: 1.0000, Val: 0.7600, Test: 0.7970
Epoch: 114, Loss: 2.5562, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 115, Loss: 2.7127, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 116, Loss: 2.6083, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 117, Loss: 2.5273, Train: 1.0000, Val: 0.7580, Test: 0.7910
Epoch: 118, Loss: 2.6344, Train: 1.0000, Val: 0.7580, Test: 0.7910
Epoch: 119, Loss: 2.1352, Train: 1.0000, Val: 0.7580, Test: 0.7930
Epoch: 120, Loss: 2.6237, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 121, Loss: 2.7708, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 122, Loss: 2.5741, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 123, Loss: 2.7628, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 124, Loss: 2.8772, Train: 1.0000, Val: 0.7660, Test: 0.7950
Epoch: 125, Loss: 2.9096, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 126, Loss: 3.0986, Train: 1.0000, Val: 0.7620, Test: 0.7930
Epoch: 127, Loss: 2.5758, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 128, Loss: 2.8852, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 129, Loss: 2.7485, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 130, Loss: 2.7555, Train: 1.0000, Val: 0.7580, Test: 0.7930
Epoch: 131, Loss: 2.7734, Train: 1.0000, Val: 0.7580, Test: 0.7910
Epoch: 132, Loss: 2.7350, Train: 1.0000, Val: 0.7580, Test: 0.7910
Epoch: 133, Loss: 2.3009, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 134, Loss: 2.5954, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 135, Loss: 2.6534, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 136, Loss: 2.3272, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 137, Loss: 2.7076, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 138, Loss: 2.4529, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 139, Loss: 2.5400, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 140, Loss: 2.5550, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 141, Loss: 2.7973, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 142, Loss: 2.3077, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 143, Loss: 3.3421, Train: 1.0000, Val: 0.7620, Test: 0.7890
Epoch: 144, Loss: 2.3318, Train: 1.0000, Val: 0.7600, Test: 0.7880
Epoch: 145, Loss: 2.5315, Train: 1.0000, Val: 0.7620, Test: 0.7870
Epoch: 146, Loss: 2.8533, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 147, Loss: 2.3450, Train: 1.0000, Val: 0.7660, Test: 0.7880
Epoch: 148, Loss: 2.7464, Train: 1.0000, Val: 0.7620, Test: 0.7890
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 149, Loss: 2.6271, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 150, Loss: 2.6351, Train: 1.0000, Val: 0.7600, Test: 0.7960
Epoch: 151, Loss: 2.6766, Train: 1.0000, Val: 0.7600, Test: 0.7960
Epoch: 152, Loss: 2.8917, Train: 1.0000, Val: 0.7620, Test: 0.7950
Epoch: 153, Loss: 2.4839, Train: 1.0000, Val: 0.7600, Test: 0.7950
Epoch: 154, Loss: 2.2264, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 155, Loss: 2.3881, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 156, Loss: 2.5813, Train: 1.0000, Val: 0.7600, Test: 0.7920
Epoch: 157, Loss: 2.5371, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 158, Loss: 2.7489, Train: 1.0000, Val: 0.7580, Test: 0.7930
Epoch: 159, Loss: 2.8466, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 160, Loss: 2.4245, Train: 1.0000, Val: 0.7580, Test: 0.7920
Epoch: 161, Loss: 2.3728, Train: 1.0000, Val: 0.7600, Test: 0.7940
Epoch: 162, Loss: 2.2086, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 163, Loss: 2.7408, Train: 1.0000, Val: 0.7600, Test: 0.7930
Epoch: 164, Loss: 2.2095, Train: 1.0000, Val: 0.7620, Test: 0.7920
Epoch: 165, Loss: 2.8764, Train: 1.0000, Val: 0.7620, Test: 0.7910
Epoch: 166, Loss: 2.9465, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 167, Loss: 2.7975, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 168, Loss: 2.6131, Train: 1.0000, Val: 0.7640, Test: 0.7900
Epoch: 169, Loss: 2.4104, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 170, Loss: 2.8984, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 171, Loss: 2.5393, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 172, Loss: 2.3842, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 173, Loss: 2.6500, Train: 1.0000, Val: 0.7620, Test: 0.7880
Epoch: 174, Loss: 2.6085, Train: 1.0000, Val: 0.7600, Test: 0.7900
Epoch: 175, Loss: 2.8033, Train: 1.0000, Val: 0.7620, Test: 0.7900
Epoch: 176, Loss: 2.6573, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 177, Loss: 2.7045, Train: 1.0000, Val: 0.7600, Test: 0.7910
Epoch: 178, Loss: 2.1792, Train: 1.0000, Val: 0.7640, Test: 0.7910
Epoch: 179, Loss: 2.9169, Train: 1.0000, Val: 0.7660, Test: 0.7910
Epoch: 180, Loss: 2.3489, Train: 1.0000, Val: 0.7640, Test: 0.7920
Epoch: 181, Loss: 2.7756, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 182, Loss: 2.2546, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 183, Loss: 2.9925, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 184, Loss: 2.3550, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 185, Loss: 2.3454, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 186, Loss: 2.6553, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 187, Loss: 2.6072, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 188, Loss: 2.4779, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 189, Loss: 2.1131, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 190, Loss: 2.3796, Train: 1.0000, Val: 0.7700, Test: 0.7970
Epoch: 191, Loss: 2.9864, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 192, Loss: 2.9465, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 193, Loss: 2.9933, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 194, Loss: 2.2779, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 195, Loss: 2.3267, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 196, Loss: 2.3311, Train: 1.0000, Val: 0.7640, Test: 0.7930
Epoch: 197, Loss: 2.5757, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 198, Loss: 2.5910, Train: 1.0000, Val: 0.7600, Test: 0.7890
Epoch: 199, Loss: 2.4821, Train: 1.0000, Val: 0.7600, Test: 0.7880
Epoch: 200, Loss: 2.4255, Train: 1.0000, Val: 0.7620, Test: 0.7890
MAD:  0.3406
Best Test Accuracy: 0.8200, Val Accuracy: 0.7860, Train Accuracy: 1.0000
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.8729, Train: 0.1429, Val: 0.0840, Test: 0.1040
Epoch: 2, Loss: 4.8016, Train: 0.3286, Val: 0.2080, Test: 0.2310
Epoch: 3, Loss: 4.6949, Train: 0.4714, Val: 0.3400, Test: 0.3810
Epoch: 4, Loss: 4.6715, Train: 0.6571, Val: 0.4480, Test: 0.4830
Epoch: 5, Loss: 4.5111, Train: 0.7357, Val: 0.4880, Test: 0.5390
Epoch: 6, Loss: 4.4694, Train: 0.7571, Val: 0.4820, Test: 0.5410
Epoch: 7, Loss: 4.2629, Train: 0.8071, Val: 0.5000, Test: 0.5390
Epoch: 8, Loss: 4.3267, Train: 0.8429, Val: 0.5100, Test: 0.5490
Epoch: 9, Loss: 4.0924, Train: 0.8786, Val: 0.5160, Test: 0.5540
Epoch: 10, Loss: 4.3166, Train: 0.8929, Val: 0.5400, Test: 0.5890
Epoch: 11, Loss: 4.4372, Train: 0.9286, Val: 0.5600, Test: 0.6260
Epoch: 12, Loss: 4.1856, Train: 0.9357, Val: 0.5880, Test: 0.6480
Epoch: 13, Loss: 4.3280, Train: 0.9429, Val: 0.6120, Test: 0.6690
Epoch: 14, Loss: 3.8698, Train: 0.9500, Val: 0.6380, Test: 0.6850
Epoch: 15, Loss: 3.7727, Train: 0.9643, Val: 0.6580, Test: 0.7060
Epoch: 16, Loss: 3.9973, Train: 0.9786, Val: 0.6780, Test: 0.7250
Epoch: 17, Loss: 3.9268, Train: 0.9786, Val: 0.7000, Test: 0.7400
Epoch: 18, Loss: 3.9648, Train: 0.9786, Val: 0.7180, Test: 0.7460
Epoch: 19, Loss: 3.7303, Train: 0.9786, Val: 0.7200, Test: 0.7570
Epoch: 20, Loss: 3.7946, Train: 0.9857, Val: 0.7240, Test: 0.7630
Epoch: 21, Loss: 3.8178, Train: 0.9857, Val: 0.7280, Test: 0.7660
Epoch: 22, Loss: 3.9087, Train: 0.9857, Val: 0.7320, Test: 0.7620
Epoch: 23, Loss: 3.5437, Train: 0.9857, Val: 0.7280, Test: 0.7520
Epoch: 24, Loss: 3.7151, Train: 0.9857, Val: 0.7280, Test: 0.7560
Epoch: 25, Loss: 3.4456, Train: 0.9857, Val: 0.7380, Test: 0.7560
Epoch: 26, Loss: 3.5712, Train: 0.9929, Val: 0.7420, Test: 0.7570
Epoch: 27, Loss: 3.4021, Train: 0.9929, Val: 0.7440, Test: 0.7630
Epoch: 28, Loss: 3.6737, Train: 0.9929, Val: 0.7460, Test: 0.7630
Epoch: 29, Loss: 3.3445, Train: 0.9929, Val: 0.7420, Test: 0.7670
Epoch: 30, Loss: 3.4345, Train: 0.9929, Val: 0.7480, Test: 0.7730
Epoch: 31, Loss: 3.3522, Train: 0.9929, Val: 0.7500, Test: 0.7770
Epoch: 32, Loss: 3.3182, Train: 0.9929, Val: 0.7540, Test: 0.7760
Epoch: 33, Loss: 3.4333, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 34, Loss: 3.4483, Train: 1.0000, Val: 0.7620, Test: 0.7850
Epoch: 35, Loss: 3.5391, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 36, Loss: 3.0227, Train: 1.0000, Val: 0.7680, Test: 0.7880
Epoch: 37, Loss: 2.9808, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 38, Loss: 3.3678, Train: 1.0000, Val: 0.7600, Test: 0.7840
Epoch: 39, Loss: 3.2831, Train: 1.0000, Val: 0.7640, Test: 0.7860
Epoch: 40, Loss: 3.1486, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 41, Loss: 3.1568, Train: 1.0000, Val: 0.7680, Test: 0.7890
Epoch: 42, Loss: 3.1154, Train: 1.0000, Val: 0.7680, Test: 0.7920
Epoch: 43, Loss: 3.4231, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 44, Loss: 3.2497, Train: 1.0000, Val: 0.7680, Test: 0.7950
Epoch: 45, Loss: 2.9536, Train: 1.0000, Val: 0.7640, Test: 0.7950
Epoch: 46, Loss: 2.7687, Train: 1.0000, Val: 0.7640, Test: 0.7940
Epoch: 47, Loss: 3.0272, Train: 1.0000, Val: 0.7680, Test: 0.8010
Epoch: 48, Loss: 3.3866, Train: 1.0000, Val: 0.7660, Test: 0.8040
Epoch: 49, Loss: 3.1968, Train: 1.0000, Val: 0.7600, Test: 0.8010
Epoch: 50, Loss: 3.0947, Train: 1.0000, Val: 0.7620, Test: 0.8040
Epoch: 51, Loss: 2.8886, Train: 1.0000, Val: 0.7620, Test: 0.8030
Epoch: 52, Loss: 2.9638, Train: 1.0000, Val: 0.7600, Test: 0.8020
Epoch: 53, Loss: 3.0671, Train: 1.0000, Val: 0.7600, Test: 0.8050
Epoch: 54, Loss: 2.9699, Train: 1.0000, Val: 0.7640, Test: 0.8030
Epoch: 55, Loss: 3.1997, Train: 1.0000, Val: 0.7620, Test: 0.8020
Epoch: 56, Loss: 3.2094, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 57, Loss: 2.8494, Train: 1.0000, Val: 0.7680, Test: 0.7980
Epoch: 58, Loss: 2.7829, Train: 1.0000, Val: 0.7660, Test: 0.7970
Epoch: 59, Loss: 2.7776, Train: 1.0000, Val: 0.7640, Test: 0.8000
Epoch: 60, Loss: 3.0324, Train: 1.0000, Val: 0.7640, Test: 0.8020
Epoch: 61, Loss: 3.1248, Train: 1.0000, Val: 0.7620, Test: 0.8050
Epoch: 62, Loss: 3.0495, Train: 1.0000, Val: 0.7640, Test: 0.8060
Epoch: 63, Loss: 2.8646, Train: 1.0000, Val: 0.7640, Test: 0.8090
Epoch: 64, Loss: 3.2038, Train: 1.0000, Val: 0.7640, Test: 0.8110
Epoch: 65, Loss: 2.7210, Train: 1.0000, Val: 0.7620, Test: 0.8130
Epoch: 66, Loss: 2.6136, Train: 1.0000, Val: 0.7720, Test: 0.8160
Epoch: 67, Loss: 2.6690, Train: 1.0000, Val: 0.7720, Test: 0.8120
Epoch: 68, Loss: 3.0038, Train: 1.0000, Val: 0.7700, Test: 0.8150
Epoch: 69, Loss: 2.8851, Train: 1.0000, Val: 0.7740, Test: 0.8160
Epoch: 70, Loss: 3.1630, Train: 1.0000, Val: 0.7760, Test: 0.8090
Epoch: 71, Loss: 3.1847, Train: 1.0000, Val: 0.7780, Test: 0.8050
Epoch: 72, Loss: 2.8634, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 73, Loss: 2.6635, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 74, Loss: 2.7554, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 75, Loss: 3.3606, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 76, Loss: 2.9471, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 77, Loss: 2.8072, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 78, Loss: 3.0383, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 79, Loss: 2.5411, Train: 1.0000, Val: 0.7700, Test: 0.7950
Epoch: 80, Loss: 2.6562, Train: 1.0000, Val: 0.7700, Test: 0.7960
Epoch: 81, Loss: 2.8515, Train: 1.0000, Val: 0.7700, Test: 0.7940
Epoch: 82, Loss: 2.6268, Train: 1.0000, Val: 0.7700, Test: 0.7930
Epoch: 83, Loss: 2.9658, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 84, Loss: 2.8088, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 85, Loss: 2.8272, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 86, Loss: 2.7869, Train: 1.0000, Val: 0.7700, Test: 0.8010
Epoch: 87, Loss: 2.6634, Train: 1.0000, Val: 0.7660, Test: 0.8010
Epoch: 88, Loss: 2.7787, Train: 1.0000, Val: 0.7700, Test: 0.8040
Epoch: 89, Loss: 2.7122, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 90, Loss: 2.8983, Train: 1.0000, Val: 0.7680, Test: 0.8060
Epoch: 91, Loss: 2.7219, Train: 1.0000, Val: 0.7700, Test: 0.8050
Epoch: 92, Loss: 2.5696, Train: 1.0000, Val: 0.7720, Test: 0.8060
Epoch: 93, Loss: 2.7865, Train: 1.0000, Val: 0.7720, Test: 0.8050
Epoch: 94, Loss: 2.4035, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 95, Loss: 2.7460, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 96, Loss: 2.7729, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 97, Loss: 2.8530, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 98, Loss: 3.1698, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 99, Loss: 2.6151, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 100, Loss: 2.3922, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 101, Loss: 2.6400, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 102, Loss: 3.1847, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 103, Loss: 2.5396, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 104, Loss: 2.5512, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 105, Loss: 2.8170, Train: 1.0000, Val: 0.7760, Test: 0.7900
Epoch: 106, Loss: 2.5262, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 107, Loss: 2.7756, Train: 1.0000, Val: 0.7740, Test: 0.7920
Epoch: 108, Loss: 2.4954, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 109, Loss: 2.7248, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 110, Loss: 2.4862, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 111, Loss: 2.7456, Train: 1.0000, Val: 0.7740, Test: 0.8000
Epoch: 112, Loss: 2.6004, Train: 1.0000, Val: 0.7720, Test: 0.8010
Epoch: 113, Loss: 2.7295, Train: 1.0000, Val: 0.7720, Test: 0.8020
Epoch: 114, Loss: 2.4492, Train: 1.0000, Val: 0.7720, Test: 0.8000
Epoch: 115, Loss: 2.6549, Train: 1.0000, Val: 0.7700, Test: 0.8000
Epoch: 116, Loss: 2.7427, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 117, Loss: 2.3790, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 118, Loss: 2.3680, Train: 1.0000, Val: 0.7800, Test: 0.7990
Epoch: 119, Loss: 2.7398, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 120, Loss: 2.7349, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 121, Loss: 2.3757, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 122, Loss: 2.6510, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 123, Loss: 2.3599, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 124, Loss: 2.6563, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 125, Loss: 2.3763, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 126, Loss: 2.7442, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 127, Loss: 2.6991, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 128, Loss: 3.1391, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 129, Loss: 2.5012, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 130, Loss: 2.6836, Train: 1.0000, Val: 0.7800, Test: 0.7950
Epoch: 131, Loss: 2.4619, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 132, Loss: 2.5382, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 133, Loss: 2.1706, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 134, Loss: 2.6202, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 135, Loss: 2.5840, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 136, Loss: 2.6308, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 137, Loss: 2.5803, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 138, Loss: 2.6743, Train: 1.0000, Val: 0.7800, Test: 0.7960
Epoch: 139, Loss: 2.2882, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 140, Loss: 2.6013, Train: 1.0000, Val: 0.7800, Test: 0.7970
Epoch: 141, Loss: 2.8065, Train: 1.0000, Val: 0.7820, Test: 0.7960
Epoch: 142, Loss: 3.0438, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 143, Loss: 2.6918, Train: 1.0000, Val: 0.7780, Test: 0.7970
Epoch: 144, Loss: 2.3860, Train: 1.0000, Val: 0.7780, Test: 0.7960
Epoch: 145, Loss: 2.5000, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 146, Loss: 2.2345, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 147, Loss: 2.5708, Train: 1.0000, Val: 0.7800, Test: 0.7910
Epoch: 148, Loss: 2.6794, Train: 1.0000, Val: 0.7780, Test: 0.7920
Epoch: 149, Loss: 2.7801, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 150, Loss: 2.4105, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 151, Loss: 2.5843, Train: 1.0000, Val: 0.7720, Test: 0.7960
Epoch: 152, Loss: 2.4954, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 153, Loss: 2.7365, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 154, Loss: 2.5695, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 155, Loss: 2.4729, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 156, Loss: 2.5266, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 157, Loss: 2.9231, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 158, Loss: 2.7196, Train: 1.0000, Val: 0.7740, Test: 0.7950
Epoch: 159, Loss: 2.1969, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 160, Loss: 2.2988, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 161, Loss: 2.3917, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 162, Loss: 2.2373, Train: 1.0000, Val: 0.7720, Test: 0.7940
Epoch: 163, Loss: 2.5491, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 164, Loss: 2.5442, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 165, Loss: 2.2954, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 166, Loss: 2.4602, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 167, Loss: 2.6742, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 168, Loss: 2.7405, Train: 1.0000, Val: 0.7780, Test: 0.8010
Epoch: 169, Loss: 2.2662, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 170, Loss: 2.3412, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 171, Loss: 2.6830, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 172, Loss: 2.3745, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 173, Loss: 2.6059, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 174, Loss: 2.7715, Train: 1.0000, Val: 0.7780, Test: 0.7980
Epoch: 175, Loss: 2.5681, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 176, Loss: 2.6052, Train: 1.0000, Val: 0.7740, Test: 0.7990
Epoch: 177, Loss: 2.7798, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 178, Loss: 2.7741, Train: 1.0000, Val: 0.7720, Test: 0.7970
Epoch: 179, Loss: 2.5154, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 180, Loss: 2.8537, Train: 1.0000, Val: 0.7720, Test: 0.7900
Epoch: 181, Loss: 2.2895, Train: 1.0000, Val: 0.7700, Test: 0.7880
Epoch: 182, Loss: 2.5128, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 183, Loss: 2.2874, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 184, Loss: 2.6151, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 185, Loss: 2.1075, Train: 1.0000, Val: 0.7700, Test: 0.7890
Epoch: 186, Loss: 2.5322, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 187, Loss: 2.6646, Train: 1.0000, Val: 0.7720, Test: 0.7900
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 188, Loss: 2.7511, Train: 1.0000, Val: 0.7740, Test: 0.7900
Epoch: 189, Loss: 2.3934, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 190, Loss: 2.5558, Train: 1.0000, Val: 0.7760, Test: 0.7930
Epoch: 191, Loss: 2.5522, Train: 1.0000, Val: 0.7760, Test: 0.7940
Epoch: 192, Loss: 2.4478, Train: 1.0000, Val: 0.7760, Test: 0.7950
Epoch: 193, Loss: 2.3549, Train: 1.0000, Val: 0.7820, Test: 0.7970
Epoch: 194, Loss: 2.4748, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 195, Loss: 2.9477, Train: 1.0000, Val: 0.7820, Test: 0.8020
Epoch: 196, Loss: 2.3019, Train: 1.0000, Val: 0.7800, Test: 0.8030
Epoch: 197, Loss: 2.5597, Train: 1.0000, Val: 0.7780, Test: 0.7990
Epoch: 198, Loss: 2.8369, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 199, Loss: 2.5468, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 200, Loss: 2.2775, Train: 1.0000, Val: 0.7760, Test: 0.7950
MAD:  0.3552
Best Test Accuracy: 0.8160, Val Accuracy: 0.7720, Train Accuracy: 1.0000
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0-1): 2 x ParallelGNNBlock(
      (conv1): GCNConv(128, 128)
      (conv2): GCNConv(128, 128)
    )
    (2): GCNConv(128, 128)
  )
  (proj): Linear(in_features=1433, out_features=128, bias=True)
  (mlp): Linear(in_features=128, out_features=7, bias=True)
)
Epoch: 1, Loss: 4.9148, Train: 0.0571, Val: 0.0300, Test: 0.0250
Epoch: 2, Loss: 4.8521, Train: 0.2071, Val: 0.0960, Test: 0.0970
Epoch: 3, Loss: 4.8118, Train: 0.3286, Val: 0.1660, Test: 0.1530
Epoch: 4, Loss: 4.7049, Train: 0.4571, Val: 0.2480, Test: 0.2180
Epoch: 5, Loss: 4.7215, Train: 0.5571, Val: 0.2960, Test: 0.2730
Epoch: 6, Loss: 4.4932, Train: 0.6500, Val: 0.3180, Test: 0.3170
Epoch: 7, Loss: 4.3002, Train: 0.6643, Val: 0.3560, Test: 0.3650
Epoch: 8, Loss: 4.4134, Train: 0.7214, Val: 0.4040, Test: 0.4070
Epoch: 9, Loss: 4.3279, Train: 0.7929, Val: 0.4300, Test: 0.4380
Epoch: 10, Loss: 4.3949, Train: 0.8214, Val: 0.4620, Test: 0.4690
Epoch: 11, Loss: 4.2807, Train: 0.8643, Val: 0.4860, Test: 0.4960
Epoch: 12, Loss: 4.2145, Train: 0.9000, Val: 0.4940, Test: 0.5170
Epoch: 13, Loss: 4.4320, Train: 0.9143, Val: 0.5140, Test: 0.5370
Epoch: 14, Loss: 4.3353, Train: 0.9286, Val: 0.5320, Test: 0.5510
Epoch: 15, Loss: 4.0033, Train: 0.9357, Val: 0.5440, Test: 0.5710
Epoch: 16, Loss: 4.0802, Train: 0.9357, Val: 0.5700, Test: 0.5850
Epoch: 17, Loss: 4.2556, Train: 0.9429, Val: 0.5780, Test: 0.6040
Epoch: 18, Loss: 3.8854, Train: 0.9429, Val: 0.6020, Test: 0.6130
Epoch: 19, Loss: 3.7671, Train: 0.9500, Val: 0.6080, Test: 0.6210
Epoch: 20, Loss: 4.1421, Train: 0.9571, Val: 0.6200, Test: 0.6340
Epoch: 21, Loss: 3.9110, Train: 0.9714, Val: 0.6260, Test: 0.6400
Epoch: 22, Loss: 3.8936, Train: 0.9714, Val: 0.6420, Test: 0.6510
Epoch: 23, Loss: 3.8093, Train: 1.0000, Val: 0.6580, Test: 0.6710
Epoch: 24, Loss: 3.7921, Train: 1.0000, Val: 0.6700, Test: 0.6880
Epoch: 25, Loss: 3.7071, Train: 1.0000, Val: 0.6780, Test: 0.6910
Epoch: 26, Loss: 3.8084, Train: 1.0000, Val: 0.6800, Test: 0.7070
Epoch: 27, Loss: 3.6666, Train: 1.0000, Val: 0.6960, Test: 0.7180
Epoch: 28, Loss: 3.6214, Train: 1.0000, Val: 0.7040, Test: 0.7240
Epoch: 29, Loss: 3.5641, Train: 1.0000, Val: 0.7040, Test: 0.7320
Epoch: 30, Loss: 3.5516, Train: 1.0000, Val: 0.7120, Test: 0.7350
Epoch: 31, Loss: 3.7892, Train: 1.0000, Val: 0.7160, Test: 0.7330
Epoch: 32, Loss: 3.1875, Train: 1.0000, Val: 0.7180, Test: 0.7340
Epoch: 33, Loss: 3.7470, Train: 1.0000, Val: 0.7160, Test: 0.7340
Epoch: 34, Loss: 3.4469, Train: 1.0000, Val: 0.7200, Test: 0.7330
Epoch: 35, Loss: 3.5275, Train: 1.0000, Val: 0.7260, Test: 0.7350
Epoch: 36, Loss: 3.2211, Train: 1.0000, Val: 0.7240, Test: 0.7370
Epoch: 37, Loss: 3.4001, Train: 1.0000, Val: 0.7300, Test: 0.7420
Epoch: 38, Loss: 3.1432, Train: 1.0000, Val: 0.7360, Test: 0.7490
Epoch: 39, Loss: 3.2064, Train: 1.0000, Val: 0.7360, Test: 0.7530
Epoch: 40, Loss: 3.3349, Train: 1.0000, Val: 0.7400, Test: 0.7630
Epoch: 41, Loss: 3.2418, Train: 1.0000, Val: 0.7300, Test: 0.7670
Epoch: 42, Loss: 3.5409, Train: 1.0000, Val: 0.7300, Test: 0.7680
Epoch: 43, Loss: 3.4002, Train: 1.0000, Val: 0.7260, Test: 0.7690
Epoch: 44, Loss: 3.5613, Train: 1.0000, Val: 0.7300, Test: 0.7700
Epoch: 45, Loss: 3.2179, Train: 1.0000, Val: 0.7340, Test: 0.7710
Epoch: 46, Loss: 3.3491, Train: 1.0000, Val: 0.7380, Test: 0.7750
Epoch: 47, Loss: 2.8728, Train: 1.0000, Val: 0.7400, Test: 0.7770
Epoch: 48, Loss: 3.2684, Train: 1.0000, Val: 0.7420, Test: 0.7740
Epoch: 49, Loss: 3.0494, Train: 1.0000, Val: 0.7400, Test: 0.7750
Epoch: 50, Loss: 3.0357, Train: 1.0000, Val: 0.7420, Test: 0.7760
Epoch: 51, Loss: 2.8298, Train: 1.0000, Val: 0.7420, Test: 0.7750
Epoch: 52, Loss: 2.9193, Train: 1.0000, Val: 0.7460, Test: 0.7750
Epoch: 53, Loss: 3.0467, Train: 1.0000, Val: 0.7460, Test: 0.7730
Epoch: 54, Loss: 3.4492, Train: 1.0000, Val: 0.7540, Test: 0.7740
Epoch: 55, Loss: 2.7190, Train: 1.0000, Val: 0.7640, Test: 0.7790
Epoch: 56, Loss: 2.8208, Train: 1.0000, Val: 0.7680, Test: 0.7790
Epoch: 57, Loss: 3.2754, Train: 1.0000, Val: 0.7620, Test: 0.7820
Epoch: 58, Loss: 2.8284, Train: 1.0000, Val: 0.7580, Test: 0.7800
Epoch: 59, Loss: 3.3216, Train: 1.0000, Val: 0.7600, Test: 0.7780
Epoch: 60, Loss: 3.0749, Train: 1.0000, Val: 0.7600, Test: 0.7790
Epoch: 61, Loss: 2.9207, Train: 1.0000, Val: 0.7600, Test: 0.7830
Epoch: 62, Loss: 2.7982, Train: 1.0000, Val: 0.7640, Test: 0.7830
Epoch: 63, Loss: 3.0302, Train: 1.0000, Val: 0.7640, Test: 0.7850
Epoch: 64, Loss: 3.1500, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 65, Loss: 3.0021, Train: 1.0000, Val: 0.7660, Test: 0.7920
Epoch: 66, Loss: 2.9774, Train: 1.0000, Val: 0.7660, Test: 0.7930
Epoch: 67, Loss: 2.9807, Train: 1.0000, Val: 0.7660, Test: 0.7940
Epoch: 68, Loss: 2.8957, Train: 1.0000, Val: 0.7660, Test: 0.7900
Epoch: 69, Loss: 3.0411, Train: 1.0000, Val: 0.7680, Test: 0.7930
Epoch: 70, Loss: 2.7703, Train: 1.0000, Val: 0.7680, Test: 0.7910
Epoch: 71, Loss: 2.8763, Train: 1.0000, Val: 0.7660, Test: 0.7890
Epoch: 72, Loss: 2.7644, Train: 1.0000, Val: 0.7640, Test: 0.7880
Epoch: 73, Loss: 2.8523, Train: 1.0000, Val: 0.7680, Test: 0.7870
Epoch: 74, Loss: 2.7224, Train: 1.0000, Val: 0.7680, Test: 0.7860
Epoch: 75, Loss: 3.1579, Train: 1.0000, Val: 0.7660, Test: 0.7840
Epoch: 76, Loss: 2.8062, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 77, Loss: 2.4066, Train: 1.0000, Val: 0.7660, Test: 0.7860
Epoch: 78, Loss: 2.5987, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 79, Loss: 2.9980, Train: 1.0000, Val: 0.7660, Test: 0.7850
Epoch: 80, Loss: 2.6488, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 81, Loss: 2.5123, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 82, Loss: 2.5999, Train: 1.0000, Val: 0.7720, Test: 0.7920
Epoch: 83, Loss: 2.9437, Train: 1.0000, Val: 0.7740, Test: 0.7930
Epoch: 84, Loss: 2.8921, Train: 1.0000, Val: 0.7700, Test: 0.7910
Epoch: 85, Loss: 2.8311, Train: 1.0000, Val: 0.7720, Test: 0.7950
Epoch: 86, Loss: 2.2995, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 87, Loss: 2.8268, Train: 1.0000, Val: 0.7740, Test: 0.7970
Epoch: 88, Loss: 2.9722, Train: 1.0000, Val: 0.7720, Test: 0.7990
Epoch: 89, Loss: 2.6839, Train: 1.0000, Val: 0.7720, Test: 0.7980
Epoch: 90, Loss: 2.4162, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 91, Loss: 2.8222, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 92, Loss: 2.6285, Train: 1.0000, Val: 0.7740, Test: 0.7980
Epoch: 93, Loss: 2.8066, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 94, Loss: 2.7471, Train: 1.0000, Val: 0.7760, Test: 0.8010
Epoch: 95, Loss: 2.8704, Train: 1.0000, Val: 0.7760, Test: 0.8000
Epoch: 96, Loss: 2.5419, Train: 1.0000, Val: 0.7760, Test: 0.7990
Epoch: 97, Loss: 2.6597, Train: 1.0000, Val: 0.7800, Test: 0.7980
Epoch: 98, Loss: 2.5353, Train: 1.0000, Val: 0.7780, Test: 0.7940
Epoch: 99, Loss: 2.8258, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 100, Loss: 2.5330, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 101, Loss: 2.6501, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 102, Loss: 2.8259, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 103, Loss: 2.8001, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 104, Loss: 2.5431, Train: 1.0000, Val: 0.7700, Test: 0.7850
/root/code/DIR/DIR-GNN/train/cora.py:470: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"./pkl/{save_name}.pkl"))
Epoch: 105, Loss: 2.7374, Train: 1.0000, Val: 0.7680, Test: 0.7840
Epoch: 106, Loss: 2.8216, Train: 1.0000, Val: 0.7680, Test: 0.7850
Epoch: 107, Loss: 2.5596, Train: 1.0000, Val: 0.7680, Test: 0.7820
Epoch: 108, Loss: 2.5052, Train: 1.0000, Val: 0.7680, Test: 0.7810
Epoch: 109, Loss: 2.3634, Train: 1.0000, Val: 0.7720, Test: 0.7830
Epoch: 110, Loss: 2.7245, Train: 1.0000, Val: 0.7720, Test: 0.7840
Epoch: 111, Loss: 2.5497, Train: 1.0000, Val: 0.7740, Test: 0.7820
Epoch: 112, Loss: 2.7641, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 113, Loss: 2.5248, Train: 1.0000, Val: 0.7740, Test: 0.7850
Epoch: 114, Loss: 2.6240, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 115, Loss: 2.5176, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 116, Loss: 2.8924, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 117, Loss: 2.5231, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 118, Loss: 2.5372, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 119, Loss: 3.0678, Train: 1.0000, Val: 0.7720, Test: 0.7840
Epoch: 120, Loss: 2.8763, Train: 1.0000, Val: 0.7760, Test: 0.7860
Epoch: 121, Loss: 2.7247, Train: 1.0000, Val: 0.7740, Test: 0.7870
Epoch: 122, Loss: 2.5213, Train: 1.0000, Val: 0.7740, Test: 0.7880
Epoch: 123, Loss: 2.6635, Train: 1.0000, Val: 0.7720, Test: 0.7910
Epoch: 124, Loss: 2.9115, Train: 1.0000, Val: 0.7740, Test: 0.7910
Epoch: 125, Loss: 2.6540, Train: 1.0000, Val: 0.7780, Test: 0.7910
Epoch: 126, Loss: 2.3303, Train: 1.0000, Val: 0.7780, Test: 0.7930
Epoch: 127, Loss: 2.6108, Train: 1.0000, Val: 0.7740, Test: 0.7940
Epoch: 128, Loss: 2.4567, Train: 1.0000, Val: 0.7760, Test: 0.7980
Epoch: 129, Loss: 2.6941, Train: 1.0000, Val: 0.7760, Test: 0.7960
Epoch: 130, Loss: 2.5789, Train: 1.0000, Val: 0.7760, Test: 0.7970
Epoch: 131, Loss: 2.9718, Train: 1.0000, Val: 0.7740, Test: 0.7960
Epoch: 132, Loss: 2.3743, Train: 1.0000, Val: 0.7780, Test: 0.7950
Epoch: 133, Loss: 2.3899, Train: 1.0000, Val: 0.7760, Test: 0.7910
Epoch: 134, Loss: 2.6243, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 135, Loss: 2.6930, Train: 1.0000, Val: 0.7740, Test: 0.7860
Epoch: 136, Loss: 2.6402, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 137, Loss: 2.5164, Train: 1.0000, Val: 0.7720, Test: 0.7840
Epoch: 138, Loss: 2.4851, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 139, Loss: 2.5259, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 140, Loss: 2.6606, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 141, Loss: 2.2099, Train: 1.0000, Val: 0.7700, Test: 0.7810
Epoch: 142, Loss: 2.6184, Train: 1.0000, Val: 0.7700, Test: 0.7800
Epoch: 143, Loss: 2.3729, Train: 1.0000, Val: 0.7700, Test: 0.7800
Epoch: 144, Loss: 2.7365, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 145, Loss: 2.6909, Train: 1.0000, Val: 0.7700, Test: 0.7820
Epoch: 146, Loss: 2.1702, Train: 1.0000, Val: 0.7680, Test: 0.7830
Epoch: 147, Loss: 2.3969, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 148, Loss: 2.9574, Train: 1.0000, Val: 0.7720, Test: 0.7840
Epoch: 149, Loss: 2.6788, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 150, Loss: 2.5847, Train: 1.0000, Val: 0.7700, Test: 0.7860
Epoch: 151, Loss: 2.7827, Train: 1.0000, Val: 0.7700, Test: 0.7870
Epoch: 152, Loss: 3.0510, Train: 1.0000, Val: 0.7700, Test: 0.7850
Epoch: 153, Loss: 2.5530, Train: 1.0000, Val: 0.7700, Test: 0.7840
Epoch: 154, Loss: 2.3335, Train: 1.0000, Val: 0.7720, Test: 0.7850
Epoch: 155, Loss: 2.3557, Train: 1.0000, Val: 0.7720, Test: 0.7860
Epoch: 156, Loss: 2.1076, Train: 1.0000, Val: 0.7720, Test: 0.7870
Epoch: 157, Loss: 2.4227, Train: 1.0000, Val: 0.7720, Test: 0.7880
Epoch: 158, Loss: 2.8141, Train: 1.0000, Val: 0.7740, Test: 0.7890
Epoch: 159, Loss: 2.8464, Train: 1.0000, Val: 0.7760, Test: 0.7880
Epoch: 160, Loss: 2.4838, Train: 1.0000, Val: 0.7780, Test: 0.7890
Epoch: 161, Loss: 2.2829, Train: 1.0000, Val: 0.7800, Test: 0.7880
Epoch: 162, Loss: 2.4286, Train: 1.0000, Val: 0.7780, Test: 0.7860
Epoch: 163, Loss: 2.0884, Train: 1.0000, Val: 0.7780, Test: 0.7840
Epoch: 164, Loss: 2.3409, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 165, Loss: 2.2573, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 166, Loss: 2.7055, Train: 1.0000, Val: 0.7740, Test: 0.7830
Epoch: 167, Loss: 2.4685, Train: 1.0000, Val: 0.7760, Test: 0.7830
Epoch: 168, Loss: 2.3234, Train: 1.0000, Val: 0.7740, Test: 0.7820
Epoch: 169, Loss: 2.4634, Train: 1.0000, Val: 0.7740, Test: 0.7770
Epoch: 170, Loss: 2.5980, Train: 1.0000, Val: 0.7780, Test: 0.7770
Epoch: 171, Loss: 2.6885, Train: 1.0000, Val: 0.7780, Test: 0.7790
Epoch: 172, Loss: 2.6139, Train: 1.0000, Val: 0.7780, Test: 0.7780
Epoch: 173, Loss: 2.5274, Train: 1.0000, Val: 0.7780, Test: 0.7750
Epoch: 174, Loss: 2.6391, Train: 1.0000, Val: 0.7740, Test: 0.7750
Epoch: 175, Loss: 2.5189, Train: 1.0000, Val: 0.7760, Test: 0.7760
Epoch: 176, Loss: 2.3966, Train: 1.0000, Val: 0.7760, Test: 0.7780
Epoch: 177, Loss: 2.2443, Train: 1.0000, Val: 0.7760, Test: 0.7760
Epoch: 178, Loss: 2.5902, Train: 1.0000, Val: 0.7760, Test: 0.7780
Epoch: 179, Loss: 2.9005, Train: 1.0000, Val: 0.7760, Test: 0.7780
Epoch: 180, Loss: 2.3815, Train: 1.0000, Val: 0.7760, Test: 0.7780
Epoch: 181, Loss: 2.3604, Train: 1.0000, Val: 0.7780, Test: 0.7780
Epoch: 182, Loss: 2.4634, Train: 1.0000, Val: 0.7800, Test: 0.7770
Epoch: 183, Loss: 2.5812, Train: 1.0000, Val: 0.7800, Test: 0.7780
Epoch: 184, Loss: 2.7390, Train: 1.0000, Val: 0.7780, Test: 0.7780
Epoch: 185, Loss: 2.7167, Train: 1.0000, Val: 0.7780, Test: 0.7820
Epoch: 186, Loss: 2.6769, Train: 1.0000, Val: 0.7780, Test: 0.7800
Epoch: 187, Loss: 2.6728, Train: 1.0000, Val: 0.7780, Test: 0.7770
Epoch: 188, Loss: 2.2760, Train: 1.0000, Val: 0.7760, Test: 0.7790
Epoch: 189, Loss: 2.5668, Train: 1.0000, Val: 0.7760, Test: 0.7810
Epoch: 190, Loss: 2.7023, Train: 1.0000, Val: 0.7760, Test: 0.7810
Epoch: 191, Loss: 2.7157, Train: 1.0000, Val: 0.7760, Test: 0.7820
Epoch: 192, Loss: 2.5947, Train: 1.0000, Val: 0.7760, Test: 0.7840
Epoch: 193, Loss: 2.7015, Train: 1.0000, Val: 0.7780, Test: 0.7850
Epoch: 194, Loss: 2.2554, Train: 1.0000, Val: 0.7780, Test: 0.7850
Epoch: 195, Loss: 2.7596, Train: 1.0000, Val: 0.7780, Test: 0.7850
Epoch: 196, Loss: 2.4038, Train: 1.0000, Val: 0.7780, Test: 0.7830
Epoch: 197, Loss: 2.4648, Train: 1.0000, Val: 0.7780, Test: 0.7840
Epoch: 198, Loss: 2.5138, Train: 1.0000, Val: 0.7780, Test: 0.7820
Epoch: 199, Loss: 2.3381, Train: 1.0000, Val: 0.7720, Test: 0.7810
Epoch: 200, Loss: 2.2506, Train: 1.0000, Val: 0.7720, Test: 0.7820
MAD:  0.4018
Best Test Accuracy: 0.8010, Val Accuracy: 0.7760, Train Accuracy: 1.0000
Training completed.
Average Test Accuracy:  0.8108888888888889 ± 0.008672362800483448
Average MAD:  0.39724444444444446 ± 0.05911281325870072
