Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1433, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 2, Loss: 1.1738, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 3, Loss: 1.1179, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 4, Loss: 1.1043, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 5, Loss: 1.1334, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 6, Loss: 1.1148, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 7, Loss: 1.1206, Train: 0.3500, Val: 0.2000, Test: 0.1890
Epoch: 8, Loss: 1.1213, Train: 0.3333, Val: 0.3900, Test: 0.4170
Epoch: 9, Loss: 1.0914, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.0812, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.1079, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.1546, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 13, Loss: 1.1076, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 14, Loss: 1.1277, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 15, Loss: 1.1247, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 16, Loss: 1.1072, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 17, Loss: 1.1172, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 18, Loss: 1.0898, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 19, Loss: 1.0949, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 20, Loss: 1.1217, Train: 0.3500, Val: 0.3900, Test: 0.4150
Epoch: 21, Loss: 1.0699, Train: 0.3667, Val: 0.3880, Test: 0.4180
Epoch: 22, Loss: 1.0764, Train: 0.4333, Val: 0.4000, Test: 0.4250
Epoch: 23, Loss: 1.0804, Train: 0.4500, Val: 0.4220, Test: 0.4540
Epoch: 24, Loss: 1.1299, Train: 0.6333, Val: 0.5420, Test: 0.5330
Epoch: 25, Loss: 1.0696, Train: 0.4500, Val: 0.2600, Test: 0.2750
Epoch: 26, Loss: 1.1052, Train: 0.4833, Val: 0.3080, Test: 0.2800
Epoch: 27, Loss: 1.1106, Train: 0.3667, Val: 0.2240, Test: 0.2040
Epoch: 28, Loss: 1.1089, Train: 0.3333, Val: 0.1980, Test: 0.1840
Epoch: 29, Loss: 1.1039, Train: 0.3500, Val: 0.2040, Test: 0.1880
Epoch: 30, Loss: 1.1217, Train: 0.3333, Val: 0.2060, Test: 0.1960
Epoch: 31, Loss: 1.1099, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.0942, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 33, Loss: 1.0955, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 34, Loss: 1.0973, Train: 0.3333, Val: 0.1960, Test: 0.1820
Epoch: 35, Loss: 1.1177, Train: 0.4000, Val: 0.2360, Test: 0.2190
Epoch: 36, Loss: 1.1289, Train: 0.5500, Val: 0.3660, Test: 0.3690
Epoch: 37, Loss: 1.0787, Train: 0.5667, Val: 0.4040, Test: 0.4020
Epoch: 38, Loss: 1.0993, Train: 0.5833, Val: 0.4520, Test: 0.4420
Epoch: 39, Loss: 1.1135, Train: 0.5833, Val: 0.4760, Test: 0.4710
Epoch: 40, Loss: 1.0898, Train: 0.4333, Val: 0.4280, Test: 0.4540
Epoch: 41, Loss: 1.0896, Train: 0.4667, Val: 0.4300, Test: 0.4520
Epoch: 42, Loss: 1.0903, Train: 0.4667, Val: 0.4260, Test: 0.4500
Epoch: 43, Loss: 1.0871, Train: 0.4167, Val: 0.4220, Test: 0.4410
Epoch: 44, Loss: 1.0774, Train: 0.4000, Val: 0.4180, Test: 0.4380
Epoch: 45, Loss: 1.0840, Train: 0.5667, Val: 0.4600, Test: 0.4710
Epoch: 46, Loss: 1.0859, Train: 0.6167, Val: 0.4880, Test: 0.4790
Epoch: 47, Loss: 1.0568, Train: 0.6833, Val: 0.5760, Test: 0.5820
Epoch: 48, Loss: 1.0692, Train: 0.7167, Val: 0.6020, Test: 0.6230
Epoch: 49, Loss: 1.0872, Train: 0.6833, Val: 0.6420, Test: 0.6160
Epoch: 50, Loss: 1.1266, Train: 0.7500, Val: 0.6240, Test: 0.6040
Epoch: 51, Loss: 1.1071, Train: 0.7333, Val: 0.5980, Test: 0.5780
Epoch: 52, Loss: 1.0283, Train: 0.7500, Val: 0.5980, Test: 0.5710
Epoch: 53, Loss: 1.0826, Train: 0.7167, Val: 0.5740, Test: 0.5480
Epoch: 54, Loss: 1.0501, Train: 0.7167, Val: 0.5300, Test: 0.5170
Epoch: 55, Loss: 1.1240, Train: 0.6833, Val: 0.5240, Test: 0.5180
Epoch: 56, Loss: 1.0526, Train: 0.6500, Val: 0.5320, Test: 0.5350
Epoch: 57, Loss: 1.0559, Train: 0.6167, Val: 0.5280, Test: 0.5450
Epoch: 58, Loss: 1.0614, Train: 0.5667, Val: 0.5320, Test: 0.5420
Epoch: 59, Loss: 1.0479, Train: 0.5500, Val: 0.5540, Test: 0.5610
Epoch: 60, Loss: 1.0267, Train: 0.5333, Val: 0.5760, Test: 0.5890
Epoch: 61, Loss: 1.0439, Train: 0.5667, Val: 0.5860, Test: 0.6010
Epoch: 62, Loss: 1.0032, Train: 0.5500, Val: 0.5940, Test: 0.6040
Epoch: 63, Loss: 0.9989, Train: 0.5500, Val: 0.5940, Test: 0.6170
Epoch: 64, Loss: 0.9891, Train: 0.5500, Val: 0.6000, Test: 0.6180
Epoch: 65, Loss: 0.9206, Train: 0.5833, Val: 0.6000, Test: 0.6230
Epoch: 66, Loss: 0.9446, Train: 0.6333, Val: 0.6040, Test: 0.6200
Epoch: 67, Loss: 0.8626, Train: 0.6333, Val: 0.6300, Test: 0.6240
Epoch: 68, Loss: 0.8500, Train: 0.6333, Val: 0.6360, Test: 0.6280
Epoch: 69, Loss: 0.8738, Train: 0.6333, Val: 0.6180, Test: 0.6340
Epoch: 70, Loss: 0.8079, Train: 0.6333, Val: 0.6200, Test: 0.6430
Epoch: 71, Loss: 0.8201, Train: 0.6333, Val: 0.6340, Test: 0.6510
Epoch: 72, Loss: 0.7467, Train: 0.6500, Val: 0.6520, Test: 0.6540
Epoch: 73, Loss: 0.7334, Train: 0.6500, Val: 0.6500, Test: 0.6600
Epoch: 74, Loss: 0.6823, Train: 0.6500, Val: 0.6000, Test: 0.6210
Epoch: 75, Loss: 0.7296, Train: 0.6500, Val: 0.6540, Test: 0.6600
Epoch: 76, Loss: 0.6614, Train: 0.6500, Val: 0.6660, Test: 0.6790
Epoch: 77, Loss: 0.6344, Train: 0.6833, Val: 0.6720, Test: 0.6760
Epoch: 78, Loss: 0.5864, Train: 0.7167, Val: 0.6700, Test: 0.6670
Epoch: 79, Loss: 0.6010, Train: 0.8167, Val: 0.7100, Test: 0.7120
Epoch: 80, Loss: 0.5624, Train: 0.8667, Val: 0.7440, Test: 0.7450
Epoch: 81, Loss: 0.6171, Train: 0.9167, Val: 0.7600, Test: 0.7480
Epoch: 82, Loss: 0.5514, Train: 0.9000, Val: 0.7680, Test: 0.7390
Epoch: 83, Loss: 0.5952, Train: 0.9000, Val: 0.7600, Test: 0.7410
Epoch: 84, Loss: 0.5970, Train: 0.9000, Val: 0.7580, Test: 0.7590
Epoch: 85, Loss: 0.4854, Train: 0.8833, Val: 0.7580, Test: 0.7590
Epoch: 86, Loss: 0.5283, Train: 0.9000, Val: 0.7680, Test: 0.7660
Epoch: 87, Loss: 0.5265, Train: 0.9333, Val: 0.7800, Test: 0.7750
Epoch: 88, Loss: 0.4651, Train: 0.9500, Val: 0.7920, Test: 0.7900
Epoch: 89, Loss: 0.4616, Train: 0.9500, Val: 0.7940, Test: 0.7710
Epoch: 90, Loss: 0.4435, Train: 0.9500, Val: 0.7700, Test: 0.7460
Epoch: 91, Loss: 0.5203, Train: 0.9667, Val: 0.7940, Test: 0.7660
Epoch: 92, Loss: 0.4464, Train: 0.9500, Val: 0.7640, Test: 0.7410
Epoch: 93, Loss: 0.3547, Train: 0.9167, Val: 0.7440, Test: 0.7040
Epoch: 94, Loss: 0.3109, Train: 0.9500, Val: 0.7800, Test: 0.7520
Epoch: 95, Loss: 0.3006, Train: 0.9500, Val: 0.7980, Test: 0.7720
Epoch: 96, Loss: 0.2933, Train: 0.9500, Val: 0.8120, Test: 0.7840
Epoch: 97, Loss: 0.2759, Train: 0.9500, Val: 0.7700, Test: 0.7520
Epoch: 98, Loss: 0.2743, Train: 0.9500, Val: 0.7660, Test: 0.7390
Epoch: 99, Loss: 0.3034, Train: 0.9667, Val: 0.8000, Test: 0.7880
Epoch: 100, Loss: 0.1685, Train: 0.9667, Val: 0.7860, Test: 0.7760
MAD:  0.4837
Best Test Accuracy: 0.7900, Val Accuracy: 0.7920, Train Accuracy: 0.9500
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1225, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 2, Loss: 1.1250, Train: 0.3000, Val: 0.2720, Test: 0.2510
Epoch: 3, Loss: 1.1147, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 4, Loss: 1.1165, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.1019, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 6, Loss: 1.0787, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 7, Loss: 1.1186, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 8, Loss: 1.1212, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 9, Loss: 1.0990, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 10, Loss: 1.1479, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 11, Loss: 1.1054, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 12, Loss: 1.1258, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 13, Loss: 1.1074, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 14, Loss: 1.1163, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 15, Loss: 1.1365, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 16, Loss: 1.1327, Train: 0.4333, Val: 0.4560, Test: 0.4840
Epoch: 17, Loss: 1.1313, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 18, Loss: 1.1318, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 19, Loss: 1.1219, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 20, Loss: 1.0717, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 21, Loss: 1.0847, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 22, Loss: 1.1357, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 23, Loss: 1.1363, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 24, Loss: 1.1746, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 25, Loss: 1.1209, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 26, Loss: 1.0974, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 27, Loss: 1.0909, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 28, Loss: 1.0906, Train: 0.5167, Val: 0.4540, Test: 0.4620
Epoch: 29, Loss: 1.1009, Train: 0.4000, Val: 0.2200, Test: 0.2070
Epoch: 30, Loss: 1.1106, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 31, Loss: 1.1074, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.0781, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 33, Loss: 1.1183, Train: 0.3333, Val: 0.1960, Test: 0.1790
Epoch: 34, Loss: 1.0926, Train: 0.3500, Val: 0.4160, Test: 0.4110
Epoch: 35, Loss: 1.1246, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 36, Loss: 1.1112, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 37, Loss: 1.1025, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 38, Loss: 1.1143, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 39, Loss: 1.0865, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 40, Loss: 1.0971, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 41, Loss: 1.1402, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 42, Loss: 1.0759, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 43, Loss: 1.0874, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 44, Loss: 1.1490, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 45, Loss: 1.1376, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 46, Loss: 1.1256, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 47, Loss: 1.0995, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 48, Loss: 1.1273, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 49, Loss: 1.0695, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 50, Loss: 1.0882, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 51, Loss: 1.1103, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 52, Loss: 1.1184, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 53, Loss: 1.0841, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 54, Loss: 1.0854, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 55, Loss: 1.0662, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 56, Loss: 1.1162, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 57, Loss: 1.1177, Train: 0.3667, Val: 0.4220, Test: 0.4120
Epoch: 58, Loss: 1.1339, Train: 0.5667, Val: 0.4080, Test: 0.3960
Epoch: 59, Loss: 1.0972, Train: 0.3833, Val: 0.2220, Test: 0.2030
Epoch: 60, Loss: 1.1159, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 61, Loss: 1.0734, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 62, Loss: 1.0838, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 63, Loss: 1.0991, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 64, Loss: 1.0805, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 65, Loss: 1.0890, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 66, Loss: 1.0962, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 67, Loss: 1.1028, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 68, Loss: 1.0909, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 69, Loss: 1.1005, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 70, Loss: 1.0813, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 71, Loss: 1.0993, Train: 0.4167, Val: 0.2480, Test: 0.2370
Epoch: 72, Loss: 1.0860, Train: 0.5000, Val: 0.3740, Test: 0.3500
Epoch: 73, Loss: 1.1048, Train: 0.6000, Val: 0.4700, Test: 0.4560
Epoch: 74, Loss: 1.1150, Train: 0.6167, Val: 0.5240, Test: 0.5100
Epoch: 75, Loss: 1.0960, Train: 0.4000, Val: 0.4240, Test: 0.4210
Epoch: 76, Loss: 1.1135, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 77, Loss: 1.1187, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 78, Loss: 1.0852, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 79, Loss: 1.0798, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 80, Loss: 1.1007, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 81, Loss: 1.0948, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 82, Loss: 1.0841, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 83, Loss: 1.0631, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 84, Loss: 1.0927, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 85, Loss: 1.0836, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 86, Loss: 1.0539, Train: 0.4000, Val: 0.4360, Test: 0.4300
Epoch: 87, Loss: 1.0777, Train: 0.6167, Val: 0.6260, Test: 0.6240
Epoch: 88, Loss: 1.0584, Train: 0.6000, Val: 0.5940, Test: 0.6110
Epoch: 89, Loss: 1.0652, Train: 0.5833, Val: 0.5600, Test: 0.5850
Epoch: 90, Loss: 1.0697, Train: 0.5500, Val: 0.5420, Test: 0.5670
Epoch: 91, Loss: 1.0662, Train: 0.5667, Val: 0.5380, Test: 0.5670
Epoch: 92, Loss: 1.0524, Train: 0.6000, Val: 0.5640, Test: 0.5970
Epoch: 93, Loss: 1.0727, Train: 0.6500, Val: 0.5940, Test: 0.6250
Epoch: 94, Loss: 1.0675, Train: 0.6833, Val: 0.6220, Test: 0.6480
Epoch: 95, Loss: 1.0911, Train: 0.6833, Val: 0.6340, Test: 0.6570
Epoch: 96, Loss: 1.0872, Train: 0.7333, Val: 0.6780, Test: 0.6820
Epoch: 97, Loss: 1.0413, Train: 0.8000, Val: 0.6960, Test: 0.7090
Epoch: 98, Loss: 1.0163, Train: 0.8500, Val: 0.7280, Test: 0.7180
Epoch: 99, Loss: 0.9836, Train: 0.8667, Val: 0.7300, Test: 0.7130
Epoch: 100, Loss: 1.0095, Train: 0.8667, Val: 0.7280, Test: 0.7150
MAD:  0.1208
Best Test Accuracy: 0.7180, Val Accuracy: 0.7280, Train Accuracy: 0.8500
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.0850, Train: 0.3333, Val: 0.3880, Test: 0.4120
Epoch: 2, Loss: 1.0806, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 3, Loss: 1.1839, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 4, Loss: 1.1190, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 5, Loss: 1.1194, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 6, Loss: 1.1117, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 7, Loss: 1.1430, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 8, Loss: 1.0795, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 9, Loss: 1.1033, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.1337, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.1236, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.1124, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 13, Loss: 1.1090, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 14, Loss: 1.0816, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 15, Loss: 1.1266, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 16, Loss: 1.1232, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 17, Loss: 1.1529, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 18, Loss: 1.1156, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 19, Loss: 1.0724, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 20, Loss: 1.0529, Train: 0.4667, Val: 0.4100, Test: 0.4370
Epoch: 21, Loss: 1.0758, Train: 0.5500, Val: 0.4960, Test: 0.4980
Epoch: 22, Loss: 1.1095, Train: 0.4833, Val: 0.4220, Test: 0.4100
Epoch: 23, Loss: 1.1396, Train: 0.4833, Val: 0.4280, Test: 0.4150
Epoch: 24, Loss: 1.1424, Train: 0.5333, Val: 0.4720, Test: 0.4720
Epoch: 25, Loss: 1.0975, Train: 0.5333, Val: 0.4940, Test: 0.4880
Epoch: 26, Loss: 1.1131, Train: 0.5333, Val: 0.4860, Test: 0.4870
Epoch: 27, Loss: 1.1060, Train: 0.4833, Val: 0.4380, Test: 0.4610
Epoch: 28, Loss: 1.1404, Train: 0.4333, Val: 0.4000, Test: 0.4180
Epoch: 29, Loss: 1.1010, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 30, Loss: 1.1319, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 31, Loss: 1.1289, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 32, Loss: 1.0800, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 33, Loss: 1.0903, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 34, Loss: 1.1042, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 35, Loss: 1.0921, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 36, Loss: 1.1255, Train: 0.3333, Val: 0.3880, Test: 0.4140
Epoch: 37, Loss: 1.0716, Train: 0.5000, Val: 0.4540, Test: 0.4650
Epoch: 38, Loss: 1.1046, Train: 0.3500, Val: 0.2040, Test: 0.1890
Epoch: 39, Loss: 1.1111, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 40, Loss: 1.1217, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 41, Loss: 1.0856, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 42, Loss: 1.0997, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 43, Loss: 1.1070, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 44, Loss: 1.0727, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 45, Loss: 1.1344, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 46, Loss: 1.0963, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 47, Loss: 1.0790, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 48, Loss: 1.0911, Train: 0.3333, Val: 0.1960, Test: 0.1850
Epoch: 49, Loss: 1.1015, Train: 0.4000, Val: 0.2480, Test: 0.2320
Epoch: 50, Loss: 1.0503, Train: 0.5167, Val: 0.3660, Test: 0.3520
Epoch: 51, Loss: 1.0954, Train: 0.6167, Val: 0.4760, Test: 0.4400
Epoch: 52, Loss: 1.1145, Train: 0.6333, Val: 0.5220, Test: 0.5040
Epoch: 53, Loss: 1.1236, Train: 0.6333, Val: 0.5360, Test: 0.5140
Epoch: 54, Loss: 1.0992, Train: 0.6333, Val: 0.5260, Test: 0.5080
Epoch: 55, Loss: 1.1026, Train: 0.6500, Val: 0.5220, Test: 0.5040
Epoch: 56, Loss: 1.1465, Train: 0.6500, Val: 0.5200, Test: 0.4950
Epoch: 57, Loss: 1.1256, Train: 0.6333, Val: 0.5140, Test: 0.4890
Epoch: 58, Loss: 1.0723, Train: 0.6333, Val: 0.5060, Test: 0.4800
Epoch: 59, Loss: 1.0842, Train: 0.6333, Val: 0.5080, Test: 0.4870
Epoch: 60, Loss: 1.1372, Train: 0.6333, Val: 0.5080, Test: 0.4840
Epoch: 61, Loss: 1.1032, Train: 0.6333, Val: 0.5060, Test: 0.4810
Epoch: 62, Loss: 1.0785, Train: 0.6333, Val: 0.5040, Test: 0.4770
Epoch: 63, Loss: 1.1118, Train: 0.6333, Val: 0.5160, Test: 0.4910
Epoch: 64, Loss: 1.0980, Train: 0.6333, Val: 0.5240, Test: 0.5060
Epoch: 65, Loss: 1.0714, Train: 0.6333, Val: 0.5240, Test: 0.5060
Epoch: 66, Loss: 1.0903, Train: 0.6333, Val: 0.5260, Test: 0.5060
Epoch: 67, Loss: 1.0805, Train: 0.6333, Val: 0.5280, Test: 0.5070
Epoch: 68, Loss: 1.0981, Train: 0.6333, Val: 0.5280, Test: 0.5070
Epoch: 69, Loss: 1.0208, Train: 0.6333, Val: 0.5320, Test: 0.5110
Epoch: 70, Loss: 1.0299, Train: 0.6333, Val: 0.5360, Test: 0.5140
Epoch: 71, Loss: 1.0477, Train: 0.6167, Val: 0.5440, Test: 0.5220
Epoch: 72, Loss: 1.0681, Train: 0.6167, Val: 0.5460, Test: 0.5250
Epoch: 73, Loss: 1.0549, Train: 0.6333, Val: 0.5440, Test: 0.5220
Epoch: 74, Loss: 1.0052, Train: 0.6500, Val: 0.5520, Test: 0.5300
Epoch: 75, Loss: 0.9820, Train: 0.6500, Val: 0.5480, Test: 0.5300
Epoch: 76, Loss: 0.9816, Train: 0.6500, Val: 0.5520, Test: 0.5290
Epoch: 77, Loss: 0.9386, Train: 0.6500, Val: 0.5540, Test: 0.5280
Epoch: 78, Loss: 0.9368, Train: 0.6333, Val: 0.5500, Test: 0.5250
Epoch: 79, Loss: 0.9102, Train: 0.6667, Val: 0.5480, Test: 0.5160
Epoch: 80, Loss: 0.9023, Train: 0.6500, Val: 0.5500, Test: 0.5190
Epoch: 81, Loss: 0.8460, Train: 0.6500, Val: 0.5520, Test: 0.5240
Epoch: 82, Loss: 0.8753, Train: 0.6333, Val: 0.5460, Test: 0.5210
Epoch: 83, Loss: 0.7986, Train: 0.6333, Val: 0.5500, Test: 0.5200
Epoch: 84, Loss: 0.8287, Train: 0.7000, Val: 0.5600, Test: 0.5160
Epoch: 85, Loss: 0.7745, Train: 0.6833, Val: 0.5480, Test: 0.5280
Epoch: 86, Loss: 0.8037, Train: 0.6667, Val: 0.5520, Test: 0.5220
Epoch: 87, Loss: 0.8059, Train: 0.6333, Val: 0.5420, Test: 0.5270
Epoch: 88, Loss: 0.7216, Train: 0.6500, Val: 0.5420, Test: 0.5240
Epoch: 89, Loss: 0.6710, Train: 0.6500, Val: 0.5580, Test: 0.5250
Epoch: 90, Loss: 0.6612, Train: 0.7000, Val: 0.5500, Test: 0.5320
Epoch: 91, Loss: 0.6990, Train: 0.6833, Val: 0.5180, Test: 0.5110
Epoch: 92, Loss: 0.6999, Train: 0.6833, Val: 0.5540, Test: 0.5250
Epoch: 93, Loss: 0.5797, Train: 0.6833, Val: 0.5540, Test: 0.5240
Epoch: 94, Loss: 0.6389, Train: 0.6833, Val: 0.5400, Test: 0.5220
Epoch: 95, Loss: 0.6801, Train: 0.6833, Val: 0.5320, Test: 0.5250
Epoch: 96, Loss: 0.6188, Train: 0.6833, Val: 0.5360, Test: 0.5270
Epoch: 97, Loss: 0.5882, Train: 0.7000, Val: 0.5520, Test: 0.5310
Epoch: 98, Loss: 0.5554, Train: 0.8167, Val: 0.5800, Test: 0.5600
Epoch: 99, Loss: 0.5191, Train: 0.8000, Val: 0.5820, Test: 0.5700
Epoch: 100, Loss: 0.7095, Train: 0.8333, Val: 0.5780, Test: 0.5660
MAD:  0.3928
Best Test Accuracy: 0.5700, Val Accuracy: 0.5820, Train Accuracy: 0.8000
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1673, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 2, Loss: 1.1034, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 3, Loss: 1.1391, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 4, Loss: 1.1107, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 5, Loss: 1.1375, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 6, Loss: 1.1706, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 7, Loss: 1.1076, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 8, Loss: 1.1353, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 9, Loss: 1.0826, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 10, Loss: 1.1043, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 11, Loss: 1.1089, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 12, Loss: 1.1260, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 13, Loss: 1.0869, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 14, Loss: 1.0824, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 15, Loss: 1.1101, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 16, Loss: 1.0960, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 17, Loss: 1.1025, Train: 0.3667, Val: 0.1960, Test: 0.1850
Epoch: 18, Loss: 1.1000, Train: 0.3500, Val: 0.1960, Test: 0.1820
Epoch: 19, Loss: 1.1098, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 20, Loss: 1.1210, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 21, Loss: 1.1391, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 22, Loss: 1.1301, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 23, Loss: 1.1244, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 24, Loss: 1.1214, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 25, Loss: 1.1212, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 26, Loss: 1.1249, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 27, Loss: 1.1277, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 28, Loss: 1.1072, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 29, Loss: 1.0817, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 30, Loss: 1.0983, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 31, Loss: 1.1218, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.1006, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 33, Loss: 1.1197, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 34, Loss: 1.0957, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 35, Loss: 1.1215, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 36, Loss: 1.0893, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 37, Loss: 1.0901, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 38, Loss: 1.1108, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 39, Loss: 1.1267, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 40, Loss: 1.1179, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 41, Loss: 1.1061, Train: 0.5500, Val: 0.4740, Test: 0.4880
Epoch: 42, Loss: 1.1081, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 43, Loss: 1.1210, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 44, Loss: 1.1216, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 45, Loss: 1.1058, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 46, Loss: 1.0922, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 47, Loss: 1.0796, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 48, Loss: 1.1255, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 49, Loss: 1.0819, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 50, Loss: 1.0880, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 51, Loss: 1.0919, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 52, Loss: 1.1174, Train: 0.3333, Val: 0.3880, Test: 0.4150
Epoch: 53, Loss: 1.1012, Train: 0.3500, Val: 0.3900, Test: 0.4170
Epoch: 54, Loss: 1.0517, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 55, Loss: 1.0971, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 56, Loss: 1.1188, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 57, Loss: 1.0782, Train: 0.3333, Val: 0.3880, Test: 0.4140
Epoch: 58, Loss: 1.0915, Train: 0.4667, Val: 0.5040, Test: 0.5370
Epoch: 59, Loss: 1.1021, Train: 0.5000, Val: 0.5640, Test: 0.5810
Epoch: 60, Loss: 1.1070, Train: 0.5333, Val: 0.5860, Test: 0.6050
Epoch: 61, Loss: 1.1027, Train: 0.6167, Val: 0.5940, Test: 0.6000
Epoch: 62, Loss: 1.0993, Train: 0.7500, Val: 0.6220, Test: 0.6260
Epoch: 63, Loss: 1.1064, Train: 0.7833, Val: 0.5820, Test: 0.6050
Epoch: 64, Loss: 1.1047, Train: 0.7500, Val: 0.5740, Test: 0.5750
Epoch: 65, Loss: 1.0972, Train: 0.8667, Val: 0.6880, Test: 0.6620
Epoch: 66, Loss: 1.1038, Train: 0.8000, Val: 0.6700, Test: 0.6430
Epoch: 67, Loss: 1.0731, Train: 0.7667, Val: 0.6360, Test: 0.6190
Epoch: 68, Loss: 1.0823, Train: 0.8000, Val: 0.6500, Test: 0.6390
Epoch: 69, Loss: 1.0805, Train: 0.7833, Val: 0.6680, Test: 0.6510
Epoch: 70, Loss: 1.0509, Train: 0.8000, Val: 0.6640, Test: 0.6440
Epoch: 71, Loss: 1.0405, Train: 0.7500, Val: 0.6540, Test: 0.6250
Epoch: 72, Loss: 1.0846, Train: 0.7333, Val: 0.6140, Test: 0.5920
Epoch: 73, Loss: 1.0370, Train: 0.6500, Val: 0.5940, Test: 0.5560
Epoch: 74, Loss: 1.0560, Train: 0.6500, Val: 0.5900, Test: 0.5560
Epoch: 75, Loss: 1.0684, Train: 0.6833, Val: 0.6100, Test: 0.5660
Epoch: 76, Loss: 0.9621, Train: 0.8000, Val: 0.6500, Test: 0.6270
Epoch: 77, Loss: 1.0065, Train: 0.7000, Val: 0.5760, Test: 0.5460
Epoch: 78, Loss: 0.9704, Train: 0.6167, Val: 0.5420, Test: 0.5360
Epoch: 79, Loss: 0.9892, Train: 0.6167, Val: 0.5440, Test: 0.5310
Epoch: 80, Loss: 0.9992, Train: 0.7000, Val: 0.5700, Test: 0.5370
Epoch: 81, Loss: 0.9310, Train: 0.7167, Val: 0.5800, Test: 0.5510
Epoch: 82, Loss: 0.8577, Train: 0.7000, Val: 0.5680, Test: 0.5570
Epoch: 83, Loss: 0.7994, Train: 0.7167, Val: 0.5620, Test: 0.5570
Epoch: 84, Loss: 0.8098, Train: 0.7000, Val: 0.5620, Test: 0.5470
Epoch: 85, Loss: 0.7946, Train: 0.6667, Val: 0.5660, Test: 0.5400
Epoch: 86, Loss: 0.7837, Train: 0.7000, Val: 0.5640, Test: 0.5400
Epoch: 87, Loss: 0.7420, Train: 0.7333, Val: 0.5660, Test: 0.5440
Epoch: 88, Loss: 0.7572, Train: 0.7333, Val: 0.5820, Test: 0.5440
Epoch: 89, Loss: 0.6858, Train: 0.6667, Val: 0.5660, Test: 0.5210
Epoch: 90, Loss: 0.7320, Train: 0.6667, Val: 0.5460, Test: 0.5240
Epoch: 91, Loss: 0.6697, Train: 0.7167, Val: 0.5840, Test: 0.5410
Epoch: 92, Loss: 0.6632, Train: 0.7833, Val: 0.6120, Test: 0.5810
Epoch: 93, Loss: 0.6404, Train: 0.7167, Val: 0.5980, Test: 0.5730
Epoch: 94, Loss: 0.6048, Train: 0.7833, Val: 0.6120, Test: 0.5830
Epoch: 95, Loss: 0.5381, Train: 0.8333, Val: 0.6640, Test: 0.6270
Epoch: 96, Loss: 0.5877, Train: 0.8000, Val: 0.6520, Test: 0.6070
Epoch: 97, Loss: 0.4507, Train: 0.7833, Val: 0.6460, Test: 0.6080
Epoch: 98, Loss: 0.5192, Train: 0.8833, Val: 0.6800, Test: 0.6400
Epoch: 99, Loss: 0.5397, Train: 0.8667, Val: 0.6600, Test: 0.6220
Epoch: 100, Loss: 0.5746, Train: 0.9000, Val: 0.7140, Test: 0.6670
MAD:  0.3811
Best Test Accuracy: 0.6670, Val Accuracy: 0.7140, Train Accuracy: 0.9000
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1193, Train: 0.3167, Val: 0.1940, Test: 0.1800
Epoch: 2, Loss: 1.1372, Train: 0.3333, Val: 0.4040, Test: 0.3930
Epoch: 3, Loss: 1.1219, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 4, Loss: 1.0907, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.1085, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 6, Loss: 1.0995, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 7, Loss: 1.1252, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 8, Loss: 1.1236, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 9, Loss: 1.1266, Train: 0.3333, Val: 0.4160, Test: 0.4090
Epoch: 10, Loss: 1.1434, Train: 0.4167, Val: 0.2720, Test: 0.2450
Epoch: 11, Loss: 1.0951, Train: 0.3333, Val: 0.2140, Test: 0.1900
Epoch: 12, Loss: 1.1064, Train: 0.3333, Val: 0.1980, Test: 0.1830
Epoch: 13, Loss: 1.0977, Train: 0.4000, Val: 0.2260, Test: 0.2120
Epoch: 14, Loss: 1.1514, Train: 0.4000, Val: 0.4300, Test: 0.4340
Epoch: 15, Loss: 1.0934, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 16, Loss: 1.1189, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 17, Loss: 1.1047, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 18, Loss: 1.1328, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 19, Loss: 1.0800, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 20, Loss: 1.0968, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 21, Loss: 1.0847, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 22, Loss: 1.1048, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 23, Loss: 1.0978, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 24, Loss: 1.0970, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 25, Loss: 1.1009, Train: 0.3833, Val: 0.3940, Test: 0.4200
Epoch: 26, Loss: 1.1094, Train: 0.3500, Val: 0.2060, Test: 0.1870
Epoch: 27, Loss: 1.0861, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 28, Loss: 1.1060, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 29, Loss: 1.0869, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 30, Loss: 1.1164, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 31, Loss: 1.1023, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.1013, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 33, Loss: 1.0683, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 34, Loss: 1.0958, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 35, Loss: 1.0876, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 36, Loss: 1.1227, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 37, Loss: 1.1282, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 38, Loss: 1.0766, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 39, Loss: 1.0843, Train: 0.3667, Val: 0.2200, Test: 0.2020
Epoch: 40, Loss: 1.0918, Train: 0.3500, Val: 0.2040, Test: 0.1840
Epoch: 41, Loss: 1.0876, Train: 0.3500, Val: 0.1980, Test: 0.1810
Epoch: 42, Loss: 1.1061, Train: 0.3667, Val: 0.2120, Test: 0.1910
Epoch: 43, Loss: 1.0891, Train: 0.3667, Val: 0.2240, Test: 0.1980
Epoch: 44, Loss: 1.1233, Train: 0.3833, Val: 0.2480, Test: 0.2320
Epoch: 45, Loss: 1.1242, Train: 0.3667, Val: 0.2620, Test: 0.2270
Epoch: 46, Loss: 1.1223, Train: 0.3500, Val: 0.2040, Test: 0.1860
Epoch: 47, Loss: 1.1017, Train: 0.3500, Val: 0.2040, Test: 0.1880
Epoch: 48, Loss: 1.0831, Train: 0.3333, Val: 0.1960, Test: 0.1810
Epoch: 49, Loss: 1.0903, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 50, Loss: 1.0837, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 51, Loss: 1.0945, Train: 0.3500, Val: 0.2240, Test: 0.2120
Epoch: 52, Loss: 1.0789, Train: 0.3333, Val: 0.1980, Test: 0.1830
Epoch: 53, Loss: 1.1351, Train: 0.4167, Val: 0.3020, Test: 0.2780
Epoch: 54, Loss: 1.0861, Train: 0.5333, Val: 0.4520, Test: 0.4600
Epoch: 55, Loss: 1.1023, Train: 0.5000, Val: 0.4340, Test: 0.4400
Epoch: 56, Loss: 1.1008, Train: 0.5333, Val: 0.4740, Test: 0.4770
Epoch: 57, Loss: 1.0772, Train: 0.5500, Val: 0.4760, Test: 0.4800
Epoch: 58, Loss: 1.0916, Train: 0.5333, Val: 0.4700, Test: 0.4780
Epoch: 59, Loss: 1.0709, Train: 0.5667, Val: 0.4960, Test: 0.4910
Epoch: 60, Loss: 1.0804, Train: 0.5667, Val: 0.5080, Test: 0.4980
Epoch: 61, Loss: 1.1061, Train: 0.5667, Val: 0.5160, Test: 0.5020
Epoch: 62, Loss: 1.1127, Train: 0.6000, Val: 0.5200, Test: 0.5020
Epoch: 63, Loss: 1.0781, Train: 0.6000, Val: 0.5080, Test: 0.5070
Epoch: 64, Loss: 1.1058, Train: 0.5833, Val: 0.4960, Test: 0.5090
Epoch: 65, Loss: 1.0376, Train: 0.5833, Val: 0.4920, Test: 0.5010
Epoch: 66, Loss: 1.0857, Train: 0.6000, Val: 0.5200, Test: 0.5200
Epoch: 67, Loss: 1.0587, Train: 0.6667, Val: 0.5620, Test: 0.5610
Epoch: 68, Loss: 1.0342, Train: 0.6500, Val: 0.5500, Test: 0.5310
Epoch: 69, Loss: 1.0209, Train: 0.6500, Val: 0.5560, Test: 0.5360
Epoch: 70, Loss: 1.0242, Train: 0.6333, Val: 0.5480, Test: 0.5190
Epoch: 71, Loss: 1.0429, Train: 0.6333, Val: 0.5460, Test: 0.5220
Epoch: 72, Loss: 1.0145, Train: 0.6333, Val: 0.5460, Test: 0.5220
Epoch: 73, Loss: 0.9457, Train: 0.6333, Val: 0.5500, Test: 0.5140
Epoch: 74, Loss: 0.9357, Train: 0.6333, Val: 0.5500, Test: 0.5200
Epoch: 75, Loss: 0.9123, Train: 0.6167, Val: 0.5540, Test: 0.5210
Epoch: 76, Loss: 0.8497, Train: 0.6333, Val: 0.5520, Test: 0.5210
Epoch: 77, Loss: 0.8472, Train: 0.6333, Val: 0.5440, Test: 0.5190
Epoch: 78, Loss: 0.7807, Train: 0.6333, Val: 0.5440, Test: 0.5210
Epoch: 79, Loss: 0.8090, Train: 0.6333, Val: 0.5460, Test: 0.5200
Epoch: 80, Loss: 0.7401, Train: 0.6333, Val: 0.5480, Test: 0.5220
Epoch: 81, Loss: 0.7824, Train: 0.6333, Val: 0.5480, Test: 0.5210
Epoch: 82, Loss: 0.7157, Train: 0.6333, Val: 0.5460, Test: 0.5190
Epoch: 83, Loss: 0.6949, Train: 0.6333, Val: 0.5540, Test: 0.5200
Epoch: 84, Loss: 0.7025, Train: 0.6500, Val: 0.5340, Test: 0.5090
Epoch: 85, Loss: 0.6601, Train: 0.6500, Val: 0.5340, Test: 0.5140
Epoch: 86, Loss: 0.6303, Train: 0.6500, Val: 0.5360, Test: 0.5230
Epoch: 87, Loss: 0.6271, Train: 0.6500, Val: 0.5380, Test: 0.5180
Epoch: 88, Loss: 0.6164, Train: 0.6500, Val: 0.5080, Test: 0.5000
Epoch: 89, Loss: 0.6050, Train: 0.6000, Val: 0.5180, Test: 0.4850
Epoch: 90, Loss: 0.7183, Train: 0.6500, Val: 0.5080, Test: 0.5080
Epoch: 91, Loss: 0.5753, Train: 0.7000, Val: 0.5420, Test: 0.5330
Epoch: 92, Loss: 0.5284, Train: 0.7667, Val: 0.6320, Test: 0.6510
Epoch: 93, Loss: 0.6307, Train: 0.6667, Val: 0.5540, Test: 0.5570
Epoch: 94, Loss: 0.6099, Train: 0.6667, Val: 0.5400, Test: 0.5360
Epoch: 95, Loss: 0.5229, Train: 0.6833, Val: 0.5480, Test: 0.5380
Epoch: 96, Loss: 0.4756, Train: 0.6667, Val: 0.5380, Test: 0.5350
Epoch: 97, Loss: 0.5697, Train: 0.6667, Val: 0.5400, Test: 0.5340
Epoch: 98, Loss: 0.5624, Train: 0.6667, Val: 0.5380, Test: 0.5310
Epoch: 99, Loss: 0.5778, Train: 0.6500, Val: 0.5180, Test: 0.5140
Epoch: 100, Loss: 0.4968, Train: 0.6500, Val: 0.4900, Test: 0.4940
MAD:  0.2088
Best Test Accuracy: 0.6510, Val Accuracy: 0.6320, Train Accuracy: 0.7667
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1266, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 2, Loss: 1.0816, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 3, Loss: 1.1489, Train: 0.3333, Val: 0.4240, Test: 0.4270
Epoch: 4, Loss: 1.1756, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.1422, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 6, Loss: 1.1179, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 7, Loss: 1.0939, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 8, Loss: 1.0984, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 9, Loss: 1.1023, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 10, Loss: 1.1236, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 11, Loss: 1.1255, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 12, Loss: 1.0839, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 13, Loss: 1.1171, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 14, Loss: 1.0759, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 15, Loss: 1.1214, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 16, Loss: 1.1079, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 17, Loss: 1.1003, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 18, Loss: 1.1366, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 19, Loss: 1.1202, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 20, Loss: 1.1170, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 21, Loss: 1.1184, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 22, Loss: 1.1053, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 23, Loss: 1.1042, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 24, Loss: 1.0732, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 25, Loss: 1.1353, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 26, Loss: 1.0799, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 27, Loss: 1.1127, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 28, Loss: 1.0908, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 29, Loss: 1.0743, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 30, Loss: 1.1021, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 31, Loss: 1.0978, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 32, Loss: 1.1181, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 33, Loss: 1.0638, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 34, Loss: 1.1174, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 35, Loss: 1.1055, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 36, Loss: 1.1106, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 37, Loss: 1.1035, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 38, Loss: 1.0800, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 39, Loss: 1.1458, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 40, Loss: 1.0844, Train: 0.3500, Val: 0.4180, Test: 0.4090
Epoch: 41, Loss: 1.0929, Train: 0.3333, Val: 0.4160, Test: 0.4080
Epoch: 42, Loss: 1.1054, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 43, Loss: 1.1074, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 44, Loss: 1.0970, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 45, Loss: 1.1229, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 46, Loss: 1.0869, Train: 0.4167, Val: 0.4240, Test: 0.4150
Epoch: 47, Loss: 1.0910, Train: 0.4167, Val: 0.4240, Test: 0.4150
Epoch: 48, Loss: 1.0920, Train: 0.4000, Val: 0.4200, Test: 0.4100
Epoch: 49, Loss: 1.1025, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 50, Loss: 1.0531, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 51, Loss: 1.0910, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 52, Loss: 1.0947, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 53, Loss: 1.0674, Train: 0.3833, Val: 0.4220, Test: 0.4100
Epoch: 54, Loss: 1.1015, Train: 0.4667, Val: 0.5040, Test: 0.4660
Epoch: 55, Loss: 1.0680, Train: 0.5167, Val: 0.5500, Test: 0.5680
Epoch: 56, Loss: 1.0908, Train: 0.6167, Val: 0.5560, Test: 0.5820
Epoch: 57, Loss: 1.1004, Train: 0.6333, Val: 0.5560, Test: 0.5910
Epoch: 58, Loss: 1.0614, Train: 0.6667, Val: 0.5720, Test: 0.5730
Epoch: 59, Loss: 1.0789, Train: 0.6667, Val: 0.5840, Test: 0.5730
Epoch: 60, Loss: 1.0795, Train: 0.6500, Val: 0.5960, Test: 0.5870
Epoch: 61, Loss: 1.0293, Train: 0.7167, Val: 0.5940, Test: 0.5570
Epoch: 62, Loss: 1.0419, Train: 0.6667, Val: 0.5660, Test: 0.5400
Epoch: 63, Loss: 1.0493, Train: 0.6667, Val: 0.5560, Test: 0.5350
Epoch: 64, Loss: 1.0594, Train: 0.6667, Val: 0.5540, Test: 0.5340
Epoch: 65, Loss: 1.0195, Train: 0.6667, Val: 0.5420, Test: 0.5230
Epoch: 66, Loss: 0.9888, Train: 0.6667, Val: 0.5420, Test: 0.5210
Epoch: 67, Loss: 0.9565, Train: 0.6667, Val: 0.5500, Test: 0.5190
Epoch: 68, Loss: 1.0190, Train: 0.6333, Val: 0.5520, Test: 0.5160
Epoch: 69, Loss: 0.9523, Train: 0.6500, Val: 0.5460, Test: 0.5180
Epoch: 70, Loss: 0.9180, Train: 0.6333, Val: 0.5480, Test: 0.5180
Epoch: 71, Loss: 0.8901, Train: 0.6500, Val: 0.5520, Test: 0.5210
Epoch: 72, Loss: 0.8151, Train: 0.6167, Val: 0.5440, Test: 0.5250
Epoch: 73, Loss: 0.8257, Train: 0.6333, Val: 0.5420, Test: 0.5230
Epoch: 74, Loss: 0.7827, Train: 0.6333, Val: 0.5520, Test: 0.5170
Epoch: 75, Loss: 0.7652, Train: 0.6333, Val: 0.5540, Test: 0.5190
Epoch: 76, Loss: 0.7622, Train: 0.6333, Val: 0.5500, Test: 0.5210
Epoch: 77, Loss: 0.7092, Train: 0.6667, Val: 0.5400, Test: 0.5140
Epoch: 78, Loss: 0.6917, Train: 0.7000, Val: 0.5320, Test: 0.5070
Epoch: 79, Loss: 0.7141, Train: 0.6500, Val: 0.5460, Test: 0.5220
Epoch: 80, Loss: 0.6578, Train: 0.6333, Val: 0.5400, Test: 0.5200
Epoch: 81, Loss: 0.7463, Train: 0.6667, Val: 0.5400, Test: 0.5180
Epoch: 82, Loss: 0.6313, Train: 0.6500, Val: 0.5440, Test: 0.5190
Epoch: 83, Loss: 0.5984, Train: 0.6833, Val: 0.5460, Test: 0.5240
Epoch: 84, Loss: 0.6761, Train: 0.6833, Val: 0.5580, Test: 0.5100
Epoch: 85, Loss: 0.5902, Train: 0.6667, Val: 0.5380, Test: 0.4900
Epoch: 86, Loss: 0.6232, Train: 0.6833, Val: 0.5400, Test: 0.5100
Epoch: 87, Loss: 0.5475, Train: 0.6500, Val: 0.5360, Test: 0.5200
Epoch: 88, Loss: 0.6003, Train: 0.6500, Val: 0.5260, Test: 0.5060
Epoch: 89, Loss: 0.6067, Train: 0.6167, Val: 0.5080, Test: 0.4990
Epoch: 90, Loss: 0.6275, Train: 0.6500, Val: 0.5220, Test: 0.5070
Epoch: 91, Loss: 0.5657, Train: 0.6500, Val: 0.5260, Test: 0.5080
Epoch: 92, Loss: 0.5553, Train: 0.7167, Val: 0.5400, Test: 0.4960
Epoch: 93, Loss: 0.5365, Train: 0.8833, Val: 0.6680, Test: 0.6210
Epoch: 94, Loss: 0.6212, Train: 0.9000, Val: 0.6580, Test: 0.6280
Epoch: 95, Loss: 0.5042, Train: 0.7000, Val: 0.5560, Test: 0.5240
Epoch: 96, Loss: 0.4869, Train: 0.6500, Val: 0.5300, Test: 0.5080
Epoch: 97, Loss: 0.5035, Train: 0.6667, Val: 0.5220, Test: 0.5060
Epoch: 98, Loss: 0.4798, Train: 0.6667, Val: 0.5240, Test: 0.5010
Epoch: 99, Loss: 0.5010, Train: 0.6667, Val: 0.5240, Test: 0.4990
Epoch: 100, Loss: 0.4997, Train: 0.6667, Val: 0.5200, Test: 0.5030
MAD:  0.3545
Best Test Accuracy: 0.6280, Val Accuracy: 0.6580, Train Accuracy: 0.9000
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1702, Train: 0.3167, Val: 0.3960, Test: 0.3860
Epoch: 2, Loss: 1.1067, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 3, Loss: 1.0865, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 4, Loss: 1.1542, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 5, Loss: 1.1065, Train: 0.3333, Val: 0.1940, Test: 0.1810
Epoch: 6, Loss: 1.0832, Train: 0.3667, Val: 0.3500, Test: 0.3650
Epoch: 7, Loss: 1.1208, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 8, Loss: 1.0922, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 9, Loss: 1.1002, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.1005, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.1088, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.1183, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 13, Loss: 1.1088, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 14, Loss: 1.0965, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 15, Loss: 1.0875, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 16, Loss: 1.1322, Train: 0.4333, Val: 0.4560, Test: 0.4980
Epoch: 17, Loss: 1.0923, Train: 0.3500, Val: 0.4180, Test: 0.4090
Epoch: 18, Loss: 1.1237, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 19, Loss: 1.1739, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 20, Loss: 1.1426, Train: 0.3500, Val: 0.4160, Test: 0.4070
Epoch: 21, Loss: 1.1118, Train: 0.4000, Val: 0.5040, Test: 0.4760
Epoch: 22, Loss: 1.0914, Train: 0.4000, Val: 0.4360, Test: 0.4650
Epoch: 23, Loss: 1.0713, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 24, Loss: 1.1005, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 25, Loss: 1.0831, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 26, Loss: 1.1046, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 27, Loss: 1.0994, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 28, Loss: 1.0860, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 29, Loss: 1.0937, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 30, Loss: 1.0964, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 31, Loss: 1.1267, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 32, Loss: 1.0560, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 33, Loss: 1.0900, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 34, Loss: 1.1201, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 35, Loss: 1.0806, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 36, Loss: 1.1228, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 37, Loss: 1.0735, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 38, Loss: 1.1081, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 39, Loss: 1.0694, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 40, Loss: 1.0918, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 41, Loss: 1.1139, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 42, Loss: 1.1165, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 43, Loss: 1.0784, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 44, Loss: 1.1322, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 45, Loss: 1.1041, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 46, Loss: 1.0764, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 47, Loss: 1.1019, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 48, Loss: 1.1233, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 49, Loss: 1.1095, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 50, Loss: 1.0936, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 51, Loss: 1.1103, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 52, Loss: 1.0969, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 53, Loss: 1.0974, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 54, Loss: 1.0869, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 55, Loss: 1.1105, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 56, Loss: 1.1014, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 57, Loss: 1.1044, Train: 0.3833, Val: 0.3940, Test: 0.4150
Epoch: 58, Loss: 1.1173, Train: 0.4000, Val: 0.3940, Test: 0.4210
Epoch: 59, Loss: 1.0711, Train: 0.4500, Val: 0.4220, Test: 0.4430
Epoch: 60, Loss: 1.0979, Train: 0.5167, Val: 0.4660, Test: 0.4830
Epoch: 61, Loss: 1.0959, Train: 0.5833, Val: 0.4940, Test: 0.4990
Epoch: 62, Loss: 1.0454, Train: 0.5833, Val: 0.5020, Test: 0.4980
Epoch: 63, Loss: 1.0630, Train: 0.6000, Val: 0.4960, Test: 0.4940
Epoch: 64, Loss: 1.0767, Train: 0.5833, Val: 0.5060, Test: 0.5020
Epoch: 65, Loss: 1.0559, Train: 0.6667, Val: 0.5820, Test: 0.5770
Epoch: 66, Loss: 1.0725, Train: 0.7667, Val: 0.6040, Test: 0.5890
Epoch: 67, Loss: 1.0317, Train: 0.6500, Val: 0.5720, Test: 0.5400
Epoch: 68, Loss: 1.0066, Train: 0.6500, Val: 0.5520, Test: 0.5310
Epoch: 69, Loss: 1.0340, Train: 0.6500, Val: 0.5520, Test: 0.5280
Epoch: 70, Loss: 0.9712, Train: 0.6500, Val: 0.5540, Test: 0.5290
Epoch: 71, Loss: 0.9334, Train: 0.6333, Val: 0.5520, Test: 0.5240
Epoch: 72, Loss: 0.9174, Train: 0.6333, Val: 0.5460, Test: 0.5210
Epoch: 73, Loss: 0.8818, Train: 0.6333, Val: 0.5420, Test: 0.5230
Epoch: 74, Loss: 0.8957, Train: 0.6167, Val: 0.5480, Test: 0.5220
Epoch: 75, Loss: 0.8663, Train: 0.6167, Val: 0.5460, Test: 0.5220
Epoch: 76, Loss: 0.8681, Train: 0.6167, Val: 0.5480, Test: 0.5230
Epoch: 77, Loss: 0.8210, Train: 0.6333, Val: 0.5420, Test: 0.5180
Epoch: 78, Loss: 0.7740, Train: 0.6500, Val: 0.5520, Test: 0.5130
Epoch: 79, Loss: 0.8095, Train: 0.6500, Val: 0.5440, Test: 0.5140
Epoch: 80, Loss: 0.7513, Train: 0.6833, Val: 0.5460, Test: 0.5200
Epoch: 81, Loss: 0.7194, Train: 0.6500, Val: 0.5440, Test: 0.5240
Epoch: 82, Loss: 0.6842, Train: 0.6667, Val: 0.5460, Test: 0.5190
Epoch: 83, Loss: 0.6627, Train: 0.6500, Val: 0.5540, Test: 0.5190
Epoch: 84, Loss: 0.6763, Train: 0.6500, Val: 0.5380, Test: 0.5280
Epoch: 85, Loss: 0.6526, Train: 0.6500, Val: 0.5180, Test: 0.4920
Epoch: 86, Loss: 0.7980, Train: 0.6667, Val: 0.5420, Test: 0.5220
Epoch: 87, Loss: 0.6347, Train: 0.6500, Val: 0.5420, Test: 0.5230
Epoch: 88, Loss: 0.6352, Train: 0.6333, Val: 0.5360, Test: 0.5140
Epoch: 89, Loss: 0.7186, Train: 0.6500, Val: 0.5320, Test: 0.5120
Epoch: 90, Loss: 0.6349, Train: 0.6500, Val: 0.5340, Test: 0.5250
Epoch: 91, Loss: 0.5676, Train: 0.6500, Val: 0.5340, Test: 0.5230
Epoch: 92, Loss: 0.6128, Train: 0.6667, Val: 0.5360, Test: 0.5230
Epoch: 93, Loss: 0.6052, Train: 0.6667, Val: 0.5420, Test: 0.5290
Epoch: 94, Loss: 0.6393, Train: 0.7000, Val: 0.5420, Test: 0.5340
Epoch: 95, Loss: 0.6009, Train: 0.7000, Val: 0.5600, Test: 0.5370
Epoch: 96, Loss: 0.5910, Train: 0.7000, Val: 0.5560, Test: 0.5410
Epoch: 97, Loss: 0.5994, Train: 0.7000, Val: 0.5580, Test: 0.5410
Epoch: 98, Loss: 0.5820, Train: 0.7000, Val: 0.5600, Test: 0.5430
Epoch: 99, Loss: 0.5861, Train: 0.7167, Val: 0.5460, Test: 0.5320
Epoch: 100, Loss: 0.6476, Train: 0.7167, Val: 0.5480, Test: 0.5140
MAD:  0.0885
Best Test Accuracy: 0.5890, Val Accuracy: 0.6040, Train Accuracy: 0.7667
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1067, Train: 0.3333, Val: 0.4140, Test: 0.4180
Epoch: 2, Loss: 1.1279, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 3, Loss: 1.1114, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 4, Loss: 1.1228, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.0886, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 6, Loss: 1.0861, Train: 0.3000, Val: 0.2100, Test: 0.2210
Epoch: 7, Loss: 1.0976, Train: 0.4000, Val: 0.2360, Test: 0.2370
Epoch: 8, Loss: 1.1317, Train: 0.4000, Val: 0.2320, Test: 0.2080
Epoch: 9, Loss: 1.1109, Train: 0.3333, Val: 0.1980, Test: 0.1800
Epoch: 10, Loss: 1.0839, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 11, Loss: 1.0803, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 12, Loss: 1.1111, Train: 0.3333, Val: 0.2000, Test: 0.1800
Epoch: 13, Loss: 1.1514, Train: 0.3500, Val: 0.2000, Test: 0.1880
Epoch: 14, Loss: 1.0987, Train: 0.3667, Val: 0.2100, Test: 0.2000
Epoch: 15, Loss: 1.0968, Train: 0.4500, Val: 0.3120, Test: 0.3140
Epoch: 16, Loss: 1.1554, Train: 0.3667, Val: 0.4220, Test: 0.4140
Epoch: 17, Loss: 1.0948, Train: 0.4000, Val: 0.4240, Test: 0.4120
Epoch: 18, Loss: 1.1306, Train: 0.4333, Val: 0.4580, Test: 0.4420
Epoch: 19, Loss: 1.0560, Train: 0.5667, Val: 0.5280, Test: 0.4880
Epoch: 20, Loss: 1.0929, Train: 0.5333, Val: 0.4180, Test: 0.4000
Epoch: 21, Loss: 1.1129, Train: 0.4667, Val: 0.3460, Test: 0.3270
Epoch: 22, Loss: 1.1041, Train: 0.4667, Val: 0.3420, Test: 0.3280
Epoch: 23, Loss: 1.1084, Train: 0.5333, Val: 0.3920, Test: 0.3680
Epoch: 24, Loss: 1.1083, Train: 0.4833, Val: 0.3640, Test: 0.3450
Epoch: 25, Loss: 1.1052, Train: 0.4667, Val: 0.3400, Test: 0.3250
Epoch: 26, Loss: 1.0924, Train: 0.4167, Val: 0.2460, Test: 0.2400
Epoch: 27, Loss: 1.1093, Train: 0.4167, Val: 0.2240, Test: 0.2100
Epoch: 28, Loss: 1.0613, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 29, Loss: 1.1190, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 30, Loss: 1.0753, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 31, Loss: 1.0969, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.0964, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 33, Loss: 1.1106, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 34, Loss: 1.0854, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 35, Loss: 1.0790, Train: 0.3333, Val: 0.2000, Test: 0.1840
Epoch: 36, Loss: 1.0827, Train: 0.4333, Val: 0.3000, Test: 0.2990
Epoch: 37, Loss: 1.0601, Train: 0.5500, Val: 0.3960, Test: 0.3670
Epoch: 38, Loss: 1.1000, Train: 0.6333, Val: 0.5000, Test: 0.4560
Epoch: 39, Loss: 1.1011, Train: 0.6500, Val: 0.5220, Test: 0.4900
Epoch: 40, Loss: 1.0845, Train: 0.6333, Val: 0.5400, Test: 0.5160
Epoch: 41, Loss: 1.1124, Train: 0.6333, Val: 0.5440, Test: 0.5240
Epoch: 42, Loss: 1.1111, Train: 0.6333, Val: 0.5460, Test: 0.5250
Epoch: 43, Loss: 1.1071, Train: 0.6167, Val: 0.5440, Test: 0.5190
Epoch: 44, Loss: 1.0890, Train: 0.6167, Val: 0.5520, Test: 0.5260
Epoch: 45, Loss: 1.1009, Train: 0.6500, Val: 0.5280, Test: 0.4990
Epoch: 46, Loss: 1.0977, Train: 0.8000, Val: 0.6240, Test: 0.6040
Epoch: 47, Loss: 1.1201, Train: 0.8000, Val: 0.6800, Test: 0.6430
Epoch: 48, Loss: 1.0790, Train: 0.7667, Val: 0.7120, Test: 0.6570
Epoch: 49, Loss: 1.1139, Train: 0.7833, Val: 0.6940, Test: 0.6570
Epoch: 50, Loss: 1.0794, Train: 0.7500, Val: 0.6520, Test: 0.6240
Epoch: 51, Loss: 1.0870, Train: 0.7333, Val: 0.6360, Test: 0.6050
Epoch: 52, Loss: 1.0789, Train: 0.6833, Val: 0.5960, Test: 0.5680
Epoch: 53, Loss: 1.0618, Train: 0.6333, Val: 0.5500, Test: 0.5130
Epoch: 54, Loss: 1.0664, Train: 0.6333, Val: 0.5200, Test: 0.4860
Epoch: 55, Loss: 1.0762, Train: 0.6333, Val: 0.5020, Test: 0.4770
Epoch: 56, Loss: 1.0730, Train: 0.6333, Val: 0.5300, Test: 0.4940
Epoch: 57, Loss: 1.0505, Train: 0.6833, Val: 0.5660, Test: 0.5510
Epoch: 58, Loss: 1.0712, Train: 0.7333, Val: 0.6060, Test: 0.5770
Epoch: 59, Loss: 1.0288, Train: 0.7667, Val: 0.5880, Test: 0.5520
Epoch: 60, Loss: 1.0588, Train: 0.6333, Val: 0.5520, Test: 0.5320
Epoch: 61, Loss: 1.0206, Train: 0.6167, Val: 0.5500, Test: 0.5290
Epoch: 62, Loss: 1.0361, Train: 0.6167, Val: 0.5480, Test: 0.5250
Epoch: 63, Loss: 1.0258, Train: 0.6167, Val: 0.5560, Test: 0.5300
Epoch: 64, Loss: 0.9657, Train: 0.6500, Val: 0.5660, Test: 0.5250
Epoch: 65, Loss: 0.9490, Train: 0.6667, Val: 0.5480, Test: 0.5220
Epoch: 66, Loss: 0.9352, Train: 0.6833, Val: 0.5500, Test: 0.5240
Epoch: 67, Loss: 0.8616, Train: 0.6833, Val: 0.5520, Test: 0.5230
Epoch: 68, Loss: 0.9165, Train: 0.6667, Val: 0.5520, Test: 0.5250
Epoch: 69, Loss: 0.8738, Train: 0.6667, Val: 0.5600, Test: 0.5250
Epoch: 70, Loss: 0.8596, Train: 0.6500, Val: 0.5660, Test: 0.5280
Epoch: 71, Loss: 0.7922, Train: 0.6667, Val: 0.5660, Test: 0.5320
Epoch: 72, Loss: 0.7812, Train: 0.6667, Val: 0.5680, Test: 0.5350
Epoch: 73, Loss: 0.7504, Train: 0.7000, Val: 0.5840, Test: 0.5300
Epoch: 74, Loss: 0.6692, Train: 0.6833, Val: 0.5800, Test: 0.5350
Epoch: 75, Loss: 0.6727, Train: 0.7000, Val: 0.5840, Test: 0.5400
Epoch: 76, Loss: 0.7566, Train: 0.7333, Val: 0.5620, Test: 0.5660
Epoch: 77, Loss: 0.6779, Train: 0.7500, Val: 0.5940, Test: 0.5700
Epoch: 78, Loss: 0.6501, Train: 0.7000, Val: 0.5980, Test: 0.5510
Epoch: 79, Loss: 0.5902, Train: 0.6833, Val: 0.5760, Test: 0.5320
Epoch: 80, Loss: 0.6366, Train: 0.7167, Val: 0.5940, Test: 0.5460
Epoch: 81, Loss: 0.5818, Train: 0.8000, Val: 0.6100, Test: 0.6020
Epoch: 82, Loss: 0.6002, Train: 0.8333, Val: 0.6260, Test: 0.6060
Epoch: 83, Loss: 0.6083, Train: 0.8500, Val: 0.6520, Test: 0.6180
Epoch: 84, Loss: 0.5308, Train: 0.7500, Val: 0.6100, Test: 0.5870
Epoch: 85, Loss: 0.6295, Train: 0.7667, Val: 0.6120, Test: 0.5980
Epoch: 86, Loss: 0.5167, Train: 0.9333, Val: 0.6980, Test: 0.6620
Epoch: 87, Loss: 0.5408, Train: 0.9167, Val: 0.7120, Test: 0.6510
Epoch: 88, Loss: 0.4742, Train: 0.9167, Val: 0.7080, Test: 0.6490
Epoch: 89, Loss: 0.5409, Train: 0.9500, Val: 0.7000, Test: 0.6690
Epoch: 90, Loss: 0.5190, Train: 0.8167, Val: 0.6520, Test: 0.6270
Epoch: 91, Loss: 0.5245, Train: 0.9667, Val: 0.6900, Test: 0.6510
Epoch: 92, Loss: 0.3649, Train: 0.7167, Val: 0.5780, Test: 0.5090
Epoch: 93, Loss: 0.8006, Train: 0.9167, Val: 0.6720, Test: 0.6460
Epoch: 94, Loss: 0.4099, Train: 0.7333, Val: 0.5880, Test: 0.5810
Epoch: 95, Loss: 0.5882, Train: 0.7500, Val: 0.6000, Test: 0.5900
Epoch: 96, Loss: 0.5396, Train: 0.9000, Val: 0.6840, Test: 0.6650
Epoch: 97, Loss: 0.3767, Train: 0.9500, Val: 0.7480, Test: 0.6970
Epoch: 98, Loss: 0.3642, Train: 0.9167, Val: 0.7220, Test: 0.6750
Epoch: 99, Loss: 0.4099, Train: 0.9167, Val: 0.7200, Test: 0.6780
Epoch: 100, Loss: 0.4951, Train: 0.9333, Val: 0.7480, Test: 0.7010
MAD:  0.3703
Best Test Accuracy: 0.7010, Val Accuracy: 0.7480, Train Accuracy: 0.9333
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1412, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 2, Loss: 1.1055, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 3, Loss: 1.0891, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 4, Loss: 1.1203, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 5, Loss: 1.1604, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 6, Loss: 1.1098, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 7, Loss: 1.1132, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 8, Loss: 1.1252, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 9, Loss: 1.1493, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 10, Loss: 1.1444, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 11, Loss: 1.0942, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 12, Loss: 1.1273, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 13, Loss: 1.1176, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 14, Loss: 1.1122, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 15, Loss: 1.0794, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 16, Loss: 1.1153, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 17, Loss: 1.0974, Train: 0.3167, Val: 0.3680, Test: 0.3860
Epoch: 18, Loss: 1.0647, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 19, Loss: 1.1246, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 20, Loss: 1.0869, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 21, Loss: 1.0933, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 22, Loss: 1.1353, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 23, Loss: 1.1151, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 24, Loss: 1.1201, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 25, Loss: 1.1745, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 26, Loss: 1.0794, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 27, Loss: 1.1313, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 28, Loss: 1.1264, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 29, Loss: 1.0943, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 30, Loss: 1.1109, Train: 0.3333, Val: 0.3900, Test: 0.4140
Epoch: 31, Loss: 1.1338, Train: 0.4000, Val: 0.4020, Test: 0.4240
Epoch: 32, Loss: 1.1220, Train: 0.6000, Val: 0.5100, Test: 0.5120
Epoch: 33, Loss: 1.0902, Train: 0.4833, Val: 0.4180, Test: 0.4190
Epoch: 34, Loss: 1.0894, Train: 0.3333, Val: 0.2020, Test: 0.1860
Epoch: 35, Loss: 1.1098, Train: 0.4000, Val: 0.2120, Test: 0.1930
Epoch: 36, Loss: 1.0931, Train: 0.3500, Val: 0.1980, Test: 0.1830
Epoch: 37, Loss: 1.1481, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 38, Loss: 1.1008, Train: 0.3500, Val: 0.1960, Test: 0.1820
Epoch: 39, Loss: 1.1031, Train: 0.4167, Val: 0.2300, Test: 0.2180
Epoch: 40, Loss: 1.1251, Train: 0.4667, Val: 0.3180, Test: 0.3130
Epoch: 41, Loss: 1.1215, Train: 0.5500, Val: 0.4400, Test: 0.4120
Epoch: 42, Loss: 1.0859, Train: 0.6167, Val: 0.5360, Test: 0.5180
Epoch: 43, Loss: 1.0929, Train: 0.5500, Val: 0.5040, Test: 0.4960
Epoch: 44, Loss: 1.1185, Train: 0.5000, Val: 0.4720, Test: 0.4700
Epoch: 45, Loss: 1.0989, Train: 0.4167, Val: 0.4340, Test: 0.4240
Epoch: 46, Loss: 1.1097, Train: 0.3833, Val: 0.4240, Test: 0.4120
Epoch: 47, Loss: 1.0978, Train: 0.3667, Val: 0.4220, Test: 0.4080
Epoch: 48, Loss: 1.0995, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 49, Loss: 1.0648, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 50, Loss: 1.0981, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 51, Loss: 1.0708, Train: 0.3833, Val: 0.4220, Test: 0.4080
Epoch: 52, Loss: 1.0680, Train: 0.3833, Val: 0.4220, Test: 0.4100
Epoch: 53, Loss: 1.0778, Train: 0.4000, Val: 0.4220, Test: 0.4140
Epoch: 54, Loss: 1.0647, Train: 0.4333, Val: 0.4300, Test: 0.4240
Epoch: 55, Loss: 1.1363, Train: 0.5167, Val: 0.4700, Test: 0.4740
Epoch: 56, Loss: 1.1430, Train: 0.7667, Val: 0.6240, Test: 0.6480
Epoch: 57, Loss: 1.0814, Train: 0.8333, Val: 0.6680, Test: 0.6670
Epoch: 58, Loss: 1.0479, Train: 0.8500, Val: 0.6980, Test: 0.6900
Epoch: 59, Loss: 1.0615, Train: 0.8333, Val: 0.6900, Test: 0.6710
Epoch: 60, Loss: 1.0890, Train: 0.8167, Val: 0.6620, Test: 0.6370
Epoch: 61, Loss: 1.0809, Train: 0.8000, Val: 0.6300, Test: 0.6000
Epoch: 62, Loss: 1.0877, Train: 0.7833, Val: 0.6020, Test: 0.5820
Epoch: 63, Loss: 1.0810, Train: 0.7667, Val: 0.5820, Test: 0.5710
Epoch: 64, Loss: 1.0414, Train: 0.7167, Val: 0.5720, Test: 0.5560
Epoch: 65, Loss: 1.0291, Train: 0.6667, Val: 0.5460, Test: 0.5330
Epoch: 66, Loss: 1.0193, Train: 0.6333, Val: 0.5320, Test: 0.5310
Epoch: 67, Loss: 1.0001, Train: 0.6333, Val: 0.5280, Test: 0.5240
Epoch: 68, Loss: 1.0580, Train: 0.6333, Val: 0.5300, Test: 0.5290
Epoch: 69, Loss: 0.9731, Train: 0.6333, Val: 0.5420, Test: 0.5250
Epoch: 70, Loss: 0.9837, Train: 0.6167, Val: 0.5440, Test: 0.5280
Epoch: 71, Loss: 0.9011, Train: 0.6333, Val: 0.5440, Test: 0.5230
Epoch: 72, Loss: 0.9197, Train: 0.6500, Val: 0.5440, Test: 0.5280
Epoch: 73, Loss: 0.8871, Train: 0.7000, Val: 0.5500, Test: 0.5390
Epoch: 74, Loss: 0.8137, Train: 0.6833, Val: 0.5440, Test: 0.5340
Epoch: 75, Loss: 0.8269, Train: 0.6667, Val: 0.5400, Test: 0.5400
Epoch: 76, Loss: 0.7687, Train: 0.6667, Val: 0.5460, Test: 0.5340
Epoch: 77, Loss: 0.7463, Train: 0.6833, Val: 0.5420, Test: 0.5190
Epoch: 78, Loss: 0.7277, Train: 0.6667, Val: 0.5580, Test: 0.5250
Epoch: 79, Loss: 0.7129, Train: 0.7000, Val: 0.5560, Test: 0.5410
Epoch: 80, Loss: 0.6813, Train: 0.6833, Val: 0.5620, Test: 0.5440
Epoch: 81, Loss: 0.6426, Train: 0.7500, Val: 0.5600, Test: 0.5460
Epoch: 82, Loss: 0.6646, Train: 0.7167, Val: 0.5900, Test: 0.5560
Epoch: 83, Loss: 0.6300, Train: 0.7667, Val: 0.5920, Test: 0.5640
Epoch: 84, Loss: 0.5674, Train: 0.8333, Val: 0.6380, Test: 0.6060
Epoch: 85, Loss: 0.5630, Train: 0.8500, Val: 0.6480, Test: 0.6160
Epoch: 86, Loss: 0.5989, Train: 0.8500, Val: 0.6700, Test: 0.6190
Epoch: 87, Loss: 0.5621, Train: 0.8667, Val: 0.6640, Test: 0.6330
Epoch: 88, Loss: 0.5901, Train: 0.8500, Val: 0.6580, Test: 0.6330
Epoch: 89, Loss: 0.5395, Train: 0.9333, Val: 0.7140, Test: 0.6610
Epoch: 90, Loss: 0.5063, Train: 0.9333, Val: 0.7080, Test: 0.6600
Epoch: 91, Loss: 0.5080, Train: 0.8833, Val: 0.6700, Test: 0.6420
Epoch: 92, Loss: 0.4978, Train: 0.9167, Val: 0.7040, Test: 0.6790
Epoch: 93, Loss: 0.4583, Train: 0.9000, Val: 0.7020, Test: 0.6530
Epoch: 94, Loss: 0.5940, Train: 0.9333, Val: 0.6980, Test: 0.6650
Epoch: 95, Loss: 0.4295, Train: 0.8000, Val: 0.6060, Test: 0.6080
Epoch: 96, Loss: 0.5046, Train: 0.9667, Val: 0.7080, Test: 0.6660
Epoch: 97, Loss: 0.3672, Train: 0.9333, Val: 0.7240, Test: 0.6870
Epoch: 98, Loss: 0.3886, Train: 0.9667, Val: 0.7180, Test: 0.6840
Epoch: 99, Loss: 0.3539, Train: 0.9500, Val: 0.6860, Test: 0.6620
Epoch: 100, Loss: 0.3199, Train: 0.9500, Val: 0.6740, Test: 0.6710
MAD:  0.0208
Best Test Accuracy: 0.6900, Val Accuracy: 0.6980, Train Accuracy: 0.8500
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-9): 9 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.0685, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 2, Loss: 1.0839, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 3, Loss: 1.1522, Train: 0.4167, Val: 0.3720, Test: 0.4150
Epoch: 4, Loss: 1.1085, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 5, Loss: 1.1098, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 6, Loss: 1.1137, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 7, Loss: 1.1652, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 8, Loss: 1.0612, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 9, Loss: 1.0908, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.1305, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.1378, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.1066, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 13, Loss: 1.1195, Train: 0.3333, Val: 0.3840, Test: 0.4140
Epoch: 14, Loss: 1.1060, Train: 0.3500, Val: 0.1900, Test: 0.1880
Epoch: 15, Loss: 1.1290, Train: 0.3333, Val: 0.1920, Test: 0.1800
Epoch: 16, Loss: 1.1183, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 17, Loss: 1.1033, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 18, Loss: 1.0933, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 19, Loss: 1.1181, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 20, Loss: 1.0555, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 21, Loss: 1.1219, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 22, Loss: 1.1031, Train: 0.4000, Val: 0.1960, Test: 0.2010
Epoch: 23, Loss: 1.1166, Train: 0.5167, Val: 0.3920, Test: 0.4110
Epoch: 24, Loss: 1.0748, Train: 0.4333, Val: 0.3880, Test: 0.4260
Epoch: 25, Loss: 1.1307, Train: 0.4333, Val: 0.4400, Test: 0.4830
Epoch: 26, Loss: 1.0978, Train: 0.5000, Val: 0.5300, Test: 0.5510
Epoch: 27, Loss: 1.1569, Train: 0.5333, Val: 0.5940, Test: 0.6160
Epoch: 28, Loss: 1.0860, Train: 0.5833, Val: 0.6100, Test: 0.6320
Epoch: 29, Loss: 1.0969, Train: 0.6333, Val: 0.6040, Test: 0.6190
Epoch: 30, Loss: 1.0778, Train: 0.7833, Val: 0.6500, Test: 0.6370
Epoch: 31, Loss: 1.0925, Train: 0.5167, Val: 0.3500, Test: 0.3550
Epoch: 32, Loss: 1.0746, Train: 0.4667, Val: 0.3060, Test: 0.3050
Epoch: 33, Loss: 1.0712, Train: 0.4500, Val: 0.3020, Test: 0.3070
Epoch: 34, Loss: 1.0550, Train: 0.4833, Val: 0.3420, Test: 0.3510
Epoch: 35, Loss: 1.0881, Train: 0.5167, Val: 0.4020, Test: 0.4010
Epoch: 36, Loss: 1.0970, Train: 0.5167, Val: 0.4160, Test: 0.4290
Epoch: 37, Loss: 1.0802, Train: 0.4000, Val: 0.4320, Test: 0.4460
Epoch: 38, Loss: 1.0841, Train: 0.4500, Val: 0.4780, Test: 0.5200
Epoch: 39, Loss: 1.0804, Train: 0.4833, Val: 0.5480, Test: 0.5730
Epoch: 40, Loss: 1.0922, Train: 0.5500, Val: 0.5860, Test: 0.5960
Epoch: 41, Loss: 1.0728, Train: 0.5500, Val: 0.5920, Test: 0.6070
Epoch: 42, Loss: 1.1017, Train: 0.6000, Val: 0.6160, Test: 0.6370
Epoch: 43, Loss: 1.0703, Train: 0.6333, Val: 0.5840, Test: 0.5990
Epoch: 44, Loss: 1.0944, Train: 0.6167, Val: 0.5460, Test: 0.5640
Epoch: 45, Loss: 1.0504, Train: 0.6167, Val: 0.5480, Test: 0.5660
Epoch: 46, Loss: 1.0366, Train: 0.6167, Val: 0.5400, Test: 0.5650
Epoch: 47, Loss: 1.0285, Train: 0.6833, Val: 0.5800, Test: 0.5930
Epoch: 48, Loss: 1.0104, Train: 0.7333, Val: 0.6320, Test: 0.6460
Epoch: 49, Loss: 1.0207, Train: 0.8667, Val: 0.7220, Test: 0.7170
Epoch: 50, Loss: 0.9649, Train: 0.8667, Val: 0.7260, Test: 0.7060
Epoch: 51, Loss: 0.9989, Train: 0.8667, Val: 0.7460, Test: 0.6920
Epoch: 52, Loss: 0.9423, Train: 0.8500, Val: 0.7020, Test: 0.6660
Epoch: 53, Loss: 0.9379, Train: 0.8333, Val: 0.6480, Test: 0.6260
Epoch: 54, Loss: 0.9252, Train: 0.7833, Val: 0.5920, Test: 0.5670
Epoch: 55, Loss: 0.8412, Train: 0.8000, Val: 0.6160, Test: 0.6000
Epoch: 56, Loss: 0.8773, Train: 0.7500, Val: 0.6220, Test: 0.6030
Epoch: 57, Loss: 0.7783, Train: 0.7000, Val: 0.5860, Test: 0.5510
Epoch: 58, Loss: 0.7693, Train: 0.7333, Val: 0.5940, Test: 0.5590
Epoch: 59, Loss: 0.7681, Train: 0.7500, Val: 0.6100, Test: 0.5990
Epoch: 60, Loss: 0.7174, Train: 0.7667, Val: 0.6160, Test: 0.5880
Epoch: 61, Loss: 0.7370, Train: 0.6500, Val: 0.5680, Test: 0.5200
Epoch: 62, Loss: 0.6376, Train: 0.6500, Val: 0.5460, Test: 0.5160
Epoch: 63, Loss: 0.6882, Train: 0.6500, Val: 0.5540, Test: 0.5170
Epoch: 64, Loss: 0.7142, Train: 0.7167, Val: 0.5940, Test: 0.5430
Epoch: 65, Loss: 0.6343, Train: 0.7500, Val: 0.6280, Test: 0.5790
Epoch: 66, Loss: 0.6187, Train: 0.6667, Val: 0.5920, Test: 0.5550
Epoch: 67, Loss: 0.5803, Train: 0.6833, Val: 0.5660, Test: 0.5500
Epoch: 68, Loss: 0.6173, Train: 0.6833, Val: 0.6140, Test: 0.5690
Epoch: 69, Loss: 0.6271, Train: 0.7500, Val: 0.6540, Test: 0.6000
Epoch: 70, Loss: 0.5775, Train: 0.8333, Val: 0.6940, Test: 0.6600
Epoch: 71, Loss: 0.5890, Train: 0.9167, Val: 0.7200, Test: 0.6920
Epoch: 72, Loss: 0.6367, Train: 0.9000, Val: 0.7300, Test: 0.7010
Epoch: 73, Loss: 0.5931, Train: 0.9333, Val: 0.7400, Test: 0.7160
Epoch: 74, Loss: 0.5786, Train: 0.9500, Val: 0.7500, Test: 0.7240
Epoch: 75, Loss: 0.6211, Train: 0.9500, Val: 0.7620, Test: 0.7380
Epoch: 76, Loss: 0.5373, Train: 0.9500, Val: 0.7640, Test: 0.7360
Epoch: 77, Loss: 0.5187, Train: 0.9500, Val: 0.7380, Test: 0.7210
Epoch: 78, Loss: 0.5459, Train: 0.9000, Val: 0.6900, Test: 0.6770
Epoch: 79, Loss: 0.4782, Train: 0.9333, Val: 0.6940, Test: 0.6780
Epoch: 80, Loss: 0.4401, Train: 0.9500, Val: 0.7120, Test: 0.6910
Epoch: 81, Loss: 0.4157, Train: 0.8833, Val: 0.7120, Test: 0.6970
Epoch: 82, Loss: 0.4772, Train: 0.8833, Val: 0.7340, Test: 0.7080
Epoch: 83, Loss: 0.4420, Train: 0.9167, Val: 0.7020, Test: 0.6750
Epoch: 84, Loss: 0.4439, Train: 0.9000, Val: 0.7000, Test: 0.6730
Epoch: 85, Loss: 0.4874, Train: 0.9500, Val: 0.7520, Test: 0.7260
Epoch: 86, Loss: 0.3946, Train: 0.9333, Val: 0.7780, Test: 0.7450
Epoch: 87, Loss: 0.3766, Train: 0.9167, Val: 0.7540, Test: 0.7280
Epoch: 88, Loss: 0.4091, Train: 0.9167, Val: 0.7580, Test: 0.7280
Epoch: 89, Loss: 0.4317, Train: 0.9500, Val: 0.7820, Test: 0.7560
Epoch: 90, Loss: 0.3204, Train: 0.9500, Val: 0.7600, Test: 0.7450
Epoch: 91, Loss: 0.3332, Train: 0.9500, Val: 0.7520, Test: 0.7190
Epoch: 92, Loss: 0.2533, Train: 0.9500, Val: 0.7440, Test: 0.7030
Epoch: 93, Loss: 0.2929, Train: 0.9833, Val: 0.7500, Test: 0.7210
Epoch: 94, Loss: 0.2606, Train: 0.9500, Val: 0.7500, Test: 0.7230
Epoch: 95, Loss: 0.2716, Train: 0.9500, Val: 0.7640, Test: 0.7350
Epoch: 96, Loss: 0.1752, Train: 0.9833, Val: 0.7720, Test: 0.7450
Epoch: 97, Loss: 0.1846, Train: 0.9667, Val: 0.7700, Test: 0.7450
Epoch: 98, Loss: 0.2035, Train: 0.9667, Val: 0.7680, Test: 0.7500
Epoch: 99, Loss: 0.2154, Train: 0.9833, Val: 0.7700, Test: 0.7530
Epoch: 100, Loss: 0.1398, Train: 0.9667, Val: 0.7760, Test: 0.7460
MAD:  0.3934
Best Test Accuracy: 0.7560, Val Accuracy: 0.7820, Train Accuracy: 0.9500
Training completed.
Average Test Accuracy:  0.6759999999999999 ± 0.06617854637267279
Average MAD:  0.28147 ± 0.1500839768263088
