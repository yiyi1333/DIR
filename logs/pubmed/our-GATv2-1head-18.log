Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1214, Train: 0.3167, Val: 0.2780, Test: 0.2360
Epoch: 2, Loss: 1.0891, Train: 0.3500, Val: 0.2520, Test: 0.2350
Epoch: 3, Loss: 1.1348, Train: 0.3667, Val: 0.2500, Test: 0.2290
Epoch: 4, Loss: 1.0755, Train: 0.3333, Val: 0.2020, Test: 0.1850
Epoch: 5, Loss: 1.1258, Train: 0.5167, Val: 0.4800, Test: 0.4780
Epoch: 6, Loss: 1.1183, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 7, Loss: 1.1308, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 8, Loss: 1.0831, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 9, Loss: 1.1300, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.0927, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.1309, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.0887, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 13, Loss: 1.1157, Train: 0.3500, Val: 0.3880, Test: 0.4130
Epoch: 14, Loss: 1.1362, Train: 0.3833, Val: 0.3960, Test: 0.4280
Epoch: 15, Loss: 1.1138, Train: 0.5333, Val: 0.4580, Test: 0.4760
Epoch: 16, Loss: 1.1266, Train: 0.5333, Val: 0.4880, Test: 0.4890
Epoch: 17, Loss: 1.1013, Train: 0.5333, Val: 0.4880, Test: 0.4880
Epoch: 18, Loss: 1.0979, Train: 0.4833, Val: 0.4660, Test: 0.4780
Epoch: 19, Loss: 1.1158, Train: 0.4333, Val: 0.4300, Test: 0.4580
Epoch: 20, Loss: 1.1420, Train: 0.3667, Val: 0.3940, Test: 0.4170
Epoch: 21, Loss: 1.1022, Train: 0.3333, Val: 0.3880, Test: 0.4140
Epoch: 22, Loss: 1.1324, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 23, Loss: 1.0908, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 24, Loss: 1.1088, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 25, Loss: 1.1274, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 26, Loss: 1.1060, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 27, Loss: 1.0929, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 28, Loss: 1.1254, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 29, Loss: 1.0938, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 30, Loss: 1.0866, Train: 0.3333, Val: 0.3880, Test: 0.4140
Epoch: 31, Loss: 1.1010, Train: 0.4333, Val: 0.4000, Test: 0.4210
Epoch: 32, Loss: 1.1032, Train: 0.6167, Val: 0.5120, Test: 0.5280
Epoch: 33, Loss: 1.0847, Train: 0.7167, Val: 0.6280, Test: 0.6330
Epoch: 34, Loss: 1.0963, Train: 0.6000, Val: 0.5260, Test: 0.4930
Epoch: 35, Loss: 1.0752, Train: 0.4500, Val: 0.4420, Test: 0.4400
Epoch: 36, Loss: 1.0870, Train: 0.3833, Val: 0.4240, Test: 0.4120
Epoch: 37, Loss: 1.0919, Train: 0.3667, Val: 0.4180, Test: 0.4080
Epoch: 38, Loss: 1.1179, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 39, Loss: 1.1103, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 40, Loss: 1.1073, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 41, Loss: 1.1084, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 42, Loss: 1.1102, Train: 0.3667, Val: 0.4220, Test: 0.4100
Epoch: 43, Loss: 1.0953, Train: 0.4500, Val: 0.4520, Test: 0.4390
Epoch: 44, Loss: 1.1166, Train: 0.6333, Val: 0.5540, Test: 0.5220
Epoch: 45, Loss: 1.0782, Train: 0.7500, Val: 0.6780, Test: 0.6510
Epoch: 46, Loss: 1.0588, Train: 0.6833, Val: 0.6120, Test: 0.6030
Epoch: 47, Loss: 1.0661, Train: 0.6000, Val: 0.5620, Test: 0.5450
Epoch: 48, Loss: 1.0960, Train: 0.5667, Val: 0.4940, Test: 0.4970
Epoch: 49, Loss: 1.1010, Train: 0.5667, Val: 0.4880, Test: 0.4870
Epoch: 50, Loss: 1.0780, Train: 0.5833, Val: 0.5200, Test: 0.5160
Epoch: 51, Loss: 1.1074, Train: 0.6333, Val: 0.5400, Test: 0.5360
Epoch: 52, Loss: 1.0624, Train: 0.6333, Val: 0.5320, Test: 0.5340
Epoch: 53, Loss: 1.0821, Train: 0.6333, Val: 0.5280, Test: 0.5290
Epoch: 54, Loss: 1.0762, Train: 0.6333, Val: 0.5280, Test: 0.5300
Epoch: 55, Loss: 1.0667, Train: 0.6333, Val: 0.5260, Test: 0.5280
Epoch: 56, Loss: 1.0711, Train: 0.6333, Val: 0.5260, Test: 0.5280
Epoch: 57, Loss: 1.0105, Train: 0.6333, Val: 0.5400, Test: 0.5340
Epoch: 58, Loss: 1.0493, Train: 0.6333, Val: 0.5460, Test: 0.5310
Epoch: 59, Loss: 1.0531, Train: 0.6333, Val: 0.5400, Test: 0.5320
Epoch: 60, Loss: 1.0149, Train: 0.6333, Val: 0.5340, Test: 0.5320
Epoch: 61, Loss: 0.9961, Train: 0.6333, Val: 0.5320, Test: 0.5310
Epoch: 62, Loss: 0.9913, Train: 0.6333, Val: 0.5400, Test: 0.5280
Epoch: 63, Loss: 0.9494, Train: 0.6333, Val: 0.5460, Test: 0.5350
Epoch: 64, Loss: 0.9320, Train: 0.6500, Val: 0.5360, Test: 0.5370
Epoch: 65, Loss: 0.9273, Train: 0.6500, Val: 0.5420, Test: 0.5390
Epoch: 66, Loss: 0.9200, Train: 0.6333, Val: 0.5500, Test: 0.5410
Epoch: 67, Loss: 0.8841, Train: 0.6333, Val: 0.5460, Test: 0.5380
Epoch: 68, Loss: 0.8925, Train: 0.6667, Val: 0.5540, Test: 0.5520
Epoch: 69, Loss: 0.8302, Train: 0.6667, Val: 0.5560, Test: 0.5450
Epoch: 70, Loss: 0.8032, Train: 0.6667, Val: 0.5580, Test: 0.5450
Epoch: 71, Loss: 0.7764, Train: 0.6667, Val: 0.5520, Test: 0.5500
Epoch: 72, Loss: 0.8242, Train: 0.7000, Val: 0.5500, Test: 0.5520
Epoch: 73, Loss: 0.7464, Train: 0.6833, Val: 0.5580, Test: 0.5570
Epoch: 74, Loss: 0.7075, Train: 0.7167, Val: 0.5600, Test: 0.5640
Epoch: 75, Loss: 0.7317, Train: 0.7167, Val: 0.5720, Test: 0.5750
Epoch: 76, Loss: 0.6690, Train: 0.7333, Val: 0.5800, Test: 0.5880
Epoch: 77, Loss: 0.6005, Train: 0.8000, Val: 0.5880, Test: 0.6090
Epoch: 78, Loss: 0.6382, Train: 0.8000, Val: 0.6100, Test: 0.6370
Epoch: 79, Loss: 0.6058, Train: 0.8167, Val: 0.6480, Test: 0.6610
Epoch: 80, Loss: 0.6054, Train: 0.8000, Val: 0.6540, Test: 0.6550
Epoch: 81, Loss: 0.5929, Train: 0.8167, Val: 0.6640, Test: 0.6730
Epoch: 82, Loss: 0.6015, Train: 0.8500, Val: 0.6800, Test: 0.6870
Epoch: 83, Loss: 0.5916, Train: 0.7833, Val: 0.6540, Test: 0.6620
Epoch: 84, Loss: 0.6040, Train: 0.7833, Val: 0.6520, Test: 0.6630
Epoch: 85, Loss: 0.5364, Train: 0.8333, Val: 0.6660, Test: 0.6770
Epoch: 86, Loss: 0.6319, Train: 0.8333, Val: 0.6640, Test: 0.6800
Epoch: 87, Loss: 0.5634, Train: 0.8167, Val: 0.6600, Test: 0.6810
Epoch: 88, Loss: 0.5138, Train: 0.7833, Val: 0.6480, Test: 0.6620
Epoch: 89, Loss: 0.5030, Train: 0.8167, Val: 0.6540, Test: 0.6780
Epoch: 90, Loss: 0.4323, Train: 0.9500, Val: 0.7220, Test: 0.6910
Epoch: 91, Loss: 0.4523, Train: 0.9333, Val: 0.7140, Test: 0.7040
Epoch: 92, Loss: 0.4478, Train: 0.8167, Val: 0.6800, Test: 0.6790
Epoch: 93, Loss: 0.4079, Train: 0.8167, Val: 0.6540, Test: 0.6630
Epoch: 94, Loss: 0.5011, Train: 0.9000, Val: 0.7180, Test: 0.7160
Epoch: 95, Loss: 0.4558, Train: 0.9333, Val: 0.7480, Test: 0.7410
Epoch: 96, Loss: 0.3118, Train: 0.9667, Val: 0.7620, Test: 0.7630
Epoch: 97, Loss: 0.2991, Train: 0.9833, Val: 0.7480, Test: 0.7280
Epoch: 98, Loss: 0.3060, Train: 0.9833, Val: 0.7560, Test: 0.7380
Epoch: 99, Loss: 0.2643, Train: 0.9500, Val: 0.7320, Test: 0.7360
Epoch: 100, Loss: 0.2652, Train: 0.8833, Val: 0.7220, Test: 0.7180
MAD:  0.3789
Best Test Accuracy: 0.7630, Val Accuracy: 0.7620, Train Accuracy: 0.9667
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1722, Train: 0.3167, Val: 0.4020, Test: 0.4130
Epoch: 2, Loss: 1.1163, Train: 0.3167, Val: 0.4140, Test: 0.4040
Epoch: 3, Loss: 1.1687, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 4, Loss: 1.1724, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.0914, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 6, Loss: 1.1644, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 7, Loss: 1.1257, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 8, Loss: 1.1703, Train: 0.3333, Val: 0.4180, Test: 0.4070
Epoch: 9, Loss: 1.1249, Train: 0.3500, Val: 0.4160, Test: 0.4030
Epoch: 10, Loss: 1.0709, Train: 0.3667, Val: 0.4220, Test: 0.4080
Epoch: 11, Loss: 1.1445, Train: 0.3833, Val: 0.4280, Test: 0.4080
Epoch: 12, Loss: 1.1095, Train: 0.3667, Val: 0.4240, Test: 0.4090
Epoch: 13, Loss: 1.0919, Train: 0.3667, Val: 0.4240, Test: 0.4100
Epoch: 14, Loss: 1.1234, Train: 0.3500, Val: 0.4200, Test: 0.4080
Epoch: 15, Loss: 1.1453, Train: 0.3667, Val: 0.4240, Test: 0.4110
Epoch: 16, Loss: 1.1024, Train: 0.4500, Val: 0.4360, Test: 0.4280
Epoch: 17, Loss: 1.0718, Train: 0.5833, Val: 0.4660, Test: 0.4320
Epoch: 18, Loss: 1.1152, Train: 0.3833, Val: 0.2800, Test: 0.2600
Epoch: 19, Loss: 1.1327, Train: 0.4000, Val: 0.2540, Test: 0.2610
Epoch: 20, Loss: 1.0625, Train: 0.4833, Val: 0.3920, Test: 0.3790
Epoch: 21, Loss: 1.0739, Train: 0.5000, Val: 0.4420, Test: 0.4610
Epoch: 22, Loss: 1.1177, Train: 0.3667, Val: 0.3920, Test: 0.4200
Epoch: 23, Loss: 1.0815, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 24, Loss: 1.1029, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 25, Loss: 1.1078, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 26, Loss: 1.0950, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 27, Loss: 1.1029, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 28, Loss: 1.1184, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 29, Loss: 1.0748, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 30, Loss: 1.1318, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 31, Loss: 1.1012, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 32, Loss: 1.0577, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 33, Loss: 1.1364, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 34, Loss: 1.1144, Train: 0.5333, Val: 0.4980, Test: 0.5000
Epoch: 35, Loss: 1.0503, Train: 0.3500, Val: 0.2040, Test: 0.1890
Epoch: 36, Loss: 1.0718, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 37, Loss: 1.1039, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 38, Loss: 1.1253, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 39, Loss: 1.0643, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 40, Loss: 1.1093, Train: 0.3333, Val: 0.1960, Test: 0.1810
Epoch: 41, Loss: 1.1130, Train: 0.3500, Val: 0.2260, Test: 0.2150
Epoch: 42, Loss: 1.0975, Train: 0.6000, Val: 0.4840, Test: 0.4870
Epoch: 43, Loss: 1.1127, Train: 0.8167, Val: 0.6520, Test: 0.6250
Epoch: 44, Loss: 1.0966, Train: 0.8000, Val: 0.5880, Test: 0.5730
Epoch: 45, Loss: 1.1255, Train: 0.7167, Val: 0.5580, Test: 0.5500
Epoch: 46, Loss: 1.0671, Train: 0.7333, Val: 0.5980, Test: 0.6290
Epoch: 47, Loss: 1.0820, Train: 0.5833, Val: 0.5220, Test: 0.5520
Epoch: 48, Loss: 1.1113, Train: 0.5333, Val: 0.5000, Test: 0.5330
Epoch: 49, Loss: 1.0602, Train: 0.5167, Val: 0.5020, Test: 0.5330
Epoch: 50, Loss: 1.0748, Train: 0.5167, Val: 0.4640, Test: 0.4870
Epoch: 51, Loss: 1.0977, Train: 0.4500, Val: 0.4220, Test: 0.4400
Epoch: 52, Loss: 1.0854, Train: 0.4167, Val: 0.4120, Test: 0.4360
Epoch: 53, Loss: 1.0648, Train: 0.5167, Val: 0.4400, Test: 0.4660
Epoch: 54, Loss: 1.0423, Train: 0.5667, Val: 0.4800, Test: 0.5050
Epoch: 55, Loss: 1.0493, Train: 0.6833, Val: 0.5580, Test: 0.5480
Epoch: 56, Loss: 1.0811, Train: 0.7667, Val: 0.6100, Test: 0.6130
Epoch: 57, Loss: 1.0369, Train: 0.8000, Val: 0.5880, Test: 0.5900
Epoch: 58, Loss: 0.9890, Train: 0.7833, Val: 0.6220, Test: 0.5980
Epoch: 59, Loss: 1.0285, Train: 0.8000, Val: 0.6000, Test: 0.5690
Epoch: 60, Loss: 1.0011, Train: 0.7667, Val: 0.5920, Test: 0.5520
Epoch: 61, Loss: 0.9832, Train: 0.6833, Val: 0.5620, Test: 0.5380
Epoch: 62, Loss: 0.9508, Train: 0.6500, Val: 0.5400, Test: 0.5280
Epoch: 63, Loss: 0.9438, Train: 0.6500, Val: 0.5420, Test: 0.5260
Epoch: 64, Loss: 0.9045, Train: 0.6333, Val: 0.5460, Test: 0.5220
Epoch: 65, Loss: 0.8786, Train: 0.6500, Val: 0.5520, Test: 0.5180
Epoch: 66, Loss: 0.8722, Train: 0.6333, Val: 0.5620, Test: 0.5280
Epoch: 67, Loss: 0.8879, Train: 0.6500, Val: 0.5500, Test: 0.5230
Epoch: 68, Loss: 0.7891, Train: 0.6333, Val: 0.5520, Test: 0.5170
Epoch: 69, Loss: 0.7585, Train: 0.6333, Val: 0.5420, Test: 0.5190
Epoch: 70, Loss: 0.7924, Train: 0.6333, Val: 0.5520, Test: 0.5180
Epoch: 71, Loss: 0.7657, Train: 0.6500, Val: 0.5500, Test: 0.5230
Epoch: 72, Loss: 0.7035, Train: 0.6500, Val: 0.5520, Test: 0.5220
Epoch: 73, Loss: 0.6905, Train: 0.6667, Val: 0.5360, Test: 0.5120
Epoch: 74, Loss: 0.7181, Train: 0.6833, Val: 0.5400, Test: 0.5010
Epoch: 75, Loss: 0.7310, Train: 0.6500, Val: 0.5520, Test: 0.5250
Epoch: 76, Loss: 0.6527, Train: 0.6500, Val: 0.5380, Test: 0.5180
Epoch: 77, Loss: 0.6145, Train: 0.6500, Val: 0.5400, Test: 0.5230
Epoch: 78, Loss: 0.7027, Train: 0.6500, Val: 0.5400, Test: 0.5190
Epoch: 79, Loss: 0.7270, Train: 0.6500, Val: 0.5440, Test: 0.5210
Epoch: 80, Loss: 0.5929, Train: 0.6667, Val: 0.5420, Test: 0.5330
Epoch: 81, Loss: 0.6253, Train: 0.6667, Val: 0.5560, Test: 0.5270
Epoch: 82, Loss: 0.6498, Train: 0.6833, Val: 0.5540, Test: 0.5300
Epoch: 83, Loss: 0.6139, Train: 0.6667, Val: 0.5560, Test: 0.5200
Epoch: 84, Loss: 0.5706, Train: 0.7167, Val: 0.5380, Test: 0.5270
Epoch: 85, Loss: 0.5882, Train: 0.7667, Val: 0.5760, Test: 0.5360
Epoch: 86, Loss: 0.5759, Train: 0.6500, Val: 0.5440, Test: 0.5220
Epoch: 87, Loss: 0.5859, Train: 0.6667, Val: 0.5400, Test: 0.5170
Epoch: 88, Loss: 0.5427, Train: 0.6833, Val: 0.5320, Test: 0.5080
Epoch: 89, Loss: 0.5751, Train: 0.6500, Val: 0.5280, Test: 0.5050
Epoch: 90, Loss: 0.5749, Train: 0.6500, Val: 0.5300, Test: 0.5060
Epoch: 91, Loss: 0.5616, Train: 0.6667, Val: 0.5280, Test: 0.4990
Epoch: 92, Loss: 0.5469, Train: 0.6667, Val: 0.5240, Test: 0.4970
Epoch: 93, Loss: 0.5455, Train: 0.6667, Val: 0.5280, Test: 0.5050
Epoch: 94, Loss: 0.5237, Train: 0.6500, Val: 0.5260, Test: 0.5050
Epoch: 95, Loss: 0.5183, Train: 0.6667, Val: 0.5200, Test: 0.4980
Epoch: 96, Loss: 0.5176, Train: 0.6833, Val: 0.5320, Test: 0.4980
Epoch: 97, Loss: 0.5024, Train: 0.6500, Val: 0.5320, Test: 0.5090
Epoch: 98, Loss: 0.5211, Train: 0.6500, Val: 0.5360, Test: 0.5100
Epoch: 99, Loss: 0.5580, Train: 0.6833, Val: 0.5340, Test: 0.5030
Epoch: 100, Loss: 0.4956, Train: 0.7000, Val: 0.5280, Test: 0.5010
MAD:  0.0037
Best Test Accuracy: 0.6290, Val Accuracy: 0.5980, Train Accuracy: 0.7333
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1136, Train: 0.4167, Val: 0.3840, Test: 0.4140
Epoch: 2, Loss: 1.1144, Train: 0.3333, Val: 0.1960, Test: 0.1830
Epoch: 3, Loss: 1.1490, Train: 0.3500, Val: 0.2160, Test: 0.1990
Epoch: 4, Loss: 1.1169, Train: 0.3833, Val: 0.2500, Test: 0.2190
Epoch: 5, Loss: 1.1269, Train: 0.4000, Val: 0.3540, Test: 0.3480
Epoch: 6, Loss: 1.1070, Train: 0.4167, Val: 0.3900, Test: 0.3610
Epoch: 7, Loss: 1.1138, Train: 0.3333, Val: 0.3880, Test: 0.4170
Epoch: 8, Loss: 1.1058, Train: 0.3333, Val: 0.3900, Test: 0.4130
Epoch: 9, Loss: 1.1257, Train: 0.4167, Val: 0.3020, Test: 0.3040
Epoch: 10, Loss: 1.1130, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 11, Loss: 1.1180, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 12, Loss: 1.1015, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 13, Loss: 1.1277, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 14, Loss: 1.0859, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 15, Loss: 1.1050, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 16, Loss: 1.0983, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 17, Loss: 1.0790, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 18, Loss: 1.1292, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 19, Loss: 1.0922, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 20, Loss: 1.0788, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 21, Loss: 1.1439, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 22, Loss: 1.1299, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 23, Loss: 1.1284, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 24, Loss: 1.1269, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 25, Loss: 1.1038, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 26, Loss: 1.1241, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 27, Loss: 1.0912, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 28, Loss: 1.1044, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 29, Loss: 1.1012, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 30, Loss: 1.1018, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 31, Loss: 1.0976, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.0854, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 33, Loss: 1.1167, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 34, Loss: 1.0954, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 35, Loss: 1.0950, Train: 0.4333, Val: 0.2780, Test: 0.2450
Epoch: 36, Loss: 1.1141, Train: 0.5000, Val: 0.4300, Test: 0.4520
Epoch: 37, Loss: 1.0990, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 38, Loss: 1.0997, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 39, Loss: 1.1290, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 40, Loss: 1.0852, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 41, Loss: 1.1161, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 42, Loss: 1.1148, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 43, Loss: 1.0885, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 44, Loss: 1.1123, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 45, Loss: 1.0817, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 46, Loss: 1.0827, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 47, Loss: 1.0929, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 48, Loss: 1.0700, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 49, Loss: 1.0903, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 50, Loss: 1.0889, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 51, Loss: 1.1047, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 52, Loss: 1.0989, Train: 0.6167, Val: 0.5720, Test: 0.5940
Epoch: 53, Loss: 1.0968, Train: 0.5833, Val: 0.5460, Test: 0.5640
Epoch: 54, Loss: 1.0779, Train: 0.4833, Val: 0.4700, Test: 0.4520
Epoch: 55, Loss: 1.0957, Train: 0.5500, Val: 0.4960, Test: 0.4750
Epoch: 56, Loss: 1.0803, Train: 0.5667, Val: 0.5060, Test: 0.4910
Epoch: 57, Loss: 1.1252, Train: 0.5667, Val: 0.5140, Test: 0.5000
Epoch: 58, Loss: 1.0818, Train: 0.6333, Val: 0.5380, Test: 0.5350
Epoch: 59, Loss: 1.1157, Train: 0.8333, Val: 0.6160, Test: 0.6310
Epoch: 60, Loss: 1.0696, Train: 0.6833, Val: 0.6280, Test: 0.6430
Epoch: 61, Loss: 1.0623, Train: 0.6333, Val: 0.5620, Test: 0.5690
Epoch: 62, Loss: 1.0544, Train: 0.6000, Val: 0.5400, Test: 0.5490
Epoch: 63, Loss: 1.0655, Train: 0.5667, Val: 0.4820, Test: 0.4910
Epoch: 64, Loss: 1.0265, Train: 0.5667, Val: 0.4820, Test: 0.4980
Epoch: 65, Loss: 1.0315, Train: 0.6000, Val: 0.4880, Test: 0.5020
Epoch: 66, Loss: 1.0471, Train: 0.5833, Val: 0.4960, Test: 0.4980
Epoch: 67, Loss: 0.9798, Train: 0.5833, Val: 0.5040, Test: 0.4970
Epoch: 68, Loss: 0.9547, Train: 0.6500, Val: 0.5880, Test: 0.5690
Epoch: 69, Loss: 0.9274, Train: 0.7500, Val: 0.5760, Test: 0.5600
Epoch: 70, Loss: 0.9292, Train: 0.6333, Val: 0.5660, Test: 0.5380
Epoch: 71, Loss: 0.8826, Train: 0.6333, Val: 0.5560, Test: 0.5230
Epoch: 72, Loss: 0.8723, Train: 0.6500, Val: 0.5500, Test: 0.5180
Epoch: 73, Loss: 0.8244, Train: 0.6333, Val: 0.5460, Test: 0.5270
Epoch: 74, Loss: 0.8190, Train: 0.6333, Val: 0.5520, Test: 0.5200
Epoch: 75, Loss: 0.7829, Train: 0.6333, Val: 0.5480, Test: 0.5180
Epoch: 76, Loss: 0.7241, Train: 0.6500, Val: 0.5500, Test: 0.5200
Epoch: 77, Loss: 0.7179, Train: 0.6500, Val: 0.5460, Test: 0.5210
Epoch: 78, Loss: 0.6686, Train: 0.6667, Val: 0.5400, Test: 0.5120
Epoch: 79, Loss: 0.7221, Train: 0.6667, Val: 0.5400, Test: 0.5180
Epoch: 80, Loss: 0.6685, Train: 0.6833, Val: 0.5440, Test: 0.5130
Epoch: 81, Loss: 0.6453, Train: 0.6667, Val: 0.5260, Test: 0.5070
Epoch: 82, Loss: 0.6429, Train: 0.6500, Val: 0.5340, Test: 0.5100
Epoch: 83, Loss: 0.6592, Train: 0.6667, Val: 0.5360, Test: 0.5130
Epoch: 84, Loss: 0.5841, Train: 0.6667, Val: 0.5380, Test: 0.5110
Epoch: 85, Loss: 0.5720, Train: 0.6667, Val: 0.5340, Test: 0.5070
Epoch: 86, Loss: 0.5878, Train: 0.6500, Val: 0.5280, Test: 0.5100
Epoch: 87, Loss: 0.5829, Train: 0.6667, Val: 0.5400, Test: 0.5080
Epoch: 88, Loss: 0.5724, Train: 0.6667, Val: 0.5380, Test: 0.5080
Epoch: 89, Loss: 0.5588, Train: 0.6667, Val: 0.5480, Test: 0.5320
Epoch: 90, Loss: 0.5410, Train: 0.6500, Val: 0.5300, Test: 0.5190
Epoch: 91, Loss: 0.5285, Train: 0.6667, Val: 0.5280, Test: 0.5190
Epoch: 92, Loss: 0.5517, Train: 0.6667, Val: 0.5220, Test: 0.5170
Epoch: 93, Loss: 0.5364, Train: 0.6667, Val: 0.5300, Test: 0.5180
Epoch: 94, Loss: 0.5027, Train: 0.6667, Val: 0.5260, Test: 0.5150
Epoch: 95, Loss: 0.5059, Train: 0.6833, Val: 0.5420, Test: 0.5370
Epoch: 96, Loss: 0.4846, Train: 0.8000, Val: 0.5900, Test: 0.6110
Epoch: 97, Loss: 0.4846, Train: 0.6667, Val: 0.5300, Test: 0.5090
Epoch: 98, Loss: 0.4622, Train: 0.6833, Val: 0.5360, Test: 0.5140
Epoch: 99, Loss: 0.5045, Train: 0.7000, Val: 0.5380, Test: 0.5050
Epoch: 100, Loss: 0.5323, Train: 0.6833, Val: 0.5300, Test: 0.5180
MAD:  0.0183
Best Test Accuracy: 0.6430, Val Accuracy: 0.6280, Train Accuracy: 0.6833
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1240, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 2, Loss: 1.0915, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 3, Loss: 1.1284, Train: 0.3333, Val: 0.1960, Test: 0.1810
Epoch: 4, Loss: 1.1506, Train: 0.3667, Val: 0.3140, Test: 0.2840
Epoch: 5, Loss: 1.1366, Train: 0.4167, Val: 0.4860, Test: 0.4890
Epoch: 6, Loss: 1.1149, Train: 0.3333, Val: 0.4460, Test: 0.4450
Epoch: 7, Loss: 1.1216, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 8, Loss: 1.0775, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 9, Loss: 1.0984, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 10, Loss: 1.1675, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 11, Loss: 1.1277, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 12, Loss: 1.1090, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 13, Loss: 1.1217, Train: 0.5333, Val: 0.4240, Test: 0.4320
Epoch: 14, Loss: 1.1042, Train: 0.3333, Val: 0.1980, Test: 0.1810
Epoch: 15, Loss: 1.1244, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 16, Loss: 1.0967, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 17, Loss: 1.0758, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 18, Loss: 1.1099, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 19, Loss: 1.1201, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 20, Loss: 1.1280, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 21, Loss: 1.1273, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 22, Loss: 1.1088, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 23, Loss: 1.1493, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 24, Loss: 1.1157, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 25, Loss: 1.1332, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 26, Loss: 1.1001, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 27, Loss: 1.0915, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 28, Loss: 1.1205, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 29, Loss: 1.1291, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 30, Loss: 1.1576, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 31, Loss: 1.1176, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.1063, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 33, Loss: 1.0686, Train: 0.4000, Val: 0.3000, Test: 0.2770
Epoch: 34, Loss: 1.0944, Train: 0.6000, Val: 0.5260, Test: 0.5090
Epoch: 35, Loss: 1.1086, Train: 0.4000, Val: 0.3120, Test: 0.2770
Epoch: 36, Loss: 1.1312, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 37, Loss: 1.0818, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 38, Loss: 1.0966, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 39, Loss: 1.0780, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 40, Loss: 1.1308, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 41, Loss: 1.0984, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 42, Loss: 1.1369, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 43, Loss: 1.0988, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 44, Loss: 1.0916, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 45, Loss: 1.0779, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 46, Loss: 1.1408, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 47, Loss: 1.1204, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 48, Loss: 1.0888, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 49, Loss: 1.1031, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 50, Loss: 1.0895, Train: 0.6000, Val: 0.5240, Test: 0.5000
Epoch: 51, Loss: 1.0879, Train: 0.4333, Val: 0.4260, Test: 0.4230
Epoch: 52, Loss: 1.0989, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 53, Loss: 1.0959, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 54, Loss: 1.1029, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 55, Loss: 1.0998, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 56, Loss: 1.0972, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 57, Loss: 1.0905, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 58, Loss: 1.1054, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 59, Loss: 1.0726, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 60, Loss: 1.0964, Train: 0.3333, Val: 0.4180, Test: 0.4070
Epoch: 61, Loss: 1.0800, Train: 0.3833, Val: 0.4220, Test: 0.4100
Epoch: 62, Loss: 1.0846, Train: 0.4000, Val: 0.4240, Test: 0.4140
Epoch: 63, Loss: 1.1093, Train: 0.4167, Val: 0.4320, Test: 0.4320
Epoch: 64, Loss: 1.0771, Train: 0.5500, Val: 0.5000, Test: 0.4870
Epoch: 65, Loss: 1.0848, Train: 0.6000, Val: 0.5320, Test: 0.5130
Epoch: 66, Loss: 1.0769, Train: 0.6333, Val: 0.5420, Test: 0.5230
Epoch: 67, Loss: 1.0729, Train: 0.6333, Val: 0.5300, Test: 0.5120
Epoch: 68, Loss: 1.0946, Train: 0.6167, Val: 0.5120, Test: 0.4940
Epoch: 69, Loss: 1.0960, Train: 0.6167, Val: 0.4940, Test: 0.4730
Epoch: 70, Loss: 1.0579, Train: 0.6333, Val: 0.4720, Test: 0.4550
Epoch: 71, Loss: 1.0656, Train: 0.6333, Val: 0.4940, Test: 0.4740
Epoch: 72, Loss: 1.0855, Train: 0.7167, Val: 0.5520, Test: 0.5360
Epoch: 73, Loss: 1.0599, Train: 0.7333, Val: 0.5920, Test: 0.5830
Epoch: 74, Loss: 1.0169, Train: 0.7167, Val: 0.5680, Test: 0.5570
Epoch: 75, Loss: 1.0236, Train: 0.6500, Val: 0.5580, Test: 0.5450
Epoch: 76, Loss: 1.0151, Train: 0.6500, Val: 0.5560, Test: 0.5370
Epoch: 77, Loss: 1.0082, Train: 0.6500, Val: 0.5520, Test: 0.5340
Epoch: 78, Loss: 0.9979, Train: 0.7167, Val: 0.5600, Test: 0.5360
Epoch: 79, Loss: 0.9487, Train: 0.7000, Val: 0.5640, Test: 0.5350
Epoch: 80, Loss: 0.9365, Train: 0.6833, Val: 0.5680, Test: 0.5370
Epoch: 81, Loss: 0.8864, Train: 0.6667, Val: 0.5520, Test: 0.5300
Epoch: 82, Loss: 0.8457, Train: 0.6667, Val: 0.5500, Test: 0.5320
Epoch: 83, Loss: 0.8313, Train: 0.6667, Val: 0.5620, Test: 0.5290
Epoch: 84, Loss: 0.8425, Train: 0.6500, Val: 0.5660, Test: 0.5390
Epoch: 85, Loss: 0.8254, Train: 0.7167, Val: 0.5740, Test: 0.5440
Epoch: 86, Loss: 0.7387, Train: 0.7167, Val: 0.5840, Test: 0.5480
Epoch: 87, Loss: 0.7262, Train: 0.7167, Val: 0.5980, Test: 0.5550
Epoch: 88, Loss: 0.7483, Train: 0.7833, Val: 0.6040, Test: 0.5920
Epoch: 89, Loss: 0.6895, Train: 0.7667, Val: 0.6420, Test: 0.5890
Epoch: 90, Loss: 0.6906, Train: 0.7833, Val: 0.6400, Test: 0.5860
Epoch: 91, Loss: 0.7425, Train: 0.9000, Val: 0.6960, Test: 0.6530
Epoch: 92, Loss: 0.6521, Train: 0.8667, Val: 0.6440, Test: 0.6300
Epoch: 93, Loss: 0.6239, Train: 0.9000, Val: 0.6580, Test: 0.6420
Epoch: 94, Loss: 0.5243, Train: 0.9333, Val: 0.7100, Test: 0.6540
Epoch: 95, Loss: 0.5042, Train: 0.9333, Val: 0.7200, Test: 0.6860
Epoch: 96, Loss: 0.4922, Train: 0.8833, Val: 0.6880, Test: 0.6640
Epoch: 97, Loss: 0.5404, Train: 0.9333, Val: 0.7180, Test: 0.6940
Epoch: 98, Loss: 0.4758, Train: 0.9500, Val: 0.7260, Test: 0.6800
Epoch: 99, Loss: 0.4346, Train: 0.9333, Val: 0.7100, Test: 0.6700
Epoch: 100, Loss: 0.3719, Train: 0.9500, Val: 0.6980, Test: 0.6670
MAD:  0.3823
Best Test Accuracy: 0.6940, Val Accuracy: 0.7180, Train Accuracy: 0.9333
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.0893, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 2, Loss: 1.1403, Train: 0.5000, Val: 0.4360, Test: 0.4400
Epoch: 3, Loss: 1.1529, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 4, Loss: 1.1461, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.1403, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 6, Loss: 1.0988, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 7, Loss: 1.1222, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 8, Loss: 1.1025, Train: 0.3667, Val: 0.4000, Test: 0.3890
Epoch: 9, Loss: 1.0912, Train: 0.3500, Val: 0.1960, Test: 0.1870
Epoch: 10, Loss: 1.1054, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 11, Loss: 1.1204, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 12, Loss: 1.1319, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 13, Loss: 1.1060, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 14, Loss: 1.1350, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 15, Loss: 1.1293, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 16, Loss: 1.1057, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 17, Loss: 1.1305, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 18, Loss: 1.1040, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 19, Loss: 1.1359, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 20, Loss: 1.1012, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 21, Loss: 1.1005, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 22, Loss: 1.1201, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 23, Loss: 1.1255, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 24, Loss: 1.1091, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 25, Loss: 1.0872, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 26, Loss: 1.0944, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 27, Loss: 1.0761, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 28, Loss: 1.1120, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 29, Loss: 1.0837, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 30, Loss: 1.1067, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 31, Loss: 1.1029, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.0880, Train: 0.3500, Val: 0.1980, Test: 0.1880
Epoch: 33, Loss: 1.0979, Train: 0.3333, Val: 0.2060, Test: 0.1900
Epoch: 34, Loss: 1.1039, Train: 0.3500, Val: 0.2180, Test: 0.2090
Epoch: 35, Loss: 1.0983, Train: 0.4667, Val: 0.3920, Test: 0.3990
Epoch: 36, Loss: 1.0973, Train: 0.5667, Val: 0.4880, Test: 0.4940
Epoch: 37, Loss: 1.1099, Train: 0.3500, Val: 0.3900, Test: 0.4150
Epoch: 38, Loss: 1.1036, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 39, Loss: 1.1454, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 40, Loss: 1.0893, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 41, Loss: 1.1058, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 42, Loss: 1.0978, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 43, Loss: 1.0892, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 44, Loss: 1.0849, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 45, Loss: 1.0926, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 46, Loss: 1.0763, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 47, Loss: 1.1046, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 48, Loss: 1.0846, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 49, Loss: 1.1031, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 50, Loss: 1.0835, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 51, Loss: 1.1145, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 52, Loss: 1.1210, Train: 0.3500, Val: 0.3880, Test: 0.4140
Epoch: 53, Loss: 1.0719, Train: 0.4000, Val: 0.3940, Test: 0.4160
Epoch: 54, Loss: 1.0988, Train: 0.4167, Val: 0.4000, Test: 0.4260
Epoch: 55, Loss: 1.1157, Train: 0.4333, Val: 0.4000, Test: 0.4300
Epoch: 56, Loss: 1.0966, Train: 0.4333, Val: 0.4120, Test: 0.4360
Epoch: 57, Loss: 1.0750, Train: 0.5000, Val: 0.4380, Test: 0.4540
Epoch: 58, Loss: 1.1093, Train: 0.4167, Val: 0.3980, Test: 0.4260
Epoch: 59, Loss: 1.1084, Train: 0.4000, Val: 0.3920, Test: 0.4160
Epoch: 60, Loss: 1.0859, Train: 0.3667, Val: 0.3900, Test: 0.4150
Epoch: 61, Loss: 1.0972, Train: 0.3667, Val: 0.3900, Test: 0.4150
Epoch: 62, Loss: 1.0928, Train: 0.4333, Val: 0.4180, Test: 0.4400
Epoch: 63, Loss: 1.1112, Train: 0.5667, Val: 0.4980, Test: 0.5090
Epoch: 64, Loss: 1.0774, Train: 0.6333, Val: 0.5180, Test: 0.5110
Epoch: 65, Loss: 1.1048, Train: 0.5833, Val: 0.5240, Test: 0.5120
Epoch: 66, Loss: 1.0917, Train: 0.5667, Val: 0.5220, Test: 0.5070
Epoch: 67, Loss: 1.0885, Train: 0.5667, Val: 0.5200, Test: 0.5070
Epoch: 68, Loss: 1.1023, Train: 0.5667, Val: 0.5220, Test: 0.5050
Epoch: 69, Loss: 1.1129, Train: 0.5667, Val: 0.5240, Test: 0.5080
Epoch: 70, Loss: 1.0938, Train: 0.5667, Val: 0.5220, Test: 0.5090
Epoch: 71, Loss: 1.1124, Train: 0.6000, Val: 0.5240, Test: 0.5140
Epoch: 72, Loss: 1.1070, Train: 0.6167, Val: 0.5240, Test: 0.5110
Epoch: 73, Loss: 1.0744, Train: 0.6167, Val: 0.5120, Test: 0.5120
Epoch: 74, Loss: 1.1163, Train: 0.6167, Val: 0.5160, Test: 0.5110
Epoch: 75, Loss: 1.0896, Train: 0.6167, Val: 0.5160, Test: 0.5120
Epoch: 76, Loss: 1.0706, Train: 0.6000, Val: 0.5160, Test: 0.5090
Epoch: 77, Loss: 1.0549, Train: 0.6167, Val: 0.5080, Test: 0.5040
Epoch: 78, Loss: 1.0253, Train: 0.5833, Val: 0.4940, Test: 0.5030
Epoch: 79, Loss: 1.0484, Train: 0.6167, Val: 0.5520, Test: 0.5520
Epoch: 80, Loss: 1.0445, Train: 0.7333, Val: 0.5640, Test: 0.5660
Epoch: 81, Loss: 1.0334, Train: 0.6500, Val: 0.5540, Test: 0.5270
Epoch: 82, Loss: 0.9926, Train: 0.6667, Val: 0.5520, Test: 0.5290
Epoch: 83, Loss: 0.9926, Train: 0.6500, Val: 0.5660, Test: 0.5300
Epoch: 84, Loss: 0.9621, Train: 0.6667, Val: 0.5800, Test: 0.5330
Epoch: 85, Loss: 0.9644, Train: 0.6667, Val: 0.5720, Test: 0.5280
Epoch: 86, Loss: 0.8788, Train: 0.6667, Val: 0.5620, Test: 0.5240
Epoch: 87, Loss: 0.8506, Train: 0.6333, Val: 0.5440, Test: 0.5230
Epoch: 88, Loss: 0.8753, Train: 0.6667, Val: 0.5480, Test: 0.5250
Epoch: 89, Loss: 0.8123, Train: 0.6167, Val: 0.5400, Test: 0.5260
Epoch: 90, Loss: 0.8000, Train: 0.6167, Val: 0.5360, Test: 0.5230
Epoch: 91, Loss: 0.7805, Train: 0.6333, Val: 0.5460, Test: 0.5250
Epoch: 92, Loss: 0.7401, Train: 0.6333, Val: 0.5540, Test: 0.5240
Epoch: 93, Loss: 0.7237, Train: 0.6333, Val: 0.5420, Test: 0.5260
Epoch: 94, Loss: 0.7177, Train: 0.6833, Val: 0.5600, Test: 0.5180
Epoch: 95, Loss: 0.6588, Train: 0.6667, Val: 0.5460, Test: 0.5190
Epoch: 96, Loss: 0.6792, Train: 0.6667, Val: 0.5400, Test: 0.5250
Epoch: 97, Loss: 0.6634, Train: 0.6667, Val: 0.5380, Test: 0.5240
Epoch: 98, Loss: 0.5989, Train: 0.6667, Val: 0.5320, Test: 0.5050
Epoch: 99, Loss: 0.6584, Train: 0.6667, Val: 0.5340, Test: 0.5030
Epoch: 100, Loss: 0.6258, Train: 0.6667, Val: 0.5420, Test: 0.5290
MAD:  0.0768
Best Test Accuracy: 0.5660, Val Accuracy: 0.5640, Train Accuracy: 0.7333
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1290, Train: 0.4167, Val: 0.4180, Test: 0.4330
Epoch: 2, Loss: 1.1176, Train: 0.3500, Val: 0.1920, Test: 0.1810
Epoch: 3, Loss: 1.1272, Train: 0.3500, Val: 0.1920, Test: 0.1800
Epoch: 4, Loss: 1.1464, Train: 0.5500, Val: 0.4360, Test: 0.4290
Epoch: 5, Loss: 1.0964, Train: 0.3500, Val: 0.3940, Test: 0.4190
Epoch: 6, Loss: 1.1231, Train: 0.3333, Val: 0.3940, Test: 0.4180
Epoch: 7, Loss: 1.0837, Train: 0.5000, Val: 0.4660, Test: 0.4740
Epoch: 8, Loss: 1.1124, Train: 0.4500, Val: 0.2140, Test: 0.2090
Epoch: 9, Loss: 1.1145, Train: 0.3500, Val: 0.1920, Test: 0.1800
Epoch: 10, Loss: 1.0739, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 11, Loss: 1.1128, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 12, Loss: 1.0980, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 13, Loss: 1.0981, Train: 0.3333, Val: 0.2000, Test: 0.1870
Epoch: 14, Loss: 1.1039, Train: 0.3833, Val: 0.2640, Test: 0.2380
Epoch: 15, Loss: 1.1116, Train: 0.5333, Val: 0.4400, Test: 0.4160
Epoch: 16, Loss: 1.0756, Train: 0.3833, Val: 0.4260, Test: 0.4330
Epoch: 17, Loss: 1.1140, Train: 0.4667, Val: 0.4580, Test: 0.4470
Epoch: 18, Loss: 1.0911, Train: 0.4667, Val: 0.4720, Test: 0.4390
Epoch: 19, Loss: 1.0932, Train: 0.3333, Val: 0.3800, Test: 0.3830
Epoch: 20, Loss: 1.0833, Train: 0.3167, Val: 0.3920, Test: 0.4120
Epoch: 21, Loss: 1.1247, Train: 0.3167, Val: 0.3940, Test: 0.4100
Epoch: 22, Loss: 1.1032, Train: 0.3333, Val: 0.3880, Test: 0.4100
Epoch: 23, Loss: 1.0670, Train: 0.3333, Val: 0.3900, Test: 0.4100
Epoch: 24, Loss: 1.1054, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 25, Loss: 1.0716, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 26, Loss: 1.1119, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 27, Loss: 1.0980, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 28, Loss: 1.0724, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 29, Loss: 1.0843, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 30, Loss: 1.0908, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 31, Loss: 1.1168, Train: 0.3500, Val: 0.3880, Test: 0.4140
Epoch: 32, Loss: 1.0832, Train: 0.3333, Val: 0.3900, Test: 0.4110
Epoch: 33, Loss: 1.0752, Train: 0.5500, Val: 0.4780, Test: 0.4940
Epoch: 34, Loss: 1.0976, Train: 0.6333, Val: 0.5360, Test: 0.5250
Epoch: 35, Loss: 1.0823, Train: 0.5500, Val: 0.4600, Test: 0.4640
Epoch: 36, Loss: 1.0943, Train: 0.3833, Val: 0.2380, Test: 0.2190
Epoch: 37, Loss: 1.0720, Train: 0.3333, Val: 0.1960, Test: 0.1810
Epoch: 38, Loss: 1.0852, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 39, Loss: 1.0819, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 40, Loss: 1.0776, Train: 0.3333, Val: 0.1960, Test: 0.1820
Epoch: 41, Loss: 1.0452, Train: 0.3500, Val: 0.2040, Test: 0.1850
Epoch: 42, Loss: 1.0842, Train: 0.3667, Val: 0.2100, Test: 0.1990
Epoch: 43, Loss: 1.0428, Train: 0.4667, Val: 0.3560, Test: 0.3590
Epoch: 44, Loss: 1.0814, Train: 0.6000, Val: 0.5480, Test: 0.5260
Epoch: 45, Loss: 1.0537, Train: 0.7167, Val: 0.6380, Test: 0.6070
Epoch: 46, Loss: 1.0314, Train: 0.7500, Val: 0.6680, Test: 0.6500
Epoch: 47, Loss: 1.0144, Train: 0.7833, Val: 0.6800, Test: 0.6730
Epoch: 48, Loss: 1.0422, Train: 0.7167, Val: 0.6040, Test: 0.6160
Epoch: 49, Loss: 1.0595, Train: 0.6833, Val: 0.5820, Test: 0.5850
Epoch: 50, Loss: 1.0095, Train: 0.7000, Val: 0.5840, Test: 0.5800
Epoch: 51, Loss: 0.9957, Train: 0.7167, Val: 0.5880, Test: 0.5850
Epoch: 52, Loss: 1.0023, Train: 0.7000, Val: 0.5880, Test: 0.5790
Epoch: 53, Loss: 0.9946, Train: 0.6833, Val: 0.5700, Test: 0.5690
Epoch: 54, Loss: 0.9576, Train: 0.6667, Val: 0.5700, Test: 0.5620
Epoch: 55, Loss: 0.9267, Train: 0.6667, Val: 0.5680, Test: 0.5700
Epoch: 56, Loss: 0.8905, Train: 0.7167, Val: 0.5660, Test: 0.5670
Epoch: 57, Loss: 0.9443, Train: 0.6667, Val: 0.5680, Test: 0.5480
Epoch: 58, Loss: 0.8872, Train: 0.6667, Val: 0.5600, Test: 0.5340
Epoch: 59, Loss: 0.8103, Train: 0.6833, Val: 0.5620, Test: 0.5370
Epoch: 60, Loss: 0.8113, Train: 0.6667, Val: 0.5480, Test: 0.5470
Epoch: 61, Loss: 0.7549, Train: 0.6667, Val: 0.5480, Test: 0.5420
Epoch: 62, Loss: 0.7300, Train: 0.6500, Val: 0.5660, Test: 0.5370
Epoch: 63, Loss: 0.6947, Train: 0.6167, Val: 0.5360, Test: 0.5300
Epoch: 64, Loss: 0.6723, Train: 0.6333, Val: 0.5420, Test: 0.5340
Epoch: 65, Loss: 0.6238, Train: 0.6833, Val: 0.5680, Test: 0.5540
Epoch: 66, Loss: 0.6001, Train: 0.7333, Val: 0.5680, Test: 0.5690
Epoch: 67, Loss: 0.6341, Train: 0.7667, Val: 0.5940, Test: 0.6070
Epoch: 68, Loss: 0.6007, Train: 0.7833, Val: 0.6740, Test: 0.6700
Epoch: 69, Loss: 0.6245, Train: 0.8500, Val: 0.7080, Test: 0.7050
Epoch: 70, Loss: 0.5884, Train: 0.9333, Val: 0.7080, Test: 0.7060
Epoch: 71, Loss: 0.6432, Train: 0.9500, Val: 0.7320, Test: 0.7270
Epoch: 72, Loss: 0.5616, Train: 0.9167, Val: 0.7320, Test: 0.7280
Epoch: 73, Loss: 0.5133, Train: 0.8667, Val: 0.7160, Test: 0.7140
Epoch: 74, Loss: 0.5495, Train: 0.8000, Val: 0.6820, Test: 0.6860
Epoch: 75, Loss: 0.5062, Train: 0.8000, Val: 0.6540, Test: 0.6570
Epoch: 76, Loss: 0.5243, Train: 0.8000, Val: 0.6340, Test: 0.6430
Epoch: 77, Loss: 0.4783, Train: 0.8167, Val: 0.6220, Test: 0.6250
Epoch: 78, Loss: 0.4847, Train: 0.8167, Val: 0.6300, Test: 0.6360
Epoch: 79, Loss: 0.4547, Train: 0.8167, Val: 0.6420, Test: 0.6430
Epoch: 80, Loss: 0.4961, Train: 0.8167, Val: 0.6600, Test: 0.6640
Epoch: 81, Loss: 0.4739, Train: 0.8667, Val: 0.6940, Test: 0.6870
Epoch: 82, Loss: 0.4669, Train: 0.8833, Val: 0.7080, Test: 0.7050
Epoch: 83, Loss: 0.4444, Train: 0.9167, Val: 0.7140, Test: 0.7170
Epoch: 84, Loss: 0.4891, Train: 0.9333, Val: 0.7060, Test: 0.7010
Epoch: 85, Loss: 0.4159, Train: 0.9000, Val: 0.6860, Test: 0.6780
Epoch: 86, Loss: 0.5336, Train: 0.9333, Val: 0.7120, Test: 0.7040
Epoch: 87, Loss: 0.3457, Train: 0.9167, Val: 0.7100, Test: 0.7050
Epoch: 88, Loss: 0.4102, Train: 0.9167, Val: 0.7040, Test: 0.7080
Epoch: 89, Loss: 0.3614, Train: 0.9333, Val: 0.7180, Test: 0.6970
Epoch: 90, Loss: 0.3404, Train: 0.9500, Val: 0.7080, Test: 0.7120
Epoch: 91, Loss: 0.2603, Train: 0.9333, Val: 0.7180, Test: 0.7120
Epoch: 92, Loss: 0.3175, Train: 0.9500, Val: 0.7160, Test: 0.7110
Epoch: 93, Loss: 0.3689, Train: 0.9833, Val: 0.7520, Test: 0.7480
Epoch: 94, Loss: 0.2299, Train: 0.9667, Val: 0.7580, Test: 0.7490
Epoch: 95, Loss: 0.2037, Train: 0.9667, Val: 0.7460, Test: 0.7360
Epoch: 96, Loss: 0.1875, Train: 0.9667, Val: 0.7440, Test: 0.7460
Epoch: 97, Loss: 0.2590, Train: 0.9667, Val: 0.7540, Test: 0.7430
Epoch: 98, Loss: 0.1465, Train: 0.9667, Val: 0.7600, Test: 0.7780
Epoch: 99, Loss: 0.1422, Train: 1.0000, Val: 0.7200, Test: 0.7130
Epoch: 100, Loss: 0.1476, Train: 0.9833, Val: 0.6860, Test: 0.6670
MAD:  0.4712
Best Test Accuracy: 0.7780, Val Accuracy: 0.7600, Train Accuracy: 0.9667
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1621, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 2, Loss: 1.1176, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 3, Loss: 1.0853, Train: 0.3667, Val: 0.4020, Test: 0.3910
Epoch: 4, Loss: 1.1212, Train: 0.3667, Val: 0.4120, Test: 0.4090
Epoch: 5, Loss: 1.1009, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 6, Loss: 1.1347, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 7, Loss: 1.1124, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 8, Loss: 1.1323, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 9, Loss: 1.1471, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.1046, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.1389, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.1038, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 13, Loss: 1.0882, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 14, Loss: 1.1110, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 15, Loss: 1.1149, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 16, Loss: 1.1716, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 17, Loss: 1.1111, Train: 0.3667, Val: 0.3940, Test: 0.4200
Epoch: 18, Loss: 1.1217, Train: 0.3500, Val: 0.3900, Test: 0.4170
Epoch: 19, Loss: 1.1152, Train: 0.4000, Val: 0.4040, Test: 0.4270
Epoch: 20, Loss: 1.1230, Train: 0.4167, Val: 0.4320, Test: 0.4420
Epoch: 21, Loss: 1.1292, Train: 0.4000, Val: 0.4120, Test: 0.4290
Epoch: 22, Loss: 1.0848, Train: 0.3667, Val: 0.3920, Test: 0.4160
Epoch: 23, Loss: 1.0980, Train: 0.4333, Val: 0.4660, Test: 0.4880
Epoch: 24, Loss: 1.1271, Train: 0.4333, Val: 0.4620, Test: 0.4460
Epoch: 25, Loss: 1.0794, Train: 0.3500, Val: 0.4160, Test: 0.4110
Epoch: 26, Loss: 1.0990, Train: 0.3333, Val: 0.4160, Test: 0.4080
Epoch: 27, Loss: 1.1058, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 28, Loss: 1.0965, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 29, Loss: 1.1035, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 30, Loss: 1.1261, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 31, Loss: 1.1123, Train: 0.3500, Val: 0.4160, Test: 0.4070
Epoch: 32, Loss: 1.0806, Train: 0.3500, Val: 0.4160, Test: 0.4070
Epoch: 33, Loss: 1.0676, Train: 0.3500, Val: 0.4160, Test: 0.4070
Epoch: 34, Loss: 1.0783, Train: 0.3500, Val: 0.4160, Test: 0.4070
Epoch: 35, Loss: 1.1177, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 36, Loss: 1.1052, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 37, Loss: 1.1053, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 38, Loss: 1.1142, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 39, Loss: 1.0865, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 40, Loss: 1.0929, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 41, Loss: 1.0966, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 42, Loss: 1.0979, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 43, Loss: 1.0896, Train: 0.3833, Val: 0.4180, Test: 0.4080
Epoch: 44, Loss: 1.1184, Train: 0.5167, Val: 0.5040, Test: 0.4860
Epoch: 45, Loss: 1.0784, Train: 0.6333, Val: 0.5200, Test: 0.5030
Epoch: 46, Loss: 1.0954, Train: 0.5167, Val: 0.4020, Test: 0.3750
Epoch: 47, Loss: 1.1023, Train: 0.4833, Val: 0.3600, Test: 0.3340
Epoch: 48, Loss: 1.1191, Train: 0.4833, Val: 0.3580, Test: 0.3310
Epoch: 49, Loss: 1.1111, Train: 0.5000, Val: 0.3740, Test: 0.3450
Epoch: 50, Loss: 1.0400, Train: 0.5000, Val: 0.3880, Test: 0.3570
Epoch: 51, Loss: 1.1061, Train: 0.5167, Val: 0.3980, Test: 0.3740
Epoch: 52, Loss: 1.0776, Train: 0.5333, Val: 0.4080, Test: 0.3810
Epoch: 53, Loss: 1.0666, Train: 0.5667, Val: 0.4260, Test: 0.4040
Epoch: 54, Loss: 1.0507, Train: 0.6500, Val: 0.5500, Test: 0.5270
Epoch: 55, Loss: 1.0820, Train: 0.7833, Val: 0.6600, Test: 0.6210
Epoch: 56, Loss: 1.0606, Train: 0.8000, Val: 0.6160, Test: 0.6200
Epoch: 57, Loss: 1.0445, Train: 0.7500, Val: 0.5860, Test: 0.5740
Epoch: 58, Loss: 1.0538, Train: 0.7000, Val: 0.5780, Test: 0.5630
Epoch: 59, Loss: 1.0330, Train: 0.7000, Val: 0.5780, Test: 0.5590
Epoch: 60, Loss: 1.0404, Train: 0.7833, Val: 0.6080, Test: 0.6030
Epoch: 61, Loss: 1.0321, Train: 0.8000, Val: 0.6000, Test: 0.6070
Epoch: 62, Loss: 1.0388, Train: 0.8333, Val: 0.6340, Test: 0.6020
Epoch: 63, Loss: 0.9692, Train: 0.7333, Val: 0.5980, Test: 0.5600
Epoch: 64, Loss: 0.9578, Train: 0.6333, Val: 0.5520, Test: 0.5320
Epoch: 65, Loss: 0.8707, Train: 0.6000, Val: 0.5200, Test: 0.5080
Epoch: 66, Loss: 0.8845, Train: 0.6167, Val: 0.5220, Test: 0.5010
Epoch: 67, Loss: 0.8351, Train: 0.6667, Val: 0.5580, Test: 0.5240
Epoch: 68, Loss: 0.7870, Train: 0.6667, Val: 0.5500, Test: 0.5500
Epoch: 69, Loss: 0.7952, Train: 0.6667, Val: 0.5480, Test: 0.5410
Epoch: 70, Loss: 0.7735, Train: 0.6667, Val: 0.5560, Test: 0.5270
Epoch: 71, Loss: 0.7063, Train: 0.6333, Val: 0.5220, Test: 0.5070
Epoch: 72, Loss: 0.6931, Train: 0.6500, Val: 0.5080, Test: 0.4860
Epoch: 73, Loss: 0.6737, Train: 0.6500, Val: 0.5180, Test: 0.5030
Epoch: 74, Loss: 0.7157, Train: 0.6833, Val: 0.5500, Test: 0.5360
Epoch: 75, Loss: 0.6117, Train: 0.7167, Val: 0.5700, Test: 0.5450
Epoch: 76, Loss: 0.6800, Train: 0.6833, Val: 0.5580, Test: 0.5220
Epoch: 77, Loss: 0.6304, Train: 0.6500, Val: 0.5300, Test: 0.5000
Epoch: 78, Loss: 0.6144, Train: 0.6333, Val: 0.5240, Test: 0.5020
Epoch: 79, Loss: 0.6619, Train: 0.7500, Val: 0.6120, Test: 0.5720
Epoch: 80, Loss: 0.5713, Train: 0.8500, Val: 0.6580, Test: 0.6350
Epoch: 81, Loss: 0.6897, Train: 0.8833, Val: 0.6800, Test: 0.6550
Epoch: 82, Loss: 0.5804, Train: 0.7833, Val: 0.6880, Test: 0.6360
Epoch: 83, Loss: 0.5357, Train: 0.7000, Val: 0.6040, Test: 0.5770
Epoch: 84, Loss: 0.5891, Train: 0.7500, Val: 0.6440, Test: 0.6190
Epoch: 85, Loss: 0.5440, Train: 0.8167, Val: 0.6960, Test: 0.6790
Epoch: 86, Loss: 0.5395, Train: 0.9167, Val: 0.7380, Test: 0.6960
Epoch: 87, Loss: 0.4484, Train: 0.9167, Val: 0.7240, Test: 0.6770
Epoch: 88, Loss: 0.4671, Train: 0.9167, Val: 0.7060, Test: 0.6520
Epoch: 89, Loss: 0.4940, Train: 0.8667, Val: 0.6560, Test: 0.6230
Epoch: 90, Loss: 0.4713, Train: 0.8167, Val: 0.6340, Test: 0.5860
Epoch: 91, Loss: 0.4541, Train: 0.9000, Val: 0.6480, Test: 0.6310
Epoch: 92, Loss: 0.4838, Train: 0.8500, Val: 0.6520, Test: 0.6090
Epoch: 93, Loss: 0.4411, Train: 0.6500, Val: 0.5820, Test: 0.5500
Epoch: 94, Loss: 0.4395, Train: 0.6667, Val: 0.5400, Test: 0.5330
Epoch: 95, Loss: 0.3865, Train: 0.6667, Val: 0.6020, Test: 0.5800
Epoch: 96, Loss: 0.4464, Train: 0.9000, Val: 0.7240, Test: 0.7070
Epoch: 97, Loss: 0.4363, Train: 0.9667, Val: 0.7560, Test: 0.7350
Epoch: 98, Loss: 0.3405, Train: 0.9500, Val: 0.7580, Test: 0.7190
Epoch: 99, Loss: 0.4104, Train: 0.9500, Val: 0.7460, Test: 0.7140
Epoch: 100, Loss: 0.3946, Train: 0.9833, Val: 0.7400, Test: 0.7190
MAD:  0.3462
Best Test Accuracy: 0.7350, Val Accuracy: 0.7560, Train Accuracy: 0.9667
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1594, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 2, Loss: 1.1189, Train: 0.4333, Val: 0.5000, Test: 0.4910
Epoch: 3, Loss: 1.1007, Train: 0.3333, Val: 0.4160, Test: 0.4080
Epoch: 4, Loss: 1.1097, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.1302, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 6, Loss: 1.1073, Train: 0.3333, Val: 0.4160, Test: 0.4080
Epoch: 7, Loss: 1.1261, Train: 0.4167, Val: 0.3940, Test: 0.3990
Epoch: 8, Loss: 1.0968, Train: 0.3333, Val: 0.2040, Test: 0.1870
Epoch: 9, Loss: 1.1189, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 10, Loss: 1.0781, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 11, Loss: 1.0989, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 12, Loss: 1.1013, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 13, Loss: 1.0875, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 14, Loss: 1.1240, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 15, Loss: 1.1283, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 16, Loss: 1.1091, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 17, Loss: 1.0846, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 18, Loss: 1.1040, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 19, Loss: 1.0914, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 20, Loss: 1.1444, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 21, Loss: 1.0790, Train: 0.3500, Val: 0.1960, Test: 0.1820
Epoch: 22, Loss: 1.1078, Train: 0.4667, Val: 0.4060, Test: 0.4080
Epoch: 23, Loss: 1.1001, Train: 0.4667, Val: 0.4180, Test: 0.4430
Epoch: 24, Loss: 1.1031, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 25, Loss: 1.1168, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 26, Loss: 1.0949, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 27, Loss: 1.0749, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 28, Loss: 1.1280, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 29, Loss: 1.1407, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 30, Loss: 1.1124, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 31, Loss: 1.1146, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 32, Loss: 1.1027, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 33, Loss: 1.0740, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 34, Loss: 1.0971, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 35, Loss: 1.0983, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 36, Loss: 1.0769, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 37, Loss: 1.1206, Train: 0.3667, Val: 0.3960, Test: 0.4210
Epoch: 38, Loss: 1.1010, Train: 0.4167, Val: 0.4400, Test: 0.4640
Epoch: 39, Loss: 1.1239, Train: 0.6000, Val: 0.5300, Test: 0.5430
Epoch: 40, Loss: 1.0731, Train: 0.5500, Val: 0.4320, Test: 0.4490
Epoch: 41, Loss: 1.1173, Train: 0.4833, Val: 0.2600, Test: 0.2530
Epoch: 42, Loss: 1.1166, Train: 0.4500, Val: 0.2400, Test: 0.2330
Epoch: 43, Loss: 1.1269, Train: 0.4333, Val: 0.2460, Test: 0.2390
Epoch: 44, Loss: 1.0929, Train: 0.4833, Val: 0.3220, Test: 0.3170
Epoch: 45, Loss: 1.0737, Train: 0.5167, Val: 0.3480, Test: 0.3310
Epoch: 46, Loss: 1.0924, Train: 0.5167, Val: 0.3560, Test: 0.3350
Epoch: 47, Loss: 1.1077, Train: 0.5333, Val: 0.3580, Test: 0.3450
Epoch: 48, Loss: 1.0774, Train: 0.5833, Val: 0.4220, Test: 0.4070
Epoch: 49, Loss: 1.0905, Train: 0.5667, Val: 0.4360, Test: 0.4390
Epoch: 50, Loss: 1.1149, Train: 0.4833, Val: 0.2820, Test: 0.2860
Epoch: 51, Loss: 1.0825, Train: 0.4667, Val: 0.2580, Test: 0.2560
Epoch: 52, Loss: 1.1342, Train: 0.5000, Val: 0.3040, Test: 0.3110
Epoch: 53, Loss: 1.0722, Train: 0.5333, Val: 0.3360, Test: 0.3190
Epoch: 54, Loss: 1.0674, Train: 0.5500, Val: 0.4020, Test: 0.3730
Epoch: 55, Loss: 1.1042, Train: 0.7500, Val: 0.6260, Test: 0.6210
Epoch: 56, Loss: 1.0870, Train: 0.6333, Val: 0.6240, Test: 0.6250
Epoch: 57, Loss: 1.0651, Train: 0.5167, Val: 0.5680, Test: 0.5840
Epoch: 58, Loss: 1.0948, Train: 0.5000, Val: 0.5340, Test: 0.5590
Epoch: 59, Loss: 1.0542, Train: 0.4833, Val: 0.5220, Test: 0.5460
Epoch: 60, Loss: 1.0778, Train: 0.4833, Val: 0.5180, Test: 0.5440
Epoch: 61, Loss: 1.1070, Train: 0.5000, Val: 0.5440, Test: 0.5660
Epoch: 62, Loss: 1.0733, Train: 0.5000, Val: 0.5600, Test: 0.5770
Epoch: 63, Loss: 1.1021, Train: 0.5500, Val: 0.5780, Test: 0.5950
Epoch: 64, Loss: 1.0847, Train: 0.5667, Val: 0.5920, Test: 0.6170
Epoch: 65, Loss: 1.0715, Train: 0.5833, Val: 0.5980, Test: 0.6110
Epoch: 66, Loss: 1.0137, Train: 0.6167, Val: 0.5980, Test: 0.6100
Epoch: 67, Loss: 1.0550, Train: 0.6167, Val: 0.6040, Test: 0.6060
Epoch: 68, Loss: 1.0892, Train: 0.6667, Val: 0.6060, Test: 0.6120
Epoch: 69, Loss: 1.0271, Train: 0.8167, Val: 0.6800, Test: 0.6790
Epoch: 70, Loss: 1.0299, Train: 0.8500, Val: 0.7100, Test: 0.7040
Epoch: 71, Loss: 1.0139, Train: 0.8333, Val: 0.7060, Test: 0.6800
Epoch: 72, Loss: 0.9861, Train: 0.7167, Val: 0.6220, Test: 0.6180
Epoch: 73, Loss: 0.9617, Train: 0.7167, Val: 0.6020, Test: 0.5660
Epoch: 74, Loss: 0.8573, Train: 0.7000, Val: 0.5840, Test: 0.5620
Epoch: 75, Loss: 0.8829, Train: 0.7833, Val: 0.6400, Test: 0.6030
Epoch: 76, Loss: 0.8499, Train: 0.7500, Val: 0.6100, Test: 0.5830
Epoch: 77, Loss: 0.7398, Train: 0.6667, Val: 0.5620, Test: 0.5240
Epoch: 78, Loss: 0.8117, Train: 0.6167, Val: 0.4780, Test: 0.4430
Epoch: 79, Loss: 0.8025, Train: 0.6167, Val: 0.4640, Test: 0.4480
Epoch: 80, Loss: 0.7101, Train: 0.6167, Val: 0.4880, Test: 0.4700
Epoch: 81, Loss: 0.7133, Train: 0.6500, Val: 0.4980, Test: 0.4920
Epoch: 82, Loss: 0.6858, Train: 0.6333, Val: 0.4880, Test: 0.4720
Epoch: 83, Loss: 0.7256, Train: 0.6333, Val: 0.5040, Test: 0.4760
Epoch: 84, Loss: 0.6567, Train: 0.6333, Val: 0.5160, Test: 0.4900
Epoch: 85, Loss: 0.6598, Train: 0.6500, Val: 0.5180, Test: 0.4910
Epoch: 86, Loss: 0.6493, Train: 0.6833, Val: 0.5980, Test: 0.5580
Epoch: 87, Loss: 0.6856, Train: 0.9333, Val: 0.7580, Test: 0.7220
Epoch: 88, Loss: 0.5780, Train: 0.6667, Val: 0.6340, Test: 0.6360
Epoch: 89, Loss: 0.5477, Train: 0.6667, Val: 0.6380, Test: 0.6410
Epoch: 90, Loss: 0.6077, Train: 0.6667, Val: 0.6360, Test: 0.6430
Epoch: 91, Loss: 0.5753, Train: 0.6667, Val: 0.6360, Test: 0.6420
Epoch: 92, Loss: 0.5558, Train: 0.6667, Val: 0.6380, Test: 0.6450
Epoch: 93, Loss: 0.5671, Train: 0.6833, Val: 0.6400, Test: 0.6440
Epoch: 94, Loss: 0.5741, Train: 0.9667, Val: 0.7620, Test: 0.7320
Epoch: 95, Loss: 0.5484, Train: 0.9167, Val: 0.7300, Test: 0.6860
Epoch: 96, Loss: 0.5606, Train: 0.8500, Val: 0.7060, Test: 0.6810
Epoch: 97, Loss: 0.5364, Train: 0.7167, Val: 0.6320, Test: 0.5920
Epoch: 98, Loss: 0.6739, Train: 0.8500, Val: 0.7140, Test: 0.6970
Epoch: 99, Loss: 0.4831, Train: 0.9000, Val: 0.7560, Test: 0.7250
Epoch: 100, Loss: 0.4985, Train: 0.9167, Val: 0.7580, Test: 0.7080
MAD:  0.4531
Best Test Accuracy: 0.7320, Val Accuracy: 0.7620, Train Accuracy: 0.9667
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1083, Train: 0.3333, Val: 0.1960, Test: 0.1760
Epoch: 2, Loss: 1.1079, Train: 0.2167, Val: 0.2200, Test: 0.1990
Epoch: 3, Loss: 1.1016, Train: 0.3833, Val: 0.3820, Test: 0.3960
Epoch: 4, Loss: 1.0748, Train: 0.4333, Val: 0.4140, Test: 0.4290
Epoch: 5, Loss: 1.1034, Train: 0.3333, Val: 0.3880, Test: 0.4120
Epoch: 6, Loss: 1.1076, Train: 0.3500, Val: 0.3900, Test: 0.4160
Epoch: 7, Loss: 1.1147, Train: 0.3500, Val: 0.3780, Test: 0.3940
Epoch: 8, Loss: 1.1421, Train: 0.3833, Val: 0.3860, Test: 0.4150
Epoch: 9, Loss: 1.1041, Train: 0.3667, Val: 0.3940, Test: 0.4100
Epoch: 10, Loss: 1.1124, Train: 0.3333, Val: 0.3900, Test: 0.4150
Epoch: 11, Loss: 1.1078, Train: 0.3167, Val: 0.3720, Test: 0.4070
Epoch: 12, Loss: 1.1013, Train: 0.4000, Val: 0.4560, Test: 0.4980
Epoch: 13, Loss: 1.1070, Train: 0.3500, Val: 0.4020, Test: 0.4370
Epoch: 14, Loss: 1.1145, Train: 0.3500, Val: 0.3860, Test: 0.4140
Epoch: 15, Loss: 1.1100, Train: 0.3333, Val: 0.3860, Test: 0.4140
Epoch: 16, Loss: 1.1072, Train: 0.4167, Val: 0.4080, Test: 0.4380
Epoch: 17, Loss: 1.1074, Train: 0.4500, Val: 0.3880, Test: 0.3750
Epoch: 18, Loss: 1.1369, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 19, Loss: 1.0867, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 20, Loss: 1.1151, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 21, Loss: 1.0781, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 22, Loss: 1.0747, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 23, Loss: 1.0950, Train: 0.3333, Val: 0.1960, Test: 0.1820
Epoch: 24, Loss: 1.0912, Train: 0.5167, Val: 0.3860, Test: 0.3480
Epoch: 25, Loss: 1.0896, Train: 0.6333, Val: 0.5260, Test: 0.5140
Epoch: 26, Loss: 1.1180, Train: 0.5667, Val: 0.5100, Test: 0.4970
Epoch: 27, Loss: 1.1211, Train: 0.4167, Val: 0.4320, Test: 0.4230
Epoch: 28, Loss: 1.1503, Train: 0.4000, Val: 0.4260, Test: 0.4140
Epoch: 29, Loss: 1.1017, Train: 0.4000, Val: 0.4220, Test: 0.4120
Epoch: 30, Loss: 1.1158, Train: 0.4000, Val: 0.4300, Test: 0.4210
Epoch: 31, Loss: 1.1262, Train: 0.5000, Val: 0.4620, Test: 0.4500
Epoch: 32, Loss: 1.0590, Train: 0.6000, Val: 0.5320, Test: 0.5210
Epoch: 33, Loss: 1.0591, Train: 0.7167, Val: 0.5720, Test: 0.5780
Epoch: 34, Loss: 1.0931, Train: 0.6000, Val: 0.5060, Test: 0.5040
Epoch: 35, Loss: 1.0845, Train: 0.5667, Val: 0.4980, Test: 0.4820
Epoch: 36, Loss: 1.0854, Train: 0.5667, Val: 0.5000, Test: 0.4830
Epoch: 37, Loss: 1.0933, Train: 0.5500, Val: 0.4980, Test: 0.4820
Epoch: 38, Loss: 1.0689, Train: 0.5833, Val: 0.4780, Test: 0.4790
Epoch: 39, Loss: 1.0889, Train: 0.5333, Val: 0.4720, Test: 0.4780
Epoch: 40, Loss: 1.1112, Train: 0.5333, Val: 0.4480, Test: 0.4750
Epoch: 41, Loss: 1.1101, Train: 0.5500, Val: 0.4680, Test: 0.4840
Epoch: 42, Loss: 1.0615, Train: 0.5333, Val: 0.4440, Test: 0.4660
Epoch: 43, Loss: 1.0955, Train: 0.5333, Val: 0.4380, Test: 0.4590
Epoch: 44, Loss: 1.1207, Train: 0.5167, Val: 0.4400, Test: 0.4590
Epoch: 45, Loss: 1.0689, Train: 0.5500, Val: 0.4620, Test: 0.4730
Epoch: 46, Loss: 1.0777, Train: 0.5667, Val: 0.4960, Test: 0.5000
Epoch: 47, Loss: 1.0689, Train: 0.5833, Val: 0.4980, Test: 0.4940
Epoch: 48, Loss: 1.0631, Train: 0.6833, Val: 0.6020, Test: 0.6020
Epoch: 49, Loss: 1.0251, Train: 0.7667, Val: 0.6500, Test: 0.6200
Epoch: 50, Loss: 1.0675, Train: 0.7167, Val: 0.5680, Test: 0.5570
Epoch: 51, Loss: 1.0345, Train: 0.6333, Val: 0.5420, Test: 0.5270
Epoch: 52, Loss: 1.0423, Train: 0.6333, Val: 0.5340, Test: 0.5240
Epoch: 53, Loss: 1.0330, Train: 0.6167, Val: 0.5400, Test: 0.5260
Epoch: 54, Loss: 1.0524, Train: 0.6167, Val: 0.5440, Test: 0.5220
Epoch: 55, Loss: 1.0209, Train: 0.6667, Val: 0.5480, Test: 0.5190
Epoch: 56, Loss: 0.9759, Train: 0.6667, Val: 0.5600, Test: 0.5190
Epoch: 57, Loss: 0.9945, Train: 0.6667, Val: 0.5700, Test: 0.5200
Epoch: 58, Loss: 0.9777, Train: 0.6333, Val: 0.5500, Test: 0.5220
Epoch: 59, Loss: 0.9021, Train: 0.6333, Val: 0.5420, Test: 0.5260
Epoch: 60, Loss: 0.8758, Train: 0.6167, Val: 0.5460, Test: 0.5300
Epoch: 61, Loss: 0.8616, Train: 0.6333, Val: 0.5420, Test: 0.5210
Epoch: 62, Loss: 0.8153, Train: 0.6500, Val: 0.5400, Test: 0.5250
Epoch: 63, Loss: 0.8083, Train: 0.6333, Val: 0.5460, Test: 0.5220
Epoch: 64, Loss: 0.8173, Train: 0.6500, Val: 0.5480, Test: 0.5250
Epoch: 65, Loss: 0.7795, Train: 0.7000, Val: 0.5640, Test: 0.5330
Epoch: 66, Loss: 0.7360, Train: 0.7000, Val: 0.5540, Test: 0.5380
Epoch: 67, Loss: 0.7202, Train: 0.7000, Val: 0.5620, Test: 0.5370
Epoch: 68, Loss: 0.7178, Train: 0.6833, Val: 0.5700, Test: 0.5200
Epoch: 69, Loss: 0.7147, Train: 0.6833, Val: 0.5620, Test: 0.5300
Epoch: 70, Loss: 0.6824, Train: 0.6500, Val: 0.5700, Test: 0.5330
Epoch: 71, Loss: 0.6469, Train: 0.6500, Val: 0.5680, Test: 0.5320
Epoch: 72, Loss: 0.6482, Train: 0.6667, Val: 0.5760, Test: 0.5310
Epoch: 73, Loss: 0.6674, Train: 0.7000, Val: 0.5860, Test: 0.5370
Epoch: 74, Loss: 0.6026, Train: 0.7667, Val: 0.6120, Test: 0.5660
Epoch: 75, Loss: 0.5471, Train: 0.8667, Val: 0.6400, Test: 0.6150
Epoch: 76, Loss: 0.5753, Train: 0.9333, Val: 0.6600, Test: 0.6420
Epoch: 77, Loss: 0.6216, Train: 0.9333, Val: 0.6940, Test: 0.6660
Epoch: 78, Loss: 0.5891, Train: 0.9500, Val: 0.7040, Test: 0.6670
Epoch: 79, Loss: 0.5558, Train: 0.8833, Val: 0.6380, Test: 0.6390
Epoch: 80, Loss: 0.5415, Train: 0.7833, Val: 0.5980, Test: 0.5990
Epoch: 81, Loss: 0.5121, Train: 0.8667, Val: 0.6220, Test: 0.6210
Epoch: 82, Loss: 0.4791, Train: 0.8833, Val: 0.6580, Test: 0.6070
Epoch: 83, Loss: 0.5606, Train: 0.8500, Val: 0.6100, Test: 0.6130
Epoch: 84, Loss: 0.4203, Train: 0.7667, Val: 0.5820, Test: 0.5860
Epoch: 85, Loss: 0.4768, Train: 0.8833, Val: 0.6360, Test: 0.6090
Epoch: 86, Loss: 0.4486, Train: 0.9000, Val: 0.6520, Test: 0.6350
Epoch: 87, Loss: 0.5081, Train: 0.9000, Val: 0.6340, Test: 0.6400
Epoch: 88, Loss: 0.3853, Train: 0.9500, Val: 0.7120, Test: 0.6870
Epoch: 89, Loss: 0.3152, Train: 0.9667, Val: 0.7360, Test: 0.6940
Epoch: 90, Loss: 0.3211, Train: 0.9667, Val: 0.7420, Test: 0.7040
Epoch: 91, Loss: 0.2805, Train: 0.9667, Val: 0.7240, Test: 0.6970
Epoch: 92, Loss: 0.2631, Train: 0.9500, Val: 0.6920, Test: 0.6740
Epoch: 93, Loss: 0.2965, Train: 0.9667, Val: 0.7180, Test: 0.6840
Epoch: 94, Loss: 0.2224, Train: 0.9667, Val: 0.7440, Test: 0.6970
Epoch: 95, Loss: 0.2812, Train: 0.9667, Val: 0.7520, Test: 0.7010
Epoch: 96, Loss: 0.2409, Train: 0.9833, Val: 0.7300, Test: 0.7010
Epoch: 97, Loss: 0.1786, Train: 0.9667, Val: 0.7080, Test: 0.6770
Epoch: 98, Loss: 0.1692, Train: 0.9667, Val: 0.6760, Test: 0.6770
Epoch: 99, Loss: 0.1172, Train: 0.9833, Val: 0.6760, Test: 0.6810
Epoch: 100, Loss: 0.1267, Train: 1.0000, Val: 0.7240, Test: 0.6870
MAD:  0.3812
Best Test Accuracy: 0.7040, Val Accuracy: 0.7420, Train Accuracy: 0.9667
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-8): 8 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1381, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 2, Loss: 1.1216, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 3, Loss: 1.1328, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 4, Loss: 1.0923, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.0951, Train: 0.3333, Val: 0.3860, Test: 0.4200
Epoch: 6, Loss: 1.0836, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 7, Loss: 1.1900, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 8, Loss: 1.0974, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 9, Loss: 1.1098, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.0953, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.1424, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.1436, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 13, Loss: 1.0888, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 14, Loss: 1.1465, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 15, Loss: 1.0940, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 16, Loss: 1.1249, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 17, Loss: 1.1210, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 18, Loss: 1.1121, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 19, Loss: 1.1149, Train: 0.3333, Val: 0.4260, Test: 0.4560
Epoch: 20, Loss: 1.1470, Train: 0.3667, Val: 0.4080, Test: 0.4450
Epoch: 21, Loss: 1.1084, Train: 0.4167, Val: 0.4080, Test: 0.4160
Epoch: 22, Loss: 1.1357, Train: 0.6000, Val: 0.5160, Test: 0.5200
Epoch: 23, Loss: 1.1325, Train: 0.6333, Val: 0.5060, Test: 0.5060
Epoch: 24, Loss: 1.0647, Train: 0.6000, Val: 0.4480, Test: 0.4400
Epoch: 25, Loss: 1.0920, Train: 0.5000, Val: 0.3860, Test: 0.3740
Epoch: 26, Loss: 1.1564, Train: 0.4167, Val: 0.2880, Test: 0.2920
Epoch: 27, Loss: 1.0723, Train: 0.4000, Val: 0.2640, Test: 0.2460
Epoch: 28, Loss: 1.1191, Train: 0.3833, Val: 0.2300, Test: 0.2090
Epoch: 29, Loss: 1.0915, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 30, Loss: 1.1015, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 31, Loss: 1.1091, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 32, Loss: 1.1113, Train: 0.3333, Val: 0.1980, Test: 0.1800
Epoch: 33, Loss: 1.0847, Train: 0.3333, Val: 0.2040, Test: 0.1930
Epoch: 34, Loss: 1.0746, Train: 0.5500, Val: 0.4720, Test: 0.4720
Epoch: 35, Loss: 1.1131, Train: 0.5833, Val: 0.5220, Test: 0.5060
Epoch: 36, Loss: 1.0742, Train: 0.6000, Val: 0.5240, Test: 0.5070
Epoch: 37, Loss: 1.0753, Train: 0.6000, Val: 0.5020, Test: 0.5160
Epoch: 38, Loss: 1.1009, Train: 0.5667, Val: 0.4940, Test: 0.5000
Epoch: 39, Loss: 1.1082, Train: 0.5500, Val: 0.4760, Test: 0.4900
Epoch: 40, Loss: 1.0944, Train: 0.4667, Val: 0.4480, Test: 0.4650
Epoch: 41, Loss: 1.0852, Train: 0.4667, Val: 0.4340, Test: 0.4580
Epoch: 42, Loss: 1.0712, Train: 0.5333, Val: 0.4700, Test: 0.4810
Epoch: 43, Loss: 1.0817, Train: 0.5667, Val: 0.4940, Test: 0.5060
Epoch: 44, Loss: 1.0710, Train: 0.5833, Val: 0.5040, Test: 0.5090
Epoch: 45, Loss: 1.0717, Train: 0.6000, Val: 0.5160, Test: 0.5080
Epoch: 46, Loss: 1.0794, Train: 0.5833, Val: 0.5180, Test: 0.4990
Epoch: 47, Loss: 1.0702, Train: 0.5833, Val: 0.5160, Test: 0.4990
Epoch: 48, Loss: 1.0894, Train: 0.5833, Val: 0.5140, Test: 0.4960
Epoch: 49, Loss: 1.0613, Train: 0.7167, Val: 0.6560, Test: 0.6340
Epoch: 50, Loss: 1.0564, Train: 0.8333, Val: 0.7080, Test: 0.6750
Epoch: 51, Loss: 1.0762, Train: 0.8167, Val: 0.6500, Test: 0.6040
Epoch: 52, Loss: 1.0563, Train: 0.6667, Val: 0.5760, Test: 0.5530
Epoch: 53, Loss: 1.0203, Train: 0.6167, Val: 0.5600, Test: 0.5400
Epoch: 54, Loss: 1.0181, Train: 0.6167, Val: 0.5500, Test: 0.5370
Epoch: 55, Loss: 0.9353, Train: 0.6167, Val: 0.5520, Test: 0.5360
Epoch: 56, Loss: 0.9724, Train: 0.6167, Val: 0.5520, Test: 0.5280
Epoch: 57, Loss: 0.9675, Train: 0.6167, Val: 0.5460, Test: 0.5290
Epoch: 58, Loss: 0.9427, Train: 0.6167, Val: 0.5560, Test: 0.5200
Epoch: 59, Loss: 0.9498, Train: 0.6833, Val: 0.5640, Test: 0.5280
Epoch: 60, Loss: 0.8691, Train: 0.6833, Val: 0.5560, Test: 0.5170
Epoch: 61, Loss: 0.8394, Train: 0.6833, Val: 0.5540, Test: 0.5250
Epoch: 62, Loss: 0.8074, Train: 0.6833, Val: 0.5580, Test: 0.5240
Epoch: 63, Loss: 0.8086, Train: 0.6833, Val: 0.5540, Test: 0.5220
Epoch: 64, Loss: 0.7819, Train: 0.7167, Val: 0.5600, Test: 0.5240
Epoch: 65, Loss: 0.7397, Train: 0.7333, Val: 0.5740, Test: 0.5300
Epoch: 66, Loss: 0.7324, Train: 0.7500, Val: 0.5680, Test: 0.5320
Epoch: 67, Loss: 0.6863, Train: 0.7333, Val: 0.5700, Test: 0.5400
Epoch: 68, Loss: 0.7033, Train: 0.7333, Val: 0.5780, Test: 0.5490
Epoch: 69, Loss: 0.6793, Train: 0.8000, Val: 0.5800, Test: 0.5580
Epoch: 70, Loss: 0.6454, Train: 0.8167, Val: 0.5820, Test: 0.5660
Epoch: 71, Loss: 0.6139, Train: 0.7833, Val: 0.5820, Test: 0.5770
Epoch: 72, Loss: 0.6191, Train: 0.8000, Val: 0.5760, Test: 0.5750
Epoch: 73, Loss: 0.6930, Train: 0.7500, Val: 0.6120, Test: 0.5740
Epoch: 74, Loss: 0.6337, Train: 0.7167, Val: 0.5940, Test: 0.5560
Epoch: 75, Loss: 0.6358, Train: 0.8833, Val: 0.6500, Test: 0.6390
Epoch: 76, Loss: 0.6240, Train: 0.9167, Val: 0.7520, Test: 0.7010
Epoch: 77, Loss: 0.4702, Train: 0.8833, Val: 0.6820, Test: 0.6790
Epoch: 78, Loss: 0.5480, Train: 0.8167, Val: 0.6520, Test: 0.6440
Epoch: 79, Loss: 0.5916, Train: 0.9000, Val: 0.7360, Test: 0.7070
Epoch: 80, Loss: 0.4495, Train: 0.9500, Val: 0.7260, Test: 0.6960
Epoch: 81, Loss: 0.4537, Train: 0.9500, Val: 0.7140, Test: 0.6770
Epoch: 82, Loss: 0.3628, Train: 0.9500, Val: 0.7140, Test: 0.6910
Epoch: 83, Loss: 0.4330, Train: 0.9833, Val: 0.7180, Test: 0.7090
Epoch: 84, Loss: 0.3820, Train: 0.9833, Val: 0.7560, Test: 0.7380
Epoch: 85, Loss: 0.3263, Train: 0.9667, Val: 0.7720, Test: 0.7600
Epoch: 86, Loss: 0.3363, Train: 0.9500, Val: 0.7700, Test: 0.7480
Epoch: 87, Loss: 0.2651, Train: 0.9500, Val: 0.7720, Test: 0.7480
Epoch: 88, Loss: 0.2877, Train: 0.9667, Val: 0.7860, Test: 0.7740
Epoch: 89, Loss: 0.2514, Train: 0.9667, Val: 0.7780, Test: 0.7530
Epoch: 90, Loss: 0.2579, Train: 0.9667, Val: 0.7680, Test: 0.7510
Epoch: 91, Loss: 0.1653, Train: 0.9833, Val: 0.7720, Test: 0.7580
Epoch: 92, Loss: 0.1337, Train: 0.9833, Val: 0.7880, Test: 0.7690
Epoch: 93, Loss: 0.1231, Train: 0.9833, Val: 0.7920, Test: 0.7690
Epoch: 94, Loss: 0.1305, Train: 1.0000, Val: 0.7920, Test: 0.7760
Epoch: 95, Loss: 0.0940, Train: 1.0000, Val: 0.7840, Test: 0.7710
Epoch: 96, Loss: 0.0827, Train: 1.0000, Val: 0.7740, Test: 0.7530
Epoch: 97, Loss: 0.0720, Train: 1.0000, Val: 0.7740, Test: 0.7520
Epoch: 98, Loss: 0.0823, Train: 1.0000, Val: 0.7860, Test: 0.7720
Epoch: 99, Loss: 0.0509, Train: 1.0000, Val: 0.7760, Test: 0.7640
Epoch: 100, Loss: 0.0736, Train: 1.0000, Val: 0.7680, Test: 0.7630
MAD:  0.4934
Best Test Accuracy: 0.7760, Val Accuracy: 0.7920, Train Accuracy: 1.0000
Training completed.
Average Test Accuracy:  0.702 ± 0.06658528365937928
Average MAD:  0.30051 ± 0.18134034548329284
