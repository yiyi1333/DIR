Seed:  0
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.0859, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 2, Loss: 1.0815, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 3, Loss: 1.1132, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 4, Loss: 1.1331, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 5, Loss: 1.1096, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 6, Loss: 1.1451, Train: 0.3500, Val: 0.2020, Test: 0.1840
Epoch: 7, Loss: 1.1098, Train: 0.5833, Val: 0.4800, Test: 0.4790
Epoch: 8, Loss: 1.1240, Train: 0.3333, Val: 0.3920, Test: 0.4150
Epoch: 9, Loss: 1.1081, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.1702, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.0908, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.1132, Train: 0.3333, Val: 0.3900, Test: 0.4140
Epoch: 13, Loss: 1.0928, Train: 0.4333, Val: 0.4200, Test: 0.4490
Epoch: 14, Loss: 1.1199, Train: 0.6000, Val: 0.5180, Test: 0.5150
Epoch: 15, Loss: 1.0429, Train: 0.6000, Val: 0.4900, Test: 0.4840
Epoch: 16, Loss: 1.1156, Train: 0.4333, Val: 0.2920, Test: 0.2600
Epoch: 17, Loss: 1.0797, Train: 0.3833, Val: 0.2360, Test: 0.2200
Epoch: 18, Loss: 1.1235, Train: 0.3833, Val: 0.2320, Test: 0.2170
Epoch: 19, Loss: 1.0739, Train: 0.3833, Val: 0.2520, Test: 0.2280
Epoch: 20, Loss: 1.0554, Train: 0.3833, Val: 0.2440, Test: 0.2250
Epoch: 21, Loss: 1.0737, Train: 0.4000, Val: 0.2760, Test: 0.2430
Epoch: 22, Loss: 1.1218, Train: 0.4167, Val: 0.3000, Test: 0.2750
Epoch: 23, Loss: 1.0709, Train: 0.4500, Val: 0.3260, Test: 0.3070
Epoch: 24, Loss: 1.0711, Train: 0.4833, Val: 0.3520, Test: 0.3450
Epoch: 25, Loss: 1.0628, Train: 0.5000, Val: 0.3860, Test: 0.3960
Epoch: 26, Loss: 1.0826, Train: 0.5167, Val: 0.4380, Test: 0.4400
Epoch: 27, Loss: 1.0520, Train: 0.5833, Val: 0.4920, Test: 0.4830
Epoch: 28, Loss: 1.0869, Train: 0.6000, Val: 0.5180, Test: 0.5130
Epoch: 29, Loss: 1.0610, Train: 0.6500, Val: 0.5340, Test: 0.5250
Epoch: 30, Loss: 1.0228, Train: 0.7167, Val: 0.5560, Test: 0.5600
Epoch: 31, Loss: 1.0353, Train: 0.7667, Val: 0.6300, Test: 0.6260
Epoch: 32, Loss: 1.0677, Train: 0.8000, Val: 0.6760, Test: 0.6670
Epoch: 33, Loss: 0.9862, Train: 0.8167, Val: 0.7000, Test: 0.6910
Epoch: 34, Loss: 0.9497, Train: 0.8500, Val: 0.7180, Test: 0.6970
Epoch: 35, Loss: 0.9341, Train: 0.9000, Val: 0.7420, Test: 0.7200
Epoch: 36, Loss: 0.8830, Train: 0.9000, Val: 0.7360, Test: 0.7220
Epoch: 37, Loss: 0.8897, Train: 0.9000, Val: 0.7320, Test: 0.7220
Epoch: 38, Loss: 0.8581, Train: 0.8833, Val: 0.7400, Test: 0.7220
Epoch: 39, Loss: 0.7903, Train: 0.8833, Val: 0.7420, Test: 0.7230
Epoch: 40, Loss: 0.8008, Train: 0.8667, Val: 0.7380, Test: 0.7240
Epoch: 41, Loss: 0.6703, Train: 0.8667, Val: 0.7420, Test: 0.7240
Epoch: 42, Loss: 0.6753, Train: 0.9167, Val: 0.7400, Test: 0.7330
Epoch: 43, Loss: 0.6059, Train: 0.9167, Val: 0.7500, Test: 0.7410
Epoch: 44, Loss: 0.5681, Train: 0.9167, Val: 0.7560, Test: 0.7440
Epoch: 45, Loss: 0.5703, Train: 0.9167, Val: 0.7620, Test: 0.7570
Epoch: 46, Loss: 0.4976, Train: 0.9167, Val: 0.7740, Test: 0.7550
Epoch: 47, Loss: 0.4647, Train: 0.9167, Val: 0.7860, Test: 0.7510
Epoch: 48, Loss: 0.4328, Train: 0.9333, Val: 0.7880, Test: 0.7550
Epoch: 49, Loss: 0.3642, Train: 0.9500, Val: 0.7860, Test: 0.7670
Epoch: 50, Loss: 0.3478, Train: 0.9500, Val: 0.7820, Test: 0.7640
Epoch: 51, Loss: 0.3149, Train: 0.9833, Val: 0.7760, Test: 0.7550
Epoch: 52, Loss: 0.2977, Train: 0.9833, Val: 0.7780, Test: 0.7570
Epoch: 53, Loss: 0.2133, Train: 0.9833, Val: 0.7840, Test: 0.7730
Epoch: 54, Loss: 0.1871, Train: 0.9833, Val: 0.7860, Test: 0.7720
Epoch: 55, Loss: 0.1844, Train: 1.0000, Val: 0.7880, Test: 0.7730
Epoch: 56, Loss: 0.1409, Train: 0.9833, Val: 0.7760, Test: 0.7820
Epoch: 57, Loss: 0.0964, Train: 0.9833, Val: 0.7860, Test: 0.7760
Epoch: 58, Loss: 0.0919, Train: 1.0000, Val: 0.7820, Test: 0.7800
Epoch: 59, Loss: 0.0896, Train: 1.0000, Val: 0.7760, Test: 0.7720
Epoch: 60, Loss: 0.0641, Train: 0.9833, Val: 0.7700, Test: 0.7550
Epoch: 61, Loss: 0.0664, Train: 1.0000, Val: 0.7720, Test: 0.7520
Epoch: 62, Loss: 0.0358, Train: 1.0000, Val: 0.7720, Test: 0.7570
Epoch: 63, Loss: 0.0350, Train: 1.0000, Val: 0.7700, Test: 0.7590
Epoch: 64, Loss: 0.0388, Train: 1.0000, Val: 0.7700, Test: 0.7520
Epoch: 65, Loss: 0.0488, Train: 1.0000, Val: 0.7860, Test: 0.7660
Epoch: 66, Loss: 0.0300, Train: 0.9833, Val: 0.7740, Test: 0.7650
Epoch: 67, Loss: 0.0374, Train: 0.9833, Val: 0.7800, Test: 0.7660
Epoch: 68, Loss: 0.0930, Train: 1.0000, Val: 0.7840, Test: 0.7630
Epoch: 69, Loss: 0.0166, Train: 1.0000, Val: 0.7760, Test: 0.7630
Epoch: 70, Loss: 0.0185, Train: 1.0000, Val: 0.7600, Test: 0.7370
Epoch: 71, Loss: 0.0592, Train: 1.0000, Val: 0.7660, Test: 0.7580
Epoch: 72, Loss: 0.0112, Train: 1.0000, Val: 0.7760, Test: 0.7620
Epoch: 73, Loss: 0.0128, Train: 1.0000, Val: 0.7720, Test: 0.7670
Epoch: 74, Loss: 0.0144, Train: 1.0000, Val: 0.7740, Test: 0.7640
Epoch: 75, Loss: 0.0126, Train: 1.0000, Val: 0.7760, Test: 0.7640
Epoch: 76, Loss: 0.0280, Train: 1.0000, Val: 0.7660, Test: 0.7610
Epoch: 77, Loss: 0.0058, Train: 1.0000, Val: 0.7600, Test: 0.7520
Epoch: 78, Loss: 0.0110, Train: 1.0000, Val: 0.7600, Test: 0.7510
Epoch: 79, Loss: 0.0081, Train: 1.0000, Val: 0.7540, Test: 0.7420
Epoch: 80, Loss: 0.0083, Train: 1.0000, Val: 0.7560, Test: 0.7400
Epoch: 81, Loss: 0.0119, Train: 1.0000, Val: 0.7620, Test: 0.7450
Epoch: 82, Loss: 0.0070, Train: 1.0000, Val: 0.7620, Test: 0.7460
Epoch: 83, Loss: 0.0026, Train: 1.0000, Val: 0.7720, Test: 0.7460
Epoch: 84, Loss: 0.0044, Train: 1.0000, Val: 0.7760, Test: 0.7410
Epoch: 85, Loss: 0.0031, Train: 1.0000, Val: 0.7740, Test: 0.7410
Epoch: 86, Loss: 0.0045, Train: 1.0000, Val: 0.7620, Test: 0.7410
Epoch: 87, Loss: 0.0165, Train: 1.0000, Val: 0.7600, Test: 0.7470
Epoch: 88, Loss: 0.0063, Train: 1.0000, Val: 0.7620, Test: 0.7530
Epoch: 89, Loss: 0.0179, Train: 1.0000, Val: 0.7820, Test: 0.7600
Epoch: 90, Loss: 0.0061, Train: 1.0000, Val: 0.7740, Test: 0.7630
Epoch: 91, Loss: 0.0051, Train: 1.0000, Val: 0.7640, Test: 0.7640
Epoch: 92, Loss: 0.0051, Train: 1.0000, Val: 0.7600, Test: 0.7610
Epoch: 93, Loss: 0.0063, Train: 1.0000, Val: 0.7640, Test: 0.7530
Epoch: 94, Loss: 0.0122, Train: 1.0000, Val: 0.7660, Test: 0.7500
Epoch: 95, Loss: 0.0065, Train: 1.0000, Val: 0.7620, Test: 0.7560
Epoch: 96, Loss: 0.0118, Train: 1.0000, Val: 0.7780, Test: 0.7490
Epoch: 97, Loss: 0.0027, Train: 1.0000, Val: 0.7680, Test: 0.7510
Epoch: 98, Loss: 0.0067, Train: 1.0000, Val: 0.7660, Test: 0.7490
Epoch: 99, Loss: 0.0027, Train: 1.0000, Val: 0.7560, Test: 0.7470
Epoch: 100, Loss: 0.0050, Train: 1.0000, Val: 0.7560, Test: 0.7400
MAD:  0.5042
Best Test Accuracy: 0.7820, Val Accuracy: 0.7760, Train Accuracy: 0.9833
Training completed.
Seed:  1
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1183, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 2, Loss: 1.1145, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 3, Loss: 1.1455, Train: 0.3500, Val: 0.4140, Test: 0.4200
Epoch: 4, Loss: 1.0696, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.1069, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 6, Loss: 1.1277, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 7, Loss: 1.1239, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 8, Loss: 1.1171, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 9, Loss: 1.0838, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 10, Loss: 1.1068, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 11, Loss: 1.1100, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 12, Loss: 1.0788, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 13, Loss: 1.1621, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 14, Loss: 1.1573, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 15, Loss: 1.1022, Train: 0.4167, Val: 0.4380, Test: 0.4300
Epoch: 16, Loss: 1.1530, Train: 0.6333, Val: 0.5500, Test: 0.5210
Epoch: 17, Loss: 1.1528, Train: 0.6333, Val: 0.5040, Test: 0.4960
Epoch: 18, Loss: 1.0638, Train: 0.5667, Val: 0.4680, Test: 0.4460
Epoch: 19, Loss: 1.0519, Train: 0.6000, Val: 0.4500, Test: 0.4350
Epoch: 20, Loss: 1.0587, Train: 0.5500, Val: 0.4220, Test: 0.3970
Epoch: 21, Loss: 1.0714, Train: 0.4667, Val: 0.3780, Test: 0.3510
Epoch: 22, Loss: 1.0598, Train: 0.5000, Val: 0.4280, Test: 0.4370
Epoch: 23, Loss: 0.9959, Train: 0.6333, Val: 0.4980, Test: 0.5030
Epoch: 24, Loss: 1.0273, Train: 0.7333, Val: 0.5760, Test: 0.5800
Epoch: 25, Loss: 1.0591, Train: 0.8000, Val: 0.7080, Test: 0.6800
Epoch: 26, Loss: 1.0453, Train: 0.8333, Val: 0.6620, Test: 0.6390
Epoch: 27, Loss: 1.0495, Train: 0.7833, Val: 0.5940, Test: 0.5690
Epoch: 28, Loss: 1.0116, Train: 0.6833, Val: 0.5540, Test: 0.5470
Epoch: 29, Loss: 1.0026, Train: 0.6667, Val: 0.5460, Test: 0.5450
Epoch: 30, Loss: 1.0095, Train: 0.6667, Val: 0.5520, Test: 0.5370
Epoch: 31, Loss: 0.9261, Train: 0.6500, Val: 0.5640, Test: 0.5360
Epoch: 32, Loss: 0.9023, Train: 0.6500, Val: 0.5600, Test: 0.5270
Epoch: 33, Loss: 0.8788, Train: 0.6500, Val: 0.5560, Test: 0.5300
Epoch: 34, Loss: 0.8392, Train: 0.6333, Val: 0.5560, Test: 0.5260
Epoch: 35, Loss: 0.8226, Train: 0.6333, Val: 0.5560, Test: 0.5270
Epoch: 36, Loss: 0.7964, Train: 0.6333, Val: 0.5560, Test: 0.5280
Epoch: 37, Loss: 0.7570, Train: 0.6333, Val: 0.5560, Test: 0.5280
Epoch: 38, Loss: 0.7926, Train: 0.6333, Val: 0.5560, Test: 0.5300
Epoch: 39, Loss: 0.7059, Train: 0.6500, Val: 0.5640, Test: 0.5300
Epoch: 40, Loss: 0.7140, Train: 0.6833, Val: 0.5600, Test: 0.5350
Epoch: 41, Loss: 0.7109, Train: 0.7000, Val: 0.5800, Test: 0.5420
Epoch: 42, Loss: 0.6562, Train: 0.7333, Val: 0.5820, Test: 0.5490
Epoch: 43, Loss: 0.7015, Train: 0.7667, Val: 0.5860, Test: 0.5610
Epoch: 44, Loss: 0.6360, Train: 0.7833, Val: 0.5940, Test: 0.5870
Epoch: 45, Loss: 0.6227, Train: 0.8000, Val: 0.6000, Test: 0.5790
Epoch: 46, Loss: 0.5557, Train: 0.7500, Val: 0.5980, Test: 0.5570
Epoch: 47, Loss: 0.5326, Train: 0.7333, Val: 0.5820, Test: 0.5460
Epoch: 48, Loss: 0.5378, Train: 0.7500, Val: 0.5820, Test: 0.5430
Epoch: 49, Loss: 0.4748, Train: 0.7333, Val: 0.5720, Test: 0.5380
Epoch: 50, Loss: 0.5094, Train: 0.7667, Val: 0.5820, Test: 0.5580
Epoch: 51, Loss: 0.4567, Train: 0.7667, Val: 0.5940, Test: 0.5760
Epoch: 52, Loss: 0.4845, Train: 0.7833, Val: 0.5960, Test: 0.5920
Epoch: 53, Loss: 0.5219, Train: 0.9167, Val: 0.6520, Test: 0.6390
Epoch: 54, Loss: 0.5185, Train: 0.9500, Val: 0.7100, Test: 0.6740
Epoch: 55, Loss: 0.4335, Train: 0.9667, Val: 0.7340, Test: 0.6860
Epoch: 56, Loss: 0.3924, Train: 0.9667, Val: 0.7460, Test: 0.6950
Epoch: 57, Loss: 0.3047, Train: 0.9667, Val: 0.7480, Test: 0.7030
Epoch: 58, Loss: 0.3304, Train: 0.9833, Val: 0.7540, Test: 0.7020
Epoch: 59, Loss: 0.2681, Train: 0.9667, Val: 0.7300, Test: 0.7050
Epoch: 60, Loss: 0.2848, Train: 0.9667, Val: 0.7340, Test: 0.7000
Epoch: 61, Loss: 0.2393, Train: 0.9833, Val: 0.7580, Test: 0.7010
Epoch: 62, Loss: 0.2382, Train: 0.9667, Val: 0.7520, Test: 0.6970
Epoch: 63, Loss: 0.2246, Train: 0.9667, Val: 0.7580, Test: 0.7230
Epoch: 64, Loss: 0.1839, Train: 0.9667, Val: 0.7580, Test: 0.7370
Epoch: 65, Loss: 0.1492, Train: 0.9833, Val: 0.7520, Test: 0.7280
Epoch: 66, Loss: 0.1811, Train: 1.0000, Val: 0.7440, Test: 0.7020
Epoch: 67, Loss: 0.1129, Train: 0.9833, Val: 0.7340, Test: 0.6970
Epoch: 68, Loss: 0.1519, Train: 1.0000, Val: 0.7320, Test: 0.7200
Epoch: 69, Loss: 0.1086, Train: 0.9833, Val: 0.7760, Test: 0.7390
Epoch: 70, Loss: 0.0953, Train: 0.9833, Val: 0.7860, Test: 0.7430
Epoch: 71, Loss: 0.0680, Train: 1.0000, Val: 0.7740, Test: 0.7470
Epoch: 72, Loss: 0.0618, Train: 1.0000, Val: 0.7560, Test: 0.7360
Epoch: 73, Loss: 0.0392, Train: 1.0000, Val: 0.7640, Test: 0.7250
Epoch: 74, Loss: 0.0345, Train: 1.0000, Val: 0.7580, Test: 0.7170
Epoch: 75, Loss: 0.0458, Train: 1.0000, Val: 0.7560, Test: 0.7250
Epoch: 76, Loss: 0.0527, Train: 1.0000, Val: 0.7660, Test: 0.7410
Epoch: 77, Loss: 0.0265, Train: 1.0000, Val: 0.7800, Test: 0.7410
Epoch: 78, Loss: 0.0304, Train: 1.0000, Val: 0.7680, Test: 0.7350
Epoch: 79, Loss: 0.0404, Train: 1.0000, Val: 0.7680, Test: 0.7450
Epoch: 80, Loss: 0.0235, Train: 1.0000, Val: 0.7700, Test: 0.7470
Epoch: 81, Loss: 0.0176, Train: 1.0000, Val: 0.7620, Test: 0.7620
Epoch: 82, Loss: 0.0145, Train: 1.0000, Val: 0.7700, Test: 0.7670
Epoch: 83, Loss: 0.0428, Train: 1.0000, Val: 0.7720, Test: 0.7550
Epoch: 84, Loss: 0.0121, Train: 1.0000, Val: 0.7700, Test: 0.7450
Epoch: 85, Loss: 0.0218, Train: 1.0000, Val: 0.7700, Test: 0.7350
Epoch: 86, Loss: 0.0121, Train: 1.0000, Val: 0.7600, Test: 0.7260
Epoch: 87, Loss: 0.0091, Train: 1.0000, Val: 0.7500, Test: 0.7220
Epoch: 88, Loss: 0.0178, Train: 1.0000, Val: 0.7740, Test: 0.7340
Epoch: 89, Loss: 0.0097, Train: 1.0000, Val: 0.7720, Test: 0.7440
Epoch: 90, Loss: 0.0095, Train: 1.0000, Val: 0.7800, Test: 0.7540
Epoch: 91, Loss: 0.0062, Train: 1.0000, Val: 0.7700, Test: 0.7600
Epoch: 92, Loss: 0.0089, Train: 1.0000, Val: 0.7700, Test: 0.7620
Epoch: 93, Loss: 0.0092, Train: 1.0000, Val: 0.7780, Test: 0.7610
Epoch: 94, Loss: 0.0082, Train: 1.0000, Val: 0.7860, Test: 0.7580
Epoch: 95, Loss: 0.0071, Train: 1.0000, Val: 0.7840, Test: 0.7550
Epoch: 96, Loss: 0.0046, Train: 1.0000, Val: 0.7820, Test: 0.7550
Epoch: 97, Loss: 0.0059, Train: 1.0000, Val: 0.7800, Test: 0.7560
Epoch: 98, Loss: 0.0044, Train: 1.0000, Val: 0.7800, Test: 0.7540
Epoch: 99, Loss: 0.0048, Train: 1.0000, Val: 0.7800, Test: 0.7570
Epoch: 100, Loss: 0.0042, Train: 1.0000, Val: 0.7800, Test: 0.7560
MAD:  0.5385
Best Test Accuracy: 0.7670, Val Accuracy: 0.7700, Train Accuracy: 1.0000
Training completed.
Seed:  2
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1211, Train: 0.3333, Val: 0.4120, Test: 0.4020
Epoch: 2, Loss: 1.1155, Train: 0.5667, Val: 0.5480, Test: 0.5200
Epoch: 3, Loss: 1.1419, Train: 0.3333, Val: 0.2020, Test: 0.1840
Epoch: 4, Loss: 1.1381, Train: 0.3333, Val: 0.1980, Test: 0.1800
Epoch: 5, Loss: 1.0873, Train: 0.5167, Val: 0.4440, Test: 0.4360
Epoch: 6, Loss: 1.1569, Train: 0.3333, Val: 0.4040, Test: 0.4230
Epoch: 7, Loss: 1.0784, Train: 0.3333, Val: 0.4000, Test: 0.4180
Epoch: 8, Loss: 1.0916, Train: 0.3833, Val: 0.4160, Test: 0.4310
Epoch: 9, Loss: 1.1231, Train: 0.5000, Val: 0.4780, Test: 0.5150
Epoch: 10, Loss: 1.1163, Train: 0.4333, Val: 0.4900, Test: 0.5320
Epoch: 11, Loss: 1.0846, Train: 0.4833, Val: 0.4700, Test: 0.5140
Epoch: 12, Loss: 1.0643, Train: 0.5167, Val: 0.5240, Test: 0.5660
Epoch: 13, Loss: 1.1064, Train: 0.5000, Val: 0.5480, Test: 0.5810
Epoch: 14, Loss: 1.1124, Train: 0.5000, Val: 0.5160, Test: 0.5700
Epoch: 15, Loss: 1.1098, Train: 0.4500, Val: 0.4840, Test: 0.5230
Epoch: 16, Loss: 1.0793, Train: 0.4333, Val: 0.4540, Test: 0.4960
Epoch: 17, Loss: 1.1039, Train: 0.4167, Val: 0.4420, Test: 0.4700
Epoch: 18, Loss: 1.0918, Train: 0.4167, Val: 0.4420, Test: 0.4750
Epoch: 19, Loss: 1.0725, Train: 0.4333, Val: 0.4760, Test: 0.5110
Epoch: 20, Loss: 1.0998, Train: 0.5167, Val: 0.5520, Test: 0.5820
Epoch: 21, Loss: 1.0316, Train: 0.7667, Val: 0.6920, Test: 0.7000
Epoch: 22, Loss: 1.1205, Train: 0.8333, Val: 0.6760, Test: 0.6800
Epoch: 23, Loss: 1.0334, Train: 0.8500, Val: 0.6480, Test: 0.6350
Epoch: 24, Loss: 1.0892, Train: 0.7833, Val: 0.6220, Test: 0.6050
Epoch: 25, Loss: 1.0728, Train: 0.6333, Val: 0.5240, Test: 0.5210
Epoch: 26, Loss: 1.0398, Train: 0.5833, Val: 0.5120, Test: 0.5030
Epoch: 27, Loss: 1.0082, Train: 0.5833, Val: 0.5120, Test: 0.5020
Epoch: 28, Loss: 1.0234, Train: 0.6333, Val: 0.5160, Test: 0.5080
Epoch: 29, Loss: 1.0588, Train: 0.7333, Val: 0.5760, Test: 0.5770
Epoch: 30, Loss: 0.9825, Train: 0.8667, Val: 0.6880, Test: 0.6720
Epoch: 31, Loss: 0.9698, Train: 0.8833, Val: 0.6920, Test: 0.6880
Epoch: 32, Loss: 0.9597, Train: 0.8667, Val: 0.7080, Test: 0.7040
Epoch: 33, Loss: 0.9150, Train: 0.8667, Val: 0.7280, Test: 0.7150
Epoch: 34, Loss: 0.9083, Train: 0.8833, Val: 0.7220, Test: 0.7190
Epoch: 35, Loss: 0.8423, Train: 0.9000, Val: 0.7200, Test: 0.7150
Epoch: 36, Loss: 0.7581, Train: 0.9000, Val: 0.7280, Test: 0.7210
Epoch: 37, Loss: 0.7388, Train: 0.8667, Val: 0.7280, Test: 0.7190
Epoch: 38, Loss: 0.7725, Train: 0.8500, Val: 0.7280, Test: 0.7140
Epoch: 39, Loss: 0.6992, Train: 0.8667, Val: 0.7340, Test: 0.7210
Epoch: 40, Loss: 0.6800, Train: 0.9000, Val: 0.7340, Test: 0.7070
Epoch: 41, Loss: 0.6024, Train: 0.9167, Val: 0.7480, Test: 0.7190
Epoch: 42, Loss: 0.5169, Train: 0.9333, Val: 0.7580, Test: 0.7280
Epoch: 43, Loss: 0.5718, Train: 0.9333, Val: 0.7700, Test: 0.7430
Epoch: 44, Loss: 0.4998, Train: 0.9333, Val: 0.7540, Test: 0.7400
Epoch: 45, Loss: 0.4444, Train: 0.9500, Val: 0.7540, Test: 0.7360
Epoch: 46, Loss: 0.4022, Train: 0.9667, Val: 0.7540, Test: 0.7400
Epoch: 47, Loss: 0.3884, Train: 0.9500, Val: 0.7740, Test: 0.7540
Epoch: 48, Loss: 0.3813, Train: 0.9500, Val: 0.7860, Test: 0.7620
Epoch: 49, Loss: 0.3277, Train: 0.9500, Val: 0.7900, Test: 0.7610
Epoch: 50, Loss: 0.2661, Train: 0.9500, Val: 0.7940, Test: 0.7780
Epoch: 51, Loss: 0.1563, Train: 0.9667, Val: 0.7880, Test: 0.7720
Epoch: 52, Loss: 0.1842, Train: 0.9833, Val: 0.7980, Test: 0.7700
Epoch: 53, Loss: 0.1567, Train: 0.9833, Val: 0.7980, Test: 0.7800
Epoch: 54, Loss: 0.1867, Train: 0.9833, Val: 0.7980, Test: 0.7740
Epoch: 55, Loss: 0.1024, Train: 0.9833, Val: 0.7800, Test: 0.7650
Epoch: 56, Loss: 0.1162, Train: 1.0000, Val: 0.7680, Test: 0.7480
Epoch: 57, Loss: 0.0786, Train: 1.0000, Val: 0.7740, Test: 0.7490
Epoch: 58, Loss: 0.0865, Train: 1.0000, Val: 0.7860, Test: 0.7690
Epoch: 59, Loss: 0.0831, Train: 1.0000, Val: 0.7880, Test: 0.7690
Epoch: 60, Loss: 0.0671, Train: 0.9833, Val: 0.7780, Test: 0.7670
Epoch: 61, Loss: 0.0601, Train: 0.9833, Val: 0.7820, Test: 0.7670
Epoch: 62, Loss: 0.0551, Train: 0.9833, Val: 0.7740, Test: 0.7680
Epoch: 63, Loss: 0.0638, Train: 0.9833, Val: 0.7720, Test: 0.7710
Epoch: 64, Loss: 0.0660, Train: 1.0000, Val: 0.7720, Test: 0.7650
Epoch: 65, Loss: 0.0420, Train: 1.0000, Val: 0.7640, Test: 0.7510
Epoch: 66, Loss: 0.0290, Train: 1.0000, Val: 0.7600, Test: 0.7480
Epoch: 67, Loss: 0.0381, Train: 1.0000, Val: 0.7580, Test: 0.7450
Epoch: 68, Loss: 0.0210, Train: 1.0000, Val: 0.7660, Test: 0.7460
Epoch: 69, Loss: 0.0289, Train: 1.0000, Val: 0.7700, Test: 0.7590
Epoch: 70, Loss: 0.0563, Train: 1.0000, Val: 0.7700, Test: 0.7630
Epoch: 71, Loss: 0.0150, Train: 1.0000, Val: 0.7840, Test: 0.7690
Epoch: 72, Loss: 0.0121, Train: 1.0000, Val: 0.7800, Test: 0.7700
Epoch: 73, Loss: 0.0094, Train: 1.0000, Val: 0.7780, Test: 0.7640
Epoch: 74, Loss: 0.0106, Train: 1.0000, Val: 0.7780, Test: 0.7670
Epoch: 75, Loss: 0.0127, Train: 1.0000, Val: 0.7660, Test: 0.7590
Epoch: 76, Loss: 0.0226, Train: 1.0000, Val: 0.7680, Test: 0.7560
Epoch: 77, Loss: 0.0080, Train: 1.0000, Val: 0.7660, Test: 0.7600
Epoch: 78, Loss: 0.0110, Train: 1.0000, Val: 0.7680, Test: 0.7520
Epoch: 79, Loss: 0.0054, Train: 1.0000, Val: 0.7560, Test: 0.7520
Epoch: 80, Loss: 0.0169, Train: 1.0000, Val: 0.7680, Test: 0.7500
Epoch: 81, Loss: 0.0069, Train: 1.0000, Val: 0.7700, Test: 0.7620
Epoch: 82, Loss: 0.0129, Train: 1.0000, Val: 0.7740, Test: 0.7650
Epoch: 83, Loss: 0.0077, Train: 1.0000, Val: 0.7780, Test: 0.7630
Epoch: 84, Loss: 0.0050, Train: 1.0000, Val: 0.7780, Test: 0.7690
Epoch: 85, Loss: 0.0116, Train: 1.0000, Val: 0.7800, Test: 0.7680
Epoch: 86, Loss: 0.0038, Train: 1.0000, Val: 0.7780, Test: 0.7670
Epoch: 87, Loss: 0.0104, Train: 1.0000, Val: 0.7780, Test: 0.7710
Epoch: 88, Loss: 0.0031, Train: 1.0000, Val: 0.7740, Test: 0.7750
Epoch: 89, Loss: 0.0046, Train: 1.0000, Val: 0.7780, Test: 0.7710
Epoch: 90, Loss: 0.0049, Train: 1.0000, Val: 0.7780, Test: 0.7700
Epoch: 91, Loss: 0.0355, Train: 1.0000, Val: 0.7680, Test: 0.7590
Epoch: 92, Loss: 0.0052, Train: 1.0000, Val: 0.7660, Test: 0.7600
Epoch: 93, Loss: 0.0029, Train: 1.0000, Val: 0.7540, Test: 0.7420
Epoch: 94, Loss: 0.0061, Train: 1.0000, Val: 0.7400, Test: 0.7340
Epoch: 95, Loss: 0.0207, Train: 1.0000, Val: 0.7560, Test: 0.7430
Epoch: 96, Loss: 0.0055, Train: 1.0000, Val: 0.7640, Test: 0.7540
Epoch: 97, Loss: 0.0106, Train: 1.0000, Val: 0.7700, Test: 0.7670
Epoch: 98, Loss: 0.0032, Train: 1.0000, Val: 0.7720, Test: 0.7580
Epoch: 99, Loss: 0.0034, Train: 1.0000, Val: 0.7740, Test: 0.7630
Epoch: 100, Loss: 0.0033, Train: 1.0000, Val: 0.7680, Test: 0.7630
MAD:  0.4954
Best Test Accuracy: 0.7800, Val Accuracy: 0.7980, Train Accuracy: 0.9833
Training completed.
Seed:  3
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1217, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 2, Loss: 1.1151, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 3, Loss: 1.1247, Train: 0.4000, Val: 0.3580, Test: 0.4260
Epoch: 4, Loss: 1.1186, Train: 0.3500, Val: 0.4240, Test: 0.4130
Epoch: 5, Loss: 1.1260, Train: 0.4333, Val: 0.4460, Test: 0.4460
Epoch: 6, Loss: 1.1174, Train: 0.5000, Val: 0.3960, Test: 0.3880
Epoch: 7, Loss: 1.1088, Train: 0.4833, Val: 0.3060, Test: 0.3090
Epoch: 8, Loss: 1.1096, Train: 0.4333, Val: 0.2520, Test: 0.2580
Epoch: 9, Loss: 1.0931, Train: 0.3500, Val: 0.2040, Test: 0.1890
Epoch: 10, Loss: 1.0810, Train: 0.3333, Val: 0.1960, Test: 0.1820
Epoch: 11, Loss: 1.0935, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 12, Loss: 1.1139, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 13, Loss: 1.1085, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 14, Loss: 1.0841, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 15, Loss: 1.1307, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 16, Loss: 1.0843, Train: 0.3333, Val: 0.1980, Test: 0.1840
Epoch: 17, Loss: 1.1015, Train: 0.3667, Val: 0.2320, Test: 0.2050
Epoch: 18, Loss: 1.1023, Train: 0.3667, Val: 0.2440, Test: 0.2220
Epoch: 19, Loss: 1.1335, Train: 0.4333, Val: 0.2700, Test: 0.2640
Epoch: 20, Loss: 1.0566, Train: 0.5167, Val: 0.3380, Test: 0.3360
Epoch: 21, Loss: 1.1037, Train: 0.5667, Val: 0.4040, Test: 0.3920
Epoch: 22, Loss: 1.1055, Train: 0.6500, Val: 0.4840, Test: 0.4640
Epoch: 23, Loss: 1.0713, Train: 0.6500, Val: 0.5080, Test: 0.4870
Epoch: 24, Loss: 1.1104, Train: 0.6500, Val: 0.5220, Test: 0.4990
Epoch: 25, Loss: 1.0698, Train: 0.6500, Val: 0.5340, Test: 0.5150
Epoch: 26, Loss: 1.0635, Train: 0.7500, Val: 0.5840, Test: 0.5710
Epoch: 27, Loss: 1.0237, Train: 0.7833, Val: 0.6040, Test: 0.5960
Epoch: 28, Loss: 1.0248, Train: 0.7833, Val: 0.6200, Test: 0.6010
Epoch: 29, Loss: 1.0043, Train: 0.7833, Val: 0.6280, Test: 0.5970
Epoch: 30, Loss: 1.0154, Train: 0.7833, Val: 0.6200, Test: 0.5930
Epoch: 31, Loss: 0.9994, Train: 0.8000, Val: 0.6080, Test: 0.5900
Epoch: 32, Loss: 0.9543, Train: 0.7833, Val: 0.6040, Test: 0.5810
Epoch: 33, Loss: 0.9309, Train: 0.7833, Val: 0.5900, Test: 0.5800
Epoch: 34, Loss: 0.9909, Train: 0.7167, Val: 0.6000, Test: 0.5410
Epoch: 35, Loss: 0.8872, Train: 0.7000, Val: 0.5700, Test: 0.5370
Epoch: 36, Loss: 0.8846, Train: 0.6833, Val: 0.5540, Test: 0.5290
Epoch: 37, Loss: 0.8921, Train: 0.6667, Val: 0.5540, Test: 0.5360
Epoch: 38, Loss: 0.8296, Train: 0.6667, Val: 0.5540, Test: 0.5360
Epoch: 39, Loss: 0.8164, Train: 0.7167, Val: 0.5780, Test: 0.5310
Epoch: 40, Loss: 0.7047, Train: 0.7000, Val: 0.5880, Test: 0.5440
Epoch: 41, Loss: 0.7102, Train: 0.7167, Val: 0.5720, Test: 0.5550
Epoch: 42, Loss: 0.6637, Train: 0.7333, Val: 0.5900, Test: 0.5620
Epoch: 43, Loss: 0.6837, Train: 0.7333, Val: 0.5960, Test: 0.5470
Epoch: 44, Loss: 0.6082, Train: 0.6667, Val: 0.5940, Test: 0.5460
Epoch: 45, Loss: 0.6184, Train: 0.6667, Val: 0.5880, Test: 0.5540
Epoch: 46, Loss: 0.5604, Train: 0.8667, Val: 0.6340, Test: 0.6140
Epoch: 47, Loss: 0.5418, Train: 0.9000, Val: 0.6840, Test: 0.6430
Epoch: 48, Loss: 0.5625, Train: 0.9167, Val: 0.7240, Test: 0.6640
Epoch: 49, Loss: 0.5683, Train: 0.9333, Val: 0.7080, Test: 0.6710
Epoch: 50, Loss: 0.4364, Train: 0.9333, Val: 0.6960, Test: 0.6690
Epoch: 51, Loss: 0.5045, Train: 0.9333, Val: 0.6940, Test: 0.6690
Epoch: 52, Loss: 0.4554, Train: 0.9500, Val: 0.7140, Test: 0.6780
Epoch: 53, Loss: 0.4554, Train: 0.9667, Val: 0.7360, Test: 0.6910
Epoch: 54, Loss: 0.3975, Train: 0.9667, Val: 0.7340, Test: 0.6820
Epoch: 55, Loss: 0.3965, Train: 0.9667, Val: 0.7120, Test: 0.6740
Epoch: 56, Loss: 0.3180, Train: 0.9500, Val: 0.7040, Test: 0.6720
Epoch: 57, Loss: 0.2912, Train: 0.9667, Val: 0.7280, Test: 0.6870
Epoch: 58, Loss: 0.2995, Train: 0.9667, Val: 0.7380, Test: 0.7000
Epoch: 59, Loss: 0.2867, Train: 0.9667, Val: 0.7440, Test: 0.7080
Epoch: 60, Loss: 0.2512, Train: 0.9833, Val: 0.7460, Test: 0.7140
Epoch: 61, Loss: 0.2501, Train: 0.9833, Val: 0.7500, Test: 0.7220
Epoch: 62, Loss: 0.1716, Train: 0.9833, Val: 0.7420, Test: 0.7280
Epoch: 63, Loss: 0.1816, Train: 0.9833, Val: 0.7520, Test: 0.7340
Epoch: 64, Loss: 0.1114, Train: 0.9833, Val: 0.7480, Test: 0.7170
Epoch: 65, Loss: 0.2421, Train: 0.9833, Val: 0.7420, Test: 0.7100
Epoch: 66, Loss: 0.1403, Train: 0.9833, Val: 0.6820, Test: 0.6700
Epoch: 67, Loss: 0.1295, Train: 0.9833, Val: 0.6980, Test: 0.6960
Epoch: 68, Loss: 0.1212, Train: 1.0000, Val: 0.7540, Test: 0.7390
Epoch: 69, Loss: 0.0382, Train: 1.0000, Val: 0.7560, Test: 0.7600
Epoch: 70, Loss: 0.0645, Train: 1.0000, Val: 0.7720, Test: 0.7530
Epoch: 71, Loss: 0.0371, Train: 1.0000, Val: 0.7720, Test: 0.7450
Epoch: 72, Loss: 0.0561, Train: 1.0000, Val: 0.7680, Test: 0.7430
Epoch: 73, Loss: 0.0452, Train: 1.0000, Val: 0.7660, Test: 0.7500
Epoch: 74, Loss: 0.0308, Train: 1.0000, Val: 0.7620, Test: 0.7510
Epoch: 75, Loss: 0.0251, Train: 1.0000, Val: 0.7660, Test: 0.7470
Epoch: 76, Loss: 0.0194, Train: 1.0000, Val: 0.7640, Test: 0.7510
Epoch: 77, Loss: 0.0489, Train: 1.0000, Val: 0.7400, Test: 0.7320
Epoch: 78, Loss: 0.0199, Train: 0.9833, Val: 0.7400, Test: 0.7150
Epoch: 79, Loss: 0.0272, Train: 0.9833, Val: 0.7360, Test: 0.7170
Epoch: 80, Loss: 0.0391, Train: 1.0000, Val: 0.7440, Test: 0.7350
Epoch: 81, Loss: 0.0109, Train: 1.0000, Val: 0.7520, Test: 0.7480
Epoch: 82, Loss: 0.0194, Train: 1.0000, Val: 0.7620, Test: 0.7550
Epoch: 83, Loss: 0.0172, Train: 1.0000, Val: 0.7660, Test: 0.7510
Epoch: 84, Loss: 0.0125, Train: 1.0000, Val: 0.7580, Test: 0.7480
Epoch: 85, Loss: 0.0667, Train: 1.0000, Val: 0.7560, Test: 0.7450
Epoch: 86, Loss: 0.0339, Train: 1.0000, Val: 0.7600, Test: 0.7450
Epoch: 87, Loss: 0.0138, Train: 1.0000, Val: 0.7500, Test: 0.7440
Epoch: 88, Loss: 0.0084, Train: 1.0000, Val: 0.7480, Test: 0.7340
Epoch: 89, Loss: 0.0095, Train: 1.0000, Val: 0.7440, Test: 0.7270
Epoch: 90, Loss: 0.0086, Train: 1.0000, Val: 0.7380, Test: 0.7290
Epoch: 91, Loss: 0.0095, Train: 1.0000, Val: 0.7400, Test: 0.7280
Epoch: 92, Loss: 0.0066, Train: 1.0000, Val: 0.7340, Test: 0.7270
Epoch: 93, Loss: 0.0053, Train: 1.0000, Val: 0.7400, Test: 0.7310
Epoch: 94, Loss: 0.0068, Train: 1.0000, Val: 0.7420, Test: 0.7320
Epoch: 95, Loss: 0.0124, Train: 1.0000, Val: 0.7600, Test: 0.7380
Epoch: 96, Loss: 0.0046, Train: 1.0000, Val: 0.7600, Test: 0.7480
Epoch: 97, Loss: 0.0044, Train: 1.0000, Val: 0.7700, Test: 0.7460
Epoch: 98, Loss: 0.0065, Train: 1.0000, Val: 0.7700, Test: 0.7520
Epoch: 99, Loss: 0.0053, Train: 1.0000, Val: 0.7700, Test: 0.7560
Epoch: 100, Loss: 0.0099, Train: 1.0000, Val: 0.7660, Test: 0.7580
MAD:  0.4898
Best Test Accuracy: 0.7600, Val Accuracy: 0.7560, Train Accuracy: 1.0000
Training completed.
Seed:  4
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1271, Train: 0.3000, Val: 0.2280, Test: 0.2280
Epoch: 2, Loss: 1.1553, Train: 0.4000, Val: 0.3880, Test: 0.4090
Epoch: 3, Loss: 1.1319, Train: 0.4833, Val: 0.3860, Test: 0.3830
Epoch: 4, Loss: 1.1124, Train: 0.5667, Val: 0.4000, Test: 0.3990
Epoch: 5, Loss: 1.0851, Train: 0.6000, Val: 0.4680, Test: 0.4680
Epoch: 6, Loss: 1.1685, Train: 0.6333, Val: 0.5020, Test: 0.4840
Epoch: 7, Loss: 1.1062, Train: 0.5833, Val: 0.4580, Test: 0.4550
Epoch: 8, Loss: 1.1234, Train: 0.4333, Val: 0.2480, Test: 0.2450
Epoch: 9, Loss: 1.1159, Train: 0.4000, Val: 0.2180, Test: 0.2120
Epoch: 10, Loss: 1.0899, Train: 0.3833, Val: 0.2160, Test: 0.1990
Epoch: 11, Loss: 1.0798, Train: 0.3333, Val: 0.1980, Test: 0.1810
Epoch: 12, Loss: 1.1086, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 13, Loss: 1.0905, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 14, Loss: 1.1279, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 15, Loss: 1.1171, Train: 0.3667, Val: 0.2100, Test: 0.1970
Epoch: 16, Loss: 1.1003, Train: 0.5333, Val: 0.4160, Test: 0.3830
Epoch: 17, Loss: 1.0971, Train: 0.6667, Val: 0.5480, Test: 0.5020
Epoch: 18, Loss: 1.1074, Train: 0.6333, Val: 0.5440, Test: 0.5130
Epoch: 19, Loss: 1.0816, Train: 0.6333, Val: 0.5520, Test: 0.5190
Epoch: 20, Loss: 1.1247, Train: 0.6333, Val: 0.5480, Test: 0.5140
Epoch: 21, Loss: 1.1035, Train: 0.6833, Val: 0.5300, Test: 0.5080
Epoch: 22, Loss: 1.0936, Train: 0.6333, Val: 0.4940, Test: 0.4830
Epoch: 23, Loss: 1.0650, Train: 0.5833, Val: 0.4620, Test: 0.4510
Epoch: 24, Loss: 1.0935, Train: 0.6500, Val: 0.4480, Test: 0.4400
Epoch: 25, Loss: 1.0427, Train: 0.6000, Val: 0.4500, Test: 0.4480
Epoch: 26, Loss: 1.0451, Train: 0.5167, Val: 0.4200, Test: 0.4260
Epoch: 27, Loss: 1.0620, Train: 0.5333, Val: 0.4100, Test: 0.4230
Epoch: 28, Loss: 1.0377, Train: 0.5333, Val: 0.4520, Test: 0.4650
Epoch: 29, Loss: 1.0351, Train: 0.6167, Val: 0.4960, Test: 0.4870
Epoch: 30, Loss: 1.0128, Train: 0.6167, Val: 0.5200, Test: 0.5130
Epoch: 31, Loss: 1.0192, Train: 0.6500, Val: 0.5560, Test: 0.5480
Epoch: 32, Loss: 0.9893, Train: 0.7000, Val: 0.5800, Test: 0.5570
Epoch: 33, Loss: 0.9781, Train: 0.7333, Val: 0.6140, Test: 0.5940
Epoch: 34, Loss: 0.9746, Train: 0.7500, Val: 0.6640, Test: 0.6440
Epoch: 35, Loss: 0.9510, Train: 0.7500, Val: 0.6800, Test: 0.6600
Epoch: 36, Loss: 0.8465, Train: 0.8167, Val: 0.6860, Test: 0.6700
Epoch: 37, Loss: 0.8275, Train: 0.7833, Val: 0.6760, Test: 0.6430
Epoch: 38, Loss: 0.8181, Train: 0.7833, Val: 0.6380, Test: 0.5920
Epoch: 39, Loss: 0.7808, Train: 0.7167, Val: 0.6180, Test: 0.5710
Epoch: 40, Loss: 0.7797, Train: 0.7500, Val: 0.6040, Test: 0.5620
Epoch: 41, Loss: 0.7206, Train: 0.7167, Val: 0.5940, Test: 0.5520
Epoch: 42, Loss: 0.7222, Train: 0.7167, Val: 0.5900, Test: 0.5510
Epoch: 43, Loss: 0.6711, Train: 0.7000, Val: 0.5820, Test: 0.5470
Epoch: 44, Loss: 0.6567, Train: 0.7000, Val: 0.5840, Test: 0.5410
Epoch: 45, Loss: 0.5900, Train: 0.7333, Val: 0.5880, Test: 0.5350
Epoch: 46, Loss: 0.6703, Train: 0.7000, Val: 0.5720, Test: 0.5370
Epoch: 47, Loss: 0.5967, Train: 0.7000, Val: 0.5560, Test: 0.5420
Epoch: 48, Loss: 0.5791, Train: 0.7000, Val: 0.5760, Test: 0.5570
Epoch: 49, Loss: 0.5100, Train: 0.8500, Val: 0.6200, Test: 0.5950
Epoch: 50, Loss: 0.5103, Train: 0.9333, Val: 0.6540, Test: 0.6540
Epoch: 51, Loss: 0.4700, Train: 0.9500, Val: 0.7100, Test: 0.6750
Epoch: 52, Loss: 0.4733, Train: 0.9500, Val: 0.7460, Test: 0.7070
Epoch: 53, Loss: 0.4431, Train: 0.9833, Val: 0.7580, Test: 0.7140
Epoch: 54, Loss: 0.3827, Train: 0.9833, Val: 0.7580, Test: 0.7260
Epoch: 55, Loss: 0.3308, Train: 0.9833, Val: 0.7520, Test: 0.7230
Epoch: 56, Loss: 0.3346, Train: 0.9833, Val: 0.7600, Test: 0.7190
Epoch: 57, Loss: 0.3408, Train: 0.9833, Val: 0.7660, Test: 0.7220
Epoch: 58, Loss: 0.2919, Train: 0.9833, Val: 0.7640, Test: 0.7240
Epoch: 59, Loss: 0.2711, Train: 0.9833, Val: 0.7740, Test: 0.7360
Epoch: 60, Loss: 0.2489, Train: 0.9833, Val: 0.7840, Test: 0.7400
Epoch: 61, Loss: 0.2312, Train: 1.0000, Val: 0.7680, Test: 0.7210
Epoch: 62, Loss: 0.1865, Train: 0.9667, Val: 0.7140, Test: 0.6920
Epoch: 63, Loss: 0.1870, Train: 0.9667, Val: 0.7120, Test: 0.7000
Epoch: 64, Loss: 0.1692, Train: 1.0000, Val: 0.7660, Test: 0.7440
Epoch: 65, Loss: 0.0908, Train: 0.9833, Val: 0.7820, Test: 0.7620
Epoch: 66, Loss: 0.1139, Train: 0.9833, Val: 0.7880, Test: 0.7620
Epoch: 67, Loss: 0.0810, Train: 0.9833, Val: 0.7900, Test: 0.7660
Epoch: 68, Loss: 0.0943, Train: 1.0000, Val: 0.7780, Test: 0.7700
Epoch: 69, Loss: 0.0992, Train: 1.0000, Val: 0.7500, Test: 0.7140
Epoch: 70, Loss: 0.0687, Train: 1.0000, Val: 0.6960, Test: 0.6760
Epoch: 71, Loss: 0.0634, Train: 1.0000, Val: 0.6860, Test: 0.6660
Epoch: 72, Loss: 0.0783, Train: 1.0000, Val: 0.7240, Test: 0.7060
Epoch: 73, Loss: 0.0262, Train: 1.0000, Val: 0.7580, Test: 0.7380
Epoch: 74, Loss: 0.0280, Train: 1.0000, Val: 0.7680, Test: 0.7520
Epoch: 75, Loss: 0.0288, Train: 1.0000, Val: 0.7700, Test: 0.7510
Epoch: 76, Loss: 0.0325, Train: 1.0000, Val: 0.7720, Test: 0.7540
Epoch: 77, Loss: 0.0373, Train: 1.0000, Val: 0.7680, Test: 0.7450
Epoch: 78, Loss: 0.0207, Train: 1.0000, Val: 0.7800, Test: 0.7490
Epoch: 79, Loss: 0.0161, Train: 1.0000, Val: 0.7820, Test: 0.7490
Epoch: 80, Loss: 0.0151, Train: 1.0000, Val: 0.7740, Test: 0.7540
Epoch: 81, Loss: 0.0135, Train: 1.0000, Val: 0.7760, Test: 0.7600
Epoch: 82, Loss: 0.0111, Train: 1.0000, Val: 0.7800, Test: 0.7590
Epoch: 83, Loss: 0.0155, Train: 1.0000, Val: 0.7760, Test: 0.7610
Epoch: 84, Loss: 0.0093, Train: 1.0000, Val: 0.7780, Test: 0.7570
Epoch: 85, Loss: 0.0094, Train: 1.0000, Val: 0.7740, Test: 0.7560
Epoch: 86, Loss: 0.0095, Train: 1.0000, Val: 0.7740, Test: 0.7470
Epoch: 87, Loss: 0.0117, Train: 1.0000, Val: 0.7680, Test: 0.7390
Epoch: 88, Loss: 0.0168, Train: 1.0000, Val: 0.7660, Test: 0.7500
Epoch: 89, Loss: 0.0052, Train: 1.0000, Val: 0.7700, Test: 0.7590
Epoch: 90, Loss: 0.0073, Train: 1.0000, Val: 0.7640, Test: 0.7490
Epoch: 91, Loss: 0.0125, Train: 1.0000, Val: 0.7620, Test: 0.7430
Epoch: 92, Loss: 0.0033, Train: 1.0000, Val: 0.7640, Test: 0.7440
Epoch: 93, Loss: 0.0134, Train: 1.0000, Val: 0.7680, Test: 0.7380
Epoch: 94, Loss: 0.0038, Train: 1.0000, Val: 0.7620, Test: 0.7380
Epoch: 95, Loss: 0.0063, Train: 1.0000, Val: 0.7520, Test: 0.7370
Epoch: 96, Loss: 0.0083, Train: 1.0000, Val: 0.7640, Test: 0.7370
Epoch: 97, Loss: 0.0053, Train: 1.0000, Val: 0.7660, Test: 0.7380
Epoch: 98, Loss: 0.0044, Train: 1.0000, Val: 0.7680, Test: 0.7390
Epoch: 99, Loss: 0.0039, Train: 1.0000, Val: 0.7720, Test: 0.7430
Epoch: 100, Loss: 0.0033, Train: 1.0000, Val: 0.7700, Test: 0.7470
MAD:  0.492
Best Test Accuracy: 0.7700, Val Accuracy: 0.7780, Train Accuracy: 1.0000
Training completed.
Seed:  5
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1194, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 2, Loss: 1.1204, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 3, Loss: 1.1166, Train: 0.3333, Val: 0.1960, Test: 0.1850
Epoch: 4, Loss: 1.0957, Train: 0.5000, Val: 0.4020, Test: 0.3910
Epoch: 5, Loss: 1.0940, Train: 0.3833, Val: 0.4700, Test: 0.4230
Epoch: 6, Loss: 1.0926, Train: 0.3333, Val: 0.4160, Test: 0.4080
Epoch: 7, Loss: 1.0980, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 8, Loss: 1.1295, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 9, Loss: 1.0864, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 10, Loss: 1.1593, Train: 0.3500, Val: 0.4180, Test: 0.4070
Epoch: 11, Loss: 1.0996, Train: 0.3500, Val: 0.4180, Test: 0.4070
Epoch: 12, Loss: 1.0875, Train: 0.3500, Val: 0.4180, Test: 0.4070
Epoch: 13, Loss: 1.1191, Train: 0.3500, Val: 0.4180, Test: 0.4070
Epoch: 14, Loss: 1.0861, Train: 0.3500, Val: 0.4180, Test: 0.4070
Epoch: 15, Loss: 1.0880, Train: 0.3500, Val: 0.4200, Test: 0.4070
Epoch: 16, Loss: 1.0789, Train: 0.3667, Val: 0.4220, Test: 0.4090
Epoch: 17, Loss: 1.1012, Train: 0.4167, Val: 0.4260, Test: 0.4130
Epoch: 18, Loss: 1.0696, Train: 0.4167, Val: 0.4240, Test: 0.4150
Epoch: 19, Loss: 1.0851, Train: 0.4167, Val: 0.4260, Test: 0.4210
Epoch: 20, Loss: 1.0840, Train: 0.4333, Val: 0.4460, Test: 0.4410
Epoch: 21, Loss: 1.0867, Train: 0.4833, Val: 0.4840, Test: 0.4710
Epoch: 22, Loss: 1.0731, Train: 0.5667, Val: 0.5120, Test: 0.5000
Epoch: 23, Loss: 1.0864, Train: 0.6167, Val: 0.5340, Test: 0.5170
Epoch: 24, Loss: 1.0481, Train: 0.6167, Val: 0.5460, Test: 0.5290
Epoch: 25, Loss: 1.0647, Train: 0.6333, Val: 0.5520, Test: 0.5270
Epoch: 26, Loss: 1.0341, Train: 0.6333, Val: 0.5500, Test: 0.5240
Epoch: 27, Loss: 1.0319, Train: 0.6333, Val: 0.5480, Test: 0.5260
Epoch: 28, Loss: 1.0191, Train: 0.6333, Val: 0.5480, Test: 0.5290
Epoch: 29, Loss: 1.0173, Train: 0.6333, Val: 0.5440, Test: 0.5350
Epoch: 30, Loss: 1.0023, Train: 0.6667, Val: 0.5620, Test: 0.5430
Epoch: 31, Loss: 0.9672, Train: 0.7833, Val: 0.6000, Test: 0.5720
Epoch: 32, Loss: 0.9751, Train: 0.9333, Val: 0.7340, Test: 0.6750
Epoch: 33, Loss: 0.9767, Train: 0.9167, Val: 0.7480, Test: 0.7180
Epoch: 34, Loss: 0.8711, Train: 0.9500, Val: 0.7400, Test: 0.6890
Epoch: 35, Loss: 0.8475, Train: 0.9500, Val: 0.7320, Test: 0.6810
Epoch: 36, Loss: 0.7910, Train: 0.9167, Val: 0.6840, Test: 0.6620
Epoch: 37, Loss: 0.7972, Train: 0.8833, Val: 0.6460, Test: 0.6380
Epoch: 38, Loss: 0.7757, Train: 0.7833, Val: 0.6320, Test: 0.6030
Epoch: 39, Loss: 0.7450, Train: 0.8000, Val: 0.6200, Test: 0.5810
Epoch: 40, Loss: 0.7121, Train: 0.8000, Val: 0.6220, Test: 0.5790
Epoch: 41, Loss: 0.6763, Train: 0.8167, Val: 0.6300, Test: 0.5890
Epoch: 42, Loss: 0.6545, Train: 0.9167, Val: 0.6600, Test: 0.6570
Epoch: 43, Loss: 0.6013, Train: 0.9333, Val: 0.7360, Test: 0.6820
Epoch: 44, Loss: 0.6055, Train: 0.9667, Val: 0.7380, Test: 0.6910
Epoch: 45, Loss: 0.5614, Train: 0.9500, Val: 0.7420, Test: 0.6940
Epoch: 46, Loss: 0.5385, Train: 0.9500, Val: 0.7740, Test: 0.7290
Epoch: 47, Loss: 0.5445, Train: 0.9333, Val: 0.7620, Test: 0.7450
Epoch: 48, Loss: 0.4160, Train: 0.9500, Val: 0.7540, Test: 0.7430
Epoch: 49, Loss: 0.3739, Train: 0.9667, Val: 0.7740, Test: 0.7450
Epoch: 50, Loss: 0.3784, Train: 0.9667, Val: 0.7760, Test: 0.7430
Epoch: 51, Loss: 0.4006, Train: 0.9667, Val: 0.7780, Test: 0.7530
Epoch: 52, Loss: 0.3122, Train: 0.9667, Val: 0.7820, Test: 0.7570
Epoch: 53, Loss: 0.3572, Train: 0.9667, Val: 0.7860, Test: 0.7610
Epoch: 54, Loss: 0.2865, Train: 0.9667, Val: 0.7780, Test: 0.7640
Epoch: 55, Loss: 0.2247, Train: 0.9833, Val: 0.7940, Test: 0.7710
Epoch: 56, Loss: 0.2330, Train: 0.9833, Val: 0.7920, Test: 0.7780
Epoch: 57, Loss: 0.1887, Train: 0.9833, Val: 0.7920, Test: 0.7760
Epoch: 58, Loss: 0.1528, Train: 1.0000, Val: 0.7820, Test: 0.7700
Epoch: 59, Loss: 0.1093, Train: 1.0000, Val: 0.7780, Test: 0.7640
Epoch: 60, Loss: 0.1311, Train: 1.0000, Val: 0.7720, Test: 0.7540
Epoch: 61, Loss: 0.1326, Train: 1.0000, Val: 0.7740, Test: 0.7560
Epoch: 62, Loss: 0.0869, Train: 1.0000, Val: 0.7780, Test: 0.7590
Epoch: 63, Loss: 0.0768, Train: 1.0000, Val: 0.7780, Test: 0.7550
Epoch: 64, Loss: 0.0738, Train: 1.0000, Val: 0.7740, Test: 0.7640
Epoch: 65, Loss: 0.0440, Train: 1.0000, Val: 0.7820, Test: 0.7600
Epoch: 66, Loss: 0.0331, Train: 1.0000, Val: 0.7720, Test: 0.7540
Epoch: 67, Loss: 0.0265, Train: 1.0000, Val: 0.7620, Test: 0.7450
Epoch: 68, Loss: 0.0249, Train: 1.0000, Val: 0.7580, Test: 0.7420
Epoch: 69, Loss: 0.0402, Train: 1.0000, Val: 0.7560, Test: 0.7560
Epoch: 70, Loss: 0.0192, Train: 1.0000, Val: 0.7660, Test: 0.7650
Epoch: 71, Loss: 0.0291, Train: 1.0000, Val: 0.7760, Test: 0.7650
Epoch: 72, Loss: 0.0164, Train: 1.0000, Val: 0.7800, Test: 0.7720
Epoch: 73, Loss: 0.0147, Train: 0.9833, Val: 0.7740, Test: 0.7620
Epoch: 74, Loss: 0.0195, Train: 0.9833, Val: 0.7700, Test: 0.7650
Epoch: 75, Loss: 0.1340, Train: 0.9833, Val: 0.7780, Test: 0.7730
Epoch: 76, Loss: 0.0965, Train: 1.0000, Val: 0.7700, Test: 0.7550
Epoch: 77, Loss: 0.0381, Train: 0.9667, Val: 0.7140, Test: 0.6870
Epoch: 78, Loss: 0.1244, Train: 0.9833, Val: 0.7260, Test: 0.7220
Epoch: 79, Loss: 0.0586, Train: 1.0000, Val: 0.7600, Test: 0.7540
Epoch: 80, Loss: 0.0067, Train: 1.0000, Val: 0.7740, Test: 0.7670
Epoch: 81, Loss: 0.0073, Train: 1.0000, Val: 0.7600, Test: 0.7580
Epoch: 82, Loss: 0.0078, Train: 0.9833, Val: 0.7380, Test: 0.7500
Epoch: 83, Loss: 0.0483, Train: 1.0000, Val: 0.7340, Test: 0.7300
Epoch: 84, Loss: 0.0145, Train: 1.0000, Val: 0.7260, Test: 0.7140
Epoch: 85, Loss: 0.0209, Train: 1.0000, Val: 0.7340, Test: 0.7150
Epoch: 86, Loss: 0.0453, Train: 1.0000, Val: 0.7580, Test: 0.7500
Epoch: 87, Loss: 0.0201, Train: 1.0000, Val: 0.7600, Test: 0.7500
Epoch: 88, Loss: 0.0078, Train: 1.0000, Val: 0.7480, Test: 0.7450
Epoch: 89, Loss: 0.0077, Train: 1.0000, Val: 0.7480, Test: 0.7330
Epoch: 90, Loss: 0.0246, Train: 1.0000, Val: 0.7400, Test: 0.7290
Epoch: 91, Loss: 0.0064, Train: 1.0000, Val: 0.7340, Test: 0.7220
Epoch: 92, Loss: 0.0395, Train: 1.0000, Val: 0.7420, Test: 0.7280
Epoch: 93, Loss: 0.0127, Train: 1.0000, Val: 0.7500, Test: 0.7400
Epoch: 94, Loss: 0.0240, Train: 1.0000, Val: 0.7540, Test: 0.7460
Epoch: 95, Loss: 0.0164, Train: 1.0000, Val: 0.7620, Test: 0.7580
Epoch: 96, Loss: 0.0047, Train: 1.0000, Val: 0.7720, Test: 0.7560
Epoch: 97, Loss: 0.0075, Train: 1.0000, Val: 0.7320, Test: 0.7430
Epoch: 98, Loss: 0.0137, Train: 1.0000, Val: 0.7380, Test: 0.7280
Epoch: 99, Loss: 0.0111, Train: 1.0000, Val: 0.7380, Test: 0.7330
Epoch: 100, Loss: 0.0072, Train: 1.0000, Val: 0.7540, Test: 0.7420
MAD:  0.4318
Best Test Accuracy: 0.7780, Val Accuracy: 0.7920, Train Accuracy: 0.9833
Training completed.
Seed:  6
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1492, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 2, Loss: 1.0915, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 3, Loss: 1.1450, Train: 0.3500, Val: 0.3600, Test: 0.3470
Epoch: 4, Loss: 1.1085, Train: 0.3333, Val: 0.3880, Test: 0.4140
Epoch: 5, Loss: 1.1134, Train: 0.3333, Val: 0.3880, Test: 0.4140
Epoch: 6, Loss: 1.1112, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 7, Loss: 1.1229, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 8, Loss: 1.1223, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 9, Loss: 1.1235, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 10, Loss: 1.1046, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 11, Loss: 1.0701, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 12, Loss: 1.1131, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 13, Loss: 1.1177, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 14, Loss: 1.1554, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 15, Loss: 1.0802, Train: 0.3333, Val: 0.3900, Test: 0.4130
Epoch: 16, Loss: 1.1248, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 17, Loss: 1.0417, Train: 0.3667, Val: 0.4140, Test: 0.4350
Epoch: 18, Loss: 1.1162, Train: 0.4833, Val: 0.5300, Test: 0.5520
Epoch: 19, Loss: 1.1506, Train: 0.5500, Val: 0.5640, Test: 0.5720
Epoch: 20, Loss: 1.0715, Train: 0.5667, Val: 0.5480, Test: 0.5550
Epoch: 21, Loss: 1.0864, Train: 0.5500, Val: 0.5180, Test: 0.5380
Epoch: 22, Loss: 1.0748, Train: 0.5667, Val: 0.5100, Test: 0.5230
Epoch: 23, Loss: 1.0745, Train: 0.5667, Val: 0.4640, Test: 0.5070
Epoch: 24, Loss: 1.0797, Train: 0.5167, Val: 0.4580, Test: 0.4920
Epoch: 25, Loss: 1.0454, Train: 0.5333, Val: 0.4620, Test: 0.4870
Epoch: 26, Loss: 1.0608, Train: 0.5500, Val: 0.4640, Test: 0.4910
Epoch: 27, Loss: 1.0557, Train: 0.7333, Val: 0.5340, Test: 0.5730
Epoch: 28, Loss: 1.0383, Train: 0.8333, Val: 0.6100, Test: 0.6210
Epoch: 29, Loss: 1.0013, Train: 0.8167, Val: 0.6480, Test: 0.6320
Epoch: 30, Loss: 0.9937, Train: 0.8500, Val: 0.6700, Test: 0.6420
Epoch: 31, Loss: 1.0170, Train: 0.8500, Val: 0.6700, Test: 0.6380
Epoch: 32, Loss: 0.9513, Train: 0.8500, Val: 0.6660, Test: 0.6230
Epoch: 33, Loss: 0.9431, Train: 0.8333, Val: 0.6400, Test: 0.6020
Epoch: 34, Loss: 0.8595, Train: 0.7833, Val: 0.6060, Test: 0.5730
Epoch: 35, Loss: 0.8520, Train: 0.7333, Val: 0.5980, Test: 0.5490
Epoch: 36, Loss: 0.8149, Train: 0.7500, Val: 0.5860, Test: 0.5560
Epoch: 37, Loss: 0.7367, Train: 0.7500, Val: 0.6020, Test: 0.5690
Epoch: 38, Loss: 0.7471, Train: 0.7500, Val: 0.6120, Test: 0.5720
Epoch: 39, Loss: 0.7242, Train: 0.7500, Val: 0.6080, Test: 0.5750
Epoch: 40, Loss: 0.6537, Train: 0.7333, Val: 0.5980, Test: 0.5490
Epoch: 41, Loss: 0.6653, Train: 0.7833, Val: 0.6020, Test: 0.5620
Epoch: 42, Loss: 0.6548, Train: 0.8333, Val: 0.6400, Test: 0.6260
Epoch: 43, Loss: 0.6146, Train: 0.8500, Val: 0.6540, Test: 0.6280
Epoch: 44, Loss: 0.5965, Train: 0.8667, Val: 0.6800, Test: 0.6460
Epoch: 45, Loss: 0.6031, Train: 0.9167, Val: 0.7000, Test: 0.6610
Epoch: 46, Loss: 0.5666, Train: 0.9167, Val: 0.7100, Test: 0.6610
Epoch: 47, Loss: 0.5378, Train: 0.9333, Val: 0.6960, Test: 0.6670
Epoch: 48, Loss: 0.5021, Train: 0.9500, Val: 0.7080, Test: 0.6680
Epoch: 49, Loss: 0.4808, Train: 0.9500, Val: 0.7380, Test: 0.6840
Epoch: 50, Loss: 0.4705, Train: 0.9667, Val: 0.7480, Test: 0.7030
Epoch: 51, Loss: 0.4282, Train: 0.9333, Val: 0.7760, Test: 0.7130
Epoch: 52, Loss: 0.3738, Train: 0.9333, Val: 0.7700, Test: 0.7160
Epoch: 53, Loss: 0.3714, Train: 0.9667, Val: 0.7540, Test: 0.7080
Epoch: 54, Loss: 0.3630, Train: 0.9667, Val: 0.7400, Test: 0.6980
Epoch: 55, Loss: 0.2458, Train: 0.9500, Val: 0.7260, Test: 0.6840
Epoch: 56, Loss: 0.3098, Train: 0.9667, Val: 0.7420, Test: 0.6920
Epoch: 57, Loss: 0.2209, Train: 0.9833, Val: 0.7380, Test: 0.7100
Epoch: 58, Loss: 0.2483, Train: 1.0000, Val: 0.7600, Test: 0.7450
Epoch: 59, Loss: 0.1745, Train: 1.0000, Val: 0.7840, Test: 0.7580
Epoch: 60, Loss: 0.1492, Train: 1.0000, Val: 0.7880, Test: 0.7680
Epoch: 61, Loss: 0.1584, Train: 1.0000, Val: 0.7820, Test: 0.7630
Epoch: 62, Loss: 0.1561, Train: 1.0000, Val: 0.7680, Test: 0.7370
Epoch: 63, Loss: 0.1204, Train: 1.0000, Val: 0.7460, Test: 0.7130
Epoch: 64, Loss: 0.0886, Train: 1.0000, Val: 0.7420, Test: 0.7040
Epoch: 65, Loss: 0.0698, Train: 1.0000, Val: 0.7400, Test: 0.7070
Epoch: 66, Loss: 0.0555, Train: 1.0000, Val: 0.7580, Test: 0.7240
Epoch: 67, Loss: 0.0663, Train: 1.0000, Val: 0.7640, Test: 0.7510
Epoch: 68, Loss: 0.0340, Train: 1.0000, Val: 0.7800, Test: 0.7630
Epoch: 69, Loss: 0.0572, Train: 1.0000, Val: 0.7860, Test: 0.7700
Epoch: 70, Loss: 0.0407, Train: 1.0000, Val: 0.7820, Test: 0.7800
Epoch: 71, Loss: 0.0319, Train: 1.0000, Val: 0.7760, Test: 0.7720
Epoch: 72, Loss: 0.0265, Train: 1.0000, Val: 0.7720, Test: 0.7650
Epoch: 73, Loss: 0.0375, Train: 1.0000, Val: 0.7720, Test: 0.7660
Epoch: 74, Loss: 0.0161, Train: 1.0000, Val: 0.7600, Test: 0.7480
Epoch: 75, Loss: 0.0198, Train: 0.9833, Val: 0.7620, Test: 0.7410
Epoch: 76, Loss: 0.0249, Train: 0.9833, Val: 0.7500, Test: 0.7330
Epoch: 77, Loss: 0.0724, Train: 1.0000, Val: 0.7640, Test: 0.7420
Epoch: 78, Loss: 0.0113, Train: 1.0000, Val: 0.7380, Test: 0.7180
Epoch: 79, Loss: 0.0249, Train: 0.9833, Val: 0.7420, Test: 0.7010
Epoch: 80, Loss: 0.0918, Train: 1.0000, Val: 0.7760, Test: 0.7480
Epoch: 81, Loss: 0.0392, Train: 1.0000, Val: 0.7720, Test: 0.7730
Epoch: 82, Loss: 0.0098, Train: 1.0000, Val: 0.7660, Test: 0.7600
Epoch: 83, Loss: 0.0091, Train: 0.9667, Val: 0.7560, Test: 0.7320
Epoch: 84, Loss: 0.0218, Train: 0.9667, Val: 0.7440, Test: 0.7150
Epoch: 85, Loss: 0.2112, Train: 0.9833, Val: 0.7700, Test: 0.7490
Epoch: 86, Loss: 0.0323, Train: 1.0000, Val: 0.7720, Test: 0.7570
Epoch: 87, Loss: 0.0142, Train: 1.0000, Val: 0.7160, Test: 0.6880
Epoch: 88, Loss: 0.1023, Train: 1.0000, Val: 0.7400, Test: 0.7100
Epoch: 89, Loss: 0.0152, Train: 1.0000, Val: 0.7780, Test: 0.7390
Epoch: 90, Loss: 0.0221, Train: 1.0000, Val: 0.7740, Test: 0.7640
Epoch: 91, Loss: 0.0136, Train: 1.0000, Val: 0.7640, Test: 0.7730
Epoch: 92, Loss: 0.0515, Train: 1.0000, Val: 0.7880, Test: 0.7640
Epoch: 93, Loss: 0.0089, Train: 1.0000, Val: 0.7680, Test: 0.7540
Epoch: 94, Loss: 0.0047, Train: 1.0000, Val: 0.7580, Test: 0.7500
Epoch: 95, Loss: 0.0051, Train: 0.9833, Val: 0.7440, Test: 0.7320
Epoch: 96, Loss: 0.0886, Train: 1.0000, Val: 0.7480, Test: 0.7290
Epoch: 97, Loss: 0.0457, Train: 1.0000, Val: 0.7540, Test: 0.7390
Epoch: 98, Loss: 0.0061, Train: 1.0000, Val: 0.7540, Test: 0.7460
Epoch: 99, Loss: 0.0058, Train: 1.0000, Val: 0.7520, Test: 0.7510
Epoch: 100, Loss: 0.0073, Train: 1.0000, Val: 0.7560, Test: 0.7550
MAD:  0.4931
Best Test Accuracy: 0.7800, Val Accuracy: 0.7820, Train Accuracy: 1.0000
Training completed.
Seed:  7
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1262, Train: 0.3333, Val: 0.3880, Test: 0.4130
Epoch: 2, Loss: 1.0819, Train: 0.5333, Val: 0.5000, Test: 0.4710
Epoch: 3, Loss: 1.1179, Train: 0.3333, Val: 0.1980, Test: 0.1800
Epoch: 4, Loss: 1.0985, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 5, Loss: 1.0852, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 6, Loss: 1.1487, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 7, Loss: 1.1051, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 8, Loss: 1.1144, Train: 0.3333, Val: 0.1960, Test: 0.1800
Epoch: 9, Loss: 1.1069, Train: 0.3333, Val: 0.2040, Test: 0.1820
Epoch: 10, Loss: 1.0918, Train: 0.4000, Val: 0.2480, Test: 0.2270
Epoch: 11, Loss: 1.0809, Train: 0.5000, Val: 0.4380, Test: 0.4320
Epoch: 12, Loss: 1.1047, Train: 0.6167, Val: 0.4880, Test: 0.4860
Epoch: 13, Loss: 1.0613, Train: 0.6167, Val: 0.5180, Test: 0.5050
Epoch: 14, Loss: 1.0829, Train: 0.5667, Val: 0.4580, Test: 0.4750
Epoch: 15, Loss: 1.0895, Train: 0.4167, Val: 0.4100, Test: 0.4330
Epoch: 16, Loss: 1.0956, Train: 0.4167, Val: 0.3980, Test: 0.4260
Epoch: 17, Loss: 1.0776, Train: 0.4167, Val: 0.3980, Test: 0.4180
Epoch: 18, Loss: 1.1323, Train: 0.4000, Val: 0.3960, Test: 0.4180
Epoch: 19, Loss: 1.0536, Train: 0.4500, Val: 0.4080, Test: 0.4400
Epoch: 20, Loss: 1.0892, Train: 0.6667, Val: 0.5060, Test: 0.5340
Epoch: 21, Loss: 1.0853, Train: 0.7667, Val: 0.6240, Test: 0.6340
Epoch: 22, Loss: 1.0715, Train: 0.8167, Val: 0.6860, Test: 0.6720
Epoch: 23, Loss: 1.0318, Train: 0.7500, Val: 0.6560, Test: 0.6340
Epoch: 24, Loss: 1.0489, Train: 0.7167, Val: 0.6220, Test: 0.5800
Epoch: 25, Loss: 1.0489, Train: 0.7167, Val: 0.5720, Test: 0.5330
Epoch: 26, Loss: 1.0088, Train: 0.6833, Val: 0.5500, Test: 0.5110
Epoch: 27, Loss: 0.9664, Train: 0.6500, Val: 0.5460, Test: 0.5080
Epoch: 28, Loss: 1.0258, Train: 0.6500, Val: 0.5260, Test: 0.5140
Epoch: 29, Loss: 0.9950, Train: 0.6667, Val: 0.5260, Test: 0.5230
Epoch: 30, Loss: 0.9432, Train: 0.7000, Val: 0.5600, Test: 0.5580
Epoch: 31, Loss: 0.9550, Train: 0.7833, Val: 0.6300, Test: 0.5980
Epoch: 32, Loss: 0.9177, Train: 0.8333, Val: 0.6500, Test: 0.6120
Epoch: 33, Loss: 0.9167, Train: 0.8167, Val: 0.6600, Test: 0.6210
Epoch: 34, Loss: 0.8079, Train: 0.8667, Val: 0.6580, Test: 0.6270
Epoch: 35, Loss: 0.8473, Train: 0.8667, Val: 0.6600, Test: 0.6250
Epoch: 36, Loss: 0.7354, Train: 0.8500, Val: 0.6340, Test: 0.6140
Epoch: 37, Loss: 0.8090, Train: 0.8500, Val: 0.6220, Test: 0.6110
Epoch: 38, Loss: 0.8029, Train: 0.8500, Val: 0.6220, Test: 0.6180
Epoch: 39, Loss: 0.7192, Train: 0.8667, Val: 0.6420, Test: 0.6300
Epoch: 40, Loss: 0.6913, Train: 0.8667, Val: 0.6680, Test: 0.6480
Epoch: 41, Loss: 0.7081, Train: 0.8833, Val: 0.6900, Test: 0.6550
Epoch: 42, Loss: 0.6151, Train: 0.9167, Val: 0.7000, Test: 0.6570
Epoch: 43, Loss: 0.5687, Train: 0.9167, Val: 0.7240, Test: 0.6700
Epoch: 44, Loss: 0.5515, Train: 0.9333, Val: 0.7300, Test: 0.6800
Epoch: 45, Loss: 0.5099, Train: 0.9333, Val: 0.7380, Test: 0.6910
Epoch: 46, Loss: 0.4275, Train: 0.9500, Val: 0.7520, Test: 0.6930
Epoch: 47, Loss: 0.4677, Train: 0.9500, Val: 0.7620, Test: 0.6970
Epoch: 48, Loss: 0.4352, Train: 0.9500, Val: 0.7460, Test: 0.7020
Epoch: 49, Loss: 0.3849, Train: 0.9667, Val: 0.7600, Test: 0.7120
Epoch: 50, Loss: 0.4213, Train: 0.9333, Val: 0.7760, Test: 0.7170
Epoch: 51, Loss: 0.3640, Train: 0.9333, Val: 0.7740, Test: 0.7270
Epoch: 52, Loss: 0.3155, Train: 0.9333, Val: 0.7800, Test: 0.7270
Epoch: 53, Loss: 0.2777, Train: 0.9667, Val: 0.7600, Test: 0.7320
Epoch: 54, Loss: 0.2037, Train: 0.9667, Val: 0.7380, Test: 0.7340
Epoch: 55, Loss: 0.1921, Train: 0.9833, Val: 0.7520, Test: 0.7400
Epoch: 56, Loss: 0.1851, Train: 0.9667, Val: 0.7720, Test: 0.7530
Epoch: 57, Loss: 0.1463, Train: 0.9667, Val: 0.7880, Test: 0.7620
Epoch: 58, Loss: 0.1702, Train: 0.9833, Val: 0.7700, Test: 0.7510
Epoch: 59, Loss: 0.1271, Train: 0.9667, Val: 0.7660, Test: 0.7540
Epoch: 60, Loss: 0.0787, Train: 0.9833, Val: 0.7620, Test: 0.7490
Epoch: 61, Loss: 0.0749, Train: 0.9833, Val: 0.7680, Test: 0.7530
Epoch: 62, Loss: 0.0992, Train: 1.0000, Val: 0.7740, Test: 0.7610
Epoch: 63, Loss: 0.0560, Train: 0.9833, Val: 0.7660, Test: 0.7530
Epoch: 64, Loss: 0.0519, Train: 0.9833, Val: 0.7660, Test: 0.7480
Epoch: 65, Loss: 0.1502, Train: 1.0000, Val: 0.7680, Test: 0.7530
Epoch: 66, Loss: 0.0501, Train: 0.9833, Val: 0.7480, Test: 0.7080
Epoch: 67, Loss: 0.1123, Train: 0.9833, Val: 0.7460, Test: 0.7180
Epoch: 68, Loss: 0.1667, Train: 0.9833, Val: 0.7560, Test: 0.7330
Epoch: 69, Loss: 0.0625, Train: 0.9833, Val: 0.7700, Test: 0.7470
Epoch: 70, Loss: 0.0621, Train: 1.0000, Val: 0.7620, Test: 0.7510
Epoch: 71, Loss: 0.0574, Train: 1.0000, Val: 0.7560, Test: 0.7390
Epoch: 72, Loss: 0.0656, Train: 0.9833, Val: 0.7620, Test: 0.7500
Epoch: 73, Loss: 0.0447, Train: 1.0000, Val: 0.7680, Test: 0.7540
Epoch: 74, Loss: 0.0153, Train: 1.0000, Val: 0.7620, Test: 0.7580
Epoch: 75, Loss: 0.0297, Train: 1.0000, Val: 0.7540, Test: 0.7610
Epoch: 76, Loss: 0.0098, Train: 1.0000, Val: 0.7660, Test: 0.7650
Epoch: 77, Loss: 0.0226, Train: 1.0000, Val: 0.7660, Test: 0.7690
Epoch: 78, Loss: 0.0100, Train: 1.0000, Val: 0.7640, Test: 0.7700
Epoch: 79, Loss: 0.0152, Train: 1.0000, Val: 0.7720, Test: 0.7670
Epoch: 80, Loss: 0.0099, Train: 1.0000, Val: 0.7780, Test: 0.7640
Epoch: 81, Loss: 0.0100, Train: 1.0000, Val: 0.7640, Test: 0.7580
Epoch: 82, Loss: 0.0139, Train: 1.0000, Val: 0.7600, Test: 0.7430
Epoch: 83, Loss: 0.0076, Train: 1.0000, Val: 0.7500, Test: 0.7300
Epoch: 84, Loss: 0.0103, Train: 1.0000, Val: 0.7400, Test: 0.7180
Epoch: 85, Loss: 0.0069, Train: 1.0000, Val: 0.7300, Test: 0.6980
Epoch: 86, Loss: 0.0092, Train: 1.0000, Val: 0.7160, Test: 0.6830
Epoch: 87, Loss: 0.0626, Train: 1.0000, Val: 0.7540, Test: 0.7360
Epoch: 88, Loss: 0.0076, Train: 1.0000, Val: 0.7540, Test: 0.7560
Epoch: 89, Loss: 0.0253, Train: 1.0000, Val: 0.7660, Test: 0.7570
Epoch: 90, Loss: 0.0067, Train: 1.0000, Val: 0.7620, Test: 0.7540
Epoch: 91, Loss: 0.0094, Train: 1.0000, Val: 0.7700, Test: 0.7550
Epoch: 92, Loss: 0.0225, Train: 1.0000, Val: 0.7680, Test: 0.7620
Epoch: 93, Loss: 0.0059, Train: 1.0000, Val: 0.7740, Test: 0.7750
Epoch: 94, Loss: 0.0293, Train: 1.0000, Val: 0.7740, Test: 0.7770
Epoch: 95, Loss: 0.0038, Train: 1.0000, Val: 0.7760, Test: 0.7790
Epoch: 96, Loss: 0.0039, Train: 1.0000, Val: 0.7800, Test: 0.7790
Epoch: 97, Loss: 0.0108, Train: 1.0000, Val: 0.7760, Test: 0.7660
Epoch: 98, Loss: 0.0068, Train: 1.0000, Val: 0.7680, Test: 0.7620
Epoch: 99, Loss: 0.0030, Train: 1.0000, Val: 0.7600, Test: 0.7500
Epoch: 100, Loss: 0.0056, Train: 1.0000, Val: 0.7520, Test: 0.7430
MAD:  0.5281
Best Test Accuracy: 0.7790, Val Accuracy: 0.7760, Train Accuracy: 1.0000
Training completed.
Seed:  8
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1481, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 2, Loss: 1.1110, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 3, Loss: 1.1128, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 4, Loss: 1.0817, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.1158, Train: 0.3500, Val: 0.4240, Test: 0.4080
Epoch: 6, Loss: 1.1132, Train: 0.3833, Val: 0.4460, Test: 0.4230
Epoch: 7, Loss: 1.1108, Train: 0.4333, Val: 0.4600, Test: 0.4410
Epoch: 8, Loss: 1.0717, Train: 0.4667, Val: 0.4600, Test: 0.4460
Epoch: 9, Loss: 1.1067, Train: 0.5333, Val: 0.4720, Test: 0.4680
Epoch: 10, Loss: 1.1228, Train: 0.6333, Val: 0.5380, Test: 0.5030
Epoch: 11, Loss: 1.1254, Train: 0.4500, Val: 0.3640, Test: 0.3310
Epoch: 12, Loss: 1.1263, Train: 0.4333, Val: 0.2520, Test: 0.2210
Epoch: 13, Loss: 1.1047, Train: 0.3500, Val: 0.2080, Test: 0.1890
Epoch: 14, Loss: 1.1308, Train: 0.3667, Val: 0.2080, Test: 0.1890
Epoch: 15, Loss: 1.1147, Train: 0.3500, Val: 0.2020, Test: 0.1840
Epoch: 16, Loss: 1.1224, Train: 0.3500, Val: 0.2020, Test: 0.1850
Epoch: 17, Loss: 1.0558, Train: 0.4333, Val: 0.2540, Test: 0.2230
Epoch: 18, Loss: 1.0772, Train: 0.4833, Val: 0.3500, Test: 0.3180
Epoch: 19, Loss: 1.0798, Train: 0.6000, Val: 0.4280, Test: 0.4170
Epoch: 20, Loss: 1.0851, Train: 0.6333, Val: 0.4900, Test: 0.4670
Epoch: 21, Loss: 1.0652, Train: 0.6500, Val: 0.5200, Test: 0.4900
Epoch: 22, Loss: 1.0651, Train: 0.6500, Val: 0.5360, Test: 0.5180
Epoch: 23, Loss: 1.0467, Train: 0.6333, Val: 0.5400, Test: 0.5200
Epoch: 24, Loss: 1.0686, Train: 0.6667, Val: 0.5380, Test: 0.5180
Epoch: 25, Loss: 1.0737, Train: 0.6667, Val: 0.5580, Test: 0.5420
Epoch: 26, Loss: 0.9910, Train: 0.7167, Val: 0.5600, Test: 0.5350
Epoch: 27, Loss: 0.9858, Train: 0.6500, Val: 0.5360, Test: 0.5340
Epoch: 28, Loss: 1.0152, Train: 0.6500, Val: 0.5440, Test: 0.5310
Epoch: 29, Loss: 0.9505, Train: 0.6333, Val: 0.5460, Test: 0.5330
Epoch: 30, Loss: 0.9389, Train: 0.6500, Val: 0.5540, Test: 0.5310
Epoch: 31, Loss: 0.9511, Train: 0.6667, Val: 0.5600, Test: 0.5340
Epoch: 32, Loss: 0.8922, Train: 0.7000, Val: 0.5640, Test: 0.5300
Epoch: 33, Loss: 0.8097, Train: 0.6833, Val: 0.5680, Test: 0.5310
Epoch: 34, Loss: 0.8521, Train: 0.6833, Val: 0.5680, Test: 0.5310
Epoch: 35, Loss: 0.7752, Train: 0.7167, Val: 0.5800, Test: 0.5350
Epoch: 36, Loss: 0.7837, Train: 0.7667, Val: 0.5880, Test: 0.5690
Epoch: 37, Loss: 0.6838, Train: 0.7667, Val: 0.5920, Test: 0.5750
Epoch: 38, Loss: 0.7006, Train: 0.7833, Val: 0.5880, Test: 0.5830
Epoch: 39, Loss: 0.6257, Train: 0.8167, Val: 0.5920, Test: 0.5910
Epoch: 40, Loss: 0.6261, Train: 0.8167, Val: 0.6100, Test: 0.6070
Epoch: 41, Loss: 0.6159, Train: 0.8500, Val: 0.6440, Test: 0.6140
Epoch: 42, Loss: 0.6340, Train: 0.9000, Val: 0.6620, Test: 0.6360
Epoch: 43, Loss: 0.6430, Train: 0.9000, Val: 0.6900, Test: 0.6420
Epoch: 44, Loss: 0.5795, Train: 0.9167, Val: 0.7200, Test: 0.6620
Epoch: 45, Loss: 0.4503, Train: 0.9167, Val: 0.7360, Test: 0.6740
Epoch: 46, Loss: 0.4191, Train: 0.9500, Val: 0.7240, Test: 0.6760
Epoch: 47, Loss: 0.4037, Train: 0.9500, Val: 0.7140, Test: 0.6860
Epoch: 48, Loss: 0.4680, Train: 0.9500, Val: 0.7380, Test: 0.6990
Epoch: 49, Loss: 0.3875, Train: 0.9667, Val: 0.7760, Test: 0.7200
Epoch: 50, Loss: 0.3628, Train: 0.9500, Val: 0.7820, Test: 0.7350
Epoch: 51, Loss: 0.3151, Train: 0.9667, Val: 0.7680, Test: 0.7350
Epoch: 52, Loss: 0.2910, Train: 0.9667, Val: 0.7480, Test: 0.7150
Epoch: 53, Loss: 0.2452, Train: 0.9667, Val: 0.7320, Test: 0.6980
Epoch: 54, Loss: 0.2268, Train: 0.9833, Val: 0.7440, Test: 0.7070
Epoch: 55, Loss: 0.2200, Train: 0.9667, Val: 0.7380, Test: 0.7010
Epoch: 56, Loss: 0.1624, Train: 0.9833, Val: 0.7440, Test: 0.7250
Epoch: 57, Loss: 0.1519, Train: 0.9833, Val: 0.7760, Test: 0.7600
Epoch: 58, Loss: 0.1038, Train: 0.9833, Val: 0.7720, Test: 0.7540
Epoch: 59, Loss: 0.1666, Train: 0.9667, Val: 0.7600, Test: 0.7440
Epoch: 60, Loss: 0.1987, Train: 1.0000, Val: 0.7780, Test: 0.7720
Epoch: 61, Loss: 0.0800, Train: 0.9833, Val: 0.7820, Test: 0.7590
Epoch: 62, Loss: 0.0887, Train: 0.9833, Val: 0.7580, Test: 0.7360
Epoch: 63, Loss: 0.1275, Train: 0.9833, Val: 0.7480, Test: 0.7260
Epoch: 64, Loss: 0.0834, Train: 1.0000, Val: 0.7600, Test: 0.7250
Epoch: 65, Loss: 0.0560, Train: 1.0000, Val: 0.7540, Test: 0.7320
Epoch: 66, Loss: 0.0380, Train: 0.9667, Val: 0.7440, Test: 0.7100
Epoch: 67, Loss: 0.0584, Train: 0.9833, Val: 0.7440, Test: 0.7220
Epoch: 68, Loss: 0.0800, Train: 0.9833, Val: 0.7580, Test: 0.7260
Epoch: 69, Loss: 0.0667, Train: 1.0000, Val: 0.7640, Test: 0.7470
Epoch: 70, Loss: 0.0570, Train: 1.0000, Val: 0.7600, Test: 0.7490
Epoch: 71, Loss: 0.0266, Train: 0.9833, Val: 0.7600, Test: 0.7460
Epoch: 72, Loss: 0.0714, Train: 1.0000, Val: 0.7560, Test: 0.7240
Epoch: 73, Loss: 0.0335, Train: 1.0000, Val: 0.7320, Test: 0.7060
Epoch: 74, Loss: 0.0378, Train: 1.0000, Val: 0.7380, Test: 0.7070
Epoch: 75, Loss: 0.0300, Train: 1.0000, Val: 0.7640, Test: 0.7300
Epoch: 76, Loss: 0.0997, Train: 1.0000, Val: 0.7680, Test: 0.7550
Epoch: 77, Loss: 0.0142, Train: 1.0000, Val: 0.7660, Test: 0.7410
Epoch: 78, Loss: 0.0692, Train: 0.9833, Val: 0.7580, Test: 0.7270
Epoch: 79, Loss: 0.0182, Train: 0.9833, Val: 0.7560, Test: 0.7250
Epoch: 80, Loss: 0.0352, Train: 1.0000, Val: 0.7620, Test: 0.7340
Epoch: 81, Loss: 0.0184, Train: 1.0000, Val: 0.7660, Test: 0.7330
Epoch: 82, Loss: 0.0095, Train: 1.0000, Val: 0.7560, Test: 0.7370
Epoch: 83, Loss: 0.0071, Train: 1.0000, Val: 0.7600, Test: 0.7360
Epoch: 84, Loss: 0.0239, Train: 1.0000, Val: 0.7600, Test: 0.7420
Epoch: 85, Loss: 0.0108, Train: 1.0000, Val: 0.7620, Test: 0.7290
Epoch: 86, Loss: 0.0057, Train: 1.0000, Val: 0.7500, Test: 0.7170
Epoch: 87, Loss: 0.0349, Train: 1.0000, Val: 0.7480, Test: 0.7230
Epoch: 88, Loss: 0.0056, Train: 1.0000, Val: 0.7540, Test: 0.7230
Epoch: 89, Loss: 0.0081, Train: 1.0000, Val: 0.7720, Test: 0.7310
Epoch: 90, Loss: 0.0073, Train: 1.0000, Val: 0.7720, Test: 0.7330
Epoch: 91, Loss: 0.0057, Train: 1.0000, Val: 0.7660, Test: 0.7320
Epoch: 92, Loss: 0.0058, Train: 1.0000, Val: 0.7680, Test: 0.7410
Epoch: 93, Loss: 0.0111, Train: 1.0000, Val: 0.7640, Test: 0.7410
Epoch: 94, Loss: 0.0066, Train: 1.0000, Val: 0.7560, Test: 0.7390
Epoch: 95, Loss: 0.0067, Train: 1.0000, Val: 0.7560, Test: 0.7420
Epoch: 96, Loss: 0.0049, Train: 1.0000, Val: 0.7540, Test: 0.7400
Epoch: 97, Loss: 0.0064, Train: 1.0000, Val: 0.7460, Test: 0.7420
Epoch: 98, Loss: 0.0060, Train: 1.0000, Val: 0.7420, Test: 0.7430
Epoch: 99, Loss: 0.0047, Train: 1.0000, Val: 0.7340, Test: 0.7410
Epoch: 100, Loss: 0.0477, Train: 1.0000, Val: 0.7440, Test: 0.7310
MAD:  0.462
Best Test Accuracy: 0.7720, Val Accuracy: 0.7780, Train Accuracy: 1.0000
Training completed.
Seed:  9
PMPGNN(
  (convs): ModuleList(
    (0): ParallelGNNBlock(
      (conv1): GATv2Conv(128, 128, heads=1)
      (conv2): GATv2Conv(128, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (1-5): 5 x ParallelGNNBlock(
      (conv1): GATv2Conv(256, 128, heads=1)
      (conv2): GATv2Conv(256, 128, heads=1)
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (mlp): Sequential(
    (0): Linear(in_features=256, out_features=64, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=64, out_features=3, bias=True)
  )
  (proj): Linear(in_features=500, out_features=128, bias=True)
)
Epoch: 1, Loss: 1.1150, Train: 0.3500, Val: 0.4180, Test: 0.4050
Epoch: 2, Loss: 1.1112, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 3, Loss: 1.1456, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 4, Loss: 1.1195, Train: 0.3333, Val: 0.4160, Test: 0.4070
Epoch: 5, Loss: 1.1221, Train: 0.3500, Val: 0.4160, Test: 0.4160
Epoch: 6, Loss: 1.0948, Train: 0.5833, Val: 0.5240, Test: 0.5790
Epoch: 7, Loss: 1.1199, Train: 0.4667, Val: 0.5140, Test: 0.5350
Epoch: 8, Loss: 1.1427, Train: 0.3500, Val: 0.4180, Test: 0.4480
Epoch: 9, Loss: 1.1109, Train: 0.3333, Val: 0.3960, Test: 0.4230
Epoch: 10, Loss: 1.1258, Train: 0.3500, Val: 0.3940, Test: 0.4270
Epoch: 11, Loss: 1.0960, Train: 0.3833, Val: 0.4040, Test: 0.4400
Epoch: 12, Loss: 1.0550, Train: 0.3833, Val: 0.3960, Test: 0.4330
Epoch: 13, Loss: 1.1083, Train: 0.4667, Val: 0.3940, Test: 0.4370
Epoch: 14, Loss: 1.0642, Train: 0.4833, Val: 0.4260, Test: 0.4590
Epoch: 15, Loss: 1.1020, Train: 0.6000, Val: 0.4840, Test: 0.4910
Epoch: 16, Loss: 1.0865, Train: 0.5667, Val: 0.5120, Test: 0.5120
Epoch: 17, Loss: 1.1094, Train: 0.6000, Val: 0.5160, Test: 0.5160
Epoch: 18, Loss: 1.0913, Train: 0.6000, Val: 0.5180, Test: 0.5080
Epoch: 19, Loss: 1.0838, Train: 0.6167, Val: 0.5140, Test: 0.5060
Epoch: 20, Loss: 1.0887, Train: 0.6333, Val: 0.5700, Test: 0.5620
Epoch: 21, Loss: 1.0748, Train: 0.7167, Val: 0.6440, Test: 0.6350
Epoch: 22, Loss: 1.0454, Train: 0.7500, Val: 0.6720, Test: 0.6620
Epoch: 23, Loss: 1.0460, Train: 0.7667, Val: 0.7000, Test: 0.6730
Epoch: 24, Loss: 1.0357, Train: 0.8000, Val: 0.7240, Test: 0.6960
Epoch: 25, Loss: 1.0328, Train: 0.8333, Val: 0.7320, Test: 0.7150
Epoch: 26, Loss: 0.9633, Train: 0.9000, Val: 0.7240, Test: 0.7180
Epoch: 27, Loss: 0.9809, Train: 0.9000, Val: 0.7280, Test: 0.7020
Epoch: 28, Loss: 0.9972, Train: 0.9000, Val: 0.7360, Test: 0.7040
Epoch: 29, Loss: 0.9215, Train: 0.8833, Val: 0.7300, Test: 0.7020
Epoch: 30, Loss: 0.8735, Train: 0.8833, Val: 0.7200, Test: 0.6940
Epoch: 31, Loss: 0.8998, Train: 0.9167, Val: 0.7260, Test: 0.6840
Epoch: 32, Loss: 0.8199, Train: 0.8833, Val: 0.7060, Test: 0.6770
Epoch: 33, Loss: 0.7896, Train: 0.8833, Val: 0.6980, Test: 0.6720
Epoch: 34, Loss: 0.7569, Train: 0.8833, Val: 0.6920, Test: 0.6700
Epoch: 35, Loss: 0.7422, Train: 0.9167, Val: 0.7260, Test: 0.6710
Epoch: 36, Loss: 0.6823, Train: 0.9000, Val: 0.7340, Test: 0.6880
Epoch: 37, Loss: 0.6958, Train: 0.9167, Val: 0.7440, Test: 0.6970
Epoch: 38, Loss: 0.6390, Train: 0.9167, Val: 0.7480, Test: 0.7080
Epoch: 39, Loss: 0.5561, Train: 0.9333, Val: 0.7520, Test: 0.7230
Epoch: 40, Loss: 0.5340, Train: 0.9333, Val: 0.7580, Test: 0.7280
Epoch: 41, Loss: 0.4766, Train: 0.9500, Val: 0.7620, Test: 0.7300
Epoch: 42, Loss: 0.4239, Train: 0.9500, Val: 0.7620, Test: 0.7340
Epoch: 43, Loss: 0.4364, Train: 0.9500, Val: 0.7780, Test: 0.7350
Epoch: 44, Loss: 0.3998, Train: 0.9500, Val: 0.7760, Test: 0.7360
Epoch: 45, Loss: 0.3402, Train: 0.9500, Val: 0.7620, Test: 0.7280
Epoch: 46, Loss: 0.3530, Train: 0.9500, Val: 0.7480, Test: 0.7170
Epoch: 47, Loss: 0.2881, Train: 0.9500, Val: 0.7440, Test: 0.7190
Epoch: 48, Loss: 0.2819, Train: 0.9667, Val: 0.7660, Test: 0.7400
Epoch: 49, Loss: 0.2333, Train: 0.9833, Val: 0.7820, Test: 0.7520
Epoch: 50, Loss: 0.3105, Train: 0.9833, Val: 0.7520, Test: 0.7330
Epoch: 51, Loss: 0.1973, Train: 0.9833, Val: 0.7600, Test: 0.7310
Epoch: 52, Loss: 0.2076, Train: 0.9833, Val: 0.7840, Test: 0.7560
Epoch: 53, Loss: 0.1220, Train: 1.0000, Val: 0.7780, Test: 0.7740
Epoch: 54, Loss: 0.1014, Train: 1.0000, Val: 0.7700, Test: 0.7450
Epoch: 55, Loss: 0.0967, Train: 1.0000, Val: 0.7580, Test: 0.7280
Epoch: 56, Loss: 0.1208, Train: 1.0000, Val: 0.7660, Test: 0.7350
Epoch: 57, Loss: 0.0898, Train: 1.0000, Val: 0.7780, Test: 0.7590
Epoch: 58, Loss: 0.0613, Train: 1.0000, Val: 0.7940, Test: 0.7740
Epoch: 59, Loss: 0.0729, Train: 0.9833, Val: 0.7780, Test: 0.7660
Epoch: 60, Loss: 0.0587, Train: 0.9833, Val: 0.7780, Test: 0.7620
Epoch: 61, Loss: 0.0541, Train: 1.0000, Val: 0.7780, Test: 0.7600
Epoch: 62, Loss: 0.0970, Train: 1.0000, Val: 0.7840, Test: 0.7700
Epoch: 63, Loss: 0.0300, Train: 1.0000, Val: 0.7680, Test: 0.7490
Epoch: 64, Loss: 0.0268, Train: 0.9833, Val: 0.7560, Test: 0.7260
Epoch: 65, Loss: 0.1109, Train: 1.0000, Val: 0.7560, Test: 0.7280
Epoch: 66, Loss: 0.0307, Train: 1.0000, Val: 0.7700, Test: 0.7370
Epoch: 67, Loss: 0.0413, Train: 1.0000, Val: 0.7720, Test: 0.7520
Epoch: 68, Loss: 0.0197, Train: 1.0000, Val: 0.7840, Test: 0.7710
Epoch: 69, Loss: 0.0885, Train: 1.0000, Val: 0.7800, Test: 0.7710
Epoch: 70, Loss: 0.0143, Train: 1.0000, Val: 0.7840, Test: 0.7750
Epoch: 71, Loss: 0.0333, Train: 1.0000, Val: 0.7820, Test: 0.7730
Epoch: 72, Loss: 0.0159, Train: 1.0000, Val: 0.7860, Test: 0.7670
Epoch: 73, Loss: 0.0512, Train: 1.0000, Val: 0.7760, Test: 0.7580
Epoch: 74, Loss: 0.0117, Train: 0.9833, Val: 0.7540, Test: 0.7260
Epoch: 75, Loss: 0.0166, Train: 0.9833, Val: 0.7280, Test: 0.6810
Epoch: 76, Loss: 0.0243, Train: 1.0000, Val: 0.7200, Test: 0.6950
Epoch: 77, Loss: 0.0175, Train: 1.0000, Val: 0.7460, Test: 0.7110
Epoch: 78, Loss: 0.0169, Train: 1.0000, Val: 0.7780, Test: 0.7450
Epoch: 79, Loss: 0.0097, Train: 1.0000, Val: 0.7740, Test: 0.7530
Epoch: 80, Loss: 0.0234, Train: 1.0000, Val: 0.7680, Test: 0.7540
Epoch: 81, Loss: 0.0102, Train: 1.0000, Val: 0.7740, Test: 0.7540
Epoch: 82, Loss: 0.0111, Train: 1.0000, Val: 0.7660, Test: 0.7510
Epoch: 83, Loss: 0.0123, Train: 1.0000, Val: 0.7700, Test: 0.7570
Epoch: 84, Loss: 0.0115, Train: 1.0000, Val: 0.7740, Test: 0.7520
Epoch: 85, Loss: 0.0104, Train: 1.0000, Val: 0.7800, Test: 0.7540
Epoch: 86, Loss: 0.0116, Train: 1.0000, Val: 0.7800, Test: 0.7530
Epoch: 87, Loss: 0.0075, Train: 1.0000, Val: 0.7820, Test: 0.7570
Epoch: 88, Loss: 0.0059, Train: 1.0000, Val: 0.7820, Test: 0.7590
Epoch: 89, Loss: 0.0201, Train: 1.0000, Val: 0.7740, Test: 0.7630
Epoch: 90, Loss: 0.0045, Train: 1.0000, Val: 0.7640, Test: 0.7600
Epoch: 91, Loss: 0.0080, Train: 1.0000, Val: 0.7600, Test: 0.7540
Epoch: 92, Loss: 0.0068, Train: 1.0000, Val: 0.7640, Test: 0.7520
Epoch: 93, Loss: 0.0039, Train: 1.0000, Val: 0.7640, Test: 0.7430
Epoch: 94, Loss: 0.0091, Train: 1.0000, Val: 0.7640, Test: 0.7380
Epoch: 95, Loss: 0.0054, Train: 1.0000, Val: 0.7480, Test: 0.7360
Epoch: 96, Loss: 0.0122, Train: 1.0000, Val: 0.7520, Test: 0.7370
Epoch: 97, Loss: 0.0057, Train: 1.0000, Val: 0.7560, Test: 0.7390
Epoch: 98, Loss: 0.0071, Train: 1.0000, Val: 0.7580, Test: 0.7400
Epoch: 99, Loss: 0.0081, Train: 1.0000, Val: 0.7600, Test: 0.7410
Epoch: 100, Loss: 0.0069, Train: 1.0000, Val: 0.7660, Test: 0.7460
MAD:  0.5369
Best Test Accuracy: 0.7750, Val Accuracy: 0.7840, Train Accuracy: 1.0000
Training completed.
Average Test Accuracy:  0.7743 ± 0.006649060083951722
Average MAD:  0.49718 ± 0.031470042897968856
